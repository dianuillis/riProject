<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 17.04.2009 00:12:12[mciao0827] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Large Scale Concept Ontology for Multimedia</title>
<id>10045226</id>
<revision>
<id>142420400</id>
<timestamp>2007-07-04T08:25:32Z</timestamp>
<contributor>
<username>Gobonobo</username>
<id>784330</id>
</contributor>
</revision>
<categories>
<category>Multimedia</category>
</categories>
</header>
<bdy>

The <b>Large-Scale Concept Ontology for Multimedia</b> (LSCOM) project was a series of workshops held from April 2004 to September 2006<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref> for the purpose of defining a standard formal vocabulary for the annotation and retrieval of video.  
<sec>
<st>
LSCOM Mandate</st>

<p>

Sponsored by the <administrative_unit wordnetid="108077292" confidence="0.8">
<agency wordnetid="108337324" confidence="0.8">
<link xlink:type="simple" xlink:href="../484/4251484.xml">
Disruptive Technology Office</link></agency>
</administrative_unit>

(DTO), LSCOM brought together representatives from a variety of research communities, such as multimedia learning, information
retrieval, computational linguistics, library science, and knowledge representation, as well as "user" communities such as intelligence agencies and broadcasters, to work collaboratively towards defining a set of 1,000 concepts.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref>. Individually, each concept was to meet the following criteria:<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%223%22])">3</ref></p>
<p>

<list>
<entry level="1" type="bullet">

Utility: the concepts must support realistic video retrieval problems</entry>
<entry level="1" type="bullet">

Feasibility: the concepts are capable or will be capable of detection given the near-term (5 year projected) state of technology</entry>
<entry level="1" type="bullet">

Observibility: the concepts occur with relatively high frequency in actual video data sets</entry>
</list>
</p>
<p>

Jointly, these concepts were to meet the additional criterion of providing broad (domain independent) coverage.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%224%22])">4</ref>  High-level target areas for coverage included physical objects, including animate objects (such as people, mobs, and animals), and inanimate objects, ranging from large-scale (such as buildings and highways) to small-scale (such as telephones and applicances); actions and events; locations and settings; and graphics.  The effort was led by researchers from <university wordnetid="108286163" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../093/48093.xml">
Carnegie Mellon University</link></university>
, <university wordnetid="108286163" confidence="0.9508927676800064">
<ranking wordnetid="114429484" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../310/6310.xml">
Columbia University</link></ranking>
</university>
, and <company wordnetid="108058098" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../259/18622259.xml">
IBM</link></company>
.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%225%22])">5</ref>  </p>

</sec>
<sec>
<st>
LSCOM Development Tracks</st>

<p>

The project had two main "tracks" -- the development and deployment of keyframe annotation tools (performed by CMU and Columbia), and the development of the LSCOM concept hierarchy itself. The second track was executed in two phases: The first consisted in the manual construction of an 884 concept hierarchy, was performed collaboratively among the research and user community representatives.</p>
<p>

The second track, performed by knowledge representation experts at <company wordnetid="108058098" confidence="0.8">
<institution wordnetid="108053576" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/99994.xml">
Cycorp, Inc.</link></institution>
</company>
, involved the mapping of the concepts into the <link xlink:type="simple" xlink:href="../874/6874.xml">
Cyc</link> knowledge base and the use of the Cyc inference engine to semi-automatically refine, correct, and expand the concept hierarchy.
The mapping/expansion phase of the project was motivated by a desire to increase breadth--the mapping had the effect of moving from 884 concepts to well past the initial goal of 1000--and to move LSCOM from a one-dimensional hierarchy of concepts, to a full-blown ontology of rich semantic connections.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref></p>

</sec>
<sec>
<st>
Project Results</st>

<p>

The outputs of the effort include:<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%227%22])">7</ref></p>
<p>

<list>
<entry level="1" type="number">

A "lite" version of the LSCOM concept hierarchy consisting of a subset of 449 concepts.</entry>
<entry level="1" type="number">

A corpus of 61,901 video keyframes, taken from the 2006 TRECVID data set, annotated using LSCOM "lite."</entry>
<entry level="1" type="number">

The full LSCOM taxonomy of 2,638 concepts, built semi-automatically by mapping 884 concepts, manually identified by collaborators, into the Cyc knowledge base, and querying the Cyc inference engine for useful additions.</entry>
<entry level="1" type="number">

The full LSCOM ontology, in the form of a 2006 ResearchCyc release that contains the LSCOM mappings into the Cyc ontology.</entry>
</list>
</p>

</sec>
<sec>
<st>
Use of LSCOM in Larger Research Community</st>

<p>

Since its release, LSCOM has begun to be used successfully in visual recognition research: Apart from research done by LSCOM project
participants, it has been used by independent research in concept extraction from images <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%228%22])">8</ref> <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%229%22])">9</ref>, and has served as the basis for a video annotation tool <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2210%22])">10</ref>.</p>

</sec>
<sec>
<st>
 See also </st>

<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../917/11988917.xml">
Multimedia Web Ontology Language</link> (<link xlink:type="simple" xlink:href="../917/11988917.xml">
MOWL</link>)</entry>
</list>
</p>

</sec>
<sec>
<st>
References</st>
<p>

<reflist>
<entry id="1">
Naphade, <it>et al</it>, "Large Scale Concept Ontology for Multimedia: VACE Workshop Report,"</entry>
<entry id="2">
<it><weblink xlink:type="simple" xlink:href="http://nrrc.mitre.org/NRRC/LSCOM%20Overview.ppt|">
Naphade, <it>et al</it>, "A Large Scale Concept Ontology for Multimedia Understanding," ppt presentation published by <link xlink:type="simple" xlink:href="../752/458752.xml">
MITRE</link></weblink></it></entry>
<entry id="3">
  <it><weblink xlink:type="simple" xlink:href="http://www.ee.columbia.edu/~lyndon/pubs/mm2006-lscom.pdf|">
Naphade, <it>et al.</it>, "Large-Scale Concept Ontology for Multimedia," IEEE MultiMedia, vol. 13, no. 3, pp. 86-91, July-September 2006.</weblink></it></entry>
<entry id="4">
  <it><weblink xlink:type="simple" xlink:href="http://www.ee.columbia.edu/~lyndon/pubs/mm2006-lscom.pdf|">
Naphade, <it>et al.</it>, "Large-Scale Concept Ontology for Multimedia," IEEE MultiMedia, vol. 13, no. 3, pp. 86-91, July-September 2006.</weblink></it></entry>
<entry id="5">
Naphade, <it>et al</it>, "Large Scale Concept Ontology for Multimedia: VACE Workshop Report,"</entry>
<entry id="6">
  <it><weblink xlink:type="simple" xlink:href="http://www.ee.columbia.edu/~lyndon/pubs/mm2006-lscom.pdf|">
Naphade, <it>et al.</it>, "Large-Scale Concept Ontology for Multimedia," IEEE MultiMedia, vol. 13, no. 3, pp. 86-91, July-September 2006.</weblink></it></entry>
<entry id="7">
Naphade, <it>et al</it>, "Large Scale Concept Ontology for Multimedia: VACE Workshop Report,"</entry>
<entry id="8">
<it><weblink xlink:type="simple" xlink:href="http://www.google.com/url?sa=t&amp;ct=res&amp;cd=1&amp;url=http%3A%2F%2Fwww.few.vu.nl%2F~guus%2Fpapers%2FSnoek07a.pdf&amp;ei=A373RfziMaOKjAG8nKzBBg&amp;usg=__cdCfgrpN4UHWSnybSrfKt_rI-Bk=&amp;sig2=UNjhQ4xlxxTju9pIhuGnxA|">
Snoek, <it>et al.</it>, "Adding Semantics to Detectors for Video Retrieval," <it>forthcoming</it> in <it>IEEE Transactions on Multimedia, 2007''</it></weblink></it></entry>
<entry id="9">
 Worring, <it>et al</it>, "The MediaMill Large-lexicon Concept Suggestion Engine," <it>forthcoming, in Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing</it>, Honolulu, Hawaii, USA, April 2007.</entry>
<entry id="10">
<it><weblink xlink:type="simple" xlink:href="http://www.eurecom.fr/util/publidownload.en.htm?file=/homesdocs/publications/htdocs/mm/arnaem-061206.pdf|">
Emilie Garanaud, Smeaton, A., and Koskela, M., "Evaluation of a Video Annotation Tool Based on the LSCOM Ontology,"  in <it>Proceedings of The First International Conference on Semantics And Digital Media Technology</it>, Athens, Greece, 6-8 December 2006.</weblink></it></entry>
</reflist>
</p>


</sec>
</bdy>
</article>
