<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 18:06:57[mciao0826] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<event  confidence="0.8" wordnetid="100029378">
<rule  confidence="0.8" wordnetid="105846932">
<act  confidence="0.8" wordnetid="100030358">
<psychological_feature  confidence="0.8" wordnetid="100023100">
<procedure  confidence="0.8" wordnetid="101023820">
<activity  confidence="0.8" wordnetid="100407535">
<algorithm  confidence="0.8" wordnetid="105847438">
<header>
<title>RANSAC</title>
<id>1089270</id>
<revision>
<id>240257794</id>
<timestamp>2008-09-22T18:07:27Z</timestamp>
<contributor>
<username>Chienloup</username>
<id>848812</id>
</contributor>
</revision>
<categories>
<category>Statistical algorithms</category>
<category>Geometry in computer vision</category>
<category>Robust statistics</category>
</categories>
</header>
<bdy>

<b>RANSAC</b> is an abbreviation for "RANdom SAmple Consensus". It is an <link xlink:type="simple" xlink:href="../237/15237.xml">
iterative method</link> to estimate parameters of a mathematical model from a set of observed data which contains <link xlink:type="simple" xlink:href="../951/160951.xml">
outliers</link>.  It is a non-deterministic algorithm in the sense that it produces a reasonable result only with a certain probability, with this probability increasing as more iterations are allowed.  The algorithm was first published by Fischler and Bolles in 1981.<p>

A basic assumption is that the data consists of "inliers", i.e., data whose distribution can be explained by some set of model parameters, and "outliers" which are data that do not fit the model.  In addition to this, the data can be subject to noise.  The outliers can come, e.g., from extreme values of the noise or from erroneous measurements or incorrect hypotheses about the interpretation of data.  RANSAC also assumes that, given a (usually small) set of inliers, there exists a procedure which can estimate the parameters of a model that optimally explains or fits this data.</p>

<sec>
<st>
 Example </st>

<p>

A simple example is fitting of a 2D line to set of observations.  Assuming that this set contains both inliers, i.e., points which approximately can be fitted to a line, and outliers, points which cannot be fitted to this line, a simple least squares method for line fitting will in general produce a line with a bad fit to the inliers.  The reason is that it is optimally fitted to all points, including the outliers.  RANSAC, on the other hand, can produce a model which is only computed from the inliers, provided that the probability of choosing only inliers in the selection of data is sufficiently high. There is no guarantee for this situation, however, and there are a number of algorithm parameters which must be carefully chosen to keep the level of probability reasonably high.</p>
<p>

<image width="150px" src="Line_with_outliers.svg">
<caption>

A data set with many outliers for which a line has to be fitted.
</caption>
</image>

<image width="150px" src="Fitted_line.svg">
<caption>

Fitted line with RANSAC, outliers have no influence on the result.
</caption>
</image>
</p>


</sec>
<sec>
<st>
Overview</st>
<p>

The input to the RANSAC algorithm is a set of observed data values, a parameterized model which can explain or be fitted to the observations, and some <link xlink:type="simple" xlink:href="../911/280911.xml">
confidence</link> parameters. </p>
<p>

RANSAC achieves its goal by iteratively selecting a random subset of the original data. These data are <it>hypothetical inliers</it> and this hypothesis is then tested as follows:</p>
<p>

<list>
<entry level="1" type="number">

 A model is fitted to the hypothetical inliers, i.e. all free parameters of the model are reconstructed from the data set.</entry>
<entry level="1" type="number">

 All other data are then tested against the fitted model and, if a point fits well to the estimated model, also considered as a hypothetical inlier.</entry>
<entry level="1" type="number">

 The estimated model is reasonably good if sufficiently many points have been classified as hypothetical inliers.</entry>
<entry level="1" type="number">

 The model is reestimated from all hypothetical inliers, because it has only been estimated from the initial set of hypothetical inliers.</entry>
<entry level="1" type="number">

 Finally, the model is evaluated by estimating the error of the inliers relative to the model.</entry>
</list>
</p>
<p>

This procedure is repeated a fixed number of times, each time producing either a model which is rejected because too few points are classified as inliers or a refined model together with a corresponding error measure. In the latter case, we keep the refined model if its error is lower than the last saved model.</p>

</sec>
<sec>
<st>
 The algorithm </st>

<p>

The generic RANSAC algorithm, in <link xlink:type="simple" xlink:href="../185/24185.xml">
pseudocode</link>, works as follows:</p>
<p>

<b>input</b>:
data - a set of observations
model - a model that can be fitted to data 
n - the minimum number of data required to fit the model
k - the maximum number of iterations allowed in the algorithm
t - a threshold value for determining when a <link xlink:type="simple" xlink:href="../040/18985040.xml">
datum</link> fits a model
d - the number of close data values required to assert that a model fits well to data
<b>output</b>:
best_model - model parameters which best fit the data (or nil if no good model is found)
best_consensus_set - data point from which this model has been estimated
best_error - the error of this model relative to the data </p>
<p>

iterations := 0
best_model := nil
best_consensus_set := nil
best_error := infinity
<b>while</b> iterations  k 
maybe_inliers := n randomly selected values from data
maybe_model := model parameters fitted to maybe_inliers
consensus_set := maybe_inliers</p>
<p>

<b>for</b> every point in data <b>not in</b> maybe_inliers 
<b>if</b> point fits maybe_model with an error smaller than t
add point to consensus_set</p>
<p>

<b>if</b> the number of elements in consensus_set is &amp;gt; d 
<it>(this implies that we may have found a good model,</it>
<it>now test how good it is)</it>
better_model := model parameters fitted to all points in consensus_set
this_error := a measure of how well better_model fits these points
<b>if</b> this_error  best_error
<it>(we have found a model which is better than any of the previous ones,</it>
<it>keep it until a better one is found)</it>
best_model := better_model
best_consensus_set := consensus_set
best_error := this_error</p>
<p>

increment iterations</p>
<p>

<b>return</b> best_model, best_consensus_set, best_error</p>
<p>

Possible variants of the RANSAC algorithm includes
<list>
<entry level="1" type="bullet">

 Break the main loop if a sufficiently good model has been found, that is, one with sufficiently small error.  May save some computation time at the expense of an additional parameter.</entry>
<entry level="1" type="bullet">

 Compute this_error directly from maybe_model without re-estimating a model from the consensus set.  May save some time at the expense of comparing errors related to models which are estimated from a small number of points and therefore more sensitive to noise.</entry>
</list>
</p>

</sec>
<sec>
<st>
 The parameters </st>

<p>

The values of parameters <it>t</it> and <it>d</it> have to be determined from specific requirements related to the application and the data set, possibly based on experimental evaluation.  The parameter <it>k</it> (the number of iterations), however, can be determined from a theoretical result.  Let <it>p</it> be the probability that the RANSAC algorithm in some iteration selects only inliers from the input data set when it chooses the <it>n</it> points from which the model parameters are estimated.  When this happens, the resulting model is likely to be useful so <it>p</it> gives the probability that the algorithm produces a useful result.  Let <it>w</it> be the probability of choosing an inlier each time a single point is selected, that is,</p>
<p>

<indent level="1">

</indent>
<it>w</it> = number of inliers in data / number of points in data</p>
<p>

A common case is that <math>w</math> is not well known beforehand, but some rough value can be given.  Assuming that the <it>n</it> points needed for estimating a model are selected independently, <math>w^{n}</math> is the probability that all <it>n</it> points are inliers and <math>1 - w^{n}</math> is the probability that at least one of the <it>n</it> points is an outlier, a case which implies that a bad model will be estimated from this point set.  That probability to the power of <it>k</it> is the probability that the algorithm never selects a set of <it>n</it> points which all are inliers and this must be the same as <math>1 - p</math>.  Consequently,</p>
<p>

<indent level="1">

<math>
1 - p = (1 - w^n)^k
</math>
</indent>

which, after taking the logarithm of both sides, leads to</p>
<p>

<indent level="1">

<math>
k = \frac{\log(1 - p)}{\log(1 - w^n)}
</math>
</indent>

It should be noted that this result assumes that the <it>n</it> data points are selected independently, that is, a point which has been selected once is replaced and can be selected again in the same iteration.  This is often not a reasonable approach and the derived value for <it>k</it> should be taken as an upper limit in the case that the points are selected without replacement.  For example, in the case of finding a line which fits the data set illustrated in the above figure, the RANSAC algorithm typically chooses 2 points in each iteration and computes maybe_model as the line between the points and it is then critical that the two points are distinct.</p>
<p>

To gain additional confidence, the <link xlink:type="simple" xlink:href="../590/27590.xml">
standard deviation</link> or multiples thereof can be added to <math>k</math>. The standard deviation of <math>k</math> is defined as
<indent level="1">

<math>SD(x) = \frac{\sqrt{1 - w^n}}{w^n}</math>
</indent>

</p>
</sec>
<sec>
<st>
 Advantages and disadvantages </st>
<p>

An advantage of RANSAC is its ability to do <link xlink:type="simple" xlink:href="../691/2885691.xml">
robust estimation</link> of the model parameters, i.e., it can estimate the parameters with a high degree of accuracy even when significant amount of <link xlink:type="simple" xlink:href="../951/160951.xml">
outlier</link>s are present in the data set.  A disadvantage of RANSAC is that there is no upper bound on the time it takes to compute these parameters.  When an upper time bound is used (a maximum number of iterations) the solution obtained may not be the most optimal one. Another disadvantage of RANSAC is
that it requires the setting of problem-specific thresholds.</p>
<p>

RANSAC can only estimate one model for a particular data set.  As for any one-model approach when two (or more) models exist, RANSAC may fail to find either one.</p>

</sec>
<sec>
<st>
Applications</st>
<p>

The RANSAC algorithm is often used in <link xlink:type="simple" xlink:href="../596/6596.xml">
computer vision</link>, e.g., to simultaneously solve the <link xlink:type="simple" xlink:href="../435/6498435.xml">
correspondence problem</link> and estimate the <link xlink:type="simple" xlink:href="../730/4486730.xml">
fundamental matrix</link> related to a pair of stereo cameras.</p>

</sec>
<sec>
<st>
References</st>

<p>

<list>
<entry level="1" type="bullet">

  <cite style="font-style:normal">Martin A. Fischler and Robert C. Bolles&#32;(June 1981).&#32;"Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography". <it>Comm. of the ACM</it>&#32;<b>24</b>: 381–395. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1145%2F358669.358692">
10.1145/358669.358692</weblink>.</cite>&nbsp;</entry>
<entry level="1" type="bullet">

 <cite style="font-style:normal" class="book">David A. Forsyth and Jean Ponce&#32;(2003). Computer Vision, a modern approach.&#32;Prentice Hall. ISBN ISBN 0-13-085198-1.</cite>&nbsp;</entry>
<entry level="1" type="bullet">

 <cite style="font-style:normal" class="book">Richard Hartley and Andrew Zisserman&#32;(2003). Multiple View Geometry in Computer Vision, 2nd edition,&#32;Cambridge University Press.</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite style="font-style:normal">P.H.S. Torr, and D.W. Murray&#32;(1997).&#32;"The Development and Comparison of Robust Methods for Estimating the Fundamental Matrix". <it>International Journal of Computer Vision</it>&#32;<b>24</b>: 271–300. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1023%2FA%3A1007927408552">
10.1023/A:1007927408552</weblink>.</cite>&nbsp;</entry>
</list>
</p>

</sec>
<sec>
<st>
External links</st>

<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.mathworks.com/matlabcentral/fileexchange/loadFile.do?objectId=18555&amp;objectType=file">
RANSAC Toolbox for Matlab</weblink>.  A research (and didactic) oriented toolbox to explore the RANSAC algorithm in <link xlink:type="simple" xlink:href="../412/20412.xml">
Matlab</link>.  It is highly configurable and contains the routines to robustly fit homographies and lines.</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://cmp.felk.cvut.cz/ransac-cvpr2006/">
25 Years of RANSAC Workshop</weblink></entry>
</list>
</p>




</sec>
</bdy>
</algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</article>
