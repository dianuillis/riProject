<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 18:06:30[mciao0825] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Approximation theory</title>
<id>1092713</id>
<revision>
<id>243307201</id>
<timestamp>2008-10-06T00:07:45Z</timestamp>
<contributor>
<username>Thijs!bot</username>
<id>1392310</id>
</contributor>
</revision>
<categories>
<category>Numerical analysis</category>
<category>Approximation theory</category>
</categories>
</header>
<bdy>

In <link xlink:type="simple" xlink:href="../831/18831.xml">
mathematics</link>, <b>approximation theory</b> is concerned with how <link xlink:type="simple" xlink:href="../427/185427.xml">
function</link>s can best be <link xlink:type="simple" xlink:href="../271/336271.xml">
approximated</link> with simpler <link xlink:type="simple" xlink:href="../427/185427.xml">
functions</link>, and with <link xlink:type="simple" xlink:href="../437/861437.xml">
quantitative</link>ly <link xlink:type="simple" xlink:href="../886/780886.xml">
characterizing</link> the <link xlink:type="simple" xlink:href="../422/640422.xml">
errors</link> introduced thereby. Note that what is meant by <it>best</it> and <it>simpler</it> will depend on the application.<p>

A closely related topic is the approximation of functions by <link xlink:type="simple" xlink:href="../530/245530.xml">
generalized Fourier series</link>, that is, approximations based upon summation of a series of terms based upon <link xlink:type="simple" xlink:href="../568/336568.xml">
orthogonal polynomials</link>.</p>
<p>

One problem of particular interest is that of approximating a function in a <link xlink:type="simple" xlink:href="../457/7878457.xml">
computer</link>
mathematical library, using operations that can be performed on the computer or calculator (e.g. addition
and multiplication), such that the result is as close to the actual function as
possible.  This is typically done with <link xlink:type="simple" xlink:href="../000/23000.xml">
polynomial</link> or <assortment wordnetid="108398773" confidence="0.8">
<collection wordnetid="107951464" confidence="0.8">
<group wordnetid="100031264" confidence="0.8">
<link xlink:type="simple" xlink:href="../210/361210.xml">
rational</link></group>
</collection>
</assortment>
 (ratio of polynomials) approximations.</p>
<p>

The objective is to make the approximation as close as possible to the actual function,
typically with an accuracy close to that of the underlying computer's <link xlink:type="simple" xlink:href="../376/11376.xml">
floating point</link>
arithmetic.  This is accomplished by using a polynomial of high degree, and/or narrowing
the domain over which the polynomial has to approximate the function.
Narrowing the domain can often be done though the use of various addition or scaling
formulas for the function being approximated.  Modern mathematical libraries often reduce
the domain into many tiny segments and use a low-degree polynomial for each segment.</p>
<p>

Once the domain and degree of the polynomial are chosen, the polynomial itself is chosen
in such a way as to minimize the worst-case error.  That is, the goal is to minimize
the maximum value of <math>\mid P(x)-f(x)\mid</math>, where P(x) is the approximating polynomial
and f(x) is the actual function.  For well-behaved functions, the optimum Nth
degree polynomial will lead to an error curve that oscillates back and forth between
<math>+\epsilon</math> and <math>-\epsilon</math> a total of N+2 times, giving a
worst-case error of <math>\epsilon</math>.  (It is possible to make contrived functions f(x)
for which this property does not hold, but in practice it is generally true.)  Example graphs,
for N=4, showing the error in approximating log(x) and exp(x), are shown below.</p>
<p>

<image location="left" width="300px" src="Logerror.png" type="thumb">
<caption>

Error between optimal polynomial and log(x) (red), and Chebyshev approximation and log(x) (blue) over the interval [2, 4].  Vertical divisions are 10-5.  Maximum error for the optimal polynomial is 6.07 x 10-5
</caption>
</image>
</p>
<p>

<image location="center" width="300px" src="Experror.png" type="thumb">
<caption>

Error between optimal polynomial and exp(x) (red), and Chebyshev approximation and exp(x) (blue) over the interval [-1, 1].  Vertical divisions are 10-4.  Maximum error for the optimal polynomial is 5.47 x 10-4
</caption>
</image>
</p>
<p>

Note that, in each case, the number of maxima is N+2, that is, 6.  Two of the maxima are
at the end points.  The red curves, for the optimal polynomial, are <b>level</b>, that is,
they oscillate between <math>+\epsilon</math> and <math>-\epsilon</math> exactly.</p>
<p>

If an Nth degree polynomial leads to an error function that oscillates between
maxima at <math>+\epsilon</math> and <math>-\epsilon</math> N+2 times, that polynomial is
optimal.     <link xlink:type="simple" xlink:href="../947/4558947.xml">
(proof)</link></p>

<sec>
<st>
Chebyshev approximation</st>
<p>

One can obtain polynomials very close to the optimal one by expanding the given function
in terms of <mathematical_relation wordnetid="113783581" confidence="0.8">
<polynomial wordnetid="105861855" confidence="0.8">
<function wordnetid="113783816" confidence="0.8">
<link xlink:type="simple" xlink:href="../539/184539.xml">
Chebyshev polynomials</link></function>
</polynomial>
</mathematical_relation>
 and then cutting off the expansion at the desired degree.
This is similar to the <link xlink:type="simple" xlink:href="../147/14147.xml">
Fourier analysis</link> of the function, using the Chebyshev polynomials instead of the usual trigonometric functions.</p>
<p>

If one calculates the coefficients in the Chebyshev expansion for a function:</p>
<p>

<indent level="1">

<math>f(x) \sim \sum_{i=0}^\infty c_i T_i(x)</math>
</indent>

and then cuts off the series after the <math>T_n</math> term, one gets an Nth degree polynomial
approximating f(x).</p>
<p>

The reason this polynomial is nearly optimal is that, for functions with rapidly converging
power series, if the series is cut off after some term, the total error
arising from the cutoff is close to the first term after the cutoff.  That is, the first
term after the cutoff dominates all later terms.  The same is true if the expansion is in terms
of Chebyshev polynomials.  If a Chebyshev expansion is cut off after <math>T_n</math>, the
error will take a form close to a multiple of <math>T_{n+1}</math>.  The Chebyshev polynomials have the
property that they are level &mdash; they oscillate between +1 and -1 in the interval [-1, 1].
<math>T_{n+1}</math> has N+2 level maxima.  This means that the error between f(x) and
its Chebyshev expansion out to <math>T_n</math> is close to a level function with N+2
maxima, so it is close to the optimal Nth degree polynomial.</p>
<p>

In the graphs above, note that the blue error function is sometimes better than (inside of)
the red function, but sometimes worse, meaning that it is not quite the optimal
polynomial.  Note also that the discrepancy is relatively less serious for the
exp function, which has an extremely rapidly converging power series, than for the log function.</p>
<p>

Chebyshev approximation is the basis for <link>
Clenshawâ€“Curtis quadrature</link>, a <link xlink:type="simple" xlink:href="../089/170089.xml">
numerical integration</link> technique.</p>

</sec>
<sec>
<st>
Remez' algorithm</st>

<p>

The <link xlink:type="simple" xlink:href="../514/4882514.xml">
Remez algorithm</link> (sometimes spelled Remes) is used to produce an optimal polynomial P(x) approximating a given function f(x)
over a given interval.  It is an iterative algorithm that converges to a polynomial that has an error function with N+2 level extrema.  By the theorem above, that polynomial is optimal.</p>
<p>

Remez' algorithm uses the fact that one can construct an Nth degree polynomial that leads to level and alternating error values, given N+2 test points.</p>
<p>

Given N+2 test points <math>x_1</math>, <math>x_2</math> ... <math>x_{n+2}</math> (where
<math>x_1</math> and <math>x_{n+2}</math> are presumably the end points of the interval
of approximation), these equations need to be solved:</p>
<p>

<indent level="1">

<math>P(x_1) - f(x_1) = + \epsilon\,</math>
</indent>
:<math>P(x_2) - f(x_2) = - \epsilon\,</math>
<indent level="1">

<math>P(x_3) - f(x_3) = + \epsilon\,</math>
</indent>
:<math>\vdots</math>
<indent level="1">

<math>P(x_{n+2}) - f(x_{n+2}) = \pm \epsilon.\,</math> 
</indent>

The right-hand-sides alternate in sign.</p>
<p>

That is,</p>
<p>

<indent level="1">

<math>P_0 + P_1 x_1 + P_2 x_1^2 + P_3 x_1^3 ... P_n x_1^n - f(x_1) = + \epsilon\,</math>
</indent>
:<math>P_0 + P_1 x_2 + P_2 x_2^2 + P_3 x_2^3 ... P_n x_2^n - f(x_2) = - \epsilon\,</math>
<indent level="1">

<math>\vdots</math>
</indent>

Since <math>x_1</math> ... <math>x_{n+2}</math> were given, all of their powers are known,
and <math>f(x_1)</math> ... <math>f(x_{n+2})</math> are also known.  That means that the
above equations are just n+2 linear equations in the n+2 variables <math>P_0</math>,
<math>P_1</math> ... <math>P_n</math>, and <math>\epsilon</math>.  Given the test
points <math>x_1</math> ... <math>x_{n+2}</math>, one can solve this system to get the polynomial P
and the number <math>\epsilon</math>.</p>
<p>

The graph below shows an example of this, producing a 4th degree polynomial
approximating <math>e^x</math> over [-1, 1].  The test points were set at
-1, -0.7, -0.1, +0.4, +0.9, and 1.  Those values are shown in green.  The resultant
value of <math>\epsilon</math> is 4.43 x 10-4</p>
<p>

<image location="center" width="300px" src="Remesdemo.png" type="thumb">
<caption>

Error of the polynomial produced by the first step of Remez' algorithm, approximating ex over the interval [-1, 1].  Vertical divisions are 10-4.
</caption>
</image>
</p>
<p>

Note that the error graph does indeed take on the values <math>\pm \epsilon</math> at
the 6 test points, including the end points, but that those points are not extrema.  If the 4 interior test points had been
extrema (that is, the function P(x)-f(x) had maxima or minima there), the polynomial would be
optimal.</p>
<p>

The second step of Remez' algorithm consists of moving the test points to the approximate
locations where the error function had its actual local minima or maxima.  For example, one can tell from looking at the graph that the point at -0.1 should have been at about -0.28.
The way to do this in the algorithm is to use a single round of
<event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../145/22145.xml">
Newton's method</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
.  Since one knows
the first and second derivatives of P(x)-f(x), one can calculate approximately how far a test point
has to be moved so that the derivative will be zero.</p>
<p>

<indent level="1">

Calculating the derivatives of a polynomial is straightforward.  One must also be able to calculate the first and second derivatives of f(x).  Remez' algorithm requires an ability to calculate <math>f(x)\,</math>, <math>f'(x)\,</math>, and <math>f''(x)\,</math> to extremely high precision.  The entire algorithm must be carried out to higher precision than the desired precision of the result.
</indent>

After moving the test points, the linear equation part is repeated, getting a new polynomial,
and Newton's method is used again to move the test points again.  This sequence is continued
until the result converges to the desired accuracy.  The algorithm converges very rapidly.
Convergence is quadratic for well-behaved functions&mdash;if the test points are within <math>10^{-15}</math> of the correct result, they will be approximately within
<math>10^{-30}</math> of the correct result after the next round.</p>
<p>

Remez' algorithm is typically started by choosing the maxima of the Chebyshev polynomial
<math>T_n</math> as the initial points, since the final error function will be similar to
that polynomial.</p>

</sec>
<sec>
<st>
Main journals</st>

<p>

<list>
<entry level="1" type="bullet">

 <periodical wordnetid="106593296" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../430/10986430.xml">
Journal of Approximation Theory</link></periodical>
</entry>
<entry level="1" type="bullet">

 <periodical wordnetid="106593296" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../233/10986233.xml">
Constructive Approximation</link></periodical>
</entry>
<entry level="1" type="bullet">

 <periodical wordnetid="106593296" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../849/10986849.xml">
East Journal on Approximations</link></periodical>
</entry>
</list>
</p>

</sec>
<sec>
<st>
See also</st>
<p>

<list>
<entry level="1" type="bullet">

<mathematical_relation wordnetid="113783581" confidence="0.8">
<polynomial wordnetid="105861855" confidence="0.8">
<function wordnetid="113783816" confidence="0.8">
<link xlink:type="simple" xlink:href="../539/184539.xml">
Chebyshev polynomials</link></function>
</polynomial>
</mathematical_relation>
</entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../530/245530.xml">
Generalized Fourier series</link></entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../568/336568.xml">
Orthogonal polynomials</link></entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../063/195063.xml">
Orthonormal basis</link></entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../038/59038.xml">
Fourier series</link></entry>
<entry level="1" type="bullet">

<space wordnetid="100028651" confidence="0.8">
<link xlink:type="simple" xlink:href="../662/3460662.xml">
Schauder basis</link></space>
</entry>
<entry level="1" type="bullet">

<link>
PadÃ© approximant</link></entry>
</list>
</p>

</sec>
<sec>
<st>
Links</st>
<p>

<list>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.math.technion.ac.il/hat/">
History of Approximation Theory (HAT)</weblink></entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.emis.de/journals/SAT/">
Surveys in Approximation Theory (SAT)</weblink></entry>
</list>
</p>

</sec>
<sec>
<st>
References</st>

<p>

<list>
<entry level="1" type="bullet">

 N.I.Achiezer (Akhiezer), Theory of approximation, Translated by Charles J. Hyman Frederick Ungar Publishing Co., New York 1956 x+307 pp.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 A.F.Timan, <it>Theory of approximation of functions of a real variable</it>, 1963 ISBN 048667830X</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 C. Hastings, Jr. <it>Approximations for Digital Computers,</it> Princeton University Press, 1955.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 J. F. Hart, E. W. Cheney, C. L. Lawson, H. J. Maehly, C. K. Mesztenyi, J. R. Rice, H. C. Thacher Jr., C. Witzgall  <it>Computer Approximations,</it> Wiley, 1968, Lib. Cong. 67-23326.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 L. Fox and I.B. Parker. "Chebyshev Polynomials in Numerical Analysis." Oxford University Press London, 1968.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 W. J. Cody Jr., W. Waite <it>Software Manual for the Elementary Functions,</it> Prentice-Hall, 1980, ISBN 0-13-822064-6.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 E. Remes [Remez] <it>Sur le calcul effectif des polynomes d'approximation de Tschebyscheff</it> 1934 C. R. Acad. Sci., Paris, <b>199</b>, 337-340,</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 K.-G. Steffens <it>The History of Approximation Theory: From Euler to Bernstein</it> Birkhauser, Boston 2006 ISBN 0817643532 </entry>
</list>
</p>


</sec>
</bdy>
</article>
