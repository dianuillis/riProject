<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 15:21:57[mciao0826] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Artificial intelligence</title>
<id>1164</id>
<revision>
<id>244428134</id>
<timestamp>2008-10-10T19:23:02Z</timestamp>
<contributor>
<username>Necz0r</username>
<id>6380013</id>
</contributor>
</revision>
<categories>
<category>All pages needing cleanup</category>
<category>Artificial intelligence</category>
<category>Articles with disputed statements from April 2008</category>
<category>Technology in society</category>
<category>Wikipedia external links cleanup</category>
<category>Articles with invalid date parameter in template</category>
<category>Formal sciences</category>
<category>Cybernetics</category>
<category>Intelligence by type</category>
<category>History of technology</category>
</categories>
</header>
<bdy>

"AI" redirects here. For the other uses, see <link xlink:type="simple" xlink:href="../846/2846.xml">
AI (disambiguation)</link>.
<b>Artificial intelligence</b> (<b>AI</b>) is the <link xlink:type="simple" xlink:href="../280/519280.xml">
intelligence</link> of <link xlink:type="simple" xlink:href="../462/51462.xml">
machines</link> and the branch of <link xlink:type="simple" xlink:href="../323/5323.xml">
computer science</link> which aims to create it.<p>

Major AI textbooks define the field as "the study and design of <link xlink:type="simple" xlink:href="../317/2711317.xml">
intelligent agents</link>,"<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref>
where an <link xlink:type="simple" xlink:href="../317/2711317.xml">
intelligent agent</link> is a system that perceives its environment and takes actions which maximize its chances of success.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref>
<person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../362/308362.xml">
John McCarthy</link></scientist>
</person>
, who coined the term in 1956,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%223%22])">3</ref>
defines it as "the science and engineering of making intelligent machines."<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%224%22])">4</ref></p>
<p>

Among the traits that researchers hope machines will exhibit are <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Deduction=2C+reasoning=2C+problem+solving%22])">
reasoning</link>, <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Knowledge+representation%22])">
knowledge</link>, <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Planning%22])">
planning</link>, <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Learning%22])">
learning</link>, <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Natural+language+processing%22])">
communication</link>, <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Perception%22])">
perception</link> and the ability to <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Motion+and+manipulation%22])">
move</link> and manipulate objects.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%225%22])">5</ref>
<link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22General+intelligence%22])">
General intelligence</link> (or "<link xlink:type="simple" xlink:href="../357/586357.xml">
strong AI</link>") has not yet been achieved and is a long-term goal of some AI research.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref></p>
<p>

AI research uses tools and insights from many fields, including <link xlink:type="simple" xlink:href="../323/5323.xml">
computer science</link>, <link xlink:type="simple" xlink:href="../921/22921.xml">
psychology</link>, <link xlink:type="simple" xlink:href="../155/13692155.xml">
philosophy</link>, <link xlink:type="simple" xlink:href="../245/21245.xml">
neuroscience</link>, <link xlink:type="simple" xlink:href="../626/5626.xml">
cognitive science</link>, <link xlink:type="simple" xlink:href="../561/5561.xml">
linguistics</link>, <link xlink:type="simple" xlink:href="../681/49681.xml">
ontology</link>, <link xlink:type="simple" xlink:href="../476/43476.xml">
operations research</link>, <link xlink:type="simple" xlink:href="../447/1420447.xml">
economics</link>, <link xlink:type="simple" xlink:href="../039/7039.xml">
control theory</link>, <link xlink:type="simple" xlink:href="../934/22934.xml">
probability</link>, <link xlink:type="simple" xlink:href="../033/52033.xml">
optimization</link> and <link xlink:type="simple" xlink:href="../225/3729225.xml">
logic</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%227%22])">7</ref>
AI research also overlaps with tasks such as <link xlink:type="simple" xlink:href="../673/46673.xml">
robotics</link>, <link xlink:type="simple" xlink:href="../473/275473.xml">
control system</link>s, <link xlink:type="simple" xlink:href="../641/1505641.xml">
scheduling</link>, <link xlink:type="simple" xlink:href="../253/42253.xml">
data mining</link>, <link xlink:type="simple" xlink:href="../547/77547.xml">
logistics</link>, <link xlink:type="simple" xlink:href="../468/29468.xml">
speech recognition</link>, <link xlink:type="simple" xlink:href="../401/602401.xml">
facial recognition</link> and many others.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%228%22])">8</ref></p>
<p>

Other names for the field have been proposed, such as <link xlink:type="simple" xlink:href="../306/1563306.xml">
computational intelligence</link>,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%229%22])">9</ref>
<link xlink:type="simple" xlink:href="../050/2548050.xml">
synthetic intelligence</link>,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%229%22])">9</ref>
<link xlink:type="simple" xlink:href="../877/3054877.xml">
intelligent systems</link>,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2210%22])">10</ref>
or computational rationality.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2211%22])">11</ref>
These alternative names are sometimes used to set oneself apart from the part of AI dealing with symbols (considered outdated by many, see <link xlink:type="simple" xlink:href="../417/339417.xml">
GOFAI</link>) which is often associated with the term “AI” itself.</p>

<p>

<table style="background:#f9f9f9; font-size:85%; line-height:110%; ">
<row>
<col>
 <image width="32x28px" src="Portal.svg">
</image>
</col>
<col style="padding:0 0.2em;">
 <b><it>
Artificial intelligence&#32;portal</it></b></col>
</row>
</table>
</p>


<sec>
<st>
 Perspectives on AI </st>

<ss1>
<st>
 AI in myth, fiction and speculation </st>

<p>

<indent level="1">

<it>Main articles: <link xlink:type="simple" xlink:href="../227/11746227.xml">
artificial intelligence in fiction</link>,&#32;<link xlink:type="simple" xlink:href="../583/13659583.xml">
ethics of artificial intelligence</link>,&#32;<link xlink:type="simple" xlink:href="../299/30299.xml">
transhumanism</link>,&#32;and&#32;<process wordnetid="105701363" confidence="0.8">
<thinking wordnetid="105770926" confidence="0.8">
<explanation wordnetid="105793000" confidence="0.8">
<theory wordnetid="105989479" confidence="0.8">
<higher_cognitive_process wordnetid="105770664" confidence="0.8">
<link xlink:type="simple" xlink:href="../245/54245.xml">
Technological singularity</link></higher_cognitive_process>
</theory>
</explanation>
</thinking>
</process>
</it>
</indent>
</p>
<p>

Thinking machines and artificial beings appear in <link xlink:type="simple" xlink:href="../961/11961.xml">
Greek myth</link>s, such as <animal wordnetid="100015388" confidence="0.8">
<link xlink:type="simple" xlink:href="../105/81105.xml">
Talos</link></animal>
 of <land wordnetid="109334396" confidence="0.8">
<island wordnetid="109316454" confidence="0.8">
<link xlink:type="simple" xlink:href="../591/6591.xml">
Crete</link></island>
</land>
, the golden robots of <deity wordnetid="109505418" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../388/14388.xml">
Hephaestus</link></deity>
 and <link xlink:type="simple" xlink:href="../085/1869085.xml">
Pygmalion's</link> <link xlink:type="simple" xlink:href="../817/839817.xml">
Galatea</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2212%22])">12</ref>
Human likenesses believed to have intelligence were built in every civilization, beginning with the <link xlink:type="simple" xlink:href="../174/3731174.xml">
sacred statue</link>s worshipped in <country wordnetid="108544813" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../628/8087628.xml">
Egypt</link></country>
 and <country wordnetid="108544813" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../108/12108.xml">
Greece</link></country>
,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2213%22])">13</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2214%22])">14</ref> 
and including the machines of <sovereign wordnetid="110628644" confidence="0.8">
<physical_entity wordnetid="100001930" confidence="0.8">
<representative wordnetid="110522035" confidence="0.8">
<communicator wordnetid="109610660" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<king wordnetid="110231515" confidence="0.8">
<head_of_state wordnetid="110164747" confidence="0.8">
<ruler wordnetid="110541229" confidence="0.8">
<negotiator wordnetid="110351874" confidence="0.8">
<link xlink:type="simple" xlink:href="../839/326839.xml#xpointer(//*[./st=%22Robotics%22])">
Yan Shi</link></negotiator>
</ruler>
</head_of_state>
</king>
</causal_agent>
</person>
</communicator>
</representative>
</physical_entity>
</sovereign>
,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2215%22])">15</ref>
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../274/68274.xml">
Hero of Alexandria</link></scientist>
,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2216%22])">16</ref>
<link xlink:type="simple" xlink:href="../981/271981.xml">
Al-Jazari</link><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2217%22])">17</ref>
or <physical_entity wordnetid="100001930" confidence="0.8">
<automaton wordnetid="109825519" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<inventor wordnetid="110214637" confidence="0.8">
<anomaly wordnetid="109606527" confidence="0.8">
<creator wordnetid="109614315" confidence="0.8">
<link xlink:type="simple" xlink:href="../100/1144100.xml">
Wolfgang von Kempelen</link></creator>
</anomaly>
</inventor>
</scientist>
</causal_agent>
</person>
</automaton>
</physical_entity>
.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2218%22])">18</ref>
It was widely believed that artificial beings had been created by <scholar wordnetid="110557854" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../140/63140.xml">
Geber</link></scholar>
,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2219%22])">19</ref>
<link xlink:type="simple" xlink:href="../031/176031.xml">
Judah Loew</link><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2220%22])">20</ref>
and <person wordnetid="100007846" confidence="0.9508927676800064">
<occultist wordnetid="110370381" confidence="0.9173553029164789">
<astrologer wordnetid="109817816" confidence="0.9173553029164789">
<doctor wordnetid="110020890" confidence="0.9173553029164789">
<link xlink:type="simple" xlink:href="../487/152487.xml">
Paracelsus</link></doctor>
</astrologer>
</occultist>
</person>
.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2221%22])">21</ref> Stories of these creatures and their fates discuss many of the same hopes, fears and <link xlink:type="simple" xlink:href="../583/13659583.xml">
ethical</link> concerns that are presented by artificial intelligence.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2222%22])">22</ref></p>

<p>

<person wordnetid="100007846" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../832/19832.xml">
Mary Shelley</link></person>
's <it><literary_composition wordnetid="106364329" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<fiction wordnetid="106367107" confidence="0.8">
<novel wordnetid="106367879" confidence="0.8">
<link xlink:type="simple" xlink:href="../673/18580673.xml">
Frankenstein</link></novel>
</fiction>
</writing>
</written_communication>
</literary_composition>
</it>,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2223%22])">23</ref> considers a key issue in the <link xlink:type="simple" xlink:href="../583/13659583.xml">
ethics of artificial intelligence</link>: if a machine can be created that has intelligence, could it also <it>feel</it>?  If it can feel, does it have the same rights as a human being? The idea also appears in modern <link xlink:type="simple" xlink:href="../787/26787.xml">
science fiction</link>: the film  considers a machine in the form of a small boy which has been given the ability to feel human emotions, including, tragically, the capacity to suffer. This issue, now known as "<link xlink:type="simple" xlink:href="../583/13659583.xml">
robot rights</link>", is currently being considered by, for example, California's <think_tank wordnetid="108478702" confidence="0.8">
<company wordnetid="108058098" confidence="0.8">
<institution wordnetid="108053576" confidence="0.8">
<link xlink:type="simple" xlink:href="../747/5539747.xml">
Institute for the Future</link></institution>
</company>
</think_tank>
,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2224%22])">24</ref>
although many critics believe that the discussion is premature.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2225%22])">25</ref></p>

<p>

Another issue explored by both <link xlink:type="simple" xlink:href="../787/26787.xml">
science fiction</link> writers and <link xlink:type="simple" xlink:href="../661/1286661.xml">
futurist</link>s is the impact of artificial intelligence on society. In fiction, AI has appeared as a servant (<link xlink:type="simple" xlink:href="../166/63166.xml">
R2D2</link> in <it><product wordnetid="104007894" confidence="0.8">
<creation wordnetid="103129123" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<social_event wordnetid="107288639" confidence="0.8">
<movie wordnetid="106613686" confidence="0.8">
<show wordnetid="106619065" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<link xlink:type="simple" xlink:href="../678/26678.xml">
Star Wars</link></psychological_feature>
</show>
</movie>
</social_event>
</event>
</artifact>
</creation>
</product>
</it>), a comrade (<fictional_character wordnetid="109587565" confidence="0.8">
<imaginary_being wordnetid="109483738" confidence="0.8">
<intelligence wordnetid="105617606" confidence="0.8">
<link xlink:type="simple" xlink:href="../676/47676.xml">
Lt. Commander Data</link></intelligence>
</imaginary_being>
</fictional_character>
 in <it><dish wordnetid="107557434" confidence="0.8">
<music wordnetid="107020895" confidence="0.8">
<music_genre wordnetid="107071942" confidence="0.8">
<snack_food wordnetid="107712382" confidence="0.8">
<classical_music wordnetid="107025900" confidence="0.8">
<substance wordnetid="100020090" confidence="0.8">
<sandwich wordnetid="107695965" confidence="0.8">
<auditory_communication wordnetid="107109019" confidence="0.8">
<food wordnetid="100021265" confidence="0.8">
<opera wordnetid="107026352" confidence="0.8">
<western wordnetid="107698672" confidence="0.8">
<nutriment wordnetid="107570720" confidence="0.8">
<expressive_style wordnetid="107066659" confidence="0.8">
<link xlink:type="simple" xlink:href="../886/17157886.xml">
Star Trek</link></expressive_style>
</nutriment>
</western>
</opera>
</food>
</auditory_communication>
</sandwich>
</substance>
</classical_music>
</snack_food>
</music_genre>
</music>
</dish>
</it>), an extension to human abilities (<it><link xlink:type="simple" xlink:href="../914/12914.xml">
Ghost in the Shell</link></it>), a conqueror (<it><movie wordnetid="106613686" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../007/30007.xml">
The Matrix</link></movie>
</it>), a dictator (<it><message wordnetid="106598915" confidence="0.8">
<narrative wordnetid="107221094" confidence="0.8">
<link xlink:type="simple" xlink:href="../537/12791537.xml">
With Folded Hands</link></narrative>
</message>
</it>), an exterminator (<it><link xlink:type="simple" xlink:href="../363/246363.xml">
Terminator</link></it>, <it><link xlink:type="simple" xlink:href="../923/488923.xml">
Battlestar Galactica</link></it>) and a race (<link xlink:type="simple" xlink:href="../024/6446024.xml">
Asurans</link> in "<series wordnetid="108457976" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../894/418894.xml">
Stargate Atlantis</link></series>
"). Academic sources have considered such consequences as: a decreased demand for human labor;<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2226%22])">26</ref>
the enhancement of human ability or experience;<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2227%22])">27</ref>
and a need for redefinition of human identity and basic values.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2228%22])">28</ref></p>

<p>

Several <link xlink:type="simple" xlink:href="../661/1286661.xml">
futurist</link>s argue that artificial intelligence will transcend the limits of progress and fundamentally transform humanity. <link xlink:type="simple" xlink:href="../984/25984.xml">
Ray Kurzweil</link> has used <link xlink:type="simple" xlink:href="../418/39418.xml">
Moore's law</link> (which describes the relentless exponential improvement in digital technology with uncanny accuracy) to calculate that <link xlink:type="simple" xlink:href="../742/52742.xml">
desktop computer</link>s will have the same processing power as human brains by the year 2029, and that by 2045 artificial intelligence will reach a point where it is able to improve <it>itself</it> at a rate that far exceeds anything conceivable in the past, a scenario that <link xlink:type="simple" xlink:href="../787/26787.xml">
science fiction</link> writer <person wordnetid="100007846" confidence="0.9508927676800064">
<writer wordnetid="110794014" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../493/32493.xml">
Vernor Vinge</link></writer>
</person>
 named the "<link xlink:type="simple" xlink:href="../245/54245.xml">
technological singularity</link>".<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2227%22])">27</ref>
<person wordnetid="100007846" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../515/405515.xml">
Edward Fredkin</link></person>
 argues that "artificial intelligence is the next stage in evolution,"<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2229%22])">29</ref> an idea first proposed by <writer wordnetid="110794014" confidence="0.9173553029164789">
<novelist wordnetid="110363573" confidence="0.9173553029164789">
<link xlink:type="simple" xlink:href="../519/937519.xml">
Samuel Butler</link></novelist>
</writer>
's <it><link xlink:type="simple" xlink:href="../221/15938221.xml">
Darwin Among the Machines</link></it> (1863), and expanded upon by <physical_entity wordnetid="100001930" confidence="0.8">
<communicator wordnetid="109610660" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<intellectual wordnetid="109621545" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<writer wordnetid="110794014" confidence="0.8">
<historian wordnetid="110177150" confidence="0.8">
<scholar wordnetid="110557854" confidence="0.8">
<link xlink:type="simple" xlink:href="../616/2293616.xml">
George Dyson</link></scholar>
</historian>
</writer>
</causal_agent>
</intellectual>
</person>
</communicator>
</physical_entity>
 in his book of the same name in 1998. 
Several <link xlink:type="simple" xlink:href="../661/1286661.xml">
futurist</link>s and <link xlink:type="simple" xlink:href="../787/26787.xml">
science fiction</link> writers have predicted that human beings and machines will merge in the future into <link xlink:type="simple" xlink:href="../838/6838.xml">
cyborg</link>s that are more capable and powerful than either. This idea, called <link xlink:type="simple" xlink:href="../299/30299.xml">
transhumanism</link>, which has roots in <person wordnetid="100007846" confidence="0.9508927676800064">
<writer wordnetid="110794014" confidence="0.9173553029164789">
<link xlink:type="simple" xlink:href="../628/628.xml">
Aldous Huxley</link></writer>
</person>
 and <link xlink:type="simple" xlink:href="../114/525114.xml">
Robert Ettinger</link>, is now associated with robot designer <link xlink:type="simple" xlink:href="../556/298556.xml">
Hans Moravec</link>, cyberneticist <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9173553029164789">
<link xlink:type="simple" xlink:href="../453/17453.xml">
Kevin Warwick</link></scientist>
</person>
 and inventor <link xlink:type="simple" xlink:href="../984/25984.xml">
Ray Kurzweil</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2227%22])">27</ref> <link xlink:type="simple" xlink:href="../299/30299.xml">
Transhumanism</link> has been illustrated in fiction as well, for example on the <link xlink:type="simple" xlink:href="../985/18985.xml">
manga</link> <it><link xlink:type="simple" xlink:href="../914/12914.xml">
Ghost in the Shell</link></it>. Pamela McCorduck believes that these scenarios are expressions of an ancient human desire to, as she calls it, "forge the gods."<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2222%22])">22</ref></p>

</ss1>
<ss1>
<st>
 History of AI research </st>


<p>

<indent level="1">

<it>Main articles: <link xlink:type="simple" xlink:href="../560/2894560.xml">
history of artificial intelligence</link>&#32;and&#32;<link xlink:type="simple" xlink:href="../470/12413470.xml">
timeline of artificial intelligence</link></it>
</indent>

In the middle of the 20th century, a handful of scientists began a new approach to building intelligent machines, based on recent discoveries in <link xlink:type="simple" xlink:href="../226/21226.xml">
neurology</link>, a new mathematical theory of <link xlink:type="simple" xlink:href="../062/18985062.xml">
information</link>, an understanding of control and stability called <link xlink:type="simple" xlink:href="../904/5904.xml">
cybernetic</link>s, and above all, by the invention of the <link xlink:type="simple" xlink:href="../457/7878457.xml">
digital computer</link>, a machine based on the abstract essence of mathematical reasoning.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2230%22])">30</ref></p>
<p>

The field of modern AI research was founded at a conference on the campus of <university wordnetid="108286163" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../418/8418.xml">
Dartmouth College</link></university>
 in the summer of 1956.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2231%22])">31</ref>
Those who attended would become the leaders of AI research for many decades, especially <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../362/308362.xml">
John McCarthy</link></scientist>
</person>
, <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../639/19639.xml">
Marvin Minsky</link></scientist>
</person>
, <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../300/287300.xml">
Allen Newell</link></scientist>
</person>
 and <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../205/14205.xml">
Herbert Simon</link></scientist>
</person>
, who founded AI laboratories at <link xlink:type="simple" xlink:href="../061/19061.xml">
MIT</link>, <university wordnetid="108286163" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../093/48093.xml">
CMU</link></university>
 and <link>
Stanford</link>. They and their students wrote programs that were, to most people, simply astonishing:<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2232%22])">32</ref>
computers were solving word problems in algebra, proving logical theorems and speaking English.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2233%22])">33</ref>
By the middle 60s their research was heavily funded by the <agency wordnetid="108337324" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../957/8957.xml">
U.S. Department of Defense</link></agency>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2234%22])">34</ref>
and they were optimistic about the future of the new field:
<list>
<entry level="1" type="bullet">

 1965, <link xlink:type="simple" xlink:href="../205/14205.xml">
H. A. Simon</link>: "[M]achines will be capable, within twenty years, of doing any work a man can do"<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2235%22])">35</ref></entry>
<entry level="1" type="bullet">

 1967, <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../639/19639.xml">
Marvin Minsky</link></scientist>
</person>
: "Within a generation ... the problem of creating 'artificial intelligence' will substantially be solved."<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2236%22])">36</ref></entry>
</list>
</p>
<p>

These predictions, and many like them, would not come true. They had failed to recognize the difficulty of some of the problems they faced.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2237%22])">37</ref>
In 1974, in response to the criticism of England's <link xlink:type="simple" xlink:href="../659/946659.xml">
Sir James Lighthill</link> and ongoing pressure from Congress to fund more productive projects, the U.S. and British governments cut off all undirected, exploratory research in AI. This was the first <link xlink:type="simple" xlink:href="../574/3548574.xml">
AI Winter</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2238%22])">38</ref></p>
<p>

In the early 80s, AI research was revived by the commercial success of <link xlink:type="simple" xlink:href="../136/10136.xml">
expert systems</link><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2239%22])">39</ref>
(a form of AI program that simulated the knowledge and analytical skills of one or more human experts). By 1985 the market for AI had reached more than a billion dollars and governments around the world poured money back into the field.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2240%22])">40</ref>
However, just a few years later, beginning with the collapse of the <link xlink:type="simple" xlink:href="../123/18123.xml">
Lisp Machine</link> market in 1987, AI once again fell into disrepute, and a second, more lasting <link xlink:type="simple" xlink:href="../574/3548574.xml">
AI Winter</link> began.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2241%22])">41</ref></p>
<p>

In the 90s and early 21st century AI achieved its greatest successes, albeit somewhat behind the scenes. Artificial intelligence was adopted throughout the technology industry, providing the heavy lifting for <link xlink:type="simple" xlink:href="../547/77547.xml">
logistics</link>, <link xlink:type="simple" xlink:href="../253/42253.xml">
data mining</link>, <link xlink:type="simple" xlink:href="../767/19013767.xml">
medical diagnosis</link> and many other areas.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2242%22])">42</ref>
The success was due to several factors: the incredible power of computers today (see <link xlink:type="simple" xlink:href="../418/39418.xml">
Moore's law</link>), a greater emphasis on solving specific subproblems, the creation of new ties between AI and other fields working on similar problems, and above all a new commitment by researchers to solid mathematical methods and rigorous scientific standards.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2243%22])">43</ref></p>

</ss1>
<ss1>
<st>
 Philosophy of AI </st>

<p>

<table style="background:#f9f9f9; font-size:85%; line-height:110%; ">
<row>
<col>
 <image width="32x28px" src="Portal.svg">
</image>
</col>
<col style="padding:0 0.2em;">
 <b><it>
Mind and Brain&#32;portal</it></b></col>
</row>
</table>
</p>

<p>

<indent level="1">

<it>Main article: <link xlink:type="simple" xlink:href="../015/2958015.xml">
philosophy of artificial intelligence</link></it>
</indent>

Artificial intelligence, by claiming to be able to recreate the capabilities of the human <link xlink:type="simple" xlink:href="../378/19378.xml">
mind</link>, is both a challenge and an inspiration for <link xlink:type="simple" xlink:href="../155/13692155.xml">
philosophy</link>. Are there limits to how intelligent machines can be? Is there an essential difference between human intelligence and artificial intelligence? Can a machine have a <link xlink:type="simple" xlink:href="../378/19378.xml">
mind</link> and <link xlink:type="simple" xlink:href="../664/5664.xml">
consciousness</link>? A few of the most influential answers to these questions are given below.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2244%22])">44</ref></p>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../048/404048.xml">
Turing's "polite convention"</link>: <it>If a machine acts as intelligently as a human being, then it is as intelligent as a human being.</it> <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../208/1208.xml">
Alan Turing</link></scientist>
</person>
 theorized that, ultimately, we can only judge the intelligence of machine based on its behavior. This theory forms the basis of the <link xlink:type="simple" xlink:href="../840/43840.xml">
Turing test</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2245%22])">45</ref></entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 The <link xlink:type="simple" xlink:href="../646/1124646.xml">
Dartmouth proposal</link>: <it>"Every aspect of learning or any other feature of intelligence can be so precisely described that a machine can be made to simulate it."</it> This assertion was printed in the proposal for the <link xlink:type="simple" xlink:href="../646/1124646.xml">
Dartmouth Conference</link> of 1956, and represents the position of most working AI researchers.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2246%22])">46</ref></entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <system wordnetid="104377057" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<link xlink:type="simple" xlink:href="../999/2685999.xml">
Newell and Simon's physical symbol system hypothesis</link></instrumentality>
</artifact>
</system>
: <it>"A physical symbol system has the necessary and sufficient means of general intelligent action."</it> This statement claims that the essence of intelligence is symbol manipulation.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2247%22])">47</ref> <philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../926/952926.xml">
Hubert Dreyfus</link></philosopher>
 argued that, on the contrary, human expertise depends on unconscious instinct rather than conscious symbol manipulation and on having a "feel" for the situation rather than explicit symbolic knowledge.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2248%22])">48</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2249%22])">49</ref></entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <link>
Gödel's incompleteness theorem</link>: <it>A <link xlink:type="simple" xlink:href="../102/396102.xml">
formal system</link> (such as a computer program) can not prove all true statements.</it> <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../193/26193.xml">
Roger Penrose</link></scientist>
</person>
 is among those who claim that Gödel's theorem limits what machines can do.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2250%22])">50</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2251%22])">51</ref></entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <work wordnetid="100575741" confidence="0.8">
<argument wordnetid="106648724" confidence="0.8">
<scientific_research wordnetid="100641820" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<indication wordnetid="106797169" confidence="0.8">
<experiment wordnetid="100639556" confidence="0.8">
<evidence wordnetid="106643408" confidence="0.8">
<investigation wordnetid="100633864" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<research wordnetid="100636921" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<link xlink:type="simple" xlink:href="../216/6216.xml#xpointer(//*[./st=%22Strong+AI%22])">
Searle's strong AI hypothesis</link></activity>
</psychological_feature>
</research>
</act>
</investigation>
</evidence>
</experiment>
</indication>
</event>
</scientific_research>
</argument>
</work>
: <it>"The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds."</it><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2252%22])">52</ref> Searle counters this assertion with his <work wordnetid="100575741" confidence="0.8">
<argument wordnetid="106648724" confidence="0.8">
<scientific_research wordnetid="100641820" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<indication wordnetid="106797169" confidence="0.8">
<experiment wordnetid="100639556" confidence="0.8">
<evidence wordnetid="106643408" confidence="0.8">
<investigation wordnetid="100633864" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<research wordnetid="100636921" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<link xlink:type="simple" xlink:href="../216/6216.xml">
Chinese room</link></activity>
</psychological_feature>
</research>
</act>
</investigation>
</evidence>
</experiment>
</indication>
</event>
</scientific_research>
</argument>
</work>
 argument, which asks us to look <it>inside</it> the computer and try to find where the "mind" might be.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2253%22])">53</ref></entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 The <link xlink:type="simple" xlink:href="../395/1908395.xml">
artificial brain</link> argument: <it>The brain can be simulated.</it> <link xlink:type="simple" xlink:href="../556/298556.xml">
Hans Moravec</link>, <link xlink:type="simple" xlink:href="../984/25984.xml">
Ray Kurzweil</link> and others have argued that it is technologically feasible to copy the brain directly into hardware and software, and that such a simulation will be essentially identical to the original. This argument combines the idea that a <link xlink:type="simple" xlink:href="../621/30621.xml">
suitably powerful</link> machine can simulate any process, with the <link xlink:type="simple" xlink:href="../376/19376.xml">
materialist</link> idea that the <link xlink:type="simple" xlink:href="../378/19378.xml">
mind</link> is the result of physical processes in the <link xlink:type="simple" xlink:href="../717/3717.xml">
brain</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2254%22])">54</ref></entry>
</list>
</p>

</ss1>
</sec>
<sec>
<st>
 AI research </st>

<ss1>
<st>
 Problems of AI </st>

<p>

While there is no universally accepted definition of intelligence,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2255%22])">55</ref>
AI researchers have studied several traits that are considered essential.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%225%22])">5</ref></p>

<ss2>
<st>
Deduction, reasoning, problem solving </st>
<p>

Early AI researchers developed algorithms that imitated the process of conscious, step-by-step reasoning that human beings use when they solve puzzles, play board games, or make logical deductions.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2256%22])">56</ref>
By the late 80s and 90s, AI research had also developed highly successful methods for dealing with <link xlink:type="simple" xlink:href="../778/63778.xml">
uncertain</link> or incomplete information, employing concepts from <link xlink:type="simple" xlink:href="../934/22934.xml">
probability</link> and <link xlink:type="simple" xlink:href="../223/9223.xml">
economics</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2257%22])">57</ref></p>
<p>

For difficult problems, most of these algorithms can require enormous computational resources — most experience a "<link xlink:type="simple" xlink:href="../738/7835738.xml">
combinatorial explosion</link>": the amount of memory or computer time required becomes astronomical when the problem goes beyond a certain size. The search for more efficient problem solving algorithms is a high priority for AI research.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2258%22])">58</ref></p>
<p>

It is not clear, however, that conscious human reasoning is any more efficient when faced with a difficult abstract problem. <link xlink:type="simple" xlink:href="../626/5626.xml">
Cognitive scientists</link> have demonstrated that human beings solve most of their problems using nonconscious reasoning, rather than the conscious, step-by-step deduction that early AI research was able to model.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2259%22])">59</ref>
<link xlink:type="simple" xlink:href="../699/6338699.xml">
Embodied cognitive science</link> argues that <link xlink:type="simple" xlink:href="../599/1058599.xml">
sensorimotor</link> skills are essential to our problem solving abilities. It is hoped that sub-symbolic methods, like <link xlink:type="simple" xlink:href="../306/1563306.xml">
computational intelligence</link> and <link xlink:type="simple" xlink:href="../720/3479720.xml">
situated</link> AI, will be able to model these instinctive skills. The problem of unconscious problem solving, which forms part of our <link xlink:type="simple" xlink:href="../026/996026.xml">
commonsense reasoning</link>, is largely unsolved&#91;&#32; &ndash; &#93;.</p>

</ss2>
<ss2>
<st>
Knowledge representation</st>

<p>

<indent level="1">

<it>Main articles: <link xlink:type="simple" xlink:href="../920/16920.xml">
knowledge representation</link>&#32;and&#32;<link xlink:type="simple" xlink:href="../339/2239339.xml">
commonsense knowledge</link></it>
</indent>

<link xlink:type="simple" xlink:href="../920/16920.xml">
Knowledge representation</link><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2260%22])">60</ref>
and <link xlink:type="simple" xlink:href="../499/458499.xml">
knowledge engineering</link><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2261%22])">61</ref>
are central to AI research. Many of the problems machines are expected to solve will require extensive knowledge about the world. Among the things that AI needs to represent are: objects, properties, categories and relations between objects;<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2262%22])">62</ref>
situations, events, states and time;<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2263%22])">63</ref>
causes and effects;<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2264%22])">64</ref>
knowledge about knowledge (what we know about what other people know);<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2265%22])">65</ref>
and many other, less well researched domains. A complete representation of "what exists" is an <link xlink:type="simple" xlink:href="../681/49681.xml">
ontology</link><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2266%22])">66</ref>
(borrowing a word from traditional <link xlink:type="simple" xlink:href="../155/13692155.xml">
philosophy</link>), of which the most general are called <link xlink:type="simple" xlink:href="../382/3200382.xml">
upper ontologies</link>.</p>
<p>

Among the most difficult problems in knowledge representation are:</p>
<p>

<list>
<entry level="1" type="bullet">

 <it>Default reasoning and the <link xlink:type="simple" xlink:href="../287/731287.xml">
qualification problem</link></it>: Many of the things people know take the form of "working assumptions." For example, if a bird comes up in conversation, people typically picture an animal that is fist sized, sings, and flies. None of these things are true about birds in general. <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../362/308362.xml">
John McCarthy</link></scientist>
</person>
 identified this problem in 1969<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2267%22])">67</ref> as the qualification problem: for any commonsense rule that AI researchers care to represent, there tend to be a huge number of exceptions. Almost nothing is simply true or false in the way that abstract logic requires. AI research has explored a number of solutions to this problem.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2268%22])">68</ref></entry>
<entry level="1" type="bullet">

 <it>Unconscious knowledge</it>: Much of what people know isn't represented as "facts" or "statements" that they could actually say out loud. They take the form of intuitions or tendencies and are represented in the brain unconsciously and sub-symbolically. This unconscious knowledge informs, supports and provides a context for our conscious knowledge. As with the related problem of unconscious reasoning, it is hoped that <link xlink:type="simple" xlink:href="../720/3479720.xml">
situated</link> AI or <link xlink:type="simple" xlink:href="../306/1563306.xml">
computational intelligence</link> will provide ways to represent this kind of knowledge.</entry>
<entry level="1" type="bullet">

 <it>The breadth of <link xlink:type="simple" xlink:href="../339/2239339.xml">
common sense knowledge</link></it>: The number of atomic facts that the average person knows is astronomical. Research projects that attempt to build a complete knowledge base of <link xlink:type="simple" xlink:href="../339/2239339.xml">
commonsense knowledge</link>, such as <link xlink:type="simple" xlink:href="../874/6874.xml">
Cyc</link>, require enormous amounts of tedious step-by-step ontological engineering — they must be built, by hand, one complicated concept at a time.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2269%22])">69</ref></entry>
</list>
</p>

</ss2>
<ss2>
<st>
Planning</st>

<p>

<indent level="1">

<it>Main article: <link xlink:type="simple" xlink:href="../641/1505641.xml">
automated planning and scheduling</link></it>
</indent>

Intelligent agents must be able to set goals and achieve them.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2270%22])">70</ref>
They need a way to visualize the future (they must have a representation of the state of the world and be able to make predictions about how their actions will change it) and be able to make choices that maximize the <link xlink:type="simple" xlink:href="../479/45479.xml">
utility</link> (or "value") of the available choices.</p>
<p>

In some planning problems, the agent can assume that it is the only thing acting on the world and it can be certain what the consequences of its actions may be.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2271%22])">71</ref>
However, if this is not true, it must periodically check if the world matches its predictions and it must change its plan as this becomes necessary, requiring the agent to reason under uncertainty.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2272%22])">72</ref></p>
<p>

<system wordnetid="104377057" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<link xlink:type="simple" xlink:href="../106/2627106.xml">
Multi-agent planning</link></instrumentality>
</artifact>
</system>
 uses the <link xlink:type="simple" xlink:href="../556/511556.xml">
cooperation</link> and <link xlink:type="simple" xlink:href="../592/181592.xml">
competition</link> of many agents to achieve a given goal. <link xlink:type="simple" xlink:href="../436/37436.xml">
Emergent behavior</link> such as this is used by <link xlink:type="simple" xlink:href="../837/190837.xml">
evolutionary algorithms</link> and <link xlink:type="simple" xlink:href="../988/762988.xml">
swarm intelligence</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2273%22])">73</ref></p>

</ss2>
<ss2>
<st>
Learning</st>

<p>

<indent level="1">

<it>Main article: <link xlink:type="simple" xlink:href="../488/233488.xml">
machine learning</link></it>
</indent>

Important <link xlink:type="simple" xlink:href="../488/233488.xml">
machine learning</link><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2274%22])">74</ref>
problems are:</p>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../497/233497.xml">
Unsupervised learning</link>: find a model that matches a stream of input "experiences", and be able to predict what new "experiences" to expect.</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../926/20926.xml">
Supervised learning</link>, such as <link xlink:type="simple" xlink:href="../244/1579244.xml">
classification</link> (be able to determine what category something belongs in, after seeing a number of examples of things from each category), or <link xlink:type="simple" xlink:href="../568/26568.xml">
regression</link> (given a set of numerical input/output examples, discover a continuous function that would generate the outputs from the inputs).</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../294/66294.xml">
Reinforcement learning</link>:<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2275%22])">75</ref> the agent is rewarded for good responses and punished for bad ones. (These can be analyzed in terms <link xlink:type="simple" xlink:href="../216/446216.xml">
decision theory</link>, using concepts like <link xlink:type="simple" xlink:href="../479/45479.xml">
utility</link>).</entry>
</list>
</p>
<p>

The mathematical analysis of machine learning algorithms and their performance is a branch of <link xlink:type="simple" xlink:href="../392/323392.xml">
theoretical computer science</link> known as <link xlink:type="simple" xlink:href="../537/387537.xml">
computational learning theory</link>.</p>

</ss2>
<ss2>
<st>
Natural language processing</st>

<p>

<indent level="1">

<it>Main article: <link xlink:type="simple" xlink:href="../652/21652.xml">
natural language processing</link></it>
</indent>

<link xlink:type="simple" xlink:href="../652/21652.xml">
Natural language processing</link><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2276%22])">76</ref>
gives machines the ability to read and understand the languages human beings speak. Many researchers hope that a sufficiently powerful natural language processing system would be able to acquire knowledge on its own, by reading the existing text available over the internet. Some straigh&amp;shy;tforward applications of natural language processing include <link xlink:type="simple" xlink:href="../271/15271.xml">
information retrieval</link> (or <link xlink:type="simple" xlink:href="../439/318439.xml">
text mining</link>) and <link xlink:type="simple" xlink:href="../980/19980.xml">
machine translation</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2277%22])">77</ref></p>

</ss2>
<ss2>
<st>
Motion and manipulation</st>
<p>

<image width="200px" src="Honda_ASIMO_Walking_Stairs.JPG" type="thumb">
</image>
</p>
<p>

<indent level="1">

<it>Main article: <link xlink:type="simple" xlink:href="../673/46673.xml">
robotics</link></it>
</indent>

The field of <link xlink:type="simple" xlink:href="../673/46673.xml">
robotics</link><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2278%22])">78</ref>
is closely related to AI. Intelligence is required for robots to be able to handle such tasks as object manipulation<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2279%22])">79</ref>
and <link xlink:type="simple" xlink:href="../875/4562875.xml">
navigation</link>, with sub-problems of <link xlink:type="simple" xlink:href="../843/126843.xml">
localization</link> (knowing where you are), <link xlink:type="simple" xlink:href="../112/623112.xml">
mapping</link> (learning what is around you) and <link xlink:type="simple" xlink:href="../875/4562875.xml">
motion planning</link> (figuring out how to get there).<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2280%22])">80</ref></p>

</ss2>
<ss2>
<st>
Perception</st>

<p>

<indent level="1">

<it>Main articles: <link xlink:type="simple" xlink:href="../671/11920671.xml">
machine perception</link>,&#32;<link xlink:type="simple" xlink:href="../596/6596.xml">
computer vision</link>,&#32;and&#32;<link xlink:type="simple" xlink:href="../468/29468.xml">
speech recognition</link></it>
</indent>

<link xlink:type="simple" xlink:href="../671/11920671.xml">
Machine perception</link><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2281%22])">81</ref>
is the ability to use input from sensors (such as cameras, microphones, sonar and others more exotic) to deduce aspects of the world. <link xlink:type="simple" xlink:href="../596/6596.xml">
Computer vision</link><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2282%22])">82</ref>
is the ability to analyze visual input. A few selected subproblems are <link xlink:type="simple" xlink:href="../468/29468.xml">
speech recognition</link>,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2283%22])">83</ref>
<link xlink:type="simple" xlink:href="../595/486595.xml">
facial recognition</link> and <link xlink:type="simple" xlink:href="../466/14661466.xml">
object recognition</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2284%22])">84</ref></p>

</ss2>
<ss2>
<st>
Social intelligence</st>

<p>

<indent level="1">

<it>Main article: <link xlink:type="simple" xlink:href="../942/233942.xml">
affective computing</link></it>
</indent>
<image width="200px" src="Wikimania_2006_POLIMEREK_100-0093_IMG.JPG" type="thumb">
</image>
</p>
<p>

Emotion and social skills play two roles for an intelligent agent:<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2285%22])">85</ref>
<list>
<entry level="1" type="bullet">

 It must be able to predict the actions of others, by understanding their motives and emotional states. (This involves elements of <link xlink:type="simple" xlink:href="../924/11924.xml">
game theory</link>, <link xlink:type="simple" xlink:href="../216/446216.xml">
decision theory</link>, as well as the ability to model human emotions and the perceptual skills to detect emotions.)</entry>
<entry level="1" type="bullet">

 For good <link xlink:type="simple" xlink:href="../516/13516.xml">
human-computer interaction</link>, an intelligent machine also needs to <it>display</it> emotions — at the very least it must appear polite and sensitive to the humans it interacts with. At best, it should appear to have normal emotions itself.</entry>
</list>
</p>

</ss2>
<ss2>
<st>
Creativity</st>

<p>

<indent level="1">

<it>Main article: <link xlink:type="simple" xlink:href="../571/16300571.xml">
computational creativity</link></it>
</indent>

A sub-field of AI addresses <link xlink:type="simple" xlink:href="../910/142910.xml">
creativity</link> both theoretically (from a philosophical and psychological perspective) and practically (via specific implementations of systems that generate outputs that can be considered creative).</p>

</ss2>
<ss2>
<st>
General intelligence</st>

<p>

<indent level="1">

<it>Main articles: <link xlink:type="simple" xlink:href="../357/586357.xml">
strong AI</link>&#32;and&#32;<link xlink:type="simple" xlink:href="../862/2862.xml">
AI-complete</link></it>
</indent>

Most researchers hope that their work will eventually be incorporated into a machine with <it>general</it> intelligence (known as <link xlink:type="simple" xlink:href="../357/586357.xml">
strong AI</link>), combining all the skills above and exceeding human abilities at most or all of them.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref> A few believe that <link xlink:type="simple" xlink:href="../060/19009060.xml">
anthropomorphic</link> features like <link xlink:type="simple" xlink:href="../552/195552.xml">
artificial consciousness</link> or an <link xlink:type="simple" xlink:href="../395/1908395.xml">
artificial brain</link> may be required for such a project.</p>
<p>

Many of the problems above are considered <link xlink:type="simple" xlink:href="../862/2862.xml">
AI-complete</link>: to solve one problem, you must solve them all. For example, even a straigh&amp;shy;tforward, specific task like <link xlink:type="simple" xlink:href="../980/19980.xml">
machine translation</link> requires that the machine follow the author's argument (<link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Deduction=2C+reasoning=2C+problem+solving%22])">
reason</link>), know what it's talking about (<link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Knowledge+representation%22])">
knowledge</link>), and faithfully reproduce the author's intention (<link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Social+intelligence%22])">
social intelligence</link>). <link xlink:type="simple" xlink:href="../980/19980.xml">
Machine translation</link>, therefore, is believed to be AI-complete: it may require <link xlink:type="simple" xlink:href="../357/586357.xml">
strong AI</link> to be done as well as humans can do it.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2286%22])">86</ref></p>

</ss2>
</ss1>
<ss1>
<st>
 Approaches to AI </st>

<p>

Artificial intelligence is a young science and there is still no established unifying theory. The field is fragmented<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2287%22])">87</ref> and research communities have grown around different approaches.</p>

<ss2>
<st>
 Cybernetics and brain simulation </st>
<p>

<image location="right" width="280px" src="ArtificialFictionBrain.png" type="thumb">
<caption>

The <link xlink:type="simple" xlink:href="../620/490620.xml">
human brain</link> provides inspiration for artificial intelligence researchers, however there is no consensus on how closely it should be <link xlink:type="simple" xlink:href="../416/375416.xml">
simulated</link>.
</caption>
</image>

In the 40s and 50s, a number of researchers explored the connection between <link xlink:type="simple" xlink:href="../226/21226.xml">
neurology</link>, <link xlink:type="simple" xlink:href="../773/14773.xml">
information theory</link>, and <link xlink:type="simple" xlink:href="../904/5904.xml">
cybernetics</link>. Some of them built machines that used electronic networks to exhibit rudimentary intelligence, such as <link xlink:type="simple" xlink:href="../410/310410.xml">
W. Grey Walter</link>'s <automaton wordnetid="102761392" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<device wordnetid="103183080" confidence="0.8">
<mechanism wordnetid="103738472" confidence="0.8">
<link xlink:type="simple" xlink:href="../198/9022198.xml">
turtles</link></mechanism>
</device>
</instrumentality>
</artifact>
</automaton>
 and the <link xlink:type="simple" xlink:href="../552/13882552.xml">
Johns Hopkins Beast</link>. Many of these researchers gathered for meetings of the <link>
Teleological Society</link> at Princeton and the <association wordnetid="108049401" confidence="0.8">
<club wordnetid="108227214" confidence="0.8">
<link xlink:type="simple" xlink:href="../170/1014170.xml">
Ratio Club</link></club>
</association>
 in England.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2230%22])">30</ref></p>

</ss2>
<ss2>
<st>
 Traditional symbolic AI </st>
<p>

When access to digital computers became possible in the middle 1950s, AI research began to explore the possibility that human intelligence could be reduced to symbol manipulation. The research was centered in three institutions: <university wordnetid="108286163" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../093/48093.xml">
CMU</link></university>
, <link>
Stanford</link> and <link xlink:type="simple" xlink:href="../061/19061.xml">
MIT</link>, and each one developed its own style of research. <skilled_worker wordnetid="110605985" confidence="0.8">
<physical_entity wordnetid="100001930" confidence="0.8">
<philosopher wordnetid="110423589" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<volunteer wordnetid="110759331" confidence="0.8">
<intellectual wordnetid="109621545" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<alumnus wordnetid="109786338" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<serviceman wordnetid="110582746" confidence="0.8">
<scholar wordnetid="110557854" confidence="0.8">
<link xlink:type="simple" xlink:href="../423/339423.xml">
John Haugeland</link></scholar>
</serviceman>
</causal_agent>
</alumnus>
</worker>
</intellectual>
</volunteer>
</person>
</philosopher>
</physical_entity>
</skilled_worker>
 named these approaches to AI "good old fashioned AI" or "<link xlink:type="simple" xlink:href="../417/339417.xml">
GOFAI</link>".<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2288%22])">88</ref></p>
<p>

<list>
<entry level="1" type="definition">

 Cognitive simulation:<link xlink:type="simple" xlink:href="../349/57349.xml">
Economist</link> <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../205/14205.xml">
Herbert Simon</link></scientist>
</person>
 and <link xlink:type="simple" xlink:href="../304/287304.xml">
Alan Newell</link> studied human problem solving skills and attempted to formalize them, and their work laid the foundations of the field of artificial intelligence, as well as <link xlink:type="simple" xlink:href="../626/5626.xml">
cognitive science</link>, <link xlink:type="simple" xlink:href="../476/43476.xml">
operations research</link> and <link xlink:type="simple" xlink:href="../200/20200.xml">
management science</link>. Their research team performed <link xlink:type="simple" xlink:href="../921/22921.xml">
psychological</link> experiments to demonstrate the similarities between human problem solving and the programs (such as their "<link xlink:type="simple" xlink:href="../658/1234658.xml">
General Problem Solver</link>") they were developing. This tradition, centered at <university wordnetid="108286163" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../093/48093.xml">
Carnegie Mellon University</link></university>
 would eventually culminate in the development of the <link xlink:type="simple" xlink:href="../751/729751.xml">
Soar</link> architecture in the middle 80s.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2289%22])">89</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2290%22])">90</ref></entry>
</list>
</p>
<p>

<list>
<entry level="1" type="definition">

 Logical AI: Unlike <link xlink:type="simple" xlink:href="../304/287304.xml">
Newell</link> and <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../205/14205.xml">
Simon</link></scientist>
</person>
, <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../362/308362.xml">
John McCarthy</link></scientist>
</person>
 felt that machines did not need to simulate human thought, but should instead try to find the essence of abstract reasoning and problem solving, regardless of whether people used the same algorithms.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2291%22])">91</ref> His laboratory at <university wordnetid="108286163" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../977/26977.xml">
Stanford</link></university>
 (<point wordnetid="108620061" confidence="0.8">
<institute wordnetid="108407330" confidence="0.8">
<geographic_point wordnetid="108578706" confidence="0.8">
<location wordnetid="100027167" confidence="0.8">
<association wordnetid="108049401" confidence="0.8">
<workplace wordnetid="104602044" confidence="0.8">
<lab wordnetid="103629986" confidence="0.8">
<link xlink:type="simple" xlink:href="../358/310358.xml">
SAIL</link></lab>
</workplace>
</association>
</location>
</geographic_point>
</institute>
</point>
) focused on using formal <link xlink:type="simple" xlink:href="../225/3729225.xml">
logic</link> to solve a wide variety of problems, including <link xlink:type="simple" xlink:href="../920/16920.xml">
knowledge representation</link>, <link xlink:type="simple" xlink:href="../641/1505641.xml">
planning</link> and <link xlink:type="simple" xlink:href="../488/233488.xml">
learning</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2292%22])">92</ref> Logic was also focus of the work at the <university wordnetid="108286163" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../395/64395.xml">
University of Edinburgh</link></university>
 and elsewhere in Europe which led to the development of the programming language <link xlink:type="simple" xlink:href="../485/23485.xml">
Prolog</link> and the science of <link xlink:type="simple" xlink:href="../de)/17927_(Z$I$P$_code).xml">
logic programming</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2293%22])">93</ref></entry>
</list>
</p>
<p>

<list>
<entry level="1" type="definition">

 "Scruffy" symbolic AI: Researchers at <link xlink:type="simple" xlink:href="../061/19061.xml">
MIT</link> (such as <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../639/19639.xml">
Marvin Minsky</link></scientist>
</person>
 and <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../802/27802.xml">
Seymour Papert</link></scientist>
</person>
) found that solving difficult problems in <link xlink:type="simple" xlink:href="../596/6596.xml">
vision</link> and <link xlink:type="simple" xlink:href="../652/21652.xml">
natural language processing</link> required ad-hoc solutions &ndash; they argued that there was no simple and general principle (like <link xlink:type="simple" xlink:href="../225/3729225.xml">
logic</link>) that would capture all the aspects of intelligent behavior. <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<research_worker wordnetid="110523076" confidence="0.8">
<link xlink:type="simple" xlink:href="../541/1076541.xml">
Roger Schank</link></research_worker>
</scientist>
</causal_agent>
</person>
</physical_entity>
 described their "anti-logic" approaches as "<link xlink:type="simple" xlink:href="../037/404037.xml">
scruffy</link>" (as opposed to the "<link xlink:type="simple" xlink:href="../037/404037.xml">
neat</link>" paradigms at <link xlink:type="simple" xlink:href="../137/61137.xml">
CMU</link> and <link>
Stanford</link>),<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2294%22])">94</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2295%22])">95</ref> and this still forms the basis of research into <link xlink:type="simple" xlink:href="../339/2239339.xml">
commonsense knowledge bases</link> (such as <link xlink:type="simple" xlink:href="../991/99991.xml">
Doug Lenat</link>'s <link xlink:type="simple" xlink:href="../874/6874.xml">
Cyc</link>) which must be built one complicated concept at a time.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2296%22])">96</ref></entry>
</list>
</p>
<p>

<list>
<entry level="1" type="definition">

 Knowledge based AI: When computers with large memories became available around 1970, researchers from all three traditions began to build <link xlink:type="simple" xlink:href="../920/16920.xml">
knowledge</link> into AI applications.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2297%22])">97</ref> This "knowledge revolution" led to the development and deployment of <link xlink:type="simple" xlink:href="../136/10136.xml">
expert system</link>s (introduced by <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../517/307517.xml">
Edward Feigenbaum</link></scientist>
</person>
), the first truly successful form of AI software.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2239%22])">39</ref> The knowledge revolution was also driven by the realization that truly enormous amounts of knowledge would be required by many simple AI applications.</entry>
</list>
</p>

</ss2>
<ss2>
<st>
 Sub-symbolic AI </st>

<p>

During the 1960s, symbolic approaches had achieved great success at simulating high-level thinking in small demonstration programs. Approaches based on <link xlink:type="simple" xlink:href="../904/5904.xml">
cybernetics</link> or <link xlink:type="simple" xlink:href="../542/1729542.xml">
neural network</link>s were abandoned or pushed into the background.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2298%22])">98</ref>
By the 1980s, however, progress in symbolic AI seemed to stall and many believed that symbolic systems would never be able to imitate all the processes of human cognition, especially <link xlink:type="simple" xlink:href="../671/11920671.xml">
perception</link>, <link xlink:type="simple" xlink:href="../673/46673.xml">
robotics</link>, <link xlink:type="simple" xlink:href="../488/233488.xml">
learning</link> and <link xlink:type="simple" xlink:href="../706/126706.xml">
pattern recognition</link>. A number of researchers began to look into "sub-symbolic" approaches to specific AI problems.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2299%22])">99</ref></p>
<p>

<list>
<entry level="1" type="definition">

 Bottom-up, situated, behavior based or nouvelle AI: Researchers from the related field of <link xlink:type="simple" xlink:href="../673/46673.xml">
robotics</link>, such as <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../498/632498.xml">
Rodney Brooks</link></scientist>
</person>
, rejected symbolic AI and focussed on the basic engineering problems that would allow robots to move and survive.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22100%22])">100</ref> Their work revived the non-symbolic viewpoint of the early <link xlink:type="simple" xlink:href="../904/5904.xml">
cybernetic</link>s researchers of the 50s and reintroduced the use of <link xlink:type="simple" xlink:href="../039/7039.xml">
control theory</link> in AI. These approaches are also conceptually related to the <link xlink:type="simple" xlink:href="../895/48895.xml">
embodied mind thesis</link>.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="definition">

 Computational Intelligence:Interest in <link>
neural networks</link> and "<link xlink:type="simple" xlink:href="../636/263636.xml">
connectionism</link>" was revived by <link xlink:type="simple" xlink:href="../113/2823113.xml">
David Rumelhart</link> and others in the middle 1980s.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22101%22])">101</ref> These and other sub-symbolic approaches, such as <link xlink:type="simple" xlink:href="../660/48660.xml">
fuzzy system</link>s and <link xlink:type="simple" xlink:href="../020/268020.xml">
evolutionary computation</link>, are now studied collectively by the emerging discipline of <link xlink:type="simple" xlink:href="../306/1563306.xml">
computational intelligence</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22102%22])">102</ref></entry>
</list>
</p>
<p>

<list>
<entry level="1" type="definition">

 Formalisation: In the 1990s, AI researchers developed sophisticated mathematical tools to solve specific subproblems. These tools are truly <link xlink:type="simple" xlink:href="../833/26833.xml">
scientific</link>, in the sense that their results are both measurable and verifiable, and they have been responsible for many of AI's recent successes. The shared mathematical language has also permitted a high level of collaboration with more established fields (like <link xlink:type="simple" xlink:href="../831/18831.xml">
mathematics</link>, <link xlink:type="simple" xlink:href="../223/9223.xml">
economics</link> or <link xlink:type="simple" xlink:href="../476/43476.xml">
operations research</link>). <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig (2003)</link> describe this movement as nothing less than a "revolution" and "the victory of the <link xlink:type="simple" xlink:href="../037/404037.xml">
neats</link>."</entry>
</list>
</p>

</ss2>
<ss2>
<st>
 Intelligent agent paradigm </st>

<p>

The "<link xlink:type="simple" xlink:href="../317/2711317.xml">
intelligent agent</link>" <link xlink:type="simple" xlink:href="../308/175308.xml">
paradigm</link> became widely accepted during the 1990s.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22103%22])">103</ref>
An <link xlink:type="simple" xlink:href="../317/2711317.xml">
intelligent agent</link> is a system that perceives its environment and takes actions which maximizes its chances of success. The simplest intelligent agents are programs that solve specific problems. The most complicated intelligent agents are rational, thinking human beings.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22104%22])">104</ref>
The paradigm gives researchers license to study isolated problems and find solutions that are both verifiable and useful, without agreeing on one single approach. An agent that solves a specific problem can use any approach that works — some agents are symbolic and logical, some are sub-symbolic <link xlink:type="simple" xlink:href="../542/1729542.xml">
neural network</link>s and others may use new approaches. The paradigm also gives researchers a common language to communicate with other fields—such as <link xlink:type="simple" xlink:href="../216/446216.xml">
decision theory</link> and <link xlink:type="simple" xlink:href="../223/9223.xml">
economics</link>—that also use concepts of abstract agents.</p>

</ss2>
<ss2>
<st>
 Integrating the approaches </st>

<p>

An <link xlink:type="simple" xlink:href="../677/4510677.xml">
agent architecture</link> or <link xlink:type="simple" xlink:href="../176/1700176.xml">
cognitive architecture</link> allows researchers to build more versatile and intelligent systems out of interacting <link xlink:type="simple" xlink:href="../317/2711317.xml">
intelligent agents</link> in a <link xlink:type="simple" xlink:href="../833/938833.xml">
multi-agent system</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22105%22])">105</ref>
A system with both symbolic and sub-symbolic components is a <link xlink:type="simple" xlink:href="../246/2932246.xml">
hybrid intelligent system</link>, and the study of such systems is <link xlink:type="simple" xlink:href="../324/7872324.xml">
artificial intelligence systems integration</link>. A <link xlink:type="simple" xlink:href="../723/15291723.xml">
hierarchical control system</link> provides a bridge between sub-symbolic AI at its lowest, reactive levels and traditional symbolic AI at its highest levels, where relaxed time constraints permit planning and world modelling.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22106%22])">106</ref>
<person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../498/632498.xml">
Rodney Brooks</link></scientist>
</person>
' <link xlink:type="simple" xlink:href="../552/83552.xml">
subsumption architecture</link> was an early proposal for such a hierarchical system.</p>


</ss2>
</ss1>
<ss1>
<st>
 Tools of AI research </st>

<p>

In the course of 50 years of research, AI has developed a large number of tools to solve the most difficult problems in <link xlink:type="simple" xlink:href="../323/5323.xml">
computer science</link>. A few of the most general of these methods are discussed below.</p>

<ss2>
<st>
 Search and optimization </st>

<p>

<indent level="1">

<it>Main articles: <link xlink:type="simple" xlink:href="../249/28249.xml">
search algorithm</link>,&#32;<link xlink:type="simple" xlink:href="../033/52033.xml">
optimization (mathematics)</link>,&#32;and&#32;<link xlink:type="simple" xlink:href="../020/268020.xml">
evolutionary computation</link></it>
</indent>

Many problems in AI can be solved in theory by intelligently searching through many possible solutions:<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22107%22])">107</ref> 
<link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Deduction=2C+reasoning=2C+problem+solving%22])">
Reasoning</link> can be reduced to performing a search. For example, logical proof can be viewed as searching for a path that leads from <link xlink:type="simple" xlink:href="../337/7993337.xml">
premise</link>s to <link xlink:type="simple" xlink:href="../907/307907.xml">
conclusion</link>s, where each step is the application of an <link xlink:type="simple" xlink:href="../311/252311.xml">
inference rule</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22108%22])">108</ref>
<link xlink:type="simple" xlink:href="../641/1505641.xml">
Planning</link> algorithms search through trees of goals and subgoals, attempting to find a path to a target goal, a process called <link xlink:type="simple" xlink:href="../094/6278094.xml">
means-ends analysis</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22109%22])">109</ref>
<link xlink:type="simple" xlink:href="../673/46673.xml">
Robotics</link> algorithms for moving limbs and grasping objects use <link xlink:type="simple" xlink:href="../942/313942.xml">
local searches</link> in <link xlink:type="simple" xlink:href="../596/473596.xml">
configuration space</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2279%22])">79</ref> 
Many <link xlink:type="simple" xlink:href="../488/233488.xml">
learning</link> algorithms use search algorithms based on <link xlink:type="simple" xlink:href="../033/52033.xml">
optimization</link>.</p>
<p>

Simple exhaustive searches<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22110%22])">110</ref>
are rarely sufficient for most real world problems: the <link xlink:type="simple" xlink:href="../707/389707.xml">
search space</link> (the number of places to search) quickly grows to <link xlink:type="simple" xlink:href="../650/50650.xml">
astronomical</link> numbers. The result is a search that is <link xlink:type="simple" xlink:href="../844/4627844.xml">
too slow</link> or never completes. The solution, for many problems, is to use "<link xlink:type="simple" xlink:href="../452/63452.xml">
heuristics</link>" or "rules of thumb" that eliminate choices that are unlikely to lead to the goal (called "<link xlink:type="simple" xlink:href="../075/5462075.xml">
pruning</link> the <link xlink:type="simple" xlink:href="../584/597584.xml">
search tree</link>"). <link xlink:type="simple" xlink:href="../452/63452.xml">
Heuristics</link> supply the program with a "best guess" for what path the solution lies on.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22111%22])">111</ref></p>
<p>

A very different kind of search came to prominence in the 1990s, based on the mathematical theory of <link xlink:type="simple" xlink:href="../033/52033.xml">
optimization</link>. For many problems, it is possible to begin the search with some form of a guess and then refine the guess incrementally until no more refinements can be made. These algorithms can be visualized as blind <link xlink:type="simple" xlink:href="../002/364002.xml">
hill climbing</link>: we begin the search at a random point on the landscape, and then, by jumps or steps, we keep moving our guess uphill, until we reach the top. Other optimization algorithms are <link xlink:type="simple" xlink:href="../244/172244.xml">
simulated annealing</link>, <link xlink:type="simple" xlink:href="../032/1686032.xml">
beam search</link> and <link xlink:type="simple" xlink:href="../864/147864.xml">
random optimization</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22112%22])">112</ref> </p>
<p>

<link xlink:type="simple" xlink:href="../020/268020.xml">
Evolutionary computation</link> uses a form of optimization search. For example, they may begin with a population of organisms (the guesses) and then allow them to mutate and recombine, <link xlink:type="simple" xlink:href="../147/21147.xml">
selecting</link> only the fittest to survive each generation (refining the guesses). Forms of <link xlink:type="simple" xlink:href="../020/268020.xml">
evolutionary computation</link> include <link xlink:type="simple" xlink:href="../988/762988.xml">
swarm intelligence</link> algorithms (such as <link xlink:type="simple" xlink:href="../615/588615.xml">
ant colony</link> or <link xlink:type="simple" xlink:href="../083/337083.xml">
particle swarm optimization</link>)<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22113%22])">113</ref>
and <link xlink:type="simple" xlink:href="../837/190837.xml">
evolutionary algorithms</link> (such as <link xlink:type="simple" xlink:href="../254/40254.xml">
genetic algorithms</link><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22114%22])">114</ref> 
and <link xlink:type="simple" xlink:href="../424/12424.xml">
genetic programming</link><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22115%22])">115</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22116%22])">116</ref>).</p>

</ss2>
<ss2>
<st>
 Logic </st>

<p>

<indent level="1">

<it>Main articles: <link xlink:type="simple" xlink:href="../de)/17927_(Z$I$P$_code).xml">
logic programming</link>&#32;and&#32;<link xlink:type="simple" xlink:href="../728/2884728.xml">
automated reasoning</link></it>
</indent>

<link xlink:type="simple" xlink:href="../225/3729225.xml">
Logic</link><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22117%22])">117</ref>
was introduced into AI research by <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../362/308362.xml">
John McCarthy</link></scientist>
</person>
 in his 1958 <link xlink:type="simple" xlink:href="../008/8992008.xml">
Advice Taker</link> proposal. The most important technical development was <skilled_worker wordnetid="110605985" confidence="0.8">
<peer wordnetid="109626238" confidence="0.8">
<physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<intellectual wordnetid="109621545" confidence="0.8">
<traveler wordnetid="109629752" confidence="0.8">
<colleague wordnetid="109935990" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<exile wordnetid="110071332" confidence="0.8">
<absentee wordnetid="109757653" confidence="0.8">
<associate wordnetid="109816771" confidence="0.8">
<editor wordnetid="110044879" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<alumnus wordnetid="109786338" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<mathematician wordnetid="110301261" confidence="0.8">
<scholar wordnetid="110557854" confidence="0.8">
<link xlink:type="simple" xlink:href="../114/8895114.xml">
J. Alan Robinson</link></scholar>
</mathematician>
</causal_agent>
</alumnus>
</worker>
</editor>
</associate>
</absentee>
</exile>
</scientist>
</colleague>
</traveler>
</intellectual>
</person>
</physical_entity>
</peer>
</skilled_worker>
's discovery of the <link xlink:type="simple" xlink:href="../082/2724082.xml">
resolution</link> and <link xlink:type="simple" xlink:href="../432/54432.xml">
unification</link> algorithm for logical deduction in 1963. This procedure is simple, complete and entirely algorithmic, and can easily be performed by digital computers.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22118%22])">118</ref>
However, a naive implementation of the algorithm quickly leads to a <link xlink:type="simple" xlink:href="../738/7835738.xml">
combinatorial explosion</link> or an <link xlink:type="simple" xlink:href="../273/45273.xml">
infinite loop</link>. In 1974, <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../364/1621364.xml">
Robert Kowalski</link></scientist>
</person>
 suggested representing logical expressions as <link xlink:type="simple" xlink:href="../824/333824.xml">
Horn clauses</link> (statements in the form of rules: "if <it>p</it> then <it>q</it>"), which reduced logical deduction to <link xlink:type="simple" xlink:href="../967/568967.xml">
backward chaining</link> or <link xlink:type="simple" xlink:href="../962/568962.xml">
forward chaining</link>. This greatly alleviated (but did not eliminate) the problem.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22108%22])">108</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22119%22])">119</ref></p>
<p>

Logic is used for knowledge representation and problem solving, but it can be applied to other problems as well. For example, the <link xlink:type="simple" xlink:href="../843/2955843.xml">
satplan</link> algorithm uses logic for <link xlink:type="simple" xlink:href="../641/1505641.xml">
planning</link>,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22120%22])">120</ref>
and <link xlink:type="simple" xlink:href="../069/54069.xml">
inductive logic programming</link> is a method for <link xlink:type="simple" xlink:href="../488/233488.xml">
learning</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22121%22])">121</ref>
There are several different forms of logic used in AI research.</p>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../335/5597335.xml">
Propositional</link> or <link xlink:type="simple" xlink:href="../154/18154.xml">
sentential logic</link><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22122%22])">122</ref> is the logic of statements which can be true or false.</entry>
<entry level="1" type="bullet">

 <system wordnetid="104377057" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<link xlink:type="simple" xlink:href="../983/10983.xml">
First-order logic</link></instrumentality>
</artifact>
</system>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22123%22])">123</ref> also allows the use of <link xlink:type="simple" xlink:href="../806/228806.xml">
quantifier</link>s and <link xlink:type="simple" xlink:href="../280/203280.xml">
predicate</link>s, and can express facts about objects, their properties, and their relations with each other.</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../180/49180.xml">
Fuzzy logic</link>, a version of first-order logic which allows the truth of a statement to be represented as a value between 0 and 1, rather than simply True (1) or False (0). <link xlink:type="simple" xlink:href="../660/48660.xml">
Fuzzy system</link>s can be used for uncertain reasoning and have been widely used in modern industrial and consumer product control systems.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22124%22])">124</ref></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../639/889639.xml">
Default logic</link>s, <link xlink:type="simple" xlink:href="../086/341086.xml">
non-monotonic logic</link>s and <link xlink:type="simple" xlink:href="../917/2634917.xml">
circumscription</link> are forms of logic designed to help with default reasoning and the <link xlink:type="simple" xlink:href="../287/731287.xml">
qualification problem</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2268%22])">68</ref></entry>
<entry level="1" type="bullet">

 Several extensions of logic have been designed to handle specific domains of <link xlink:type="simple" xlink:href="../920/16920.xml">
knowledge</link>, such as: <link xlink:type="simple" xlink:href="../503/183503.xml">
description logic</link>s;<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2262%22])">62</ref> <link xlink:type="simple" xlink:href="../109/2256109.xml">
situation calculus</link>, <link xlink:type="simple" xlink:href="../680/2897680.xml">
event calculus</link> and <link xlink:type="simple" xlink:href="../091/2961091.xml">
fluent calculus</link> (for representing events and time);<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2263%22])">63</ref> <link xlink:type="simple" xlink:href="../196/37196.xml#xpointer(//*[./st=%22causal+calculus%22])">
causal calculus</link>;<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2264%22])">64</ref> <link>
belief calculus</link>; and <link xlink:type="simple" xlink:href="../365/333365.xml">
modal logic</link>s.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2265%22])">65</ref></entry>
</list>
</p>

</ss2>
<ss2>
<st>
Probabilistic methods for uncertain reasoning</st>

<p>

<indent level="1">

<it>Main articles: <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../996/203996.xml">
Bayesian network</link></causal_agent>
</worker>
</assistant>
</model>
</person>
</physical_entity>
,&#32;<link xlink:type="simple" xlink:href="../770/98770.xml">
hidden Markov model</link>,&#32;<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<device wordnetid="103183080" confidence="0.8">
<filter wordnetid="103339643" confidence="0.8">
<link xlink:type="simple" xlink:href="../855/180855.xml">
Kalman filter</link></filter>
</device>
</instrumentality>
</artifact>
,&#32;<link xlink:type="simple" xlink:href="../216/446216.xml">
decision theory</link>,&#32;and&#32;<link xlink:type="simple" xlink:href="../479/45479.xml">
utility theory</link></it>
</indent>

Many problems in AI (in reasoning, planning, learning, perception and robotics) require the agent to operate with incomplete or uncertain information. Starting in the late 80s and early 90s, <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../964/699964.xml">
Judea Pearl</link></scientist>
</person>
 and others championed the use of methods drawn from <link xlink:type="simple" xlink:href="../934/22934.xml">
probability</link> theory and <link xlink:type="simple" xlink:href="../223/9223.xml">
economics</link> to devise a number of powerful tools to solve these problems.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22125%22])">125</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22126%22])">126</ref></p>
<p>

<physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../996/203996.xml">
Bayesian network</link></causal_agent>
</worker>
</assistant>
</model>
</person>
</physical_entity>
s<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22127%22])">127</ref>
are very general tool that can be used for a large number of problems: reasoning (using the <link xlink:type="simple" xlink:href="../571/49571.xml">
Bayesian inference</link> algorithm),<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22128%22])">128</ref>
<link xlink:type="simple" xlink:href="../488/233488.xml">
learning</link> (using the <link xlink:type="simple" xlink:href="../752/470752.xml">
expectation-maximization algorithm</link>),<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22129%22])">129</ref>
<link xlink:type="simple" xlink:href="../641/1505641.xml">
planning</link> (using <link xlink:type="simple" xlink:href="../259/1194259.xml">
decision network</link>s)<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22130%22])">130</ref>
and <link xlink:type="simple" xlink:href="../671/11920671.xml">
perception</link> (using <link xlink:type="simple" xlink:href="../713/1242713.xml">
dynamic Bayesian network</link>s).<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22131%22])">131</ref></p>
<p>

Probabilistic algorithms can also be used for filtering, prediction, smoothing and finding explanations for streams of data, helping <link xlink:type="simple" xlink:href="../671/11920671.xml">
perception</link> systems to analyze processes that occur over time<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22132%22])">132</ref>
(e.g., <link xlink:type="simple" xlink:href="../770/98770.xml">
hidden Markov model</link>s<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22133%22])">133</ref>
and <artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<device wordnetid="103183080" confidence="0.8">
<filter wordnetid="103339643" confidence="0.8">
<link xlink:type="simple" xlink:href="../855/180855.xml">
Kalman filter</link></filter>
</device>
</instrumentality>
</artifact>
s<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22134%22])">134</ref>).</p>
<p>

A key concept from the science of <link xlink:type="simple" xlink:href="../133/6639133.xml">
economic</link>s is "<link xlink:type="simple" xlink:href="../479/45479.xml">
utility</link>": a measure of how valuable something is to an intelligent agent. Precise mathematical tools have been developed that analyze how an agent can make choices and plan, using <link xlink:type="simple" xlink:href="../216/446216.xml">
decision theory</link>, <link xlink:type="simple" xlink:href="../842/1190842.xml">
decision analysis</link>,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22135%22])">135</ref>
<link xlink:type="simple" xlink:href="../212/11636212.xml">
information value theory</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22136%22])">136</ref>
These tools include models such as <link xlink:type="simple" xlink:href="../883/1125883.xml">
Markov decision process</link>es,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22137%22])">137</ref>
dynamic <link xlink:type="simple" xlink:href="../259/1194259.xml">
decision network</link>s,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22137%22])">137</ref>
<link xlink:type="simple" xlink:href="../924/11924.xml">
game theory</link> and <link xlink:type="simple" xlink:href="../895/689895.xml">
mechanism design</link><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22138%22])">138</ref></p>

</ss2>
<ss2>
<st>
 Classifiers and statistical learning methods </st>

<p>

<indent level="1">

<it>Main articles: <link xlink:type="simple" xlink:href="../224/1579224.xml">
classifier (mathematics)</link>,&#32;<link xlink:type="simple" xlink:href="../244/1579244.xml">
statistical classification</link>,&#32;and&#32;<link xlink:type="simple" xlink:href="../488/233488.xml">
machine learning</link></it>
</indent>

The simplest AI applications can be divided into two types: classifiers ("if shiny then diamond") and controllers ("if shiny then pick up"). Controllers do however also classify conditions before inferring actions, and therefore classification forms a central part of many AI systems.</p>
<p>

<link xlink:type="simple" xlink:href="../224/1579224.xml">
Classifiers</link><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22139%22])">139</ref>
are functions that use <link xlink:type="simple" xlink:href="../688/279688.xml">
pattern matching</link>  to determine a closest match. They can be tuned according to examples, making them very attractive for use in AI. These examples are known as observations or patterns. In supervised learning, each pattern belongs to a certain predefined class. A class can be seen as a decision that has to be made. All the observations combined with their class labels are known as a data set.</p>
<p>

When a new observation is received, that observation is classified based on previous experience. A classifier can be trained in various ways; there are many statistical and <link xlink:type="simple" xlink:href="../488/233488.xml">
machine learning</link> approaches.</p>
<p>

A wide range of classifiers are available, each with its strengths and weaknesses. Classifier performance depends greatly on the characteristics of the data to be classified. There is no single classifier that works best on all given problems; this is also referred to as the "no free lunch" theorem. Various empirical tests have been performed to compare classifier performance and to find the characteristics of data that determine classifier performance. Determining a suitable classifier for a given problem is however still more an art than science.</p>
<p>

The most widely used classifiers are the <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../523/21523.xml">
neural network</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
,
<link xlink:type="simple" xlink:href="../576/3424576.xml">
kernel methods</link> such as the <link xlink:type="simple" xlink:href="../309/65309.xml">
support vector machine</link>,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22140%22])">140</ref>
<link xlink:type="simple" xlink:href="../388/1775388.xml">
k-nearest neighbor algorithm</link>,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22141%22])">141</ref>
<link xlink:type="simple" xlink:href="../681/871681.xml">
Gaussian mixture model</link>,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22142%22])">142</ref>
<link xlink:type="simple" xlink:href="../339/87339.xml">
naive Bayes classifier</link>,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22143%22])">143</ref>
and <link xlink:type="simple" xlink:href="../602/232602.xml">
decision tree</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22144%22])">144</ref>
The performance of these classifiers have been compared over a wide range of classification tasks<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22145%22])">145</ref>
in order to find data characteristics that determine classifier performance.</p>

</ss2>
<ss2>
<st>
 Neural networks </st>

<p>

<indent level="1">

<it>Main articles: <link>
neural networks</link>&#32;and&#32;<link xlink:type="simple" xlink:href="../636/263636.xml">
connectionism</link></it>
</indent>
<image width="180px" src="Artificial_neural_network.svg" type="thumb">
<caption>

A neural network is an interconnected group of nodes, akin to the vast network of <link xlink:type="simple" xlink:href="../120/21120.xml">
neuron</link>s in the <link xlink:type="simple" xlink:href="../620/490620.xml">
human brain</link>.
</caption>
</image>
</p>
<p>

The study of <link xlink:type="simple" xlink:href="../523/21523.xml">
artificial neural network</link>s<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22146%22])">146</ref>
began in the decade before the field AI research was founded. In the 1960s <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<psychologist wordnetid="110488865" confidence="0.8">
<link xlink:type="simple" xlink:href="../462/1945462.xml">
Frank Rosenblatt</link></psychologist>
</scientist>
</causal_agent>
</person>
</physical_entity>
 developed an important early version, the <link xlink:type="simple" xlink:href="../777/172777.xml">
perceptron</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22147%22])">147</ref>
<physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<link xlink:type="simple" xlink:href="../764/5693764.xml">
Paul Werbos</link></scientist>
</causal_agent>
</person>
</physical_entity>
 developed the <link xlink:type="simple" xlink:href="../091/1360091.xml">
backpropagation</link> algorithm for <link xlink:type="simple" xlink:href="../644/2266644.xml">
multilayer perceptron</link>s in 1974,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22148%22])">148</ref>
which led to a renaissance in neural network research and <link xlink:type="simple" xlink:href="../636/263636.xml">
connectionism</link> in general in the middle 1980s. The <link xlink:type="simple" xlink:href="../097/1170097.xml">
Hopfield net</link>, a form of <link>
attractor network</link>, was first described by <link xlink:type="simple" xlink:href="../572/649572.xml">
John Hopfield</link> in 1982.  </p>
<p>

Common network architectures which have been developed include the <link xlink:type="simple" xlink:href="../332/1706332.xml">
feedforward neural network</link>, the <link xlink:type="simple" xlink:href="../443/9651443.xml">
radial basis network</link>, the Kohonen <link xlink:type="simple" xlink:href="../996/76996.xml">
self-organizing map</link> and various <link xlink:type="simple" xlink:href="../303/1706303.xml">
recurrent neural network</link>s. Neural networks are applied to the problem of <link xlink:type="simple" xlink:href="../488/233488.xml">
learning</link>, using such techniques as <link xlink:type="simple" xlink:href="../084/404084.xml">
Hebbian learning</link>, <link>
competitive learning</link><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22149%22])">149</ref>
and the relatively new field of <link xlink:type="simple" xlink:href="../721/11273721.xml">
Hierarchical Temporal Memory</link> which simulates the architecture of the <link xlink:type="simple" xlink:href="../922/487922.xml">
neocortex</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22150%22])">150</ref></p>

</ss2>
<ss2>
<st>
 Control theory </st>

<p>

<indent level="1">

<it>Main article: <link xlink:type="simple" xlink:href="../104/741104.xml">
intelligent control</link></it>
</indent>

<link xlink:type="simple" xlink:href="../039/7039.xml">
Control theory</link>, the grandchild of <link xlink:type="simple" xlink:href="../904/5904.xml">
cybernetics</link>, has many important applications, especially in <link xlink:type="simple" xlink:href="../673/46673.xml">
robotics</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22151%22])">151</ref></p>

</ss2>
<ss2>
<st>
 Specialized languages </st>

<p>

AI researchers have developed several specialized languages for AI research:</p>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../031/303031.xml">
IPL</link>,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22152%22])">152</ref> includes features intended to support programs that could perform general problem solving, including lists, associations, schemas (frames), dynamic memory allocation, data types, recursion, associative retrieval, functions as arguments, generators (streams), and cooperative multitasking.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../016/18016.xml">
Lisp</link><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22153%22])">153</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22154%22])">154</ref> is a practical mathematical notation for computer programs based on <link xlink:type="simple" xlink:href="../203/18203.xml">
lambda calculus</link>. <link xlink:type="simple" xlink:href="../167/18167.xml">
Linked list</link>s are one of Lisp languages' major <link xlink:type="simple" xlink:href="../519/8519.xml">
data structure</link>s, and Lisp <link xlink:type="simple" xlink:href="../661/27661.xml">
source code</link> is itself made up of lists. As a result, Lisp programs can manipulate source code as a data structure, giving rise to the <idea wordnetid="105833840" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<link xlink:type="simple" xlink:href="../560/20560.xml">
macro</link></concept>
</idea>
 systems that allow programmers to create new syntax or even new <link xlink:type="simple" xlink:href="../239/519239.xml">
domain-specific programming language</link>s embedded in Lisp. There are many dialects of Lisp in use today.</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../485/23485.xml">
Prolog</link>,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22155%22])">155</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22119%22])">119</ref> is a <link xlink:type="simple" xlink:href="../648/210648.xml">
declarative</link> language where programs are expressed in terms of relations, and execution occurs by running <it>queries</it> over these relations. Prolog is particularly useful for symbolic reasoning, database and language parsing applications. Prolog is widely used in AI today.</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../958/1953958.xml">
STRIPS</link>, a language for expressing <link xlink:type="simple" xlink:href="../641/1505641.xml">
automated planning problem instance</link>s. It expresses an initial state, the goal states, and a set of actions. For each action preconditions (what must be established before the action is performed) and postconditions (what is established after the action is performed) are specified.</entry>
<entry level="1" type="bullet">

 <language wordnetid="106282651" confidence="0.8">
<link xlink:type="simple" xlink:href="../143/46143.xml">
Planner</link></language>
 is a hybrid between procedural and logical languages. It gives a procedural interpretation to logical sentences where implications are interpreted with pattern-directed inference.</entry>
</list>

AI applications are also often written in standard languages like <programming_language wordnetid="106898352" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../038/72038.xml">
C++</link></programming_language>
 and languages designed for mathematics, such as <link xlink:type="simple" xlink:href="../412/20412.xml">
Matlab</link> and <programming_language wordnetid="106898352" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../903/989903.xml">
Lush</link></programming_language>
.</p>

</ss2>
</ss1>
<ss1>
<st>
 Evaluating artificial intelligence </st>

<p>

<indent level="1">

<it>Main article: <link xlink:type="simple" xlink:href="../232/16598232.xml">
Progress in artificial intelligence</link></it>
</indent>
How can one determine if an agent is intelligent? In 1950, Alan Turing proposed a general procedure to test the intelligence of an agent now known as the <link xlink:type="simple" xlink:href="../840/43840.xml">
Turing test</link>. This procedure allows almost all the major problems of artificial intelligence to be tested. However, it is a very difficult challenge and at present all agents fail.</p>
<p>

Artificial intelligence can also be evaluated on specific problems such as small problems in chemistry, hand-writing recognition and game-playing. Such tests have been termed <link xlink:type="simple" xlink:href="../165/3682165.xml">
subject matter expert Turing test</link>s. Smaller problems provide more achievable goals and there are an ever-increasing number of positive results.</p>
<p>

The broad classes of outcome for an AI test are:</p>
<p>

<list>
<entry level="1" type="bullet">

 <b>optimal</b>: it is not possible to perform better</entry>
<entry level="1" type="bullet">

 <b>strong super-human</b>: performs better than all humans</entry>
<entry level="1" type="bullet">

 <b>super-human</b>: performs better than most humans</entry>
<entry level="1" type="bullet">

 <b>sub-human</b>: performs worse than most humans</entry>
</list>
</p>
<p>

For example, performance at checkers (<link xlink:type="simple" xlink:href="../459/62459.xml">
draughts</link>) is optimal,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22156%22])">156</ref>
performance at chess is super-human and nearing strong super-human,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22157%22])">157</ref>
and performance at many everyday tasks performed by humans is sub-human.</p>

</ss1>
<ss1>
<st>
 Competitions and prizes </st>

<p>

<indent level="1">

<it>Main article: <link xlink:type="simple" xlink:href="../225/15893225.xml">
Competitions and prizes in artificial intelligence</link></it>
</indent>
There are a number of competitions and prizes to promote research in artificial intelligence. The main areas promoted are: general machine intelligence, conversational behaviour, data-mining, driverless cars, robot soccer and games.</p>

</ss1>
</sec>
<sec>
<st>
 Applications of artificial intelligence </st>

<p>

<indent level="1">

<it>Main article: <link xlink:type="simple" xlink:href="../057/15893057.xml">
Applications of artificial intelligence</link></it>
</indent>

Artificial intelligence has successfully been used in a wide range of fields including <link xlink:type="simple" xlink:href="../767/19013767.xml">
medical diagnosis</link>, <link xlink:type="simple" xlink:href="../607/2785607.xml">
stock trading</link>, <link xlink:type="simple" xlink:href="../885/175885.xml">
robot control</link>, <link xlink:type="simple" xlink:href="../668/18949668.xml">
law</link>, scientific discovery and toys. Frequently, when a technique reaches mainstream use it is no longer considered artificial intelligence, sometimes described as the <link>
AI effect</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22158%22])">158</ref>
It may also become integrated into <link xlink:type="simple" xlink:href="../656/58656.xml">
artificial life</link>.</p>

</sec>
<sec>
<st>
 See also </st>

<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../513/6585513.xml">
List of basic artificial intelligence topics</link></entry>
<entry level="1" type="bullet">

 
Artificial intelligence researchers|List of AI researchers</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../142/2142.xml">
List of AI projects</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../351/454351.xml#xpointer(//*[./st=%22Artificial+intelligence%22])">
List of important AI publications</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../125/13706125.xml">
List of emerging technologies</link></entry>
</list>
</p>


</sec>
<sec>
<st>
 Notes </st>

<p>

<reflist>
<entry id="1">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998%22])">
Poole, Mackworth &amp; Goebel 1998</link>, <weblink xlink:type="simple" xlink:href="http://www.cs.ubc.ca/spider/poole/ci/ch1.pdf">
p. 1</weblink> (who use the term "computational intelligence" as a synonym for artificial intelligence). Other textbooks that define AI this way include <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNilsson1998%22])">
Nilsson (1998)</link>, and <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig (2003)</link> (who prefer the term "rational agent") and write "The whole-agent view is now widely accepted in the field"  <cite class="inline">(<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;55)</cite>
</entry>
<entry id="2">
This definition, in terms of goals, actions, perception and environment, is due to <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig (2003)</link>. Other definitions also include knowledge and learning as additional criteria. See also <weblink xlink:type="simple" xlink:href="http://erg4146.casaccia.enea.it/wwwerg26701/gad-zyt.htm">
<it>Abstract Intelligent Agents: Paradigms, Foundations and Conceptualization Problems''</it></weblink>, A.M. Gadomski, J.M. Zytkow, in "Abstract Intelligent Agent, 2". Printed by ENEA, Rome 1995, ISSN/1120-558X]
</entry>
<entry id="3">
Although there is some controversy on this point (see <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, p.&nbsp;50), <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../362/308362.xml">
McCarthy</link></scientist>
</person>
 states unequivocally "I came up with the term" in a c|net interview. (See <weblink xlink:type="simple" xlink:href="http://news.com.com/Getting+machines+to+think+like+us/2008-11394_3-6090207.html">
Getting Machines to Think Like Us</weblink>.)
</entry>
<entry id="4">
See <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../362/308362.xml">
John McCarthy</link></scientist>
</person>
, <weblink xlink:type="simple" xlink:href="http://www-formal.stanford.edu/jmc/whatisai/whatisai.html">
What is Artificial Intelligence?</weblink>
</entry>
<entry id="5">
This list of intelligent traits is based on the topics covered by the major AI textbooks, including: <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998%22])">
Poole, Mackworth &amp; Goebel 1998</link> and <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNilsson1998%22])">
Nilsson 1998</link>.
</entry>
<entry id="6">
General intelligence (<link xlink:type="simple" xlink:href="../357/586357.xml">
strong AI</link>) is discussed by popular introductions to AI, such as: <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFKurzweil1999%22])">
Kurzweil 1999</link> and <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFKurzweil2005%22])">
Kurzweil 2005</link>
</entry>
<entry id="7">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;5-16
</entry>
<entry id="8">
See <weblink xlink:type="simple" xlink:href="http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Applications">
AI Topics: applications</weblink>
</entry>
<entry id="9">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998%22])">
Poole, Mackworth &amp; Goebel 1998</link>, <weblink xlink:type="simple" xlink:href="http://www.cs.ubc.ca/spider/poole/ci/ch1.pdf">
p. 1</weblink>
</entry>
<entry id="10">
The name of the journal <weblink xlink:type="simple" xlink:href="http://www.computer.org/portal/site/intelligent">
Intelligent Systems</weblink>
</entry>
<entry id="11">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;17
</entry>
<entry id="12">
AI in Myth:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;4-5</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;939</entry>
</list>
</entry>
<entry id="13">
<link xlink:type="simple" xlink:href="../174/3731174.xml">
Sacred statue</link>s as artificial intelligence:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier (1993</link>, p.&nbsp;1) (statue of <belief wordnetid="105941423" confidence="0.8">
<deity wordnetid="109505418" confidence="0.8">
<spiritual_being wordnetid="109504135" confidence="0.8">
<link xlink:type="simple" xlink:href="../789/19230789.xml">
Amun</link></spiritual_being>
</deity>
</belief>
)</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck (2004</link>, pp.&nbsp;6-9) </entry>
</list>
</entry>
<entry id="14">
These were the first machines to be believed to have true intelligence and consciousness. <belief wordnetid="105941423" confidence="0.8">
<deity wordnetid="109505418" confidence="0.8">
<spiritual_being wordnetid="109504135" confidence="0.8">
<link xlink:type="simple" xlink:href="../928/68928.xml">
Hermes Trismegistus</link></spiritual_being>
</deity>
</belief>
 expressed the common belief that with these statues, craftsman had reproduced "the true nature of the gods", their <it>sensus</it> and <it>spiritus</it>. McCorduck makes the connection between sacred automatons and <link xlink:type="simple" xlink:href="../873/13873.xml">
Mosaic law</link> (developed around the same time), which expressly forbids the worship of robots  <cite class="inline">(<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;6-9)</cite>
</entry>
<entry id="15">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNeedham1986%22])">
Needham 1986</link>, p.&nbsp;53
</entry>
<entry id="17">
<weblink xlink:type="simple" xlink:href="http://www.shef.ac.uk/marcoms/eview/articles58/robot.html">
A Thirteenth Century Programmable Robot</weblink>
</entry>
<entry id="16">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;6
</entry>
<entry id="19">
<link xlink:type="simple" xlink:href="../652/1158652.xml">
Takwin</link>: 
O'Connor, Kathleen Malone&#32;(1994).&#32;"<it><weblink xlink:type="simple" xlink:href="http://repository.upenn.edu/dissertations/AAI9503804">
The alchemical creation of life (takwin) and other concepts of Genesis in medieval Islam</weblink></it>". &#32;University of Pennsylvania.&#32;Retrieved on <link>
2007-01-10</link>. 
</entry>
<entry id="18">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;17
</entry>
<entry id="21">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;13-14 
</entry>
<entry id="20">
 
<link xlink:type="simple" xlink:href="../888/11888.xml">
Golem</link>:
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;15-16, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFBuchanan2005%22])">
Buchanan 2005</link>, p.&nbsp;50
</entry>
<entry id="23">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck (2004</link>, p.&nbsp;190-25) discusses <it><literary_composition wordnetid="106364329" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<fiction wordnetid="106367107" confidence="0.8">
<novel wordnetid="106367879" confidence="0.8">
<link xlink:type="simple" xlink:href="../673/18580673.xml">
Frankenstein</link></novel>
</fiction>
</writing>
</written_communication>
</literary_composition>
</it> and identifies the key ethical issues as scientific hubris and the suffering of the monster, i.e. <link xlink:type="simple" xlink:href="../583/13659583.xml">
robot rights</link>.
</entry>
<entry id="22">
This is a central idea of Pamela McCorduck's <it>Machines That Think</it>. She writes: "I like to think of artificial intelligence as the scientific apotheosis of a veneralbe cultural tradition."  <cite class="inline">(<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;34)</cite> "Artificial intelligence in one form or another is an idea that has pervaded Western intellectual history, a dream in urgent need of being realized."  <cite class="inline">(<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;xviii)</cite> "Our history is full of attempts—nutty, eerie, comical, earnest, legendary and real—to make artificial intelligences, to repreduce what is the essential us—bypassing the ordinary means. Back and forth between myth and reality, our imaginations supplying what our workshops couldn't, we have engaged for a long time in this odd form of self-reproduction."  <cite class="inline">(<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;3)</cite> She traces the desire back to its <link xlink:type="simple" xlink:href="../771/13771.xml">
Hellenistic</link> roots and calls it the urge to "forge the Gods."  <cite class="inline">(<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;340-400)</cite>
</entry>
<entry id="25">
See the Times Online, <weblink xlink:type="simple" xlink:href="http://www.timesonline.co.uk/tol/news/uk/science/article1695546.ece">
Human rights for robots? We’re getting carried away</weblink>
</entry>
<entry id="24">
<link xlink:type="simple" xlink:href="../583/13659583.xml">
Robot rights</link>:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;964</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://news.bbc.co.uk/2/hi/technology/6200005.stm">
Robots could demand legal rights</weblink></entry>
</list>
</entry>
<entry id="27">
<link xlink:type="simple" xlink:href="../659/28659.xml">
Singularity</link>, <link xlink:type="simple" xlink:href="../299/30299.xml">
transhumanism</link>: 
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFKurzweil2005%22])">
Kurzweil 2005</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;963</entry>
</list>
</entry>
<entry id="26">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig (2003</link>, p.&nbsp;960-961)
</entry>
<entry id="29">
Quoted in <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck (2004</link>, p.&nbsp;401)
</entry>
<entry id="28">
<link xlink:type="simple" xlink:href="../003/16003.xml">
Joseph Weizenbaum</link>'s critique of AI:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFWeizenbaum1976%22])">
Weizenbaum 1976</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;132−144</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;356-373 </entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;961 </entry>
</list>

Weizenbaum (the AI researcher who developed the first <link xlink:type="simple" xlink:href="../349/148349.xml">
chatterbot</link> program, <link xlink:type="simple" xlink:href="../235/10235.xml">
ELIZA</link>) argued in 1976 that the misuse of artificial intelligence has the potential to devalue human life. 
</entry>
<entry id="31">
<link xlink:type="simple" xlink:href="../646/1124646.xml">
Dartmouth conference</link>:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck%22])">
McCorduck</link>, pp.&nbsp;111-136</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;47-49</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;17</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNRC1999%22])">
NRC 1999</link>, pp.&nbsp;200-201</entry>
</list>
</entry>
<entry id="30">
AI's immediate precursors:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;51-107</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;27-32</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;15,940</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMoravec1988%22])">
Moravec 1988</link>, p.&nbsp;3</entry>
</list>

Among the researchers who laid the foundations of the <link xlink:type="simple" xlink:href="../402/30402.xml">
theory of computation</link>, <link xlink:type="simple" xlink:href="../904/5904.xml">
cybernetic</link>s, <link xlink:type="simple" xlink:href="../773/14773.xml">
information theory</link> and <link>
neural networks</link> were <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../208/1208.xml">
Alan Turing</link></scientist>
</person>
, <link xlink:type="simple" xlink:href="../942/15942.xml">
John Von Neumann</link>, <link xlink:type="simple" xlink:href="../185/63185.xml">
Norbert Weiner</link>, <scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../693/5693.xml">
Claude Shannon</link></scientist>
, <link xlink:type="simple" xlink:href="../508/44508.xml">
Warren McCullough</link>, <link xlink:type="simple" xlink:href="../949/302949.xml">
Walter Pitts</link> and <link xlink:type="simple" xlink:href="../121/323121.xml">
Donald Hebb</link>
</entry>
<entry id="34">
<agency wordnetid="108337324" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../957/8957.xml">
DARPA</link></agency>
 pours money into undirected pure research into AI during the 1960s:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2005%22])">
McCorduck 2005</link>, pp.&nbsp;131</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;51, 64-65</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNRC1999%22])">
NRC 1999</link>, pp.&nbsp;204-205</entry>
</list>
</entry>
<entry id="35">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFSimon1965%22])">
Simon 1965</link>, p.&nbsp;96 quoted in <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, p.&nbsp;109
</entry>
<entry id="32">
Russell and Norvig write "it was astonishing whenever a computer did anything kind of smartish." <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;18
</entry>
<entry id="33">
"<link xlink:type="simple" xlink:href="../560/2894560.xml#xpointer(//*[./st=%22Golden+years%22])">
Golden years</link>" of AI (successful symbolic reasoning programs 1956-1973):
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck%22])">
McCorduck</link>, pp.&nbsp;243-252</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;52-107</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMoravec1988%22])">
Moravec 1988</link>, p.&nbsp;9 </entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;18-21</entry>
</list>

The programs described are <link xlink:type="simple" xlink:href="../635/8383635.xml">
Daniel Bobrow</link>'s <link xlink:type="simple" xlink:href="../997/8511997.xml">
STUDENT</link>, <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../300/287300.xml">
Newell</link></scientist>
</person>
 and <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../205/14205.xml">
Simon</link></scientist>
</person>
's <link xlink:type="simple" xlink:href="../265/13685265.xml">
Logic Theorist</link> and <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<employee wordnetid="110053808" confidence="0.8">
<research_worker wordnetid="110523076" confidence="0.8">
<link xlink:type="simple" xlink:href="../786/192786.xml">
Terry Winograd</link></research_worker>
</employee>
</scientist>
</causal_agent>
</worker>
</person>
</physical_entity>
's <software wordnetid="106566077" confidence="0.8">
<application wordnetid="106570110" confidence="0.8">
<program wordnetid="106568978" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106359877" confidence="0.8">
<code wordnetid="106355894" confidence="0.8">
<coding_system wordnetid="106353757" confidence="0.8">
<link xlink:type="simple" xlink:href="../791/98791.xml">
SHRDLU</link></coding_system>
</code>
</writing>
</written_communication>
</program>
</application>
</software>
.
</entry>
<entry id="38">
First <link xlink:type="simple" xlink:href="../574/3548574.xml">
AI Winter</link>: 
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;115-117 </entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;22 </entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNRC1999%22])">
NRC 1999</link>, pp.&nbsp;212-213</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFHowe1994%22])">
Howe 1994</link></entry>
</list>
</entry>
<entry id="39">
Expert systems:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFACM1998%22])">
ACM 1998</link>, I.2.1,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;22−24</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, pp.&nbsp;227-331,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNilsson1998%22])">
Nilsson 1998</link>, chpt. 17.4</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;327-335, 434-435</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;145-62, 197−203</entry>
</list>
</entry>
<entry id="36">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMinsky1967%22])">
Minsky 1967</link>, p.&nbsp;2 quoted in <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, p.&nbsp;109
</entry>
<entry id="37">
See <link xlink:type="simple" xlink:href="../560/2894560.xml#xpointer(//*[./st=%22The+problems%22])">
History of artificial intelligence — the problems</link>.
</entry>
<entry id="42">
AI applications widely used behind the scenes:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;28 </entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFKurzweil2005%22])">
Kurzweil 2005</link>, p.&nbsp;265</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNRC1999%22])">
NRC 1999</link>, pp.&nbsp;216-222</entry>
</list>
</entry>
<entry id="43">
Formal methods are now preferred ("Victory of the <link xlink:type="simple" xlink:href="../037/404037.xml">
neats</link>"):
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;25-26</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;486-487</entry>
</list>
</entry>
<entry id="40">
Boom of the 1980s: rise of <link xlink:type="simple" xlink:href="../136/10136.xml">
expert systems</link>, <link xlink:type="simple" xlink:href="../832/347832.xml">
Fifth Generation Project</link>, <link xlink:type="simple" xlink:href="../479/6487479.xml">
Alvey</link>, <link xlink:type="simple" xlink:href="../100/3185100.xml">
MCC</link>, <link>
SCI</link>:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;426-441</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;161-162,197-203, 211, 240 </entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;24</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNRC1999%22])">
NRC 1999</link>, pp.&nbsp;210-211</entry>
</list>
</entry>
<entry id="41">
Second <link xlink:type="simple" xlink:href="../574/3548574.xml">
AI Winter</link>:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;430-435</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;209-210</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNRC1999%22])">
NRC 1999</link>, pp.&nbsp;214-216</entry>
</list>
</entry>
<entry id="46">
<link xlink:type="simple" xlink:href="../646/1124646.xml">
Dartmouth proposal</link>: 
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCarthyMinskyRochesterShannon1955%22])">
McCarthy et al. 1955</link> </entry>
</list>
</entry>
<entry id="47">
The physical symbol systems hypothesis:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNewellSimon1976%22])">
Newell &amp; Simon 1976</link>, p.&nbsp;116</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;18</entry>
</list>
</entry>
<entry id="44">
All of these positions below are mentioned in standard discussions of the subject, such as:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;947-960</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFFearn2007%22])">
Fearn 2007</link>, pp.&nbsp;38-55</entry>
</list>
</entry>
<entry id="45">
Philosophical implications of the <link xlink:type="simple" xlink:href="../840/43840.xml">
Turing test</link>:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFTuring1950%22])">
Turing 1950</link>, </entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFHaugeland1985%22])">
Haugeland 1985</link>, pp.&nbsp;6-9, </entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, p.&nbsp;24, </entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;2-3 and 948</entry>
</list>
</entry>
<entry id="51">
The Mathematical Objection:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;949</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;448-449</entry>
</list>

Refuting Mathematical Objection: 
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFTuring1950%22])">
Turing 1950</link> under “(2) The Mathematical Objection”</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFHofstadter1979%22])">
Hofstadter 1979</link>,</entry>
</list>

Making the Mathematical Objection:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLucas1961%22])">
Lucas 1961</link>,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPenrose1989%22])">
Penrose 1989</link>.</entry>
</list>

Background:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREF_G=C3=B6del1931%22])">
Gödel 1931</link>, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFChurch1936%22])">
Church 1936</link>, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFKleene1935%22])">
Kleene 1935</link>, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFTuring1937%22])">
Turing 1937</link>,</entry>
</list>
</entry>
<entry id="50">
This is a paraphrase of the important implication of Gödel's theorems.</entry>
<entry id="49">
Dreyfus' Critique of AI: 
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFDreyfus1972%22])">
Dreyfus 1972</link>,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFDreyfusDreyfus1986%22])">
Dreyfus &amp; Dreyfus 1986</link>, </entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;950-952, </entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;120-132 and </entry>
</list>
</entry>
<entry id="48">
Dreyfus criticized the <link xlink:type="simple" xlink:href="../319/169319.xml">
necessary</link> condition of the <link xlink:type="simple" xlink:href="../999/2685999.xml">
physical symbol system</link> hypothesis, which he called the "psychological assumption": "The mind can be viewed as a device operating on bits of information according to formal rules".  <cite class="inline">(<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFDreyfus1992%22])">
Dreyfus 1992</link>, p.&nbsp;156)</cite></entry>
<entry id="55">
"We cannot yet characterize in general what kinds of computational procedures we want to call intelligent." <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../362/308362.xml">
John McCarthy</link></scientist>
</person>
, <weblink xlink:type="simple" xlink:href="http://www-formal.stanford.edu/jmc/whatisai/node1.html">
Basic Questions</weblink>
</entry>
<entry id="54">
Artificial brain:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMoravec1988%22])">
Moravec 1988</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFKurzweil2005%22])">
Kurzweil 2005</link>, p.&nbsp;262</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig%22])">
Russell Norvig</link>, p.&nbsp;957 </entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;271 and 279</entry>
</list>

The most extreme form of this argument (the brain replacement scenario) was put forward by <link>
Clark Glymour</link> in the mid-70s and was touched on by <philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../182/7644182.xml">
Zenon Pylyshyn</link></philosopher>
 and <philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../079/147079.xml">
John Searle</link></philosopher>
 in 1980. Daniel Dennett sees human consciousness as multiple functional thought patterns; see "Consciousness Explained."
</entry>
<entry id="53">
Searle's <link>
Chinese Room</link> argument:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFSearle1980%22])">
Searle 1980</link>, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFSearle1991%22])">
Searle 1991</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;958-960</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;443-445</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;269-271</entry>
</list>
</entry>
<entry id="52">
This version is from <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFSearle1999%22])">
Searle (1999)</link>, and is also quoted in <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFDennett1991%22])">
Dennett 1991</link>, p.&nbsp;435. Searle's original formulation was "The appropriately programmed computer really is a mind, in the sense that computers given the right programs can be literally said to understand and have other cognitive states."   <cite class="inline">(<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFSearle1980%22])">
Searle 1980</link>, p.&nbsp;1)</cite>. Strong AI is defined similarly by <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig (2003</link>, p.&nbsp;947): "The assertion that machines could possibly act intelligently (or, perhaps better, act as if they were intelligent) is called the 'weak AI' hypothesis by philosophers, and the assertion that machines that do so are actually thinking (as opposed to simulating thinking) is called the 'strong AI' hypothesis."</entry>
<entry id="59">
Several famous examples: 
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFWason1966%22])">
Wason (1966)</link> showed that people do poorly on completely abstract problems, but if the problem is restated to allowed the use of intuitive <link xlink:type="simple" xlink:href="../799/5197799.xml">
social intelligence</link>, performance dramatically improves. (See <puzzle wordnetid="106784639" confidence="0.8">
<message wordnetid="106598915" confidence="0.8">
<subject wordnetid="106599788" confidence="0.8">
<problem wordnetid="106784003" confidence="0.8">
<question wordnetid="106783768" confidence="0.8">
<link xlink:type="simple" xlink:href="../236/823236.xml">
Wason selection task</link></question>
</problem>
</subject>
</message>
</puzzle>
)</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFTverskySlovicKahnemann1982%22])">
Tversky, Slovic &amp; Kahnemann (1982)</link> have shown that people are terrible at elementary problems that involve uncertain reasoning. (See <link xlink:type="simple" xlink:href="../791/510791.xml">
list of cognitive biases</link> for several examples).</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLakoffN=C3=BA=C3=B1ez2000%22])">
Lakoff &amp; Núñez (2000)</link> have controversially argued that even our skills at mathematics depend on knowledge and skills that come from "the body", i.e. sensorimotor and perceptual skills. (See <work wordnetid="104599396" confidence="0.8">
<product wordnetid="104007894" confidence="0.8">
<creation wordnetid="103129123" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<book wordnetid="106410904" confidence="0.8">
<publication wordnetid="106589574" confidence="0.8">
<link xlink:type="simple" xlink:href="../754/45754.xml">
Where Mathematics Comes From</link></publication>
</book>
</artifact>
</creation>
</product>
</work>
)</entry>
</list>
</entry>
<entry id="58">
<link>
Intractability and efficiency</link> and the <link xlink:type="simple" xlink:href="../738/7835738.xml">
combinatorial explosion</link>: 
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;9, 21-22</entry>
</list>
</entry>
<entry id="57">
Uncertain reasoning: 
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;452-644,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998%22])">
Poole, Mackworth &amp; Goebel 1998</link>, pp.&nbsp;345-395,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, pp.&nbsp;333-381,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNilsson1998%22])">
Nilsson 1998</link>, chpt. 19</entry>
</list>
</entry>
<entry id="56">
Problem solving, puzzle solving, game playing and deduction: 
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, chpt. 3-9,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998chpt._2=2C3=2C7=2C9%22])">
Poole et al. chpt. 2,3,7,9</link>,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, chpt. 3,4,6,8,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNilsson%22])">
Nilsson</link>, chpt. 7-12.</entry>
</list>
</entry>
<entry id="63">
Representing events and time:<link xlink:type="simple" xlink:href="../109/2256109.xml">
Situation calculus</link>, <link xlink:type="simple" xlink:href="../680/2897680.xml">
event calculus</link>, <link xlink:type="simple" xlink:href="../091/2961091.xml">
fluent calculus</link> (including solving the <link xlink:type="simple" xlink:href="../306/11306.xml">
frame problem</link>):
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;328-341,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998%22])">
Poole, Mackworth &amp; Goebel 1998</link>, pp.&nbsp;281-298,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNilsson1998%22])">
Nilsson 1998</link>, chpt. 18.2</entry>
</list>
</entry>
<entry id="62">
Representing categories and relations: <link xlink:type="simple" xlink:href="../109/29109.xml">
Semantic network</link>s, <link xlink:type="simple" xlink:href="../503/183503.xml">
description logic</link>s, <link xlink:type="simple" xlink:href="../746/2617746.xml">
inheritance</link> (including <link xlink:type="simple" xlink:href="../067/9924067.xml">
frame</link>s and <link xlink:type="simple" xlink:href="../688/6132688.xml">
scripts</link>):
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;349-354,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998%22])">
Poole, Mackworth &amp; Goebel 1998</link>, pp.&nbsp;174-177,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, pp.&nbsp;248-258,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNilsson1998%22])">
Nilsson 1998</link>, chpt. 18.3</entry>
</list>
</entry>
<entry id="61">
<link xlink:type="simple" xlink:href="../499/458499.xml">
Knowledge engineering</link>: 
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;260-266,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998%22])">
Poole, Mackworth &amp; Goebel 1998</link>, pp.&nbsp;199-233,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNilsson1998%22])">
Nilsson 1998</link>, chpt. ~17.1-17.4</entry>
</list>
</entry>
<entry id="60">
<link xlink:type="simple" xlink:href="../920/16920.xml">
Knowledge representation</link>: 
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFACM1998%22])">
ACM 1998</link>, I.2.4, </entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;320-363,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998%22])">
Poole, Mackworth &amp; Goebel 1998</link>, pp.&nbsp;23-46, 69-81, 169-196, 235-277, 281-298, 319-345,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, pp.&nbsp;227-243, </entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNilsson1998%22])">
Nilsson 1998</link>, chpt. 18</entry>
</list>
</entry>
<entry id="68">
Default reasoning and <link xlink:type="simple" xlink:href="../639/889639.xml">
default logic</link>, <link xlink:type="simple" xlink:href="../086/341086.xml">
non-monotonic logic</link>s, <link xlink:type="simple" xlink:href="../917/2634917.xml">
circumscription</link>, <link xlink:type="simple" xlink:href="../582/2526582.xml">
closed world assumption</link>, <link xlink:type="simple" xlink:href="../304/1304.xml">
abduction</link> (Poole <it>et al.</it> places abduction under "default reasoning". Luger <it>et al.</it> places this under "uncertain reasoning"): 
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;354-360, </entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998%22])">
Poole, Mackworth &amp; Goebel 1998</link>, pp.&nbsp;248-256, 323-335,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, pp.&nbsp;335-363,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNilsson1998%22])">
Nilsson 1998</link>, ~18.3.3</entry>
</list>
</entry>
<entry id="69">
Breadth of commonsense knowledge:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;21,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;113-114,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMoravec1988%22])">
Moravec 1988</link>, p.&nbsp;13,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLenatGuha1989%22])">
Lenat &amp; Guha 1989</link> (Introduction)</entry>
</list>
</entry>
<entry id="70">
<link xlink:type="simple" xlink:href="../641/1505641.xml">
Planning</link>:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFACM1998%22])">
ACM 1998</link>, ~I.2.8,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;375-459,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998%22])">
Poole, Mackworth &amp; Goebel 1998</link>, pp.&nbsp;281-316,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, pp.&nbsp;314-329,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNilsson1998%22])">
Nilsson 1998</link>, chpt. 10.1-2, 22</entry>
</list>
</entry>
<entry id="71">
<link>
Classical planning</link>:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;375-430, </entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998%22])">
Poole, Mackworth &amp; Goebel 1998</link>, pp.&nbsp;281-315, </entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, pp.&nbsp;314-329,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNilsson1998%22])">
Nilsson 1998</link>, chpt. 10.1-2, 22</entry>
</list>
</entry>
<entry id="64">
<link xlink:type="simple" xlink:href="../196/37196.xml#xpointer(//*[./st=%22causal+calculus%22])">
Causal calculus</link>:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998%22])">
Poole, Mackworth &amp; Goebel 1998</link>, pp.&nbsp;335-337</entry>
</list>
</entry>
<entry id="65">
Representing knowledge about knowledge: <link>
Belief calculus</link>, <link xlink:type="simple" xlink:href="../365/333365.xml">
modal logic</link>s:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;341-344,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998%22])">
Poole, Mackworth &amp; Goebel 1998</link>, pp.&nbsp;275-277</entry>
</list>
</entry>
<entry id="66">
<link xlink:type="simple" xlink:href="../681/49681.xml">
Ontology</link>:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;320-328</entry>
</list>
</entry>
<entry id="67">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCarthyHayes1969%22])">
McCarthy &amp; Hayes 1969</link>
</entry>
<entry id="76">
<link xlink:type="simple" xlink:href="../652/21652.xml">
Natural language processing</link>: 
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFACM1998%22])">
ACM 1998</link>, I.2.7</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;790-831</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998%22])">
Poole, Mackworth &amp; Goebel 1998</link>, pp.&nbsp;91-104</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, pp.&nbsp;591-632</entry>
</list>
</entry>
<entry id="77">
Applications of natural language processing, including <link xlink:type="simple" xlink:href="../271/15271.xml">
information retrieval</link> (i.e. <link xlink:type="simple" xlink:href="../439/318439.xml">
text mining</link>) and <link xlink:type="simple" xlink:href="../980/19980.xml">
machine translation</link>:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;840-857,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, pp.&nbsp;623-630</entry>
</list>
</entry>
<entry id="78">
<link xlink:type="simple" xlink:href="../673/46673.xml">
Robotic</link>s:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFACM1998%22])">
ACM 1998</link>, I.2.9,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;901-942,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998%22])">
Poole, Mackworth &amp; Goebel 1998</link>, pp.&nbsp;443-460</entry>
</list>
</entry>
<entry id="79">
Moving and <link xlink:type="simple" xlink:href="../596/473596.xml">
configuration space</link>:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;916-932</entry>
</list>
</entry>
<entry id="72">
Planning and acting in non-deterministic domains: conditional planning, execution monitoring, replanning and continuous planning:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;430-449</entry>
</list>
</entry>
<entry id="73">
Multi-agent planning and emergent behavior:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;449-455</entry>
</list>
</entry>
<entry id="74">
<link xlink:type="simple" xlink:href="../488/233488.xml">
Learning</link>:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFACM1998%22])">
ACM 1998</link>, I.2.6,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;649-788,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998%22])">
Poole, Mackworth &amp; Goebel 1998</link>, pp.&nbsp;397-438,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, pp.&nbsp;385-542,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNilsson1998%22])">
Nilsson 1998</link>, chpt. 3.3 , 10.3, 17.5, 20</entry>
</list>
</entry>
<entry id="75">
<link xlink:type="simple" xlink:href="../294/66294.xml">
Reinforcement learning</link>: 
<list>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;763-788</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, pp.&nbsp;442-449</entry>
</list>
</entry>
<entry id="85">
Emotion and <link xlink:type="simple" xlink:href="../942/233942.xml">
affective computing</link>:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMinsky2007%22])">
Minsky 2007</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPicard1997%22])">
Picard 1997</link></entry>
</list>
</entry>
<entry id="84">
<link xlink:type="simple" xlink:href="../466/14661466.xml">
Object recognition</link>:
<list>
<entry level="1" type="bullet">

  <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;885-892</entry>
</list>
</entry>
<entry id="87">
Fractioning of AI into subfields:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;421-425</entry>
</list>
</entry>
<entry id="86">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFShapiro1992%22])">
Shapiro 1992</link>, p.&nbsp;9
</entry>
<entry id="81">
<link xlink:type="simple" xlink:href="../671/11920671.xml">
Machine perception</link>: <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;537-581, 863-898, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNilsson1998%22])">
Nilsson 1998</link>, ~chpt. 6
</entry>
<entry id="80">
<link xlink:type="simple" xlink:href="../112/623112.xml">
Robotic mapping</link> (localization, etc):
<list>
<entry level="1" type="bullet">

  <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;908-915 </entry>
</list>
</entry>
<entry id="83">
<link xlink:type="simple" xlink:href="../468/29468.xml">
Speech recognition</link>: 
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFACM1998%22])">
ACM 1998</link>, ~I.2.7</entry>
<entry level="1" type="bullet">

  <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;568-578</entry>
</list>
</entry>
<entry id="82">
<link xlink:type="simple" xlink:href="../596/6596.xml">
Computer vision</link>: 
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFACM1998%22])">
ACM 1998</link>, I.2.10</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;863-898</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNilsson1998%22])">
Nilsson 1998</link>, chpt. 6</entry>
</list>
</entry>
<entry id="93">
AI research at <university wordnetid="108286163" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../395/64395.xml">
Edinburgh</link></university>
 and <country wordnetid="108544813" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../419/5843419.xml">
France</link></country>
, birth of <link xlink:type="simple" xlink:href="../485/23485.xml">
Prolog</link>:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;193-196</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFHowe1994%22])">
Howe 1994</link></entry>
</list>
</entry>
<entry id="92">
<person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../362/308362.xml">
McCarthy</link></scientist>
</person>
 and AI research at <point wordnetid="108620061" confidence="0.8">
<institute wordnetid="108407330" confidence="0.8">
<geographic_point wordnetid="108578706" confidence="0.8">
<location wordnetid="100027167" confidence="0.8">
<association wordnetid="108049401" confidence="0.8">
<workplace wordnetid="104602044" confidence="0.8">
<lab wordnetid="103629986" confidence="0.8">
<link xlink:type="simple" xlink:href="../358/310358.xml">
SAIL</link></lab>
</workplace>
</association>
</location>
</geographic_point>
</institute>
</point>
 and <link>
SRI</link>:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;251-259</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;<link>
CHECK</link></entry>
</list>
</entry>
<entry id="95">
<link xlink:type="simple" xlink:href="../037/404037.xml">
Neats vs. scruffies</link>:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;421-424, 486-489</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;168</entry>
</list>
</entry>
<entry id="94">
<link xlink:type="simple" xlink:href="../268/1268.xml">
AI</link> at <link xlink:type="simple" xlink:href="../061/19061.xml">
MIT</link> under <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../639/19639.xml">
Marvin Minsky</link></scientist>
</person>
 in the 1960s :
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;259-305</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;83-102, 163-176 <link>
CHECK</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;19</entry>
</list>
</entry>
<entry id="89">
Cognitive simulation, <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../300/287300.xml">
Newell</link></scientist>
</person>
 and <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../205/14205.xml">
Simon</link></scientist>
</person>
, AI at <link xlink:type="simple" xlink:href="../137/61137.xml">
CMU</link> (then called <link xlink:type="simple" xlink:href="../573/286573.xml">
Carnegie Tech</link>):
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;139-179, 245-250, 322-323 (EPAM)</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier2004%22])">
Crevier 2004</link>, pp.&nbsp;145-149</entry>
</list>
</entry>
<entry id="88">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFHaugeland1985%22])">
Haugeland 1985</link>, pp.&nbsp;112-117
</entry>
<entry id="91">
McCarthy's opposition to "cognitive simulation":
<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://books.google.com/books?id=PEkqAAAAMAAJ&amp;q=%22we+don't+care+if+it's+psychologically+real%22&amp;dq=%22we+don't+care+if+it's+psychologically+real%22&amp;output=html&amp;pgis=1">
Science at Google Books</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.engagingexperience.com/2006/07/ai50_ai_past_pr.html">
McCarthy's presentation at AI@50</weblink></entry>
</list>
</entry>
<entry id="90">
<link xlink:type="simple" xlink:href="../751/729751.xml">
Soar</link> (history):
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;450-451</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;258-263</entry>
</list>
</entry>
<entry id="102">
See <weblink xlink:type="simple" xlink:href="http://www.ieee-cis.org/">
IEEE Computational Intelligence Society</weblink>
</entry>
<entry id="103">
"The whole-agent view is now widely accepted in the field" <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;55.
</entry>
<entry id="100">
<link xlink:type="simple" xlink:href="../169/179169.xml">
Embodied</link> approaches to AI:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;454-462</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFBrooks1990%22])">
Brooks 1990</link> </entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMoravec1988%22])">
Moravec 1988</link></entry>
</list>
</entry>
<entry id="101">
Revival of <link xlink:type="simple" xlink:href="../636/263636.xml">
connectionism</link>:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;214-215</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;25</entry>
</list>
</entry>
<entry id="98">
The most dramatic case of sub-symbolic AI being pushed into the background was the devastating critique of <link xlink:type="simple" xlink:href="../777/172777.xml">
perceptron</link>s by <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../639/19639.xml">
Marvin Minsky</link></scientist>
</person>
 and <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../802/27802.xml">
Seymour Papert</link></scientist>
</person>
 in 1969. See <link xlink:type="simple" xlink:href="../560/2894560.xml">
History of AI</link>, <bubble wordnetid="109229709" confidence="0.8">
<ball wordnetid="113899404" confidence="0.8">
<globule wordnetid="109289709" confidence="0.8">
<sphere wordnetid="113899200" confidence="0.8">
<round_shape wordnetid="113865483" confidence="0.8">
<shape wordnetid="100027807" confidence="0.8">
<link xlink:type="simple" xlink:href="../574/3548574.xml">
AI winter</link></shape>
</round_shape>
</sphere>
</globule>
</ball>
</bubble>
, or <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<psychologist wordnetid="110488865" confidence="0.8">
<link xlink:type="simple" xlink:href="../462/1945462.xml">
Frank Rosenblatt</link></psychologist>
</scientist>
</causal_agent>
</person>
</physical_entity>
.
</entry>
<entry id="99">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNilsson1998%22])">
Nilsson (1998</link>, p.&nbsp;7) characterizes these newer approaches to AI as "sub-symbolic".
</entry>
<entry id="96">
<link xlink:type="simple" xlink:href="../874/6874.xml">
Cyc</link>: 
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;489, who calls it "a determinedly scruffy enterprise"</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;239−243</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;363−365 </entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLenatGuha1989%22])">
Lenat &amp; Guha 1989</link></entry>
</list>
</entry>
<entry id="97">
Knowledge revolution: 
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;266-276, 298-300, 314, 421 </entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;22-23</entry>
</list>
</entry>
<entry id="110">
Uninformed searches (<link xlink:type="simple" xlink:href="../026/97026.xml">
breadth first search</link>, <link xlink:type="simple" xlink:href="../034/97034.xml">
depth first search</link> and general <link xlink:type="simple" xlink:href="../075/546075.xml">
state space search</link>):
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;59-93</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998%22])">
Poole, Mackworth &amp; Goebel 1998</link>, pp.&nbsp;113-132</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, pp.&nbsp;79-121</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNilsson1998%22])">
Nilsson 1998</link>, chpt. 8</entry>
</list>
</entry>
<entry id="111">
<link xlink:type="simple" xlink:href="../452/63452.xml">
Heuristic</link> or informed searches (e.g., greedy <link xlink:type="simple" xlink:href="../271/148271.xml">
best first</link> and <link xlink:type="simple" xlink:href="../558/100558.xml">
A*</link>):
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;94-109,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998%22])">
Poole, Mackworth &amp; Goebel 1998</link>, pp.&nbsp;pp. 132-147,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, pp.&nbsp;133-150,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNilsson1998%22])">
Nilsson 1998</link>, chpt. 9</entry>
</list>
</entry>
<entry id="108">
<system wordnetid="104377057" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<link xlink:type="simple" xlink:href="../962/568962.xml">
Forward chaining</link></instrumentality>
</artifact>
</system>
, <link xlink:type="simple" xlink:href="../967/568967.xml">
backward chaining</link>, <link xlink:type="simple" xlink:href="../824/333824.xml">
Horn clause</link>s, and logical deduction as search:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;217-225, 280-294</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998%22])">
Poole, Mackworth &amp; Goebel 1998</link>, pp.&nbsp;~46-52</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, pp.&nbsp;62-73</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNilsson1998%22])">
Nilsson 1998</link>, chpt. 4.2, 7.2</entry>
</list>
</entry>
<entry id="109">
<event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../075/546075.xml">
State space search</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
 and <link xlink:type="simple" xlink:href="../641/1505641.xml">
planning</link>:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;382-387</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998%22])">
Poole, Mackworth &amp; Goebel 1998</link>, pp.&nbsp;298-305</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNilsson1998%22])">
Nilsson 1998</link>, chpt. 10.1-2</entry>
</list>
</entry>
<entry id="106">
Albus, J. S. <weblink xlink:type="simple" xlink:href="http://www.isd.mel.nist.gov/documents/albus/4DRCS.pdf">
4-D/RCS reference model architecture for unmanned ground vehicles.</weblink> In G Gerhart, R Gunderson, and C Shoemaker, editors, Proceedings of the SPIE AeroSense Session on Unmanned Ground Vehicle Technology, volume 3693, pages 11&mdash;20
</entry>
<entry id="107">
<link xlink:type="simple" xlink:href="../249/28249.xml">
Search algorithm</link>s:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;59-189</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998%22])">
Poole, Mackworth &amp; Goebel 1998</link>, pp.&nbsp;113-163</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, pp.&nbsp;79-164, 193-219</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNilsson1998%22])">
Nilsson 1998</link>, chpt. 7-12</entry>
</list>
</entry>
<entry id="104">
The <link xlink:type="simple" xlink:href="../317/2711317.xml">
intelligent agent</link> paradigm:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;27, 32-58, 968-972,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998%22])">
Poole, Mackworth &amp; Goebel 1998</link>, pp.&nbsp;7-21, </entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, pp.&nbsp;235-240</entry>
</list>
</entry>
<entry id="105">
<structure wordnetid="104341686" confidence="0.8">
<building wordnetid="102913152" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<architecture wordnetid="102734725" confidence="0.8">
<link xlink:type="simple" xlink:href="../677/4510677.xml">
Agent architecture</link></architecture>
</artifact>
</building>
</structure>
s, <link xlink:type="simple" xlink:href="../246/2932246.xml">
hybrid intelligent system</link>s:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig1998%22])">
Russell &amp; Norvig (1998</link>, pp.&nbsp;27, 932, 970-972)</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNilsson1998%22])">
Nilsson (1998</link>, chpt. 25)</entry>
</list>
</entry>
<entry id="119">
History of logic programming:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;190-196.</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFHowe1994%22])">
Howe 1994</link></entry>
</list>

Advice Taker:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;51,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;19</entry>
</list>
</entry>
<entry id="118">
<idea wordnetid="105833840" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<rule wordnetid="105846054" confidence="0.8">
<link xlink:type="simple" xlink:href="../082/2724082.xml">
Resolution</link></rule>
</concept>
</idea>
 and <link xlink:type="simple" xlink:href="../432/54432.xml">
unification</link>:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;213-217, 275-280, 295-306,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998%22])">
Poole, Mackworth &amp; Goebel 1998</link>, pp.&nbsp;56-58,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, pp.&nbsp;554-575,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNilsson1998%22])">
Nilsson 1998</link>, chpt. 14 &amp; 16</entry>
</list>
</entry>
<entry id="117">
<link xlink:type="simple" xlink:href="../225/3729225.xml">
Logic</link>:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFACM1998%22])">
ACM 1998</link>, ~I.2.3,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;194-310,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, pp.&nbsp;35-77,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNilsson1998%22])">
Nilsson 1998</link>, chpt. 13-16</entry>
</list>
</entry>
<entry id="116">
 <cite style="font-style:normal" class="book">Poli, R., Langdon, W. B., McPhee, N. F.&#32;(2008). A Field Guide to Genetic Programming.&#32;Lulu.com, freely available from http://www.gp-field-guide.org.uk/. ISBN 978-1-4092-0073-4.</cite>&nbsp;
</entry>
<entry id="115">
 <cite id="Reference-Koza-1992" style="font-style:normal" class="book">Koza, John R.&#32;(1992). Genetic Programming.&#32;MIT Press.</cite>&nbsp;
</entry>
<entry id="114">
<event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../254/40254.xml">
Genetic algorithm</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
s for learning:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, pp.&nbsp;509-530,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNilsson1998%22])">
Nilsson 1998</link>, chpt. 4.2.</entry>
</list>

See also:
 <cite id="Reference-Holland-1975" style="font-style:normal" class="book">Holland, John H.&#32;(1975). Adaptation in Natural and Artificial Systems.&#32;University of Michigan Press. ISBN 0262581116.</cite>&nbsp;
</entry>
<entry id="113">
<link xlink:type="simple" xlink:href="../656/58656.xml">
Artificial life</link> and society based learning:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, pp.&nbsp;530-541</entry>
</list>
</entry>
<entry id="112">
<link xlink:type="simple" xlink:href="../033/52033.xml">
Optimization</link> searches: 
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;110-116,120-129</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998%22])">
Poole, Mackworth &amp; Goebel 1998</link>, pp.&nbsp;56-163</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, pp.&nbsp;127-133</entry>
</list>
</entry>
<entry id="127">
<physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../996/203996.xml">
Bayesian network</link></causal_agent>
</worker>
</assistant>
</model>
</person>
</physical_entity>
s:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;492-523,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998%22])">
Poole, Mackworth &amp; Goebel 1998</link>, pp.&nbsp;361-381,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, pp.&nbsp;~182-190, ~363-379,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNilsson1998%22])">
Nilsson 1998</link>, chpt. 19.3-4</entry>
</list>
</entry>
<entry id="126">
Stochastic methods for uncertain reasoning:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFACM1998%22])">
ACM 1998</link>, ~I.2.3,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;462-644,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998%22])">
Poole, Mackworth &amp; Goebel 1998</link>, pp.&nbsp;345-395,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, pp.&nbsp;165-191, 333-381,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNilsson1998%22])">
Nilsson 1998</link>, chpt. 19</entry>
</list>
</entry>
<entry id="125">
<person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../964/699964.xml">
Judea Pearl</link></scientist>
</person>
's contribution to AI:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;25-26</entry>
</list>
</entry>
<entry id="124">
<link xlink:type="simple" xlink:href="../180/49180.xml">
Fuzzy logic</link>:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;526-527</entry>
</list>
</entry>
<entry id="123">
<system wordnetid="104377057" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<link xlink:type="simple" xlink:href="../983/10983.xml">
First-order logic</link></instrumentality>
</artifact>
</system>
 and features such as <link xlink:type="simple" xlink:href="../446/90446.xml">
equality</link>:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFACM1998%22])">
ACM 1998</link>, ~I.2.4,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;240-310,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998%22])">
Poole, Mackworth &amp; Goebel 1998</link>, pp.&nbsp;268-275,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, pp.&nbsp;50-62,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNilsson1998%22])">
Nilsson 1998</link>, chpt. 15</entry>
</list>
</entry>
<entry id="122">
<link xlink:type="simple" xlink:href="../335/5597335.xml">
Propositional logic</link>:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;204-233,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, pp.&nbsp;45-50</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNilsson1998%22])">
Nilsson 1998</link>, chpt. 13</entry>
</list>
</entry>
<entry id="121">
<link>
Explanation based learning</link>, <link>
relevance based learning</link>, <link xlink:type="simple" xlink:href="../069/54069.xml">
inductive logic programming</link>, <link xlink:type="simple" xlink:href="../333/170333.xml">
case based reasoning</link>:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;678-710,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998%22])">
Poole, Mackworth &amp; Goebel 1998</link>, pp.&nbsp;414-416,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, pp.&nbsp;~422-442,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNilsson1998%22])">
Nilsson 1998</link>, chpt. 10.3, 17.5</entry>
</list>
</entry>
<entry id="120">
<link xlink:type="simple" xlink:href="../843/2955843.xml">
Satplan</link>:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;402-407,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998%22])">
Poole, Mackworth &amp; Goebel 1998</link>, pp.&nbsp;300-301,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNilsson1998%22])">
Nilsson 1998</link>, chpt. 21</entry>
</list>
</entry>
<entry id="137">
<link xlink:type="simple" xlink:href="../883/1125883.xml">
Markov decision process</link>es and dynamic <link xlink:type="simple" xlink:href="../259/1194259.xml">
decision network</link>s:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;613-631</entry>
</list>
</entry>
<entry id="136">
<link xlink:type="simple" xlink:href="../212/11636212.xml">
Information value theory</link>:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;600-604</entry>
</list>
</entry>
<entry id="139">
Statistical learning methods and <link xlink:type="simple" xlink:href="../224/1579224.xml">
classifiers</link>:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;712-754,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, pp.&nbsp;453-541</entry>
</list>
</entry>
<entry id="138">
<link xlink:type="simple" xlink:href="../924/11924.xml">
Game theory</link> and <link xlink:type="simple" xlink:href="../895/689895.xml">
mechanism design</link>:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;631-643</entry>
</list>
</entry>
<entry id="141">
<event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../388/1775388.xml">
K-nearest neighbor algorithm</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;733-736</entry>
</list>
</entry>
<entry id="140">
<event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../576/3424576.xml">
Kernel methods</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;749-752</entry>
</list>
</entry>
<entry id="143">
<event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../339/87339.xml">
Naive Bayes classifier</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;718</entry>
</list>
</entry>
<entry id="142">
<link xlink:type="simple" xlink:href="../681/871681.xml">
Gaussian mixture model</link>:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;725-727</entry>
</list>
</entry>
<entry id="129">
<link xlink:type="simple" xlink:href="../526/38526.xml">
Bayesian</link> learning and the <link xlink:type="simple" xlink:href="../752/470752.xml">
expectation-maximization algorithm</link>:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;712-724,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998%22])">
Poole, Mackworth &amp; Goebel 1998</link>, pp.&nbsp;424-433,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNilsson1998%22])">
Nilsson 1998</link>, chpt. 20</entry>
</list>
</entry>
<entry id="128">
<link xlink:type="simple" xlink:href="../571/49571.xml">
Bayesian inference</link> algorithm:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;504-519,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998%22])">
Poole, Mackworth &amp; Goebel 1998</link>, pp.&nbsp;361-381,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, pp.&nbsp;~363-379,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNilsson1998%22])">
Nilsson 1998</link>, chpt. 19.4 &amp; 7</entry>
</list>
</entry>
<entry id="131">
<system wordnetid="108435388" confidence="0.8">
<group wordnetid="100031264" confidence="0.8">
<network wordnetid="108434259" confidence="0.8">
<link xlink:type="simple" xlink:href="../713/1242713.xml">
Dynamic Bayesian network</link></network>
</group>
</system>
:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;551-557</entry>
</list>
</entry>
<entry id="130">
<link xlink:type="simple" xlink:href="../526/38526.xml">
Bayesian</link> <link xlink:type="simple" xlink:href="../259/1194259.xml">
decision network</link>s: 
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;597-600</entry>
</list>
</entry>
<entry id="133">
<physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../770/98770.xml">
Hidden Markov model</link></causal_agent>
</worker>
</assistant>
</model>
</person>
</physical_entity>
: 
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;549-551</entry>
</list>
</entry>
<entry id="132">
Stochastic temporal models:
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;537-581
</entry>
<entry id="135">
<link xlink:type="simple" xlink:href="../216/446216.xml">
decision theory</link> and <link xlink:type="simple" xlink:href="../842/1190842.xml">
decision analysis</link>:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;584-597,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998%22])">
Poole, Mackworth &amp; Goebel 1998</link>, pp.&nbsp;381-394</entry>
</list>
</entry>
<entry id="134">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<device wordnetid="103183080" confidence="0.8">
<filter wordnetid="103339643" confidence="0.8">
<link xlink:type="simple" xlink:href="../855/180855.xml">
Kalman filter</link></filter>
</device>
</instrumentality>
</artifact>
:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;551-557</entry>
</list>
</entry>
<entry id="152">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, p.&nbsp;46-48
</entry>
<entry id="153">
<programming_language wordnetid="106898352" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../016/18016.xml">
Lisp</link></programming_language>
:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, pp.&nbsp;723-821</entry>
</list>
</entry>
<entry id="154">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;59-62,
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;18
</entry>
<entry id="155">
<link xlink:type="simple" xlink:href="../485/23485.xml">
Prolog</link>:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998%22])">
Poole, Mackworth &amp; Goebel 1998</link>, pp.&nbsp;477-491,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, pp.&nbsp;641-676, 575-581</entry>
</list>
</entry>
<entry id="156">
Schaeffer, Jonathan&#32;(2007-07-19).&#32;"<weblink xlink:type="simple" xlink:href="http://www.sciencemag.org/cgi/content/abstract/1144079">
Checkers Is Solved</weblink>".&#32;  Science.&#32;Retrieved on <link>
2007-07-20</link>.
</entry>
<entry id="157">
<link>
Computer Chess#Computers versus humans</link>
</entry>
<entry id="158">
"<weblink xlink:type="simple" xlink:href="http://www.cnn.com/2006/TECH/science/07/24/ai.bostrom/">
AI set to exceed human brain power</weblink>"&#32;(web article).&#32;  CNN.com&#32;(2006-07-26).&#32;Retrieved on <link>
2008-02-26</link>.
</entry>
<entry id="144">
<plant wordnetid="100017222" confidence="0.8">
<tree wordnetid="113104059" confidence="0.8">
<vascular_plant wordnetid="113083586" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<woody_plant wordnetid="113103136" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../998/11288998.xml">
Decision tree</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</woody_plant>
</rule>
</event>
</vascular_plant>
</tree>
</plant>
:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;653-664,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998%22])">
Poole, Mackworth &amp; Goebel 1998</link>, pp.&nbsp;403-408,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, pp.&nbsp;408-417</entry>
</list>
</entry>
<entry id="145">
van der Walt, Christiaan.&#32;"<weblink xlink:type="simple" xlink:href="http://www.patternrecognition.co.za/publications/cvdwalt_data_characteristics_classifiers.pdf">
Data characteristics that determine classifier performance</weblink>".
</entry>
<entry id="146">
Neural networks and connectionism:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;736-748,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998%22])">
Poole, Mackworth &amp; Goebel 1998</link>, pp.&nbsp;408-414,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, pp.&nbsp;453-505,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNilsson1998%22])">
Nilsson 1998</link>, chpt. 3</entry>
</list>
</entry>
<entry id="147">
<link xlink:type="simple" xlink:href="../777/172777.xml">
Perceptrons</link>:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;740-743,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, pp.&nbsp;458-467</entry>
</list>
</entry>
<entry id="148">
<link xlink:type="simple" xlink:href="../091/1360091.xml">
Backpropagation</link>:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;744-748,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, pp.&nbsp;467-474,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNilsson1998%22])">
Nilsson 1998</link>, chpt. 3.3</entry>
</list>
</entry>
<entry id="149">
<link>
Competitive learning</link>, <link xlink:type="simple" xlink:href="../084/404084.xml">
Hebbian</link>  coincidence learning, <link xlink:type="simple" xlink:href="../097/1170097.xml">
Hopfield network</link>s and attractor networks:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, pp.&nbsp;474-505.</entry>
</list>
</entry>
<entry id="150">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFHawkinsBlakeslee2004%22])">
Hawkins &amp; Blakeslee 2004</link>
</entry>
<entry id="151">
<link xlink:type="simple" xlink:href="../039/7039.xml">
Control theory</link>:
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFACM1998%22])">
ACM 1998</link>, ~I.2.8,</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;926-932</entry>
</list>
</entry>
</reflist>
</p>

</sec>
<sec>
<st>
 References </st>


<ss1>
<st>
 Major AI textbooks </st>

<p>

<list>
<entry level="1" type="bullet">

  <cite id="CITEREFLugerStubblefield2004" style="font-style:normal"><link>
Luger, George</link>&#32;&amp;&#32;<link>
Stubblefield, William</link>&#32;(2004),&#32;<it><weblink xlink:type="simple" xlink:href="http://www.cs.unm.edu/~luger/ai-final/tocfull.html">
Artificial Intelligence: Structures and Strategies for Complex Problem Solving</weblink></it>&#32;(5th ed.), The Benjamin/Cummings Publishing Company, Inc., ISBN 0-8053-4780-1, </cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFNilsson1998" style="font-style:normal"><link>
Nilsson, Nils</link>&#32;(1998),&#32;<it>Artificial Intelligence: A New Synthesis</it>, Morgan Kaufmann Publishers, ISBN 978-1-55860-467-4</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFRussellNorvig2003" style="font-style:normal"><link>
Russell, Stuart J.</link>&#32;&amp;&#32;<link>
Norvig, Peter</link>&#32;(2003),&#32;<it><weblink xlink:type="simple" xlink:href="http://aima.cs.berkeley.edu/">
</weblink></it>&#32;(2nd ed.), Upper Saddle River, NJ: Prentice Hall, ISBN 0-13-790395-2, </cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFPooleMackworthGoebel1998" style="font-style:normal"><link>
Poole, David</link>; <link>
Mackworth, Alan</link>&#32;&amp;&#32;<link>
Goebel, Randy</link>&#32;(1998),&#32;<it><weblink xlink:type="simple" xlink:href="http://www.cs.ubc.ca/spider/poole/ci.html">
Computational Intelligence: A Logical Approach</weblink></it>, Oxford University Press, </cite>&nbsp;</entry>
</list>
</p>

</ss1>
<ss1>
<st>
 History of AI </st>
<p>

<list>
<entry level="1" type="bullet">

  <cite id="CITEREFCrevier1993" style="font-style:normal"><link>
Crevier, Daniel</link>&#32;(1993),&#32;<it>AI: The Tumultuous Search for Artificial Intelligence</it>, New York, NY: BasicBooks, ISBN 0-465-02997-3</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFMcCorduck2004" style="font-style:normal">McCorduck, Pamela&#32;(2004),&#32;<it><weblink xlink:type="simple" xlink:href="http://www.pamelamc.com/html/machines_who_think.html">
Machines Who Think</weblink></it>&#32;(2nd ed.), Natick, MA: A. K. Peters, Ltd., ISBN 1-56881-205-1, </cite>&nbsp;</entry>
</list>
</p>

</ss1>
<ss1>
<st>
 Other sources </st>
<p>

<list>
<entry level="1" type="bullet">

  <cite id="CITEREFACM1998" style="font-style:normal"><link>
ACM, (Association of Computing Machinery)</link>&#32;(1998),&#32;<it><weblink xlink:type="simple" xlink:href="http://www.acm.org/class/1998/I.2.html">
ACM Computing Classification System: Artificial intelligence</weblink></it>, </cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFBrooks1990" style="font-style:normal"><link>
Brooks, Rodney</link>&#32;(1990),&#32;"<weblink xlink:type="simple" xlink:href="http://people.csail.mit.edu/brooks/papers/elephants.pdf">
Elephants Don't Play Chess</weblink>",&#32;<it>Robotics and Autonomous Systems</it>&#32;<b>6</b>:  3–15, <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1016%2FS0921-8890%2805%2980025-9">
10.1016/S0921-8890(05)80025-9</weblink>, .&#32;Retrieved on 29 August 2007</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFBuchanan2005" style="font-style:normal">Buchanan, Bruce G.&#32;(2005),&#32;"<weblink xlink:type="simple" xlink:href="http://www.aaai.org/AITopics/assets/PDF/AIMag26-04-016.pdf">
A (Very) Brief History of Artificial Intelligence</weblink>",&#32;<it>AI Magazine date = Winter 2005</it>:  53–60, .&#32;Retrieved on 29 August 2007</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFDreyfus1972" style="font-style:normal"><link>
Dreyfus, Hubert</link>&#32;(1972),&#32;<it><work wordnetid="104599396" confidence="0.8">
<product wordnetid="104007894" confidence="0.8">
<creation wordnetid="103129123" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<book wordnetid="106410904" confidence="0.8">
<publication wordnetid="106589574" confidence="0.8">
<link xlink:type="simple" xlink:href="../856/8919856.xml">
What Computers Can't Do</link></publication>
</book>
</artifact>
</creation>
</product>
</work>
</it>, New York: MIT Press, ISBN 0060110821</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFDreyfus1979" style="font-style:normal"><link>
Dreyfus, Hubert</link>&#32;(1979),&#32;<it>What Computers Still Can't Do</it>, New York: MIT Press</cite>&nbsp;.</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFDreyfusDreyfus1986" style="font-style:normal"><link>
Dreyfus, Hubert</link>&#32;&amp;&#32;Dreyfus, Stuart&#32;(1986),&#32;<it>Mind over Machine: The Power of Human Intuition and Expertise in the Era of the Computer</it>, Oxford, UK: Blackwell</cite>&nbsp; </entry>
<entry level="1" type="bullet">

  <cite id="CITEREFHaugeland1985" style="font-style:normal"><link>
Haugeland, John</link>&#32;(1985),&#32;<it>Artificial Intelligence: The Very Idea</it>, Cambridge, Mass.: MIT Press, ISBN 0-262-08153-9</cite>&nbsp;.</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFHawkinsBlakeslee2004" style="font-style:normal"><link>
Hawkins, Jeff</link>&#32;&amp;&#32;Blakeslee, Sandra&#32;(2004),&#32;<it>On Intelligence</it>, New York, NY: Owl Books, ISBN 0-8050-7853-3</cite>&nbsp;.</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFHofstadter1979" style="font-style:normal"><link>
Hofstadter, Douglas</link>&#32;(1979),&#32;</cite>&nbsp;.</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFHowe1994" style="font-style:normal">Howe, J.&#32;(November 1994),&#32;<it><weblink xlink:type="simple" xlink:href="http://www.inf.ed.ac.uk/about/AIhistory.html">
Artificial Intelligence at Edinburgh University: a Perspective</weblink></it>, </cite>&nbsp;.</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFKahnemanSlovicTversky1982" style="font-style:normal"><link>
Kahneman, Daniel</link>; Slovic, D.&#32;&amp;&#32;<link>
Tversky, Amos</link>&#32;(1982),&#32;<it>Judgment under uncertainty: Heuristics and biases</it>, New York: Cambridge University Press</cite>&nbsp;.</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFKurzweil1999" style="font-style:normal"><link>
Kurzweil, Ray</link>&#32;(1999),&#32;<it>The Age of Spiritual Machines</it>, Penguin Books, ISBN 0-670-88217-8</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFKurzweil2005" style="font-style:normal"><link>
Kurzweil, Ray</link>&#32;(2005),&#32;<it>The Singularity is Near</it>, Penguin Books, ISBN 0-670-03384-7</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFLakoff1987" style="font-style:normal"><link>
Lakoff, George</link>&#32;(1987),&#32;<it>Women, Fire, and Dangerous Things: What Categories Reveal About the Mind</it>, University of Chicago Press., ISBN 0-226-46804-6</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFLakoffN.C3.BA.C3.B1ez2000" style="font-style:normal"><link>
Lakoff, George</link>&#32;&amp;&#32;<link>
Núñez, Rafael E.</link>&#32;(2000),&#32;, Basic Books, ISBN 0-465-03771-2</cite>&nbsp;.</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFLenatGuha1989" style="font-style:normal"><link>
Lenat, Douglas</link>&#32;&amp;&#32;Guha, R. V.&#32;(1989),&#32;<it>Building Large Knowledge-Based Systems</it>, Addison-Wesley</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFLighthill1973" style="font-style:normal"><link>
Lighthill, Professor Sir James</link>&#32;(1973),&#32;"Artificial Intelligence: A General Survey",&#32;<it>Artificial Intelligence: a paper symposium</it>, Science Research Council</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFLucas1961" style="font-style:normal"><link>
Lucas, John</link>&#32;(1961),&#32;<weblink xlink:type="simple" xlink:href="http://users.ox.ac.uk/~jrlucas/Godel/mmg.html">
"Minds, Machines and Gödel"</weblink>, in&#32;Anderson, A.R.,&#32;<it>Minds and Machines</it>, </cite>&nbsp;.</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFMcCarthyMinskyRochesterShannon1955" style="font-style:normal"><link>
McCarthy, John</link>; <link>
Minsky, Marvin</link>; <link>
Rochester, Nathan</link>&#32;&amp;&#32;<link>
Shannon, Claude</link>&#32;(1955),&#32;<it><weblink xlink:type="simple" xlink:href="http://www-formal.stanford.edu/jmc/history/dartmouth/dartmouth.html">
A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence</weblink></it>, </cite>&nbsp;.</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFMcCarthyHayes1969" style="font-style:normal"><link>
McCarthy, John</link>&#32;&amp;&#32;Hayes, P. J.&#32;(1969),&#32;"<weblink xlink:type="simple" xlink:href="http://www-formal.stanford.edu/jmc/mcchay69.html">
Some philosophical problems from the standpoint of artificial intelligence</weblink>",&#32;<it>Machine Intelligence</it>&#32;<b>4</b>:  463–502, </cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFMinsky1967" style="font-style:normal"><link>
Minsky, Marvin</link>&#32;(1967),&#32;<it>Computation: Finite and Infinite Machines</it>, Englewood Cliffs, N.J.: Prentice-Hall</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFMinsky2006" style="font-style:normal"><link>
Minsky, Marvin</link>&#32;(2006),&#32;<it>The Emotion Machine</it>, New York, NY: Simon &amp; Schusterl, ISBN 0-7432-7663-9</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFMoravec1976" style="font-style:normal"><link>
Moravec, Hans</link>&#32;(1976),&#32;<it><weblink xlink:type="simple" xlink:href="http://www.frc.ri.cmu.edu/users/hpm/project.archive/general.articles/1975/Raw.Power.html">
The Role of Raw Power in Intelligence</weblink></it>, </cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFMoravec1988" style="font-style:normal"><link>
Moravec, Hans</link>&#32;(1988),&#32;<it>Mind Children</it>, Harvard University Press</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFNRC1999" style="font-style:normal"><link>
NRC</link>&#32;(1999),&#32;"Developments in Artificial Intelligence",&#32;<it>Funding a Revolution: Government Support for Computing Research</it>, National Academy Press</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFNeedham1986" style="font-style:normal">Needham, Joseph&#32;(1986),&#32;<it>Science and Civilization in China: Volume 2</it>, Caves Books Ltd.</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFNewellSimon1963" style="font-style:normal"><link>
Newell, Allen</link>&#32;&amp;&#32;<link>
Simon, H. A.</link>&#32;(1963),&#32;"GPS: A Program that Simulates Human Thought", in&#32;Feigenbaum, E.A.&#32;&amp;&#32;Feldman, J.,&#32;<it>Computers and Thought</it>, McGraw-Hill</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFNewellSimon1976" style="font-style:normal"><link>
Newell, Allen</link>&#32;&amp;&#32;Simon, H. A.&#32;(1976),&#32;<weblink xlink:type="simple" xlink:href="http://www.rci.rutgers.edu/~cfs/472_html/AI_SEARCH/PSS/PSSH4.html">
"Computer Science as Empirical Inquiry: Symbols and Search"</weblink>,&#32;<it>Communications of the ACM</it>, <b>19</b>, </cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFSearle1980" style="font-style:normal"><link>
Searle, John</link>&#32;(1980),&#32;"<weblink xlink:type="simple" xlink:href="http://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html">
Minds, Brains and Programs</weblink>",&#32;<it>Behavioral and Brain Sciences</it>&#32;<b>3</b>(3):  417–457, </cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFSearle1999" style="font-style:normal"><link>
Searle, John</link>&#32;(1999),&#32;<it>Mind, language and society</it>, New York, NY: Basic Books, ISBN 0465045219, <link xlink:type="simple" xlink:href="../885/883885.xml">
OCLC</link> <weblink xlink:type="simple" xlink:href="http://worldcat.org/oclc/231867665+43689264">
231867665 43689264</weblink></cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFShapiro1992" style="font-style:normal">Shapiro, Stuart C.&#32;(1992),&#32;<weblink xlink:type="simple" xlink:href="http://www.cse.buffalo.edu/~shapiro/Papers/ai.ps">
"Artificial Intelligence"</weblink>, in&#32;Shapiro, Stuart C.,&#32;<it>Encyclopedia of Artificial Intelligence</it>&#32;(2nd ed.), New York: John Wiley, pp. 54–57, </cite>&nbsp;.</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFSimon1965" style="font-style:normal"><link>
Simon, H. A.</link>&#32;(1965),&#32;<it>The Shape of Automation for Men and Management</it>, New York: Harper &amp; Row</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFTuring1950" style="font-style:normal"><link>
Turing, Alan</link>&#32;(October 1950),&#32;"<weblink xlink:type="simple" xlink:href="http://loebner.net/Prizef/TuringArticle.html">
Computing Machinery and Intelligence</weblink>",&#32;<it><periodical wordnetid="106593296" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../598/3995598.xml">
Mind</link></periodical>
</it>&#32;<b>LIX</b>(236):  433–460, <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1093%2Fmind%2FLIX.236.433">
10.1093/mind/LIX.236.433</weblink>, <symbol wordnetid="106806469" confidence="0.8">
<standard wordnetid="107260623" confidence="0.8">
<signal wordnetid="106791372" confidence="0.8">
<identifier wordnetid="107270601" confidence="0.8">
<system_of_measurement wordnetid="113577171" confidence="0.8">
<link xlink:type="simple" xlink:href="../930/234930.xml">
ISSN</link></system_of_measurement>
</identifier>
</signal>
</standard>
</symbol>
 <weblink xlink:type="simple" xlink:href="http://worldcat.org/issn/0026-4423">
0026-4423</weblink>, .&#32;Retrieved on 17 August 2008</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFWason1966" style="font-style:normal"><link>
Wason, P. C.</link>&#32;(1966),&#32;"Reasoning", in&#32;Foss, B. M.,&#32;<it>New horizons in psychology</it>, Harmondsworth: Penguin</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFWeizenbaum1976" style="font-style:normal"><link>
Weizenbaum, Joseph</link>&#32;(1976),&#32;<it>Computer Power and Human Reason</it>, San Francisco: W.H. Freeman &amp; Company, ISBN 0716704641</cite>&nbsp;</entry>
</list>
</p>


</ss1>
</sec>
<sec>
<st>
 Further reading </st>
<p>

<list>
<entry level="1" type="bullet">

 R. Sun &amp; L. Bookman, (eds.), <it>Computational Architectures: Integrating Neural and Symbolic Processes</it>. Kluwer Academic Publishers, Needham, MA. 1994.</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../868/1499868.xml">
Margaret Boden</link>, Mind As Machine, <company wordnetid="108058098" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../518/48518.xml">
Oxford University Press</link></company>
, 2006</entry>
<entry level="1" type="bullet">

 John Johnston, (2008) "The Allure of Machinic Life: Cybernetics, Artificial Life, and the New AI", MIT Press</entry>
<entry level="1" type="bullet">

 <link>
Michaela Ong</link>, pioneer of Artificial Intelligence. "Origin of AI through cs191"</entry>
</list>
</p>

</sec>
<sec>
<st>
 External links </st>

<p>

<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-style" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="40x40px" src="Ambox_style.png">
</image>
</p>
</col>
<col style="" class="mbox-text">
 <b>The external links in this article may not follow Wikipedia's  or .</b>
Please <weblink xlink:type="simple" xlink:href="http://localhost:18088/wiki/index.php?title=Artificial_intelligence&amp;action=edit">
improve this article</weblink> by removing excessive or inappropriate external links. </col>
</row>
</table>
</p>

<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.dmoz.org/Computers/Artificial_Intelligence//">
AI</weblink> at the <work wordnetid="100575741" confidence="0.8">
<possession wordnetid="100032613" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<company wordnetid="108058098" confidence="0.8">
<undertaking wordnetid="100795720" confidence="0.8">
<property wordnetid="113244109" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<subsidiary_company wordnetid="108003935" confidence="0.8">
<institution wordnetid="108053576" confidence="0.8">
<link xlink:type="simple" xlink:href="../501/18949501.xml">
Open Directory Project</link></institution>
</subsidiary_company>
</activity>
</psychological_feature>
</act>
</property>
</undertaking>
</company>
</event>
</possession>
</work>
</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.aaai.org/AITopics/">
The Association for the Advancement of Artificial Intelligence (AAAI) - AI Topics</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.vega.org.uk/video/programme/16">
Freeview Video 'Machines with Minds' by the Vega Science Trust and the BBC/OU</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www-formal.stanford.edu/jmc/whatisai/whatisai.html">
John McCarthy's frequently asked questions about AI</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.wfs.org/Dec-janfiles/AIInt.htm">
The Futurist magazine interviews "Ai chasers" Rodney Brooks, Peter Norvig, Barney Pell, et al.</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.aiai.ed.ac.uk/events/jonathanedwards2007/bbc-r4-jonathan-edwards-2007-03-28.mp3">
Jonathan Edwards looks at AI (BBC audio)</weblink>С</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.kurzweilai.net/">
Ray Kurzweil's website dedicated to AI including prediction of future development in AI</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://plato.stanford.edu/entries/logic-ai">
Logic and Artificial Intelligence</weblink> entry in the <it><work wordnetid="104599396" confidence="0.8">
<product wordnetid="104007894" confidence="0.8">
<encyclopedia wordnetid="106427387" confidence="0.8">
<creation wordnetid="103129123" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<book wordnetid="106410904" confidence="0.8">
<reference_book wordnetid="106417598" confidence="0.8">
<publication wordnetid="106589574" confidence="0.8">
<link xlink:type="simple" xlink:href="../356/357356.xml">
Stanford Encyclopedia of Philosophy</link></publication>
</reference_book>
</book>
</artifact>
</creation>
</encyclopedia>
</product>
</work>
</it>&amp;gt; by Richmond Thomason</entry>
</list>
</p>


<p>

<table style=";" class="navbox" cellspacing="0">
<row>
<col style="padding:2px;">
<table style="width:100%;background:transparent;color:inherit;;" class="nowraplinks collapsible autocollapse " cellspacing="0">
<row>
<header colspan="2" style=";" class="navbox-title">
Major fields of <link xlink:type="simple" xlink:href="../816/29816.xml">
Technology</link></header>
</row>
<row style="height:2px;">

</row>
<row>
<col style=";;" class="navbox-group">
<link xlink:type="simple" xlink:href="../386/419386.xml">
Applied science</link></col>
<col style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;padding:0.25em 0; line-height:1.4em;;;" class="navbox-list navbox-odd">
<link xlink:type="simple" xlink:href="../164/1164.xml">
Artificial intelligence</link>&nbsp;·  <link xlink:type="simple" xlink:href="../666/4480666.xml">
Ceramic engineering</link>&nbsp;·  <link xlink:type="simple" xlink:href="../213/5213.xml">
Computing technology</link>&nbsp;·  <link xlink:type="simple" xlink:href="../663/9663.xml">
Electronics</link>&nbsp;·  <link xlink:type="simple" xlink:href="../649/9649.xml">
Energy</link>&nbsp;·  <link xlink:type="simple" xlink:href="../130/24130.xml">
Energy storage</link>&nbsp;·  <link xlink:type="simple" xlink:href="../540/740540.xml">
Engineering physics</link>&nbsp;·  <occupation wordnetid="100582388" confidence="0.8">
<application wordnetid="100949134" confidence="0.8">
<technology wordnetid="100949619" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<profession wordnetid="100609953" confidence="0.8">
<use wordnetid="100947128" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<link xlink:type="simple" xlink:href="../002/1443002.xml">
Environmental technology</link></activity>
</psychological_feature>
</act>
</use>
</profession>
</event>
</technology>
</application>
</occupation>
&nbsp;·  <link xlink:type="simple" xlink:href="../019/1171019.xml">
Fisheries science</link>&nbsp;·  <link xlink:type="simple" xlink:href="../622/19622.xml">
Materials science and engineering</link>&nbsp;·  <idea wordnetid="105833840" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<category wordnetid="105838765" confidence="0.8">
<type wordnetid="105840188" confidence="0.8">
<kind wordnetid="105839024" confidence="0.8">
<link xlink:type="simple" xlink:href="../428/156428.xml">
Microtechnology</link></kind>
</type>
</category>
</concept>
</idea>
&nbsp;·  <link xlink:type="simple" xlink:href="../488/21488.xml">
Nanotechnology</link>&nbsp;·  <link xlink:type="simple" xlink:href="../830/97830.xml">
Nuclear technology</link>&nbsp;·  <knowledge_domain wordnetid="105999266" confidence="0.8">
<discipline wordnetid="105996646" confidence="0.8">
<link xlink:type="simple" xlink:href="../619/372619.xml">
Optics</link></discipline>
</knowledge_domain>
&nbsp;·  <link xlink:type="simple" xlink:href="../611/13787611.xml">
Zoography</link></col>
</row>
<row style="height:2px">

</row>
<row>
<col style=";;" class="navbox-group">
<link xlink:type="simple" xlink:href="../062/18985062.xml">
Information</link></col>
<col style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;padding:0.25em 0; line-height:1.4em;;;" class="navbox-list navbox-even">
<link xlink:type="simple" xlink:href="../257/295257.xml">
Communication</link>&nbsp;·  <link xlink:type="simple" xlink:href="../466/382466.xml">
Graphics</link>&nbsp;·  <link xlink:type="simple" xlink:href="../924/70924.xml">
Music technology</link>&nbsp;·  <link xlink:type="simple" xlink:href="../468/29468.xml">
Speech recognition</link>&nbsp;·  <link xlink:type="simple" xlink:href="../452/190452.xml">
Visual technology</link></col>
</row>
<row style="height:2px">

</row>
<row>
<col style=";;" class="navbox-group">
<link xlink:type="simple" xlink:href="../543/14543.xml">
Industry</link></col>
<col style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;padding:0.25em 0; line-height:1.4em;;;" class="navbox-list navbox-odd">
<link xlink:type="simple" xlink:href="../038/239038.xml">
Construction</link>&nbsp;·  <occupation wordnetid="100582388" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<link xlink:type="simple" xlink:href="../837/2910837.xml">
Financial engineering</link></activity>
</psychological_feature>
</act>
</event>
</occupation>
&nbsp;·  <link xlink:type="simple" xlink:href="../388/39388.xml">
Manufacturing</link>&nbsp;·  <link xlink:type="simple" xlink:href="../462/51462.xml">
Machine</link>ry&nbsp;·  <link xlink:type="simple" xlink:href="../381/20381.xml">
Mining</link>&nbsp;·  <knowledge_domain wordnetid="105999266" confidence="0.8">
<discipline wordnetid="105996646" confidence="0.8">
<link xlink:type="simple" xlink:href="../115/9634115.xml">
Business informatics</link></discipline>
</knowledge_domain>
</col>
</row>
<row style="height:2px">

</row>
<row>
<col style=";;" class="navbox-group">
<link xlink:type="simple" xlink:href="../357/92357.xml">
Military</link></col>
<col style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;padding:0.25em 0; line-height:1.4em;;;" class="navbox-list navbox-even">
<link xlink:type="simple" xlink:href="../621/18940621.xml">
Ammunition</link>&nbsp;·  <link xlink:type="simple" xlink:href="../628/47628.xml">
Bomb</link>s&nbsp;·  <link xlink:type="simple" xlink:href="../650/11650.xml">
Gun</link>s&nbsp;·  <link xlink:type="simple" xlink:href="../493/19493.xml">
Military technology and equipment</link>&nbsp;·  <link xlink:type="simple" xlink:href="../653/76653.xml">
Naval engineering</link></col>
</row>
<row style="height:2px">

</row>
<row>
<col style=";;" class="navbox-group">
<link xlink:type="simple" xlink:href="../429/249429.xml">
Domestic</link></col>
<col style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;padding:0.25em 0; line-height:1.4em;;;" class="navbox-list navbox-odd">
<link xlink:type="simple" xlink:href="../675/1944675.xml">
Educational technology</link>&nbsp;·  <link xlink:type="simple" xlink:href="../883/176883.xml">
Domestic appliances</link>&nbsp;·  <idea wordnetid="105833840" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<category wordnetid="105838765" confidence="0.8">
<type wordnetid="105840188" confidence="0.8">
<kind wordnetid="105839024" confidence="0.8">
<link xlink:type="simple" xlink:href="../425/79425.xml">
Domestic technology</link></kind>
</type>
</category>
</concept>
</idea>
&nbsp;·  <link xlink:type="simple" xlink:href="../646/1636646.xml">
Food technology</link></col>
</row>
<row style="height:2px">

</row>
<row>
<col style=";;" class="navbox-group">
<link xlink:type="simple" xlink:href="../251/9251.xml">
Engineering</link></col>
<col style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;padding:0.25em 0; line-height:1.4em;;;" class="navbox-list navbox-even">
<knowledge_domain wordnetid="105999266" confidence="0.8">
<discipline wordnetid="105996646" confidence="0.8">
<link xlink:type="simple" xlink:href="../991/19231991.xml">
Aerospace</link></discipline>
</knowledge_domain>
&nbsp;·  <knowledge_domain wordnetid="105999266" confidence="0.8">
<discipline wordnetid="105996646" confidence="0.8">
<link xlink:type="simple" xlink:href="../ury/25th_century.xml">
Agricultural</link></discipline>
</knowledge_domain>
&nbsp;·  <link xlink:type="simple" xlink:href="../728/19278728.xml">
Architectural</link>&nbsp;·  <occupation wordnetid="100582388" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<link xlink:type="simple" xlink:href="../478/597478.xml">
Audio</link></activity>
</psychological_feature>
</act>
</event>
</occupation>
&nbsp;·  <link xlink:type="simple" xlink:href="../882/351882.xml">
Automotive</link>&nbsp;·  <link xlink:type="simple" xlink:href="../674/6074674.xml">
Biological</link>&nbsp;·  <link xlink:type="simple" xlink:href="../670/616670.xml">
Biochemical</link>&nbsp;·  <link xlink:type="simple" xlink:href="../827/4827.xml">
Biomedical</link>&nbsp;·  <occupation wordnetid="100582388" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<link xlink:type="simple" xlink:href="../299/768299.xml">
Broadcast</link></activity>
</psychological_feature>
</act>
</event>
</occupation>
&nbsp;·  <link xlink:type="simple" xlink:href="../154/8066154.xml">
Building officials</link>&nbsp;· <link xlink:type="simple" xlink:href="../666/4480666.xml">
Ceramic</link>&nbsp;·  <link xlink:type="simple" xlink:href="../038/6038.xml">
Chemical</link>&nbsp;·  <link xlink:type="simple" xlink:href="../ar)/5762_(H$ebrew_year).xml">
Civil</link>&nbsp;·  <link xlink:type="simple" xlink:href="../408/50408.xml">
Computer</link>&nbsp;·  <occupation wordnetid="100582388" confidence="0.8">
<knowledge_domain wordnetid="105999266" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<discipline wordnetid="105996646" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<link xlink:type="simple" xlink:href="../705/50705.xml">
Construction</link></activity>
</psychological_feature>
</act>
</discipline>
</event>
</knowledge_domain>
</occupation>
&nbsp;·  <link xlink:type="simple" xlink:href="../176/7176.xml">
Cryogenic</link>&nbsp;·  <link xlink:type="simple" xlink:href="../531/9531.xml">
Electrical</link>&nbsp;·  <occupation wordnetid="100582388" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<link xlink:type="simple" xlink:href="../247/219247.xml">
Electronic</link></activity>
</psychological_feature>
</act>
</event>
</occupation>
&nbsp;·  <link xlink:type="simple" xlink:href="../702/50702.xml">
Environmental</link>&nbsp;·  <knowledge_domain wordnetid="105999266" confidence="0.8">
<discipline wordnetid="105996646" confidence="0.8">
<link xlink:type="simple" xlink:href="../853/1515853.xml">
Food</link></discipline>
</knowledge_domain>
&nbsp;·  <link xlink:type="simple" xlink:href="../701/195701.xml">
Industrial</link>&nbsp;·  <link xlink:type="simple" xlink:href="../622/19622.xml">
Materials</link>&nbsp;·  <link xlink:type="simple" xlink:href="../528/19528.xml">
Mechanical</link>&nbsp;·  <link xlink:type="simple" xlink:href="../604/304604.xml">
Mechatronics</link>&nbsp;·  <link xlink:type="simple" xlink:href="../722/19722.xml">
Metallurgical</link>&nbsp;·  <link xlink:type="simple" xlink:href="../361/488361.xml">
Mining</link>&nbsp;·  <idea wordnetid="105833840" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<category wordnetid="105838765" confidence="0.8">
<type wordnetid="105840188" confidence="0.8">
<kind wordnetid="105839024" confidence="0.8">
<link xlink:type="simple" xlink:href="../653/76653.xml">
Naval</link></kind>
</type>
</category>
</concept>
</idea>
&nbsp;·  <link xlink:type="simple" xlink:href="../407/41407.xml">
Network</link>&nbsp;·  <link xlink:type="simple" xlink:href="../207/37207.xml">
Nuclear</link>&nbsp;·  <knowledge_domain wordnetid="105999266" confidence="0.8">
<discipline wordnetid="105996646" confidence="0.8">
<link xlink:type="simple" xlink:href="../619/372619.xml">
Optical</link></discipline>
</knowledge_domain>
&nbsp;·  <knowledge_domain wordnetid="105999266" confidence="0.8">
<discipline wordnetid="105996646" confidence="0.8">
<link xlink:type="simple" xlink:href="../465/65465.xml">
Petroleum</link></discipline>
</knowledge_domain>
&nbsp;·  <link xlink:type="simple" xlink:href="../805/13485805.xml">
Radio Frequency</link>&nbsp;·  <link xlink:type="simple" xlink:href="../010/27010.xml">
Software</link>&nbsp;·  <occupation wordnetid="100582388" confidence="0.8">
<knowledge_domain wordnetid="105999266" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<discipline wordnetid="105996646" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<link xlink:type="simple" xlink:href="../829/45829.xml">
Structural</link></activity>
</psychological_feature>
</act>
</discipline>
</event>
</knowledge_domain>
</occupation>
&nbsp;·  <link xlink:type="simple" xlink:href="../764/27764.xml">
Systems</link>&nbsp;·  <creation wordnetid="103129123" confidence="0.8">
<text wordnetid="106387980" confidence="0.8">
<occupation wordnetid="100582388" confidence="0.8">
<document wordnetid="103217458" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<letter wordnetid="106624161" confidence="0.8">
<representation wordnetid="104076846" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<link xlink:type="simple" xlink:href="../477/6997477.xml">
Technician</link></activity>
</psychological_feature>
</act>
</event>
</representation>
</letter>
</artifact>
</document>
</occupation>
</text>
</creation>
&nbsp;·  <knowledge_domain wordnetid="105999266" confidence="0.8">
<discipline wordnetid="105996646" confidence="0.8">
<link xlink:type="simple" xlink:href="../420/3696420.xml">
Textile</link></discipline>
</knowledge_domain>
&nbsp;·  <link xlink:type="simple" xlink:href="../065/307065.xml">
Tissue</link>&nbsp;·  <link xlink:type="simple" xlink:href="../571/50571.xml">
Transport</link></col>
</row>
<row style="height:2px">

</row>
<row>
<col style=";;" class="navbox-group">
<link xlink:type="simple" xlink:href="../381/80381.xml">
Health and</link>&nbsp;<link xlink:type="simple" xlink:href="../712/252712.xml">
safety</link></col>
<col style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;padding:0.25em 0; line-height:1.4em;;;" class="navbox-list navbox-odd">
<link xlink:type="simple" xlink:href="../827/4827.xml">
Biomedical&nbsp;engineering</link>&nbsp;·  <link xlink:type="simple" xlink:href="../214/4214.xml">
Bioinformatics</link>&nbsp;·  <link xlink:type="simple" xlink:href="../502/4502.xml">
Biotechnology</link>&nbsp;·  <link xlink:type="simple" xlink:href="../697/575697.xml">
Cheminformatics</link>&nbsp;·  <link xlink:type="simple" xlink:href="../359/2195359.xml">
Fire protection engineering</link>&nbsp;·  <link xlink:type="simple" xlink:href="../643/50643.xml">
Health&nbsp;technologies</link>&nbsp;·  <link xlink:type="simple" xlink:href="../525/21525.xml">
Nutrition</link>&nbsp;·  <link xlink:type="simple" xlink:href="../354/24354.xml">
Pharmaceuticals</link>&nbsp;·  <link xlink:type="simple" xlink:href="../278/29278.xml">
Safety engineering</link>&nbsp;·  <idea wordnetid="105833840" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<knowledge_domain wordnetid="105999266" confidence="0.8">
<discipline wordnetid="105996646" confidence="0.8">
<link xlink:type="simple" xlink:href="../361/8416361.xml">
Sanitary engineering</link></discipline>
</knowledge_domain>
</concept>
</idea>
</col>
</row>
<row style="height:2px">

</row>
<row>
<col style=";;" class="navbox-group">
<link xlink:type="simple" xlink:href="../879/18580879.xml">
Transport</link></col>
<col style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;padding:0.25em 0; line-height:1.4em;;;" class="navbox-list navbox-even">
<link xlink:type="simple" xlink:href="../711/154711.xml">
Aerospace</link>&nbsp;·  <knowledge_domain wordnetid="105999266" confidence="0.8">
<discipline wordnetid="105996646" confidence="0.8">
<link xlink:type="simple" xlink:href="../991/19231991.xml">
Aerospace engineering</link></discipline>
</knowledge_domain>
&nbsp;·  <link xlink:type="simple" xlink:href="../882/351882.xml">
Automotive engineering</link>&nbsp;·  <occupation wordnetid="100582388" confidence="0.8">
<knowledge_domain wordnetid="105999266" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<discipline wordnetid="105996646" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<link xlink:type="simple" xlink:href="../882/44882.xml">
Marine engineering</link></activity>
</psychological_feature>
</act>
</discipline>
</event>
</knowledge_domain>
</occupation>
&nbsp;·  <link xlink:type="simple" xlink:href="../095/145095.xml">
Motor vehicle</link>s&nbsp;·  <link xlink:type="simple" xlink:href="../375/40375.xml">
Space technology</link></col>
</row>
</table>
</col>
</row>
</table>
</p>



</sec>
</bdy>
</article>
