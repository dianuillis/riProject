<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 18:15:16[mciao0826] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Boltzmann machine</title>
<id>1166059</id>
<revision>
<id>243253951</id>
<timestamp>2008-10-05T20:19:09Z</timestamp>
<contributor>
<username>DaveWF</username>
<id>356401</id>
</contributor>
</revision>
<categories>
<category>Neural networks</category>
</categories>
</header>
<bdy>

A <b>Boltzmann machine</b> is the name given to a type of <link xlink:type="simple" xlink:href="../605/2070605.xml">
stochastic recurrent neural network</link> by <physical_entity wordnetid="100001930" confidence="0.8">
<peer wordnetid="109626238" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<colleague wordnetid="109935990" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<research_worker wordnetid="110523076" confidence="0.8">
<associate wordnetid="109816771" confidence="0.8">
<link xlink:type="simple" xlink:href="../174/507174.xml">
Geoffrey Hinton</link></associate>
</research_worker>
</scientist>
</causal_agent>
</colleague>
</person>
</peer>
</physical_entity>
 and <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<research_worker wordnetid="110523076" confidence="0.8">
<link xlink:type="simple" xlink:href="../552/1171552.xml">
Terry Sejnowski</link></research_worker>
</scientist>
</causal_agent>
</person>
</physical_entity>
.  Boltzmann machines can be seen as the <link xlink:type="simple" xlink:href="../895/47895.xml">
stochastic</link>, <link xlink:type="simple" xlink:href="../578/1222578.xml">
generative</link> counterpart of <link xlink:type="simple" xlink:href="../097/1170097.xml">
Hopfield net</link>s.  They were one of the first examples of a neural network capable of learning internal representations, and are able to represent and (given sufficient time) solve difficult combinatoric problems.  However, due to a number of issues discussed below, Boltzmann machines with unconstrained connectivity have not proven useful for practical problems in machine learning or inference.  They are still theoretically intriguing, however, due to the locality and <link xlink:type="simple" xlink:href="../084/404084.xml">
Hebbian</link> nature of their training algorithm, as well as their parallelism and the resemblance of their dynamics to simple physical processes. If the connectivity is constrained, the learning can be made efficient enough to be useful for practical problems.
<sec>
<st>
Structure</st>

<p>

A Boltzmann machine, like a <link xlink:type="simple" xlink:href="../097/1170097.xml">
Hopfield Network</link>, is a network of units with an "energy" defined for the network. It also has  units, but unlike Hopfield nets, Boltzmann machine units are <link xlink:type="simple" xlink:href="../222/292222.xml">
stochastic</link>. The global energy, <math>E</math>, in a Boltzmann machine is identical in form to that of a Hopfield network:</p>
<p>

<indent level="1">

<math>E = -\sum_{i&amp;lt;j} w_{ij} \, s_i \, s_j + \sum_i \theta_i \, s_i</math>
</indent>

Where:
<list>
<entry level="1" type="bullet">

 <math>w_{ij}</math> is the connection strength between unit <math>j</math> and unit <math>i</math>.</entry>
<entry level="1" type="bullet">

 <math>s_i</math> is the state, <math>s_i \in \{0,1\}</math>, of unit <math>i</math>.</entry>
<entry level="1" type="bullet">

 <math>\theta_i</math> is the <link xlink:type="simple" xlink:href="../791/41791.xml">
threshold</link> of unit <math>i</math>.</entry>
</list>
</p>
<p>

The connections in a Boltzmann machine have two restrictions:
<list>
<entry level="1" type="bullet">

 <math>w_{ii}=0 \qquad \forall i</math>. (No unit has a connection with itself.)</entry>
<entry level="1" type="bullet">

 <math>w_{ij}=w_{ji}\qquad \forall i,j</math>. (All connections are <link xlink:type="simple" xlink:href="../741/53741.xml">
symmetric</link>.)</entry>
</list>
</p>
<p>

Thus, the difference in the global energy that results from a single unit <math>i</math> being 0 versus 1, written <math>\Delta E_i</math>, is given by:</p>
<p>

<indent level="1">

<math>\Delta E_i = \sum_j w_{ij} \, s_j - \theta_i</math>
</indent>

A Boltzmann machine is made up of stochastic units. The probability, <math>p_i</math> of the <math>i</math>-th unit being on is given by:</p>
<p>

<indent level="1">

<math>p_i = \frac{1}{1+\exp (-\frac{1}{T} \Delta E_i)}</math>
</indent>

where the <link xlink:type="simple" xlink:href="../425/3588425.xml">
scalar</link> <math>T</math> is referred to as the <link xlink:type="simple" xlink:href="../300/19572300.xml">
temperature</link> of the system.</p>
<p>

The network is run by repeatedly choosing a unit and setting its state according to the above formula.  After running for long enough at a certain temperature, the probability of a global state of the network will depend only upon that global state's energy, according to a <link xlink:type="simple" xlink:href="../107/4107.xml">
Boltzmann distribution</link>.  This means that log-probabilities of global states become linear in their energies.  This relationship is true when the machine is "at <link>
thermal equilibrium</link>", meaning that the probability distribution of global states has converged.  If we start running the network from a high temperature, and gradually decrease it until we reach a <link>
thermal equilibrium</link> at a low temperature, we are guaranteed to converge to a distribution where the energy level fluctuates around the global minimum.  This process is called <link xlink:type="simple" xlink:href="../244/172244.xml">
simulated annealing</link>.</p>
<p>

If we want to train the network so that the chance it will converge to a global state is according to an external distribution that we have over these states, we need to set the weights so that the global states with the highest probabilities will get the lowest energies.  This is done by the following training procedure.</p>

</sec>
<sec>
<st>
Training</st>

<p>

The units in the Boltzmann Machine are divided into "visible" units, V, and "hidden" units, H. The visible units are those which receive information from the "environment", i.e. our training set is a set of binary vectors over the set V.  The distribution over the training set is denoted <math>P^{+}(V)</math>.  </p>
<p>

On the Boltzmann Machine side, as recalled, the distribution over the global states is converging as we reach a <link>
thermal equilibrium</link>.  We denote the converged distribution, after we marginalize it over the visible units <math>V</math>, as <math>P^{-}(V)</math>.  </p>
<p>

Our goal is to approximate the "real" distribution <math>P^{+}(V)</math> using the <math>P^{-}(V)</math> which will be produced (eventually) by the machine.  To measure how similar the two distributions are we use the <link xlink:type="simple" xlink:href="../527/467527.xml">
Kullback-Leibler distance</link>, <math>G</math>:</p>
<p>

<indent level="1">

<math>G = \sum_{v}{P^{+}(v)\ln{\frac{P^{+}(v)}{P^{-}(v)}}}</math>
</indent>

Where the sum is over all the possible states of <math>V</math>.  <math>G</math> is a function of the weights, since they determine the energy of a state, and the energy determines <math>P^{-}(v)</math>, as promised by the <link xlink:type="simple" xlink:href="../107/4107.xml">
Boltzmann distribution</link>.  Hence, we can use a <link xlink:type="simple" xlink:href="../489/201489.xml">
gradient descent</link> algorithm over <math>G</math>, so a given weight, <math>w_{ij}</math> is changed by subtracting the <link xlink:type="simple" xlink:href="../565/52565.xml">
partial derivative</link> of <math>G</math> with respect to the weight. </p>
<p>

There are two phases to Boltzmann machine training, and we switch iteratively between them. One is the "positive" phase where the visible units' states are clamped to a particular binary state vector sampled from the training set (according to <math>P^{+}</math>).  The other is the "negative" phase where the network is allowed to run freely, i.e. no units have their state determined by external data.  Surprisingly enough, the gradient with respect to a given weight, <math>w_{ij}</math>, is given by the very simple equation (proved in Ackley et al.):</p>
<p>

<indent level="1">

<math>\frac{\partial{G}}{\partial{w_{ij}}} = \frac{1}{T}[p_{ij}^{+}-p_{ij}^{-}]</math>
</indent>

Where:
<list>
<entry level="1" type="bullet">

 <math>p_{ij}^{+}</math> is the probability of units <it>i</it> and <it>j</it> both being on when the machine is at equilibrium on the positive phase. </entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <math>p_{ij}^{-}</math> is the probability of units <it>i</it> and <it>j</it> both being on when the machine is at equilibrium on the negative phase. </entry>
</list>
</p>
<p>

This result follows from the fact that at the <link>
thermal equilibrium</link> the probability <math>P^{-}(s)</math> of any global state <math>s</math> when the network is free-running is given by the <link xlink:type="simple" xlink:href="../107/4107.xml">
Boltzmann distribution</link> (hence the name "Boltzmann machine").  </p>
<p>

Remarkably, this learning rule is fairly biologically plausible because the only information needed to change the weights is provided by "local" information. That is, the connection (or <link xlink:type="simple" xlink:href="../809/27809.xml">
synapse</link> biologically speaking) does not need information about anything other than the two neurons it connects. This is far more biologically realistic than the information needed by a connection in many other neural network training algorithms, such as <link xlink:type="simple" xlink:href="../091/1360091.xml">
backpropagation</link>.</p>
<p>

The training of a Boltzmann machines can also be viewed as an application of the <link xlink:type="simple" xlink:href="../752/470752.xml">
EM algorithm</link>, which is heavily used in <link xlink:type="simple" xlink:href="../488/233488.xml">
machine learning</link>.  We are given an incomplete dataset (we only know the values of the visible units).  At the positive phase, we estimate the completed data based on the current parameters of the system (the weights).  Later, the weights are updated to maximize the probability of the network producing the completed data.</p>
<p>

Training the biases is similar, but uses only single node activity:</p>
<p>

<indent level="1">

<math>\frac{\partial{G}}{\partial{\theta_{i}}} = -\frac{1}{T}[p_{i}^{+}-p_{i}^{-}]</math>
</indent>

</p>
</sec>
<sec>
<st>
Problems</st>

<p>

If it worked, the Boltzmann machine would be a rather general computational medium.  For instance, if trained on photographs, the machine would model the distribution of photographs, and could use that model to, for example, complete a partial photograph.</p>
<p>

Unfortunately, there is a serious practical problem with the Boltzmann machine, namely that the learning seems to stop working correctly when the machine is scaled up to anything larger than a trivial machine.  This is due to a number of effects, the most important of which are:</p>
<p>

<list>
<entry level="1" type="bullet">

 the time the machine must be run in order to collect equilibrium statistics grows exponentially with the machine's size, and with the magnitude of the connection strengths</entry>
<entry level="1" type="bullet">

 connection strengths are more plastic when the units being connected have activation probabilities intermediate between zero and one, leading to a so-called <link>
variance trap</link>.  The net effect is that noise causes the connection strengths to random walk until the activities saturate.</entry>
</list>
</p>

</sec>
<sec>
<st>
Restricted Boltzmann Machine</st>
<p>

Although learning is impractical in general Boltzmann machines, it can be made quite efficient in 
an architecture called the "Restricted Boltzmann Machine" or "RBM" which does not allow connections between hidden units. After learning one RBM, the activities of its hidden units can be treated as data 
for training a higher-level RBM. This method of stacking RBM's makes it possible to learn many layers of hidden units efficiently and as each new layer is added the overall generative model gets better.</p>


</sec>
<sec>
<st>
History</st>

<p>

The Boltzmann machine is a <technique wordnetid="105665146" confidence="0.8">
<know-how wordnetid="105616786" confidence="0.8">
<method wordnetid="105660268" confidence="0.8">
<link xlink:type="simple" xlink:href="../098/56098.xml">
Monte Carlo</link></method>
</know-how>
</technique>
 version of the <link xlink:type="simple" xlink:href="../097/1170097.xml">
Hopfield net</link>work.</p>
<p>

The idea of using annealed <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../744/292744.xml">
Ising model</link></causal_agent>
</worker>
</assistant>
</model>
</person>
</physical_entity>
s for inference is often thought to have originated from <link xlink:type="simple" xlink:href="../174/507174.xml">
Geoff Hinton</link>, in the following papers:  </p>
<p>

<list>
<entry level="1" type="bullet">

 Geoffrey E. Hinton and Terrence J. Sejnowski, Analyzing Cooperative Computation. In Proceedings of the 5th Annual Congress of the Cognitive Science Society, Rochester, NY, May 1983.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 Geoffrey E. Hinton and Terrence J. Sejnowski, Optimal Perceptual Inference. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition (CVPR), pages 448-453, IEEE Computer Society, Washington DC, June 1983.</entry>
</list>
</p>
<p>

However the same idea of applying the Ising model with annealed Gibbs sampling is also present in <person wordnetid="100007846" confidence="0.9508927676800064">
<professor wordnetid="110480730" confidence="0.9173553029164789">
<writer wordnetid="110794014" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../758/8758.xml">
Douglas Hofstadter</link></writer>
</professor>
</person>
's <link>
Copycat</link> project, described in the following two papers:</p>
<p>

<list>
<entry level="1" type="bullet">

 Hofstadter, Douglas R., The Copycat Project: An Experiment in Nondeterminism and Creative Analogies. MIT Artificial Intelligence Laboratory Memo No. 755, January 1984.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 Hofstadter, Douglas R., A Non-Deterministic Approach to Analogy, Involving the Ising Model of Ferromagnetism. In E. Caianiello, ed. The Physics of Cognitive Processes. Teaneck, NJ: World Scientific, 1987.</entry>
</list>
</p>
<p>

It seems probable that these works were conducted independently, reflecting general interest in the ideas by a wide community at the time.  Hinton went on to build and obtain funding for a large community around the ideas, whereas Hofstadter is funded mostly as an individual to continue his version in the <link>
Copycat</link> family of models.  For these reasons the Hinton terminology has become standard for a larger group of researchers.</p>
<p>

Ising models are now considered to be a special case of <link xlink:type="simple" xlink:href="../985/1323985.xml">
Markov random field</link>s, which do find widespread application in various fields, including linguistics, robotics and AI.</p>

</sec>
<sec>
<st>
References</st>
<p>

<list>
<entry level="1" type="bullet">

 Ackley, D. H., Hinton, G. E., Sejnowski, T. J. (1985), "A Learning Algorithm for Boltzmann Machines", <it>Cognitive Science</it>, 9: 147-169.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 Hinton, G. E., Sejnowski, T. J. (1986), "Learning and Relearning in Boltzmann Machines". In D. E. Rumelhart, J. L. McClelland, and the PDP Research Group, <it>Parallel Distributed Processing: Explorations in the Microstructure of Cognition. Volume 1: Foundations</it>, pp 282-317. Cambridge: MIT Press.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 Hinton, G. E.(2002), "Training Products of Experts by Minimizing Contrastive Divergence", <it>Neural Computation</it>, 14: 1771-1800.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 Hinton, G. E., Osindero, S., Teh, Y. (2006), "A fast learning algorithm for deep belief nets", <it>Neural Computation</it>, 18: 1527-1554.<weblink xlink:type="simple" xlink:href="http://www.cs.toronto.edu/~hinton/absps/fastnc.pdf">
http://www.cs.toronto.edu/~hinton/absps/fastnc.pdf</weblink></entry>
</list>
</p>

</sec>
<sec>
<st>
 External links </st>
<p>

<list>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.scholarpedia.org/article/Boltzmann_Machine">
Scholarpedia article by Hinton about Boltzmann machines</weblink></entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://youtube.com/watch?v=AyzOUbkUf3M">
Speech at Google by Geoffrey Hinton</weblink></entry>
</list>
</p>

</sec>
</bdy>
</article>
