<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 17.04.2009 00:59:44[mciao0827] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<body  confidence="0.8" wordnetid="107965085">
<university  confidence="0.8" wordnetid="108286163">
<social_group  confidence="0.8" wordnetid="107950920">
<group  confidence="0.8" wordnetid="100031264">
<header>
<title>Faculty Scholarly Productivity Index</title>
<id>11759510</id>
<revision>
<id>216279542</id>
<timestamp>2008-05-31T22:56:03Z</timestamp>
<contributor>
<username>DumZiBoT</username>
<id>6085301</id>
</contributor>
</revision>
<categories>
<category>Articles with invalid date parameter in template</category>
<category>All pages needing to be wikified</category>
<category>Wikify from July 2007</category>
<category>Educational assessment and evaluation</category>
<category>University and college rankings</category>
<category>Universities and colleges in the United States</category>
</categories>
</header>
<bdy>
<p>

<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-style" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="50px" src="Wikitext.svg">
</image>
</p>
</col>
<col style="" class="mbox-text">
 <b>Please  this article or section.</b>
Help <weblink xlink:type="simple" xlink:href="http://localhost:18088/wiki/index.php?title=Faculty_Scholarly_Productivity_Index&amp;action=edit">
improve this article</weblink> by adding  . <it>(July 2007)''</it></col>
</row>
</table>


The <b>Faculty Scholarly Productivity Index</b>, a product of <link xlink:type="simple" xlink:href="../275/13292275.xml">
Academic Analytics</link>, is a metric designed to create benchmark standards for the measurement of academic and scholarly quality within and among <body wordnetid="107965085" confidence="0.8">
<social_group wordnetid="107950920" confidence="0.8">
<political_orientation wordnetid="106212839" confidence="0.8">
<colony wordnetid="108374049" confidence="0.8">
<state wordnetid="108168978" confidence="0.8">
<political_unit wordnetid="108359949" confidence="0.8">
<group wordnetid="100031264" confidence="0.8">
<democracy wordnetid="106217103" confidence="0.8">
<link xlink:type="simple" xlink:href="../750/3434750.xml">
United States</link></democracy>
</group>
</political_unit>
</state>
</colony>
</political_orientation>
</social_group>
</body>
 research <link xlink:type="simple" xlink:href="../260/19725260.xml">
universities</link>. </p>
<p>

The index is based on a set of statistical <link xlink:type="simple" xlink:href="../775/775.xml">
algorithm</link>s developed by Lawrence Martin and Anthony Olejniczak. It measures the annual amount and impact of faculty scholarly work in several areas, including:
<list>
<entry level="1" type="bullet">

 Publications (how many books and <link xlink:type="simple" xlink:href="../116/24116.xml">
peer-review</link>ed journal articles have been published and what proportion of the faculty is involved in publication activity?)</entry>
<entry level="1" type="bullet">

 Citations of journal publications (who is referring to those journal articles in subsequent work?)</entry>
<entry level="1" type="bullet">

 Federal research funding (what and how many projects have been deemed of sufficient value to merit federal dollars, and at what level of funding?)</entry>
<entry level="1" type="bullet">

 Awards and honors (a key indicator of innovative thinking and/or scholarly excellence that has impacted the discipline over a period of time)</entry>
</list>
</p>
<p>

The FSPI analysis creates, by academic field of study, a statistical score and a ranking based on the cumulative scoring of a program's faculty using these quantitative measures compared against national standards within the particular discipline. Individual program scores can then be combined to demonstrate the quality of the scholarly work of the entire university. This information is gathered for over 230,000 faculty members representing 118 academic disciplines in roughly 7,300 Ph.D. programs throughout more than 350 universities in the United States. </p>

<sec>
<st>
Rankings approach</st>
<p>

Unlike other annual <link xlink:type="simple" xlink:href="../834/448834.xml">
college and university rankings</link>, <it>e.g.</it>, the <it><magazine wordnetid="106595351" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../826/449826.xml">
U.S. News &amp; World Report</link></magazine>
</it> annual survey, the FSPI focuses on research institutions as defined by the <link xlink:type="simple" xlink:href="../943/540943.xml">
Carnegie Classification of Institutions of Higher Education</link>. It draws on the approach used by the <link xlink:type="simple" xlink:href="../638/37638.xml">
United States National Research Council</link> (NRC), which publishes a ranking of U.S.-based graduate programs approximately every ten years, but focuses on providing a more frequently-gathered set of benchmark measurements that do not include the qualitative and subjective reputation assessments favored by the NRC and other ranking systems.</p>

</sec>
<sec>
<st>
History of Faculty Scholarly Productivity Index</st>
<p>

The system for evaluating university programs that forms the basis of the FSPI was developed by Lawrence Martin and Anthony Olejniczak, of <university wordnetid="108286163" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../208/251208.xml">
Stony Brook University</link></university>
. Martin had been studying, speaking, and writing about faculty scholarly productivity since 1995. During that period, a series of discipline-specific, per-capita regression models was created and tested to evaluate their accuracy and the feasibility of predicting the academic reputation of the faculty of doctoral programs.</p>
<p>

These prototype materials employed data from the <link xlink:type="simple" xlink:href="../503/501503.xml">
National Research Council</link>'s 1995 publication <it>Continuity and Change</it> (and the subsequent CD-ROM publication of data), describing and evaluating American Ph.D. programs by field. Martin and Olejniczak found that the reputation of a program (as measured by faculty scholarly reputation from a survey conducted by the NRC) could be predicted well using a discipline-specific regression equation derived from quantitative, per capita data available for each program (the number of journal articles, citations, federally funded grants, and honorific awards). Reputation could be predicted with high statistical significance but important deviations from the regression line were also apparent; that is to say, some schools were outperforming their reputation, while others were underperforming. The prototype materials based on this method, and the data from the 1995 NRC study, were subsequently presented at numerous academic conferences from 1996 to 2004, and have formed the basis on which the FSP Index was developed.</p>
<p>

Martin's concepts became a commercial product when, at the Council of Graduate Schools' 2005 Annual Meeting, he met Mark Shay, then President of Educational Directories Unlimited.  The two worked together to develop the company that eventually became Academic Analytics.</p>
<p>

Today, the product is used by numerous universities to improve the quality of their programs.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref></p>

</sec>
<sec>
<st>
 References </st>

<p>

<reflist>
<entry id="1">
<weblink xlink:type="simple" xlink:href="http://www.academicanalytics.com/About/ClientList.aspx">
Academic Analytics Client List</weblink></entry>
</reflist>
</p>

</sec>
<sec>
<st>
External links</st>
<p>

<list>
<entry level="1" type="bullet">

 The Top 50 Overall</entry>
</list>

<weblink xlink:type="simple" xlink:href="http://www.academicanalytics.com/TopSchools/TopSchools.aspx">
"Top 50"</weblink>
<list>
<entry level="1" type="bullet">

 “A New Standard for Measuring Doctoral Programs,” Piper Fogg, <it>The Chronicle of Higher Education</it>, <link xlink:type="simple" xlink:href="../112/16112.xml">
January 12</link>, <link xlink:type="simple" xlink:href="../165/36165.xml">
2007</link>. (<weblink xlink:type="simple" xlink:href="http://chronicle.com/free/v53/i19/19a00801.htm">
http://chronicle.com/free/v53/i19/19a00801.htm</weblink>)</entry>
<entry level="1" type="bullet">

 "How Productive Are your Programs?",  Scott Jaschik, <it>Inside Higher Education</it>, <link xlink:type="simple" xlink:href="../845/15845.xml">
January 25</link>, <link xlink:type="simple" xlink:href="../164/36164.xml">
2006</link>. (http://www.insidehighered.com/news/2006/01/25/analytics)</entry>
<entry level="1" type="bullet">

 “Towards a Better Way to Rate Research Doctoral Programs: Executive Summary,” Joan Lorden and Lawrence Martin, position paper from NASULG’s Council on Research Policy and Graduate Education, (<weblink xlink:type="simple" xlink:href="http://www.academicanalytics.com/positionpaper.html">
http://www.academicanalytics.com/positionpaper.html</weblink>)</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.academicanalytics.com">
Academic Analytics website</weblink></entry>
<entry level="1" type="bullet">

 "Are Public Universities Losing Ground?", <it>Inside Higher Education</it>, <link xlink:type="simple" xlink:href="../199/20199.xml">
March 14</link>, <link xlink:type="simple" xlink:href="../165/36165.xml">
2007</link>.  (http://www.insidehighered.com/news/2007/03/14/analytics)</entry>
</list>
</p>

</sec>
</bdy>
</group>
</social_group>
</university>
</body>
</article>
