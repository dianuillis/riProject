<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 18:17:08[mciao0827] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<event  confidence="0.8" wordnetid="100029378">
<act  confidence="0.8" wordnetid="100030358">
<psychological_feature  confidence="0.8" wordnetid="100023100">
<procedure  confidence="0.8" wordnetid="101023820">
<activity  confidence="0.8" wordnetid="100407535">
<header>
<title>Memory-prediction framework</title>
<id>1196714</id>
<revision>
<id>200103509</id>
<timestamp>2008-03-22T17:14:46Z</timestamp>
<contributor>
<username>Realelite</username>
<id>2543508</id>
</contributor>
</revision>
<categories>
<category>Futurology</category>
<category>Neural networks</category>
<category>Memory processes</category>
</categories>
</header>
<bdy>

The <b>memory-prediction framework</b> is a theory of <link xlink:type="simple" xlink:href="../717/3717.xml">
brain</link> function that was created by <person wordnetid="100007846" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../957/399957.xml">
Jeff Hawkins</link></person>
 and described in his book <it><book wordnetid="106410904" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../709/1196709.xml">
On Intelligence</link></book>
</it>. This theory concerns the role of the human <link xlink:type="simple" xlink:href="../922/487922.xml">
neocortex</link> and its associations with the <link xlink:type="simple" xlink:href="../948/53948.xml">
hippocampus</link> and the <link xlink:type="simple" xlink:href="../227/78227.xml">
thalamus</link> in matching sensory inputs to stored <link xlink:type="simple" xlink:href="../844/18844.xml">
memory</link> patterns and how this process leads to predictions of what will happen in the future.
<sec>
<st>
 Overview </st>

<p>

The theory is motivated by the observed similarities between the brain structures (especially <link xlink:type="simple" xlink:href="../686/58686.xml">
neocortical</link> tissue) which are used for a wide range of behaviours available to mammals. The theory posits that the remarkably uniform <it>physical</it> arrangement of cortical tissue reflects a single principle or algorithm which underlies all cortical information processing. The basic processing principle is hypothesized to be a feedback/recall <link xlink:type="simple" xlink:href="../545/11545.xml">
loop</link> which involves both <link xlink:type="simple" xlink:href="../686/58686.xml">
cortical</link> and extra-cortical participation (the latter from the <link xlink:type="simple" xlink:href="../227/78227.xml">
thalamus</link> and the <link xlink:type="simple" xlink:href="../948/53948.xml">
hippocampus</link> in particular). </p>
<p>

The memory-prediction framework provides a unified basis for thinking about the adaptive control of complex behavior. Although certain brain structures are identified as participants in the core 'algorithm' of prediction-from-memory, these details are less important than the set of principles that are proposed as basis for all high-level cognitive processing.</p>

</sec>
<sec>
<st>
 The basic theory: recognition and prediction in bi-directional hierarchies </st>

<p>

The central concept of the <link xlink:type="simple" xlink:href="../714/1196714.xml">
memory-prediction framework</link> is that bottom-up inputs are matched in a <link xlink:type="simple" xlink:href="../998/13998.xml">
hierarchy</link> of <link xlink:type="simple" xlink:href="../543/1208543.xml">
recognition</link>, and evoke a series of top-down expectations encoded as potentiations. These expectations interact with the bottom-up signals to both analyse those inputs and generate <link xlink:type="simple" xlink:href="../066/246066.xml">
prediction</link>s of subsequent expected inputs. Each hierarchy level remembers frequently observed temporal sequences of input patterns and generates labels or 'names' for these sequences. When an input sequence matches a memorized sequence at a given layer of the hierarchy, a label or 'name' is propagated up the hierarchy - thus eliminating details at higher levels and enabling them to learn higher-order sequences. This process produces increased <link xlink:type="simple" xlink:href="../391/136391.xml">
invariance</link> at higher levels. Higher levels predict future input by matching partial sequences and projecting their expectations to the lower levels. However, when a mismatch between input and memorized/predicted sequences occurs, a more complete representation propagates upwards.  This causes alternative 'interpretations' to be activated at higher levels, which in turn generates other predictions at lower levels.</p>
<p>

Consider, for example, the process of <link xlink:type="simple" xlink:href="../675/241675.xml">
vision</link>. Bottom-up information starts as low-level <link xlink:type="simple" xlink:href="../334/48334.xml">
retina</link>l signals (indicating the presence of simple visual elements and contrasts). At higher levels of the hierarchy, increasingly meaningful information is extracted, regarding the presence of <link xlink:type="simple" xlink:href="../323/76323.xml">
line</link>s, <link xlink:type="simple" xlink:href="../633/55633.xml">
region</link>s, <link xlink:type="simple" xlink:href="../580/20580.xml">
motion</link>s, etc. Even further up the hierarchy, activity corresponds to the presence of specific objects - and then to behaviours of these objects. Top-down information fills in details about the recognized objects, and also about their expected behaviour as time progresses.</p>
<p>

The sensory hierarchy induces a number of differences between the various layers. As one moves up the hierarchy, <link xlink:type="simple" xlink:href="../920/16920.xml">
representations</link> have increased:
<list>
<entry level="1" type="bullet">

 Extent - for example, larger areas of the visual field, or more extensive tactile regions.</entry>
<entry level="1" type="bullet">

 Temporal <link xlink:type="simple" xlink:href="../946/28946.xml">
stability</link> - lower-level entities change quickly, whereas, higher-level percepts tend to be more stable.</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../ury/30th_century.xml">
Abstraction</link> - through the process of successive extraction of <link xlink:type="simple" xlink:href="../392/136392.xml">
invariant</link> <link xlink:type="simple" xlink:href="../752/187752.xml">
feature</link>s, increasingly abstract entities are recognized.</entry>
</list>
</p>
<p>

The relationship between sensory and motor processing is an important aspect of the basic theory. It is proposed that the motor areas of <link xlink:type="simple" xlink:href="../686/58686.xml">
cortex</link> consist of a behavioural hierarchy similar to the sensory hierarchy, with the lowest levels consisting of explicit motor commands to musculature and the highest levels corresponding to abstract prescriptions (e.g. 'resize the browser'). The sensory and motor hierarchies are tightly coupled, with behaviour giving rise to sensory expectations and sensory <link xlink:type="simple" xlink:href="../140/25140.xml">
perception</link>s driving motor processes.</p>
<p>

Finally, it is important to note that all the memories in the cortical hierarchy have to be learnt - this information is not pre-wired in the brain. Hence, the process of extracting this <link xlink:type="simple" xlink:href="../920/16920.xml">
representation</link> from the flow of inputs and behaviours is theorized as a  process that happens continually during <link xlink:type="simple" xlink:href="../238/106238.xml">
cognition</link>.</p>

<ss1>
<st>
Other Terms</st>
<p>

Hawkins has extensive training as an electrical engineer.  Another way to describe the theory (hinted at in his book) is as a <link xlink:type="simple" xlink:href="../846/243846.xml">
learning</link> <link xlink:type="simple" xlink:href="../998/13998.xml">
hierarchy</link> of <link xlink:type="simple" xlink:href="../759/574759.xml">
feed forward</link> <link xlink:type="simple" xlink:href="../222/292222.xml">
stochastic</link> <link xlink:type="simple" xlink:href="../931/10931.xml">
state machine</link>s.  In this view, the brain is analyzed as an encoding problem, not too dissimilar from future-predicting error-correction codes.  The hierarchy is a hierarchy of <link xlink:type="simple" xlink:href="../ury/30th_century.xml">
abstraction</link>, with the higher level machines' states representing more abstract conditions or events, and these states predisposing lower-level machines to perform certain transitions.  The lower level machines model limited domains of experience, or control or interpret sensors or effectors.  The whole system actually controls the organism's behavior.  Since the state machine is "feed forward", the organism responds to future events predicted from past data.  Since it is hierarchical, the system exhibits behavioral flexibility, easily producing new sequences of behavior in response to new sensory data.  Since the system learns, the new behavior adapts to changing conditions.</p>
<p>

That is, the evolutionary purpose of the brain is to predict the future, in admittedly limited ways, so as to change it.</p>
<p>

Early computer experiments with <link xlink:type="simple" xlink:href="../526/38526.xml">
Bayesian</link> learning in feed-forward hierarchical state machines seem to indicate that this model generates behavior very similar to that of real organisms.</p>

</ss1>
</sec>
<sec>
<st>
 Neurophysiological implementation </st>

<p>

The hierarchies described above are theorized to occur primarily in mammalian neocortex. In particular, neocortex is assumed to consist of a large number of <link xlink:type="simple" xlink:href="../745/941745.xml">
columns</link> (as surmised also by <link xlink:type="simple" xlink:href="../840/1828840.xml">
Mountcastle</link> from anatomical and theoretical considerations). Each column is attuned to a particular feature at a given level in a hierarchy. It receives bottom-up inputs from lower levels, and top-down inputs from higher levels. (Other columns at the same level also feed into a given column, and serve mostly to inhibit the activiation exclusive representations.) When an input is recognized - that is, acceptable agreement is obtained between the bottom-up and top-down sources - a column generates outputs which in turn propagate to both lower and higher levels.
</p>
<ss1>
<st>
Cortex</st>
<p>

These processes map well to specific layers within mammalian cortex. (The cortical layers should not be confused with different levels of the processing hierarchy: all the layers in a single column participate as one element in a single hierarchical level). Bottom-up input arrives at layer 4 (L4), whence it propagates to L2 and L3 for recognition of the invariant content. Top-down activation arrives to L2 and L3 via L1 (the mostly axonal layer that distributes activation locally across columns. L2 and L3 compare bottom up and top-down information, and generate either the invariant 'names' when sufficient match is achieved, or the more variable signals that occur when this fails. These signals are propagated up the hierarchy (via L5) and also down the hierarchy (via L6 and L1).
</p>
</ss1>
<ss1>
<st>
Thalamus</st>
<p>

To account for storage and recognition of <it>sequences</it> of patterns, a combination of two processes is suggested. The nonspecific <link xlink:type="simple" xlink:href="../227/78227.xml">
thalamus</link> acts as a 'delay line' - that is, L5 activates this brain area, which re-activates L1 after a slight delay. Thus, the output of one column generates L1 activity, which will coincide with the input to a column which is temporally subsequent within a sequence. This time ordering operates in conjunction with the higher-level identification of the sequence, which does not change in time; hence, activation of the sequence representation causes the lower-level components to be predicted one after the other. (Besides this role in sequencing, the thalamus is also active as sensory <link xlink:type="simple" xlink:href="../925/13791925.xml">
waystation</link> - these roles apparently involve distinct regions of this anatomically non-uniform structure.)</p>

</ss1>
<ss1>
<st>
Hippocampus</st>
<p>

Another anatomically diverse brain structure which is hypothesized to play an important role in hierarchical cognition is the <link xlink:type="simple" xlink:href="../948/53948.xml">
hippocampus</link>. It is well known that damage to the hippocampus impairs the formation of long-term declarative memory; individuals with such damage are unable to form new memories of episodic nature, although they can recall earlier memories without difficulties and can also learn new skills. In the current theory, the hippocampus is thought as the top level of the cortical hierarchy; it is specialized to retain memories of events that propagate all the way to the top. As such events fit into predictable patterns, they become memorizable at lower levels in the hierarchy. (Such movement of memories down the hierarchy is, incidentally, a general prediction of the theory.) Thus, the hippocampus continually memorizes 'unexpected' events (that is, those not predicted at lower levels); if it is damaged, the entire process of memorization through the hierarchy is compromised.</p>
<p>

<indent level="1">

<it>Further information: <link xlink:type="simple" xlink:href="../228/1049228.xml">
place cell</link></it>
</indent>

<indent level="1">

<it>Further information: <link xlink:type="simple" xlink:href="../066/2473066.xml">
Papez circuit</link></it>
</indent>

</p>
</ss1>
</sec>
<sec>
<st>
 Explanatory successes and predictions </st>

<p>

The memory-prediction framework explains a number of psychologically salient aspects of cognition. For example, the ability of experts in any field to effortlessly analyze and remember complex problems within their field is a natural consequence of their formation of increasingly refined conceptual hierarchies. Also, the procession from '<link xlink:type="simple" xlink:href="../140/25140.xml">
perception</link>' to '<link xlink:type="simple" xlink:href="../180/216180.xml">
understanding</link>' is readily understandable as a result of the matching of top-down and bottom-up <link xlink:type="simple" xlink:href="../395/243395.xml">
expectation</link>s. Mismatches, in contrast, generate the exquisite ability of biological cognition to detect unexpected perceptions and situations. (Deficiencies in this regard are a common characteristic of current approaches to artificial intelligence.)</p>
<p>

Besides these subjectively satisfying explanations, the framework also makes a number of testable <link xlink:type="simple" xlink:href="../066/246066.xml">
prediction</link>s. For example, the important role that prediction plays throughout the sensory hierarchies calls for anticipatory neural activity in certain cells throughout sensory cortex. In addition, cells that 'name' certain invariants should remain active throughout the presence of those invariants, even if the underlying inputs change. The predicted patterns of bottom-up and top-down activity - with former being more complex when expectations are not met - may be detectable, for example by functional magnetic resonance imaging (<link xlink:type="simple" xlink:href="../725/226725.xml">
fMRI</link>).</p>
<p>

Although these predictions are not highly specific to the proposed theory, they are sufficiently unambiguous to make verification or rejection of its central tenets possible. See  <it><book wordnetid="106410904" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../709/1196709.xml">
On Intelligence</link></book>
</it> for details on the predictions and findings.</p>

</sec>
<sec>
<st>
 Contribution and limitations </st>

<p>

By design, the current theory builds on the work of numerous neurobiologists, and it may be argued that most of these ideas have already been proposed by researchers such as <link xlink:type="simple" xlink:href="../981/2141981.xml">
Grossberg</link> and <link xlink:type="simple" xlink:href="../840/1828840.xml">
Mountcastle</link>. On the other hand, the novel separation of the conceptual machinery of bidirectional processing and invariant recognition from the biological details of neural layers, columns and structures lays the foundation for abstract thinking about a wide range of cognitive processes.</p>
<p>

The most significant limitation of this theory is its current lack of detail. For example, the concept of <link xlink:type="simple" xlink:href="../392/136392.xml">
invariance</link> plays a crucial role; Hawkins posits "<link>
name cell</link>s" for at least some of these <link xlink:type="simple" xlink:href="../392/136392.xml">
invariant</link>s. (
See also <link xlink:type="simple" xlink:href="../457/2860457.xml#xpointer(//*[./st=%22Encoding%22])">
Neural ensemble#Encoding</link> for <it>grandmother neurons</it> which perform this type of function, and <link xlink:type="simple" xlink:href="../317/1168317.xml">
mirror neuron</link>s for a <link xlink:type="simple" xlink:href="../524/635524.xml">
somatosensory system</link> viewpoint.
) But it is far from obvious how to develop a mathematically rigorous definition, which will carry the required conceptual load across the domains presented by Hawkins. Similarly, a complete theory will require credible details on both the short-term dynamics and the learning processes that will enable the cortical layers to behave as advertised.</p>

</sec>
<sec>
<st>
 Machine learning models </st>
<p>

The memory-prediction theory claims a common algorithm is employed by all regions in the neocortex. The theory has given rise to a number of software models aiming to simulate this common algorithm using a hierarchical memory structure. The year in the list below indicates when the model was last updated. 
</p>
<ss1>
<st>
 Models based on Bayesian networks </st>
<p>

The following models use belief propagation or belief revision in singly connected <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../996/203996.xml">
Bayesian network</link></causal_agent>
</worker>
</assistant>
</model>
</person>
</physical_entity>
s. 
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../721/11273721.xml">
Hierarchical Temporal Memory</link> (HTM), a model, a related development platform and source code by <link xlink:type="simple" xlink:href="../246/1643246.xml">
Numenta, Inc.</link> (2008).</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.numenta.com/phpBB2/download.php?id=130">
HtmLib</weblink>, an alternative implementation of HTM algorithms by Greg Kochaniak with a number of modifications for improving the recognition accuracy and speed (2008). </entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://sourceforge.net/projects/neocortex/">
Project Neocortex</weblink>, an open source project for modeling memory-prediction framework (2008). </entry>
<entry level="2" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.phillylac.org/prediction/">
Saulius Garalevicius' research page</weblink>, research papers and programs presenting experimental results with a model of the memory-prediction framework, a basis for the Neocortex project (2007).</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.stanford.edu/~dil/invariance">
Dileep George's webpage</weblink>, several papers describing earlier pre-HTM Bayesian models, source code by co-founder of <link xlink:type="simple" xlink:href="../246/1643246.xml">
Numenta, Inc.</link> (2005). This is the first model of memory-prediction framework that uses Bayesian networks and all the above models are based on these initial ideas. </entry>
</list>
</p>

</ss1>
<ss1>
<st>
 Other models </st>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.phillylac.org/prediction/2005%2005%20Analysis%20and%20Implementation%20of%20MPF.pdf">
Implementation of MPF</weblink>, a paper by Saulius Garalevicius describing a method of classification and prediction in a model that stores temporal sequences and employs unsupervised learning (2005).</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://home.earthlink.net/~gmayhak/M5_htm.htm">
M5</weblink>, a pattern machine for Palm OS that stores pattern sequences and recalls the patterns relevant to its present environment (2007).</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://sourceforge.net/projects/brain-game">
BrainGame</weblink>, open source predictor class which learns patterns and can be linked to other predictors (2005).</entry>
</list>
</p>

</ss1>
</sec>
<sec>
<st>
 See also </st>
<p>

<list>
<entry level="1" type="bullet">

 <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<biologist wordnetid="109855630" confidence="0.8">
<intellectual wordnetid="109621545" confidence="0.8">
<neurobiologist wordnetid="110353928" confidence="0.8">
<alumnus wordnetid="109786338" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<neuroscientist wordnetid="110354580" confidence="0.8">
<scholar wordnetid="110557854" confidence="0.8">
<link xlink:type="simple" xlink:href="../840/1828840.xml">
Vernon Mountcastle</link></scholar>
</neuroscientist>
</scientist>
</causal_agent>
</alumnus>
</neurobiologist>
</intellectual>
</biologist>
</person>
</physical_entity>
, the neuroscientist who discovered and characterized the columnar organization of the cerebral cortex.</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../879/3056879.xml">
Adaptive resonance theory</link>, a neural network architecture developed by <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<intellectual wordnetid="109621545" confidence="0.8">
<alumnus wordnetid="109786338" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<scholar wordnetid="110557854" confidence="0.8">
<link xlink:type="simple" xlink:href="../441/2593441.xml">
Stephen Grossberg</link></scholar>
</scientist>
</causal_agent>
</alumnus>
</intellectual>
</person>
</physical_entity>
.</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../430/271430.xml">
Computational neuroscience</link></entry>
<entry level="1" type="bullet">

 <work wordnetid="104599396" confidence="0.8">
<work wordnetid="100575741" confidence="0.8">
<creation wordnetid="103129123" confidence="0.8">
<examination wordnetid="100635850" confidence="0.8">
<publication wordnetid="106589574" confidence="0.8">
<product wordnetid="104007894" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<book wordnetid="106410904" confidence="0.8">
<survey wordnetid="100644503" confidence="0.8">
<investigation wordnetid="100633864" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<link xlink:type="simple" xlink:href="../000/22000.xml">
Neural Darwinism</link></activity>
</psychological_feature>
</act>
</investigation>
</survey>
</book>
</event>
</artifact>
</product>
</publication>
</examination>
</creation>
</work>
</work>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../650/2291650.xml">
Predictive learning</link></entry>
</list>
</p>

</sec>
<sec>
<st>
 External links </st>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://cbcl.mit.edu/software-datasets">
Hierarchical vision algorithm source code &amp; data</weblink> - similar to the Memory-Prediction Framework (from <weblink xlink:type="simple" xlink:href="http://cbcl.mit.edu">
MIT Center for Biological &amp; Computational Learning</weblink>)</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.neurosecurity.com">
Group of articles about neuroscience and AI</weblink> - Group of articles and papers supporting Jeff's MPF theory.</entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.technologyreview.com/read_article.aspx?id=18164&amp;ch=infotech">
MIT <it>Technology Review</it> Monday, February 12, 2007: Building the Cortex in Silicon </weblink></entry>
</list>
</p>

</sec>
<sec>
<st>
 Further reading </st>
<p>

<list>
<entry level="1" type="bullet">

 Jeff Hawkins (<link xlink:type="simple" xlink:href="../524/35524.xml">
2004</link>), <it><book wordnetid="106410904" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../709/1196709.xml">
On Intelligence</link></book>
</it>, New York: Henry Holt. Bibliography, Index, 251 pages. ISBN 0-8050-7456-2</entry>
</list>
</p>



</sec>
</bdy>
</activity>
</procedure>
</psychological_feature>
</act>
</event>
</article>
