<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 18:21:17[mciao0827] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Vector space model</title>
<id>1256134</id>
<revision>
<id>238025139</id>
<timestamp>2008-09-12T22:11:49Z</timestamp>
<contributor>
<username>Tobacman</username>
<id>103909</id>
</contributor>
</revision>
<categories>
<category>Information retrieval</category>
</categories>
</header>
<bdy>

<b>Vector space model</b> (or <it>term vector model</it>) is an algebraic model for representing text documents (and any objects, in general) as <link xlink:type="simple" xlink:href="../370/32370.xml">
vectors</link> of identifiers, such as, for example, index terms. It is used in <link xlink:type="simple" xlink:href="../390/9854390.xml">
information filtering</link>, <link xlink:type="simple" xlink:href="../271/15271.xml">
information retrieval</link>, <link xlink:type="simple" xlink:href="../270/15270.xml">
indexing</link> and relevancy rankings.  Its first use was in the <link xlink:type="simple" xlink:href="../628/509628.xml">
SMART Information Retrieval System</link>.
<sec>
<st>
Definitions</st>

<p>

A document is represented as a vector. Each <link xlink:type="simple" xlink:href="../267/38267.xml">
dimension</link> corresponds to a separate term. If a term occurs in the document, its value in the vector is non-zero. Several different ways of computing these values, also known as (term) weights, have been developed. One of the best known schemes is <link xlink:type="simple" xlink:href="../290/2057290.xml">
tf-idf</link> weighting (see the example below).</p>
<p>

The definition of <it>term</it> depends on the application. Typically terms are single words, <link xlink:type="simple" xlink:href="../000/2634000.xml">
keyword</link>s, or longer phrases. If the words are chosen to be the terms, the dimensionality of the vector is the number of words in the vocabulary (the number of distinct words occurring in the <link xlink:type="simple" xlink:href="../887/53887.xml">
corpus</link>).</p>

</sec>
<sec>
<st>
Applications</st>

<p>

<link xlink:type="simple" xlink:href="../684/442684.xml">
Relevancy</link> <link xlink:type="simple" xlink:href="../394/1482394.xml">
ranking</link>s of documents in a keyword search can be calculated, using the assumptions of <link xlink:type="simple" xlink:href="../135/1473135.xml">
document similarities</link> theory, by comparing the deviation of angles between each document vector and the original query vector where the query is represented as same kind of vector as the documents.</p>
<p>

In practice, it is easier to calculate the <link xlink:type="simple" xlink:href="../367/30367.xml">
cosine</link> of the angle between the vectors instead of the angle:</p>
<p>

<indent level="1">

<math>
\cos{\theta} = \frac{\mathbf{v_1} \cdot \mathbf{v_2}}{\left\| \mathbf{v_1} \right\| \left \| \mathbf{v_2} \right\|}
</math>
</indent>

A cosine value of zero means that the query and document vector were <link xlink:type="simple" xlink:href="../221/102221.xml">
orthogonal</link> and had no match (i.e. the query term did not exist in the document being considered).</p>

</sec>
<sec>
<st>
Example: tf-idf weights</st>

<p>

In the classic vector space model proposed by <physical_entity wordnetid="100001930" confidence="0.8">
<peer wordnetid="109626238" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<pioneer wordnetid="110434725" confidence="0.8">
<colleague wordnetid="109935990" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<originator wordnetid="110383816" confidence="0.8">
<creator wordnetid="109614315" confidence="0.8">
<associate wordnetid="109816771" confidence="0.8">
<link xlink:type="simple" xlink:href="../624/509624.xml">
Salton</link></associate>
</creator>
</originator>
</scientist>
</causal_agent>
</colleague>
</pioneer>
</person>
</peer>
</physical_entity>
, Wong and Yang the term specific weights in the document vectors are products of local and global parameters. The model is known as <link xlink:type="simple" xlink:href="../290/2057290.xml">
term frequency-inverse document frequency</link> model. The weight vector for document <it>d</it> is <math>\mathbf{v}_d = [w_{1,d}, w_{2,d}, \ldots, w_{N,d}]^T</math>, where</p>
<p>

<indent level="1">

<math>
w_{t,d} = \mathrm{tf}_t \cdot \log{\frac{|D|}{|\{t \in d\}|}}
</math>
</indent>

and
<list>
<entry level="1" type="bullet">

 <math>\mathrm{tf}_t</math> is term frequency of term <it>t</it> in document <it>d</it> (a local parameter)</entry>
<entry level="1" type="bullet">

 <math>\log{\frac{|D|}{|\{t \in d\}|}}</math> is inverse document frequency (a global parameter). <math>|D|</math> is the total number of documents in the document set; <math>|\{t \in d\}|</math> is the number of documents containing the term <it>t</it>.</entry>
</list>
</p>
<p>

In a simpler <link>
Term Count Model</link> the term specific weights do not include the global parameter. Instead the weights are just the counts of term occurrences: <math>w_{t,d} = \mathrm{tf}_t</math>.</p>

</sec>
<sec>
<st>
Limitations</st>

<p>

The vector space model has the following limitations:</p>
<p>

<list>
<entry level="1" type="number">

Long documents are poorly represented because they have poor similarity values (a small <link xlink:type="simple" xlink:href="../093/157093.xml">
scalar product</link> and a <link xlink:type="simple" xlink:href="../776/787776.xml">
large dimensionality</link>)</entry>
<entry level="1" type="number">

Search keywords must precisely match document terms; word <link xlink:type="simple" xlink:href="../560/2696560.xml">
substring</link>s might result in a "<link>
false positive</link> match"</entry>
<entry level="1" type="number">

Semantic sensitivity; documents with similar context but different term vocabulary won't be associated, resulting in a "<link>
false negative</link> match".</entry>
<entry level="1" type="number">

The order in which the terms appear in the document is lost in the vector space representation.</entry>
</list>
</p>

</sec>
<sec>
<st>
Models based on and extending the vector space model</st>

<p>

Models based on and extending the vector space model include:
<list>
<entry level="1" type="bullet">

 Generalized vector space model</entry>
<entry level="1" type="bullet">

 (enhanced) Topic-based Vector Space Model <weblink xlink:type="simple" xlink:href="http://kuropka.net/files/HPI_Evaluation_of_eTVSM.pdf">
http://kuropka.net/files/HPI_Evaluation_of_eTVSM.pdf</weblink> (eTVSM) &mdash; Extends the vector space model by removing the constraint that the term-vectors be <link xlink:type="simple" xlink:href="../221/102221.xml">
orthogonal</link>. In contrast to the generalized vector space model the (enhanced) Topic-based Vector Space Model does not depend on concurrence-based similarities between terms. The enhancement of the enhanced Topic-based Vector Space Model (compared to the not enhanced one) is a proposal on how to derive term-vectors from an Ontology.</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../427/689427.xml">
Latent semantic analysis</link></entry>
<entry level="1" type="bullet">

 <link>
DSIR model</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../979/15101979.xml">
Term Discrimination</link></entry>
</list>
</p>

</sec>
<sec>
<st>
Further reading</st>

<p>

<list>
<entry level="1" type="bullet">

 <physical_entity wordnetid="100001930" confidence="0.8">
<peer wordnetid="109626238" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<pioneer wordnetid="110434725" confidence="0.8">
<colleague wordnetid="109935990" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<originator wordnetid="110383816" confidence="0.8">
<creator wordnetid="109614315" confidence="0.8">
<associate wordnetid="109816771" confidence="0.8">
<link xlink:type="simple" xlink:href="../624/509624.xml">
G. Salton</link></associate>
</creator>
</originator>
</scientist>
</causal_agent>
</colleague>
</pioneer>
</person>
</peer>
</physical_entity>
, A. Wong, and C. S. Yang (1975), "<weblink xlink:type="simple" xlink:href="http://www.cs.uiuc.edu/class/fa05/cs511/Spring05/other_papers/p613-salton.pdf">
A Vector Space Model for Automatic Indexing</weblink>," <it>Communications of the ACM</it>, vol. 18, nr. 11, pages 613â€“620. <it>(The article in which the vector space model was first presented)''</it></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://isp.imm.dtu.dk/thor/projects/multimedia/textmining/node5.html">
Description of the vector space model</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://kuropka.net/files/HPI_Evaluation_of_eTVSM.pdf">
Description and Evaluation of the enhanced Topic-based Vector Space Model</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.miislita.com/term-vector/term-vector-3.html">
Description of the classic vector space model by Dr E Garcia</weblink></entry>
</list>
</p>



</sec>
<sec>
<st>
See also</st>
<p>

<list>
<entry level="1" type="bullet">

<event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../116/3125116.xml">
Inverted index</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../649/18046649.xml">
Compound term processing</link></entry>
</list>
</p>


</sec>
</bdy>
</article>
