<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 17.04.2009 01:31:19[mciao0827] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Neural cryptography</title>
<id>12589161</id>
<revision>
<id>235891795</id>
<timestamp>2008-09-02T20:59:41Z</timestamp>
<contributor>
<username>Juraj.somi</username>
<id>7753732</id>
</contributor>
</revision>
<categories>
<category>Neural networks</category>
<category>Theory of cryptography</category>
</categories>
</header>
<bdy>

<b>Neural cryptography</b> is a branch of <link xlink:type="simple" xlink:href="../432/18934432.xml">
cryptography</link> dedicated to analyzing the application of <link xlink:type="simple" xlink:href="../222/292222.xml">
stochastic</link> algorithms, especially <link xlink:type="simple" xlink:href="../542/1729542.xml">
neural network</link> algorithms, for use in <link xlink:type="simple" xlink:href="../294/10294.xml">
encryption</link> and <link xlink:type="simple" xlink:href="../715/5715.xml">
cryptanalysis</link>.
<sec>
<st>
 Definition </st>

<p>

The ability of neural networks to explore the solution space could also be used in the field of <link xlink:type="simple" xlink:href="../715/5715.xml">
Cryptanalysis</link>. It also could be possible to generate new kind of attacks on existing algorithms based on the idea that any function could be reproduced by a neural network, so it will be possible to find the exact solution, at least theoretically, breaking the algorithm.</p>
<p>

The ideas of mutual learning, self learning, and stochastic behavior of neural networks and similar algorithms can be used for different aspects of cryptography, like <link xlink:type="simple" xlink:href="../222/24222.xml">
public-key cryptography</link>, solving the <link xlink:type="simple" xlink:href="../039/53039.xml">
key</link> distribution problem using neural network mutual synchronization, <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<primitive wordnetid="109627462" confidence="0.8">
<link xlink:type="simple" xlink:href="../526/439526.xml">
hashing</link></primitive>
</causal_agent>
</person>
</physical_entity>
 or generation of <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../249/182249.xml">
pseudo-random numbers</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
.</p>
<p>

Another idea is the ability of Neural Network to separate space in non-linear pieces using "bias". By the way, it gives different probabilities of activating or not the neural network. This is very useful in the case of the Cryptography or Cryptanalysis.</p>
<p>

Two names are used to design the same domain of researches : Neuro-Cryptography and Neural Cryptography.
We can add followings derivated names: Neuro-Cryptanalysis, Neuro-Encoding, Neuro-Key, ... as well for Neural.</p>
<p>

To try to bring you a beginning date, Sebastien Dourlens has introduced this domain the first time in his IT Master in 1995.
At least 30 years after the first talk on the definition of the basics of <link xlink:type="simple" xlink:href="../542/1729542.xml">
Neural Network</link>.</p>

</sec>
<sec>
<st>
 Applications </st>

<p>

As of yet there no practical applications due to the recent development of the field, but it could be used specially where the keys are continually generated and the system (both pairs and the insecure media) is in a continuously evolving mode.
In 1995, Sebastien Dourlens applied neural networks cryptanalyze <link xlink:type="simple" xlink:href="../273/665273.xml">
DES</link> by allowing the networks to learn how to invert the S-tables of the DES. The bias in DES studied through Differential Cryptanalysis by <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../314/57314.xml">
Adi Shamir</link></scientist>
</person>
 is highlighted. The experiment shows about 50% of the key bits can be found, allowing the complete key to be found in a short time. Hardware application with multi micro-controllers have been proposed due to the easy implementation of multilayer neural networks in hardware.
One example of public-key protocol is given by Khalil Shihab. He describes the decryption scheme and the public key creation that are based on a backpropagation neural network. The encryption scheme and the private key creation process are based on Boolean algebra. This technique has the advantage of small time and memory complexities. A disadvantage is the property of backpropagation algorithm: By huge training sets lasts the learning of neural network very long. Therefore the use of this protocol is only theoretical so far.</p>

</sec>
<sec>
<st>
 Neural key exchange protocol </st>

<p>

The most used protocol for key exchange between two parties A and B in the practice is Diffie-Hellman protocol. Neural key exchange, which is based on the synchronization of two tree parity machines, should be a secure replacement for this method.</p>
<p>

<image location="right" width="350px" src="TreeParityMachine.jpg" type="thumb">
<caption>

Tree parity machine
</caption>
</image>
</p>

<ss1>
<st>
 Tree parity machine </st>

<p>

The tree parity machine is a special type of multi-layer feed-forward neural network. </p>
<p>

It consists of one output neuron, K hidden neurons and K*N input neurons. Inputs to the network are binary: 
<indent level="1">

<math>x_{ij} \in \left\{ -1,+1 \right\}</math>
</indent>
The weights between input and hidden neurons take the values: 
<indent level="1">

<math>w_{ij} \in \left\{-L,...,0,...,+L \right\}</math>
</indent>
Output value of each hidden neuron is calculated as a sum of all multiplications of input neurons and these weights: 
<indent level="1">

<math>\sigma_i=sgn(\sum_{j=1}^{N}w_{ij}x_{ij})</math>
</indent>
Signum is a simple function, which returns -1,0 or 1: 
<indent level="1">

<math>\sgn (x) = \begin{cases}
-1 &amp; \text{if } x &amp;lt; 0, \\
0 &amp; \text{if } x = 0, \\
1 &amp; \text{if } x &amp;gt; 0. \end{cases}</math> 
</indent>

If the scalar product is 0, the output of the hidden neuron is mapped to -1 in order to ensure a binary output value. The output of neural network is then computed as the multiplication of all values produced by hidden elements: 
<indent level="1">

<math>\tau=\prod_{i=1}^{K}\sigma_i</math>
</indent>
Output of the tree parity machine is binary.</p>

</ss1>
<ss1>
<st>
 Protocol </st>

<p>

Each party (A and B) uses its own tree parity machine. Synchronization of the tree parity machines is achieved in these steps:
<list>
<entry level="1" type="number">

 Initialize random weight values</entry>
<entry level="1" type="number">

 Execute these steps until the full synchronization is achieved</entry>
<entry level="2" type="number">

 Generate random input vector X</entry>
<entry level="2" type="number">

 Compute the values of the hidden neurons</entry>
<entry level="2" type="number">

 Compute the value of the output neuron</entry>
<entry level="2" type="number">

 Compare the values of both tree parity machines:</entry>
<entry level="3" type="number">

 Outputs are others: go to 2.1</entry>
<entry level="3" type="number">

 Outputs are same: one of the suitable learning rules is applied to the weights</entry>
</list>
</p>
<p>

After the full synchronization is achieved (the weights wij of both tree parity machines are same), A and B can use their weights as keys.
This method is known as a bidirectional learning. 
One of the following learning rules can be used for the synchronization:
<list>
<entry level="1" type="bullet">

 Hebbian learning rule: </entry>
<entry level="1" type="indent">

<math>w_i^+=w_i+\sigma_ix_i\Theta(\sigma_i\tau)\Theta(\tau^A\tau^B)</math></entry>
<entry level="1" type="bullet">

 Anti-Hebbian learning rule: </entry>
<entry level="1" type="indent">

<math>w_i^+=w_i-\sigma_ix_i\Theta(\sigma_i\tau)\Theta(\tau^A\tau^B)</math></entry>
<entry level="1" type="bullet">

 Random walk:</entry>
<entry level="1" type="indent">

<math>w_i^+=w_i+x_i\Theta(\sigma_i\tau)\Theta(\tau^A\tau^B)</math></entry>
</list>
</p>

</ss1>
<ss1>
<st>
 Attacks and security of this protocol </st>

<p>

In every attack it is considered, that the attacker E can eavesdrop messages between the parties A and B, but does not have an opportunity to change them.</p>

<ss2>
<st>
 Brute force </st>
<p>

To provide a brute force attack, an attacker has to test all possible keys (all possible values of weights wij). By K hidden neurons, K*N input neurons and boundary of weights L, this gives (2L+1)KN possibilities. For example, the configuration K = 3, L = 3 and N = 100 gives us 3*10253 key possibilities, making the attack impossible with today’s computer power.</p>

</ss2>
<ss2>
<st>
 Learning with own tree parity machine </st>
<p>

One of the basic attacks can be provided by an attacker, who owns the same tree parity machine as the parties A and B. He wants to synchronize his tree parity machine with these two parties. In each step there are three situations possible:
<list>
<entry level="1" type="number">

 Output(A) ≠ Output(B): None of the parties updates its weights.</entry>
<entry level="1" type="number">

 Output(A) = Output(B) = Output(E): All the three parties update weights in their tree parity machines.</entry>
<entry level="1" type="number">

 Output(A) = Output(B) ≠ Output(E): Parties A and B update their tree parity machines, but the attacker can not do that. Because of this situation his learning is slower than the synchronization of parties A and B.</entry>
</list>

It has been proven, that the synchronization of two parties is faster then learning of an attacker. It can be improved by increasing of the synaptic depth L of the neural network. That gives this protocol enough security and an attacker can find out the key only with small probability.</p>

</ss2>
<ss2>
<st>
 Other attacks </st>
<p>

For conventional cryptographic systems, we can improve the security of the protocol by increasing of the key length. In the case of neural cryptography, we improve it by increasing of the synaptic depth L of the neural networks. Changing this parameter increases the cost of a successful attack exponentially, while the effort for the users grows polynomially. Therefore, breaking the security of neural key exchange belongs to the complexity class NP. 
There are other more sophisticated attacks against this protocol (e.g. geometric, majority, genetic attack). The most successful is majority attack. So far, none of the known attacks could break security of the neural key exchange protocol.</p>

</ss2>
</ss1>
<ss1>
<st>
 Security against quantum computers </st>
<p>

A quantum computer is a device that uses quantum mechanisms for computation. In this device the data are stored as qubits (quantum binary digits). That gives a quantum computer in comparison with a conventional computer the opportunity to solve complicated problems in a short time, e.g. discrete logarithm problem or factorization. Algorithms that are not based on any of these number theory problems, are being searched because of this property.
Neural key exchange protocol is not based on any number theory. It is based on the difference between unidirectional and bidirectional synchronization of neural networks. Therefore, we can say it is secure against quantum computer and belongs to the post quantum cryptography.</p>

</ss1>
</sec>
<sec>
<st>
 See also </st>

<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../542/1729542.xml">
Neural Network</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../605/2070605.xml">
Stochastic neural network</link></entry>
</list>
</p>

</sec>
<sec>
<st>
 References </st>

<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://translate.google.com/translate?u=http%3A%2F%2Fs.dourlens.free.fr%2Fmaitrise%2Fmaitrise.htm">
Neuro-Cryptography</weblink> 1995 - The first definition of the Neuro-Cryptography (AI Neural-Cryptography) applied to DES cryptanalysis by Sebastien Dourlens, France.</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://theorie.physik.uni-wuerzburg.de/~ruttor/neurocrypt.html">
Neural Cryptography</weblink> - Description of one kind of neural cryptography at the <link>
University of Würzburg</link>, Germany.</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://ieeexplore.ieee.org/Xplore/defdeny.jsp?url=/iel5/8534/27062/01202841.pdf?tp=&amp;tp=x&amp;arnumber=1202841&amp;isnumber=27062&amp;code=4">
Using synchronized neural networks to achieve public key authentication system</weblink> - One of the leading papers that introduce the concept.</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=963786">
 A remote password authentication scheme for multiserverarchitecture using neural networks</weblink> - Possible practical application of Neural Cryptography.</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.springerlink.com/content/kbpxkbnkgtk4ymhh/">
Analysis of Neural Cryptography</weblink> - Analysis of neural cryptography in general and focusing on the weakness and possible attacks of using synchronized neural networks.</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.opus-bayern.de/uni-wuerzburg/volltexte/2007/2361/">
Neural Synchronization and Cryptography</weblink> - Andreas Ruttor. PhD thesis, Bayerische Julius-Maximilians-Universität Würzburg, 2006.</entry>
<entry level="1" type="bullet">

  <cite style="font-style:normal">Andreas Ruttor, Wolfgang Kinzel, Rivka Naeh, and Ido Kanter&#32;(2006).&#32;"<weblink xlink:type="simple" xlink:href="http://link.aps.org/abstract/PRE/v73/e036121">
Genetic attack on neural cryptography</weblink>". <it>Physical Review E</it>.</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite style="font-style:normal">Khalil Shihab&#32;(2006).&#32;"<weblink xlink:type="simple" xlink:href="http://www.scipub.org/fulltext/jcs/jcs29710-715.pdf">
A backpropagation neural network for computer network security</weblink>". <it>Journal of Computer Science 2</it>: 710&ndash;715.</cite>&nbsp;</entry>
</list>
</p>

<p>

<table style=";" class="navbox" cellspacing="0">
<row>
<col style="padding:2px;">
<table style="width:100%;background:transparent;color:inherit;;" class="nowraplinks  " cellspacing="0">
<row>
<col colspan="2" style="width:100%;padding:0px;;;" class="navbox-list navbox-even">
<table style="width:100%;;;;" class="nowraplinks  navbox-subgroup" cellspacing="0">
<row>
<header colspan="2" style=";background:#ccf;" class="navbox-title">
&nbsp;<link xlink:type="simple" xlink:href="../432/18934432.xml">
Cryptography</link></header>
</row>
<row style="height:2px;">

</row>
<row>
<col colspan="2" style="width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<link xlink:type="simple" xlink:href="../066/520066.xml">
History of cryptography</link> | <link xlink:type="simple" xlink:href="../715/5715.xml">
Cryptanalysis</link> | 
Cryptography portal | <link xlink:type="simple" xlink:href="../585/449585.xml">
Topics in cryptography</link></col>
</row>
<row style="height:2px">

</row>
<row>
<col colspan="2" style="width:100%;padding:0px;;;" class="navbox-list navbox-even">
<event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../042/53042.xml">
Symmetric-key algorithm</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
 | <link xlink:type="simple" xlink:href="../594/4594.xml">
Block cipher</link> | <link xlink:type="simple" xlink:href="../007/49007.xml">
Stream cipher</link> | <link xlink:type="simple" xlink:href="../222/24222.xml">
Public-key cryptography</link> | <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<primitive wordnetid="109627462" confidence="0.8">
<link xlink:type="simple" xlink:href="../526/439526.xml">
Cryptographic hash function</link></primitive>
</causal_agent>
</person>
</physical_entity>
 | <link xlink:type="simple" xlink:href="../523/567523.xml">
Message authentication code</link> | <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../249/182249.xml">
Random numbers</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
 | <link xlink:type="simple" xlink:href="../733/28733.xml">
Steganography</link></col>
</row>
</table>
</col>
</row>
</table>
</col>
</row>
</table>
</p>


</sec>
</bdy>
</article>
