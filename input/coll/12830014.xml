<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 17.04.2009 01:31:05[mciao0828] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Eight-point algorithm</title>
<id>12830014</id>
<revision>
<id>242464976</id>
<timestamp>2008-10-02T10:21:29Z</timestamp>
<contributor>
<username>KYN</username>
<id>505011</id>
</contributor>
</revision>
<categories>
<category>Geometry in computer vision</category>
</categories>
</header>
<bdy>

The <b>eight-point algorithm</b> is an algorithm used in <link xlink:type="simple" xlink:href="../596/6596.xml">
computer vision</link> to estimate the <link xlink:type="simple" xlink:href="../806/7931806.xml">
essential matrix</link> or the <link xlink:type="simple" xlink:href="../619/10125619.xml">
fundamental matrix</link> related to a stereo camera pair from a set of corresponding image points.  It was introduced by <link xlink:type="simple" xlink:href="../682/7867682.xml">
Christopher Longuet-Higgins</link> in <link xlink:type="simple" xlink:href="../776/34776.xml">
1981</link> for the case of the essential matrix.  In theory, this algorithm can be used also for the fundamental matrix, but in practice <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22The+normalized+eight-point+algorithm%22])">
the normalized eight-point algorithm</link>, described by Richard Hartley in <link xlink:type="simple" xlink:href="../601/34601.xml">
1997</link>, is better suited for this case.<p>

The algorithm's name derives from the fact that it estimates the essential matrix or the fundamental matrix from a set of eight (or more) corresponding image points.  However, variations of the algorithm can be used for fewer than eight points.</p>

<sec>
<st>
 The basic algorithm </st>

<p>

The basic eight-point algorithm is here described for the case of estimating the essential matrix <math> \mathbf{E} </math>.  It consists of three steps.  First, it formulates a <link xlink:type="simple" xlink:href="../654/12643654.xml">
homogeneous linear equation</link>, where the solution is directly related to <math> \mathbf{E} </math>, and then solves the equation, taking into account that it may not have an exact solution.  Finally, the internal constraints of the resulting matrix are managed.  The first step is described in Longuet-Higgins' paper, the second and third steps are standard approaches in estimation theory.</p>
<p>

The constraint defined by the essential matrix <math> \mathbf{E} </math> is</p>
<p>

<indent level="1">

<math> (\mathbf{y}')^{T} \, \mathbf{E} \, \mathbf{y} = 0</math>
</indent>

for corresponding image points represented in normalized image coordinates <math> \mathbf{y}, \mathbf{y}' </math>.  The problem which the algorithm solves is to determine <math> \mathbf{E} </math> for a set of matching image points.  In practice, the image coordinates of the image points are affected by noise and the solution may also be over-determined which means that it may not be possible to find <math> \mathbf{E} </math> which satisfies the above constraint exactly for all points.  This issue is addressed in the second step of the algorithm.</p>

<ss1>
<st>
 Step 1: Formulating a <link xlink:type="simple" xlink:href="../654/12643654.xml">
homogeneous linear equation</link> </st>

<p>

With</p>
<p>

<indent level="1">

<math> \mathbf{y} = \begin{pmatrix} y_{1} \\ y_{2} \\ 1 \end{pmatrix} </math> &nbsp; and &nbsp; <math> \mathbf{y}' = \begin{pmatrix} y'_{1} \\ y'_{2} \\ 1 \end{pmatrix} </math> &nbsp; and &nbsp; <math> \mathbf{E} = \begin{pmatrix} e_{11} &amp; e_{12} &amp; e_{13} \\ e_{21} &amp; e_{22} &amp; e_{23} \\ e_{31} &amp; e_{32} &amp; e_{33} \end{pmatrix} </math>
</indent>

the constraint can also be rewritten as</p>
<p>

<indent level="1">

<math> y'_1 y_1 e_{11} + y'_1 y_2 e_{12} + y'_1 e_{13} + y'_2 y_1 e_{21} + y'_2 y_2 e_{22} + y'_2 e_{23} + y_1 e_{31} + y_2 e_{32} + e_{33} = 0 \, </math>
</indent>

or</p>
<p>

<indent level="1">

<math> \mathbf{e} \cdot \tilde\mathbf{y} = 0 </math>
</indent>

where</p>
<p>

<indent level="1">

<math> \tilde\mathbf{y} = \begin{pmatrix} y'_1 y_1 \\ y'_1 y_2 \\ y'_1 \\ y'_2 y_1 \\ y'_2 y_2 \\ y'_2 \\ y_1 \\ y_2 \\ 1 \end{pmatrix} </math> &nbsp; and &nbsp; <math> \mathbf{e} = \begin{pmatrix} e_{11} \\ e_{12} \\ e_{13} \\ e_{21} \\ e_{22} \\ e_{23} \\ e_{31} \\ e_{32} \\ e_{33} \end{pmatrix} </math>
</indent>

that is, <math> \mathbf{e} </math> represents the essential matrix in the form of a 9-dimensional vector and this vector must be orthogonal to the vector <math> \tilde\mathbf{y} </math> which can be seen as a vector representation of the <math> 3 \times 3 </math> matrix <math> \mathbf{y}' \, \mathbf{y}^{T} </math>.</p>
<p>

Each pair of corresponding image points produces a vector <math> \tilde\mathbf{y} </math>. Given a set of 3D points <math> \mathbf{P}_k </math> this corresponds to a set of vectors <math> \tilde\mathbf{y}_{k} </math> and all of them must satisfy</p>
<p>

<indent level="1">

<math> \mathbf{e} \cdot \tilde\mathbf{y}_{k} = 0 </math>
</indent>

for the vector <math> \mathbf{e} </math>. Given sufficiently many (at least eight) and linearly independent vectors <math> \tilde\mathbf{y}_{k} </math> it is then possible to determine <math> \mathbf{e} </math> in a straight-forward way. Collect all vectors <math> \tilde\mathbf{y}_{k} </math> as the columns of a matrix <math> \mathbf{Y} </math> and it must then be the case that</p>
<p>

<indent level="1">

<math> \mathbf{e}^{T} \, \mathbf{Y} = \mathbf{0} </math>
</indent>

This means that <math> \mathbf{e} </math> is the solution to a <link xlink:type="simple" xlink:href="../654/12643654.xml">
homogeneous linear equation</link>.</p>

</ss1>
<ss1>
<st>
 Step 2: Solving the equation </st>

<p>

A standard approach to solving this equation implies that <math> \mathbf{e} </math> is a <link xlink:type="simple" xlink:href="../207/142207.xml">
left singular vector</link> of <math> \mathbf{Y} </math> corresponding to a <link xlink:type="simple" xlink:href="../207/142207.xml">
singular value</link> that equals zero.  Provided that at eight vectors <math> \tilde\mathbf{y}_{k} </math>, which in addition are linearly independent, are used to construct <math> \mathbf{Y} </math> it follows that this singular vector is unique (disregarding scalar multiplication) and, consequently, <math> \mathbf{e} </math> and then <math> \mathbf{E} </math> can be determined.</p>
<p>

In the case that more than eight corresponding points are used to construct <math> \mathbf{Y} </math> it is possible that it does not have any singular value equal to zero.  This case occurs in practice when the image coordinates are affected by various types of noise.  A common approach to deal with this situation is to describe it as a total least squares problem; find <math> \mathbf{e} </math> which minimizes</p>
<p>

<indent level="1">

<math> \| \mathbf{e}^{T} \, \mathbf{Y} \| </math>
</indent>

when <math> \| \mathbf{e} \| = 1 </math>.  The solution is to choose <math> \mathbf{e} </math> as the left singular vector corresponding to the <it>smallest</it> singular value of <math> \mathbf{Y} </math>.  A reordering of this <math> \mathbf{e} </math> back into a <math> 3 \times 3 </math> matrix gives the result of this step, here referred to as <math> \mathbf{E}_{\rm est} </math>.</p>

</ss1>
<ss1>
<st>
 Step 3: Enforcing the internal constraint </st>

<p>

Another consequence of dealing with noisy image coordinates is that the resulting matrix may not satisfy the internal constraint of the essential matrix, that is, it has two equal and non-zero singular values and one singular values which is zero.  Depending on the application, smaller or larger deviations from the internal constraint may or may not be a problem.  If it is critical that the estimated matrix satisfies the internal constraints, this can be accomplished by finding the matrix <math> \mathbf{E}' </math> of rank 2 which minimizes</p>
<p>

<indent level="1">

<math> \| \mathbf{E}' - \mathbf{E}_{\rm est} \| </math>
</indent>

where <math> \mathbf{E}_{\rm est} </math> is the resulting matrix from Step 2 and the <link xlink:type="simple" xlink:href="../735/1543735.xml#xpointer(//*[./st=%22Frobenius+norm%22])">
Frobenius matrix norm</link> is used.  The solution to the problem is given by first computing a singular value decomposition of <math> \mathbf{E}_{\rm est} </math>:</p>
<p>

<indent level="1">

<math> \mathbf{E}_{\rm est} = \mathbf{U} \, \mathbf{S} \, \mathbf{V}^{T} </math>
</indent>

where <math> \mathbf{U}, \mathbf{V} </math> are orthogonal matrices and <math> \mathbf{S} </math> is a diagonal matrix which contains the singular values of <math> \mathbf{E}_{\rm est} </math>.  In the ideal case, one of the diagonal elements of <math> \mathbf{S} </math> should be zero, or at least small compared to the other two which should be equal.  In any case, set</p>
<p>

<indent level="1">

<math> \mathbf{S}' = \begin{pmatrix} 1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 0 \end{pmatrix} </math>
</indent>

Finally, <math> \mathbf{E}' </math> is given by</p>
<p>

<indent level="1">

<math> \mathbf{E}' = \mathbf{U} \, \mathbf{S}' \, \mathbf{V}^{T} </math>
</indent>

The matrix <math> \mathbf{E}' </math> is the resulting estimate of the essential matrix provided by the algorithm.</p>

</ss1>
</sec>
<sec>
<st>
 The normalized eight-point algorithm </st>

<p>

The basic eight-point algorithm can in principle be used also for estimating the fundamental matrix <math> \mathbf{F} </math>.  The defining constraint for <math> \mathbf{F} </math> is</p>
<p>

<indent level="1">

<math> (\mathbf{y}')^{T} \, \mathbf{F} \, \mathbf{y} = 0</math>
</indent>

where <math> \mathbf{y}, \mathbf{y}' </math> are the homogeneous representations of corresponding image coordinates (not necessary normalized).  This means that it is possible to form a matrix <math> \mathbf{Y} </math> in a similar way as for the essential matrix and solve the equation</p>
<p>

<indent level="1">

<math> \mathbf{f}^{T} \, \mathbf{Y} = \mathbf{0} </math> 
</indent>

for <math> \mathbf{f} </math> which is a reshaped version of <math> \mathbf{F} </math>.  By followíng the procedure outlines above, it is then possible to determine <math> \mathbf{F} </math> from a set of eight matching points.  In practice, however, the resulting fundamental matrix may not be useful for determining epipolar constraints.</p>

<ss1>
<st>
 The problem </st>

<p>

The problem is that the resulting <math> \mathbf{Y} </math> often is <link xlink:type="simple" xlink:href="../934/6934.xml">
ill-conditioned</link>.  In theory, <math> \mathbf{Y} </math> should have one singular value equal to zero and the rest are non-zero.  In practice, however, some of the non-zero singular values can become small relative to the larger ones.  If more than eight corresponding points are used to construct <math> \mathbf{Y} </math>, where the coordinates are only approximately correct, there may not be a well-defined singular value which can be identified as approximately zero.  Consequently, the solution of the homogeneous linear system of equations may not be sufficiently accurate to be useful.</p>

</ss1>
<ss1>
<st>
 What's causing the problem </st>

<p>

Hartley addressed this estimation problem in his 1997 article.  His analysis of the problem shows that the problem is caused by the homogeneous image coordinates, vectors in <math> \mathbb{R}^{3} </math>, can have a poor distribution in that space.  A typical homogeneous representation of the 2D image coordinate <math> (y_{1}, y_{2}) \, </math> is</p>
<p>

<indent level="1">

<math> \mathbf{y} = \begin{pmatrix} y_{1} \\ y_{2} \\ 1 \end{pmatrix} </math>
</indent>

where both <math> y_{1}, y_{2} \, </math> lie in the range 0 to 1000-2000 for a modern digital camera.  This means that the first two coordinates in <math> \mathbf{y} </math> vary over a much larger range than the third coordinate.  Furthermore, if the image points which are used to construct <math> \mathbf{Y} </math> lie in a relatively small region of the image, for example at <math> (700,700) \pm (100,100) \, </math>, again the vector <math> \mathbf{y} </math> points in more or less the same direction for all points.  As a consequence, <math> \mathbf{Y} </math> will have one large singular value and the remaining are small.</p>

</ss1>
<ss1>
<st>
 How it can be solved </st>

<p>

As a solution to this problem, Hartley proposed that the coordinate system of each of the two images should be transformed, independently, into a new coordinate system according to the following principle.</p>
<p>

<list>
<entry level="1" type="bullet">

 The origin of the new coordinate system should be centered (have its origin) at the centroid (center of gravity) of the image points.  This is accomplished by a translation of the original origin to the new one.</entry>
<entry level="1" type="bullet">

 After the translation the coordinates are uniformly scaled so that the mean distance from the origin to a point equals <math> \sqrt{2} </math>.</entry>
</list>
</p>
<p>

This principle results, normally, in a distinct coordinate transformation for each of the two images.  As a result, new homogeneous image coordinates <math> \mathbf{\bar y}, \mathbf{\bar y}' </math> are given by</p>
<p>

<indent level="1">

<math> \mathbf{\bar y} = \mathbf{T} \, \mathbf{y} </math>
</indent>
:<math> \mathbf{\bar y}' = \mathbf{T}' \, \mathbf{y}' </math></p>
<p>

where <math> \mathbf{T}, \mathbf{T}' </math> are the transformations (translation and scaling) from the old to the new <it>normalized image coordinates</it>.  This normalization is only dependent on the image points which are used in a single image and is, in general, distinct from normalized image coordinates produced by a normalized camera.</p>
<p>

The epipolar constraint based on the fundamental matrix can now be rewritten as</p>
<p>

<indent level="1">

<math> 0 = (\mathbf{\bar y}')^{T} \, ((\mathbf{T}')^{T})^{-1} \, \mathbf{F} \, \mathbf{T}^{-1}\, \mathbf{\bar y} = (\mathbf{\bar y}')^{T} \, \mathbf{\bar F} \, \mathbf{\bar y} </math>
</indent>

where <math> \mathbf{\bar F} = ((\mathbf{T}')^{T})^{-1} \, \mathbf{F} \, \mathbf{T}^{-1} </math>.  This means that it is possible to use the normalized homogeneous image coordinates <math> \mathbf{\bar y}, \mathbf{\bar y}' </math> to estimate the transformed fundamental matrix <math> \mathbf{\bar F} </math> using the basic eight-point algorithm described above.</p>
<p>

The purpose of the normalization transformations is that the matrix <math> \mathbf{\bar Y} </math>, constructed from the normalized image coordinates, in general has a better condition number than <math> \mathbf{Y} </math> has.  This means that the solution <math> \mathbf{\bar f} </math> is more well-defined as a solution of the homogeneous equation <math> \mathbf{\bar Y} \, \mathbf{\bar f} </math> than <math> \mathbf{f} </math> is relative to <math> \mathbf{Y} </math>.  Once <math> \mathbf{\bar f} </math> has been determined and reshaped into <math> \mathbf{\bar F} </math> the latter can be <it>de-normalized</it> to give <math> \mathbf{F} </math> according to</p>
<p>

<indent level="1">

<math> \mathbf{F} = (\mathbf{T}')^{T} \, \mathbf{\bar F} \, \mathbf{T} </math>
</indent>

In general, this estimate of the fundamental matrix is a better one than would have been obtained by estimating from the un-normalized coordinates.</p>

</ss1>
</sec>
<sec>
<st>
 Using fewer than eight points </st>

<p>

Each point pair contributes with one constraining equation on the element in <math> \mathbf{E} </math>. Since <math> \mathbf{E} </math> has five degrees of freedom it should therefore be sufficient with only five point pairs to determined <math> \mathbf{E} </math>. Though possible from a theoretical point of view, the practical implementation of this is not straight-forward and have to rely on solving various non-linear equations.</p>

</sec>
<sec>
<st>
 References </st>

<p>

<list>
<entry level="1" type="bullet">

  <cite style="font-style:normal">Richard I. Hartley&#32;(June 1997).&#32;"In Defense of the Eight-Point Algorithm". <it>IEEE Transaction on Pattern Recognition and Machine Intelligence</it>&#32;<b>19</b>&#32;(6): 580–593. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1109%2F34.601246">
10.1109/34.601246</weblink>.</cite>&nbsp;</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

  <cite style="font-style:normal" class="book">Richard Hartley and Andrew Zisserman&#32;(2003). Multiple View Geometry in computer vision.&#32;Cambridge University Press. ISBN 978-0-521-54051-3.</cite>&nbsp;</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

  <cite style="font-style:normal">H. Christopher Longuet-Higgins&#32;(Sep 1981).&#32;"A computer algorithm for reconstructing a scene from two projections". <it>Nature</it>&#32;<b>293</b>: 133–135. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1038%2F293133a0">
10.1038/293133a0</weblink>.</cite>&nbsp;</entry>
</list>
</p>

</sec>
</bdy>
</article>
