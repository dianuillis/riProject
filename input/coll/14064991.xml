<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 17.04.2009 02:18:05[mciao0826] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<artifact  confidence="0.8" wordnetid="100021939">
<instrumentality  confidence="0.8" wordnetid="103575240">
<engine  confidence="0.8" wordnetid="103287733">
<motor  confidence="0.8" wordnetid="103789946">
<device  confidence="0.8" wordnetid="103183080">
<machine  confidence="0.8" wordnetid="103699975">
<header>
<title>Audio search engine</title>
<id>14064991</id>
<revision>
<id>243387751</id>
<timestamp>2008-10-06T09:07:04Z</timestamp>
<contributor>
<username>Rick.nolan</username>
<id>7937793</id>
</contributor>
</revision>
<categories>
<category>Internet search engines</category>
</categories>
</header>
<bdy>

A <b>audio search engine</b> is a web-based <link xlink:type="simple" xlink:href="../023/4059023.xml">
search engine</link> which <link xlink:type="simple" xlink:href="../451/502451.xml">
crawl</link>s the web for <link xlink:type="simple" xlink:href="../ury/25th_century.xml">
audio</link> content. 
<sec>
<st>
 Popular audio search engines </st>


<ss2>
<st>
 Agnostic Search </st>
<p>
 
Search that is not affected by the hosting of video, where results are agnostic no matter where the video is located:</p>
<p>

<list>
<entry level="1" type="bullet">

 <b><link xlink:type="simple" xlink:href="../692/12548692.xml">
Everyzing</link></b> (formerly <link xlink:type="simple" xlink:href="../692/12548692.xml">
Podzinger</link> until May, 2007) claims to have spent millions of dollars building speech to text audio search.  Everyzing takes the user within the actual content by using speech recognition.  This enables online video consumers to jump directly to the point in the video for which they are searching. Everyzing founder/CEO recently acknowledged publicly.</entry>
<entry level="1" type="bullet">

  <b><company wordnetid="108058098" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../857/1619857.xml">
Picsearch</link></company>
 Audio Search</b> has been licensed to search portals since 2006. Picsearch is a search technology provider who powers image, video and audio search for over 100 major search engines around the world.</entry>
<entry level="1" type="bullet">

  <b><link xlink:type="simple" xlink:href="../579/19571579.xml">
Munax</link> Audio Video Search</b> released their first version all-content search engine in 2005 and powers both nation-wide and world-wide search engines.</entry>
</list>
</p>

</ss2>
<ss2>
<st>
 Non-agnostic Search </st>
<p>

Search results are modified, or suspect, due to the large hosted video being given preferential treatment in search results:</p>

</ss2>
</sec>
<sec>
<st>
 Design and algorithms </st>

<p>

Audio search has evolved slowly through several basic search formats which exist today and all use <link xlink:type="simple" xlink:href="../394/460394.xml">
keywords</link>.  The keywords for each search can be found in the title of the media, any text attached to the media and content linked web pages, also defined by authors and users of video hosted resources. </p>
<p>

It is generally acknowledged that speech to text is possible, though recently Thomas Wilde, the new CEO of EveryZing, acknowledged that Everyzing works 70% of the time when there is music, ambient noise or more than one person speaking. If newscast style speaking (one person, speaking clearly, no ambient noise) is available, that can rise to 93%.  (From the Web Video Summit, San Jose, CA, June 27, 2007).</p>
<p>

Around 40 <link xlink:type="simple" xlink:href="../980/22980.xml">
phonemes</link> exist in every language with about 400 in all spoken languages. Rather than applying a text search algorithm after speech-to-text processing is completed, some engines use a phonetic search algorithm to find results within the spoken word. Others work by literally listening to the entire podcast and creating a text transcription using a sophisticated speech-to-text process. Once the text file is created, the  website lets you search the file for any number of search words and phrases.</p>

</sec>
<sec>
<st>
See also</st>

<p>

<list>
<entry level="1" type="bullet">

<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<engine wordnetid="103287733" confidence="0.8">
<motor wordnetid="103789946" confidence="0.8">
<device wordnetid="103183080" confidence="0.8">
<machine wordnetid="103699975" confidence="0.8">
<link xlink:type="simple" xlink:href="../204/2849204.xml">
Video search engine</link></machine>
</device>
</motor>
</engine>
</instrumentality>
</artifact>
</entry>
<entry level="1" type="bullet">

<message wordnetid="106598915" confidence="0.8">
<information wordnetid="106634376" confidence="0.8">
<word wordnetid="106286395" confidence="0.8">
<format wordnetid="106636806" confidence="0.8">
<part wordnetid="113809207" confidence="0.8">
<neologism wordnetid="106294441" confidence="0.8">
<language_unit wordnetid="106284225" confidence="0.8">
<link xlink:type="simple" xlink:href="../453/1034453.xml">
Podcast</link></language_unit>
</neologism>
</part>
</format>
</word>
</information>
</message>
</entry>
</list>
</p>


</sec>
</bdy>
</machine>
</device>
</motor>
</engine>
</instrumentality>
</artifact>
</article>
