<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 17.04.2009 02:27:11[mciao0826] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Dominance-based Rough Set Approach</title>
<id>14333272</id>
<revision>
<id>200512818</id>
<timestamp>2008-03-24T11:21:50Z</timestamp>
<contributor>
<username>Welsh</username>
<id>310131</id>
</contributor>
</revision>
<categories>
<category>Theoretical computer science</category>
<category>Machine learning</category>
</categories>
</header>
<bdy>

<b>Dominance-based Rough Set Approach (DRSA)</b> is an extension of <link xlink:type="simple" xlink:href="../778/1634778.xml">
rough set theory</link> for <link xlink:type="simple" xlink:href="../551/1050551.xml">
 Multi Criteria Decision Analysis (MCDA)</link>, introduced by Greco, Matarazzo and Słowiński <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%223%22])">3</ref>. The main change comparing to the classical <link xlink:type="simple" xlink:href="../778/1634778.xml">
rough sets</link> is the substitution of the indiscernibility relation by a dominance relation, which permits to deal with inconsistencies typical to consideration of <b>criteria</b>  and <b>preference-ordered decision classes</b>.
<sec>
<st>
Multicriteria Classification (Sorting)</st>
<p>

<b><link>
Multicriteria classification</link></b> (<link>
sorting</link>) is one of the problems considered within <link xlink:type="simple" xlink:href="../551/1050551.xml">
MCDA</link> and can be stated as follows: given a set of objects evaluated by a set of <link>
 criteria</link> (attributes with preference-order domains), assign these objects to some pre-defined and preference-ordered decision classes, such that each object is assigned to exactly one class. Due to the preference ordering, improvement of evaluations of an object on the criteria should not worsen its class assignment. The sorting problem is very similar to the problem of <link xlink:type="simple" xlink:href="../244/1579244.xml">
 classification</link>, however, in the latter, the objects are evaluated by regular attributes and the decision classes are not necessarily preference ordered. The problem of multicriteria classification is also referred to as <link>
ordinal classification problem with monotonicity constraints</link> and often appears in real-life application when <link xlink:type="simple" xlink:href="../365/22365.xml">
ordinal</link> and <link xlink:type="simple" xlink:href="../260/48260.xml">
 monotone</link> properties follow from the domain knowledge about the problem.</p>
<p>

As an illustrative example, consider the problem of evaluation in a high school. The director of the school wants to assign students (<it>objects</it>) to three classes: <it>bad</it>, <it>medium</it> and <it>good</it> (notice that class <it>good</it> is preferred to <it>medium</it> and <it>medium</it> is preferred to <it>bad</it>). Each student is described by three criteria: level in Physics, Mathematics and Literature, each taking one of three possible values <it>bad</it>, <it>medium</it> and <it>good</it>. Criteria are preference-ordered and improving the level from one of the subjects should not result in worse global evaluation (class). </p>
<p>

As a more serious example, consider classification of bank clients, from the viewpoint of bankruptcy risk, into classes <it>safe</it> and <it>risky</it>. This may involve such characteristics as "<link xlink:type="simple" xlink:href="../537/1410537.xml">
return on equity</link> (ROE)", "<link xlink:type="simple" xlink:href="../956/3440956.xml">
return on investment</link> (ROI)" and "<link xlink:type="simple" xlink:href="../681/1324681.xml">
return on sales</link> (ROS)". The domains of these attributes are not simply ordered but involve a preference order since, from the viewpoint of bank managers, greater values of ROE, ROI or ROS are better for clients being analysed for bankruptcy risk . Thus, these attributes are criteria. Neglecting this information in <link xlink:type="simple" xlink:href="../947/2044947.xml">
knowledge discovery</link> may lead to wrong conclusions.</p>

</sec>
<sec>
<st>
Data Representation</st>

<ss1>
<st>
Decision Table</st>

<p>

In DRSA, data are often presented in the form of <b>decision table</b>. Formally, a decision table is the 4-touple <math>S = \langle U, Q, V, f \rangle</math>, where <math>U\,\!</math> is a finite set of objects, <math>Q\,\!</math> is a finite set of criteria, <math>V=\bigcup {}_{q \in Q} V_q</math> where <math>V_q\,\!</math> is the domain of the criterion <math>q\,\!</math> and <math>f \colon U \times Q \to V</math> is an <it>information function</it> such that <math>f(x,q) \in V_q</math> for every <math>(x,q) \in U \times Q</math>. The set <math>Q\,\!</math> is divided into <it>condition criteria</it> (set <math>C \neq \emptyset</math>) and the <it>decision criterion</it> (<it>class</it>) <math>d\,\!</math>. Notice, that <math>f(x,q)\,\!</math> is an evaluation of object <math>x\,\!</math> on criterion <math>q \in C</math>, while <math>f(x,d)\,\!</math> is the class assignment (decision value) of the object. An example of decision table is shown in Table 1 below.</p>

</ss1>
<ss1>
<st>
Outranking Relation</st>

<p>

It is assumed that the domain of a criterion <math>q \in Q</math> is completely <link xlink:type="simple" xlink:href="../582/23582.xml">
preorder</link>ed by an <b><link>
outranking relation</link></b> <math>\succeq_q</math>; <math>x \succeq_q y</math> means that <math>x\,\!</math> is at least as good as (outranks) <math>y\,\!</math> with respect to the criterion <math>q\,\!</math>. Without loss of generality, we assume that the domain of <math>q\,\!</math> is a subset of <link xlink:type="simple" xlink:href="../491/19725491.xml">
reals</link>, <math>V_q \subseteq \mathbb{R}</math>, and that the outranking relation is a simple order between real numbers <math>\geq\,\!</math> such that the following relation holds: <math>x \succeq_q y \iff f(x,q) \geq f(y,q)</math>. This relation is straightforward for gain-type ("the more, the better") criterion, e.g. <it>company profit</it>. For cost-type ("the less, the better") criterion, e.g. <it>product price</it>, this relation can be satisfied by negating the values from <math>V_q\,\!</math>.</p>

</ss1>
<ss1>
<st>
Decision Classes and Class Unions</st>

<p>

Let <math>T = \{1,\ldots,n\}\,\!</math>. The domain of decision criterion, <math>V_d\,\!</math> consist of <math>n\,\!</math> elements (without loss of generality we assume <math>V_d = T\,\!</math>) and induces a partition of <math>U\,\!</math> into <math>n\,\!</math> classes <math>\textbf{Cl}=\{Cl_t, t \in T\}</math>, where <math>Cl_t = \{x \in U \colon f(x,d) = t\}</math>. Each object <math>x \in U</math> is assigned to one and only one class <math>Cl_t, t \in T</math>. The classes are preference-ordered according to an increasing order of class indices, i.e. for all <math>r,s \in T</math> such that <math>r \geq s\,\!</math>, the objects from <math>Cl_r\,\!</math> are strictly preferred to the objects from <math>Cl_s\,\!</math>. For this reason, we can consider the <b>upward and downward unions of classes</b>, defined respectively, as:</p>
<p>

<indent level="1">

<math>
Cl^{\geq}_t = \bigcup_{s \geq t} Cl_s \qquad Cl^{\leq}_t \bigcup_{s \leq t} Cl_s \qquad t \in T
</math>
</indent>

</p>
</ss1>
</sec>
<sec>
<st>
Main Concepts</st>

<ss1>
<st>
Dominance</st>

<p>

We say that <math>x\,\!</math> <b>dominates</b> <math>y\,\!</math> with respect to <math>P \subseteq C</math>, denoted by <math> x D_p y\,\!</math>, if <math>x\,\!</math> is better than <math>y\,\!</math> on every criterion from <math>P\,\!</math>, <math>x \succeq_q y, \, \forall q \in P</math>.  For each <math>P \subseteq C</math>, the dominance relation <math>D_P\,\!</math> is <link xlink:type="simple" xlink:href="../458/200458.xml">
reflexive</link> and <link xlink:type="simple" xlink:href="../463/200463.xml">
transitive</link>, i.e. it is a <link xlink:type="simple" xlink:href="../582/23582.xml">
partial pre-order</link>. Given <math>P \subseteq C</math> and <math>x \in U</math>, let</p>
<p>

<indent level="1">

<math>
D_P^+(x) = \{y \in U \colon y D_p x \}
</math>
</indent>

<indent level="1">

<math>
D_P^-(x) = \{y \in U \colon x D_p y \}
</math>
</indent>

represent <b><it>P</it></b><b>-dominating</b> set and <b><it>P</it></b><b>-dominated</b> set with respect to <math>x \in U</math>, respectively.</p>

</ss1>
<ss1>
<st>
Rough Approximations</st>

<p>

The key idea of the <link xlink:type="simple" xlink:href="../778/1634778.xml">
rough set</link> philosophy is approximation of one knowledge by another knowledge. In DRSA, the knowledge being approximated is a collection of upward and downward unions of decision classes and the "granules of knowledge" used for approximation are <it>P</it>-dominating and <it>P</it>-dominated sets. </p>
<p>

The <b><it>P</it></b><b>-lower</b> and the <b><it>P</it></b><b>-upper approximation</b> of <math>Cl_t^{\geq}, t \in T</math> with respect to <math>P \subseteq C</math>, denoted as <math>\underline{P}(Cl_t^{\geq})</math> and <math>\overline{P}(Cl_t^{\geq})</math>, respectively, are defined as:</p>
<p>

<indent level="1">

<math>
\underline{P}(Cl_t^{\geq}) = \{x \in U \colon D_P^+(x) \subseteq Cl_t^{\geq} \}
</math>
</indent>

<indent level="1">

<math>
\overline{P}(Cl_t^{\geq}) = \{x \in U \colon D_P^-(x) \cap Cl_t^{\geq} \neq \emptyset\}
</math>
</indent>

Analogously, the <it>P</it>-lower and the <it>P</it>-upper approximation of <math>Cl_t^{\leq}, t \in T</math> with respect to <math>P \subseteq C</math>, denoted as <math>\underline{P}(Cl_t^{\leq})</math> and <math>\overline{P}(Cl_t^{\leq})</math>, respectively, are defined as:</p>
<p>

<indent level="1">

<math>
\underline{P}(Cl_t^{\leq}) = \{x \in U \colon D_P^-(x) \subseteq Cl_t^{\leq} \}
</math>
</indent>

<indent level="1">

<math>
\overline{P}(Cl_t^{\leq}) = \{x \in U \colon D_P^+(x) \cap Cl_t^{\leq} \neq \emptyset\}
</math>
</indent>

Lower approximations group the objects which <it>certainly</it> belong to class union <math>Cl^{\ge}_t</math> (respectively <math>Cl^{\le}_t</math>). This certainty comes from the fact, that object <math>x \in U</math> belongs to the lower approximation <math>\underline{P}(Cl^{\ge}_t)</math> (respectively <math>\underline{P}(Cl^{\le}_t)</math>), if no other object in <math>U\,\!</math> contradicts this claim, i.e. every object <math>y \in U</math> which <it>P</it>-dominates <math>x\,\!</math>, also belong to the class union <math>Cl^{\ge}_t</math> (respectively <math>Cl^{\le}_t</math>). Upper approximations group the objects which <it>could belong</it> to <math>Cl^{\ge}_t</math> (respectively <math>Cl^{\le}_t</math>), since object <math>x \in U</math> belongs to the upper approximation <math>\overline{P}(Cl^{\ge}_t)</math> (respectively <math>\overline{P}(Cl^{\le}_t)</math>), if there exist another object <math>y \in U</math> P-dominated by <math>x\,\!</math> from class union <math>Cl^{\ge}_t</math> (respectively <math>Cl^{\le}_t</math>).</p>
<p>

The <it>P</it>-lower and <it>P</it>-upper approximations defined as above satisfy the following properties for all <math>t \in T</math> and for any <math>P \subseteq C</math>:</p>
<p>

<indent level="1">

<math>
\underline{P}(Cl_t^{\geq}) \subseteq Cl_t^{\geq} \subseteq \overline{P}(Cl_t^{\geq})
</math>
</indent>

<indent level="1">

<math>
\underline{P}(Cl_t^{\leq}) \subseteq Cl_t^{\leq} \subseteq \overline{P}(Cl_t^{\leq})
</math>
</indent>

The <b><it>P</it></b><b>-boundaries</b> (<it>P-doubtful regions</it>) of <math>Cl_t^{\geq}</math> and <math>Cl_t^{\leq}</math> are defined as:</p>
<p>

<indent level="1">

<math>
Bn_P(Cl_t^{\geq}) = \overline{P}(Cl_t^{\geq})-\underline{P}(Cl_t^{\geq})
</math>
</indent>

<indent level="1">

<math>
Bn_P(Cl_t^{\leq}) = \overline{P}(Cl_t^{\leq})-\underline{P}(Cl_t^{\leq})
</math>
</indent>

</p>
</ss1>
<ss1>
<st>
Quality of Approximation and Reducts</st>

<p>

The ratio</p>
<p>

<indent level="1">

<math>
\gamma_P(\textbf{Cl}) = \frac{\left|U - \left( \left( \bigcup_{t \in T} Bn_P(Cl_t^{\geq}) \right) \cup \left( \bigcup_{t \in T} Bn_P(Cl_t^{\leq}) \right) \right)\right|}{|U|}
</math>
</indent>

defines the <b>quality of approximation</b> of the partition <math>\textbf{Cl}\,\!</math> into classes by means of the set of criteria <math>P\,\!</math>. This ratio express the relation between all the <it>P</it>-correctly classified objects and all the objects in the table.</p>
<p>

Every minimal subset <math>P \subseteq C</math> such that <math>\gamma_P(\mathbf{Cl}) = \gamma_C(\mathbf{Cl})\,\!</math> is called a <b><link xlink:type="simple" xlink:href="../972/12747972.xml">
reduct</link></b> of <math>C\,\!</math> and is denoted by <math>RED_{\mathbf{Cl}}(P)</math>. A decision table may have more than one reduct. The intersection of all reducts is known as the <it>core</it>.</p>

</ss1>
</sec>
<sec>
<st>
Decision Rules</st>

<p>

On the basis of the approximations obtained by means of the dominance relations, it is possible to induce a generalized description of the preferential information contained in the decision table, in terms of <b><link xlink:type="simple" xlink:href="../593/12769593.xml">
decision rules</link></b>. The decision rules are expressions of the form <it>if</it> [condition] <it>then</it> [consequent], that represent a form of dependency between condition criteria and decision criteria. Procedures for generating decision rules from a decision table use an inducive learning principle. We can distinguish three types of rules: certain, possible and approximate. Certain rules are generated from lower approximations of unions of classes; possible rules are generated from upper approximations of unions of classes and approximate rules are generated from boundary regions.</p>
<p>

Certain rules has the following form:</p>
<p>

<indent level="1">

</indent>
if <math>f(x,q_1) \geq r_1\,\!</math> and <math>f(x,q_2) \geq r_2\,\!</math> and <math>\ldots f(x,q_p) \geq r_p\,\!</math> then <math>x \in Cl_t^{\geq}</math></p>
<p>

<indent level="1">

</indent>
if <math>f(x,q_1) \leq r_1\,\!</math> and <math>f(x,q_2) \leq r_2\,\!</math> and <math>\ldots f(x,q_p) \leq r_p\,\!</math> then <math>x \in Cl_t^{\leq}</math></p>
<p>

Possible rules has a similar syntax, however the <it>consequent</it> part of the rule has the form: <math>x\,\!</math> <it>could belong to</it> <math>Cl_t^{\geq}</math> or the form: <math>x\,\!</math> <it>could belong to</it> <math>Cl_t^{\leq}</math>.</p>
<p>

Finally, approximate rules has the syntax:</p>
<p>

<indent level="1">

</indent>
if <math>f(x,q_1) \geq r_1\,\!</math> and <math>f(x,q_2) \geq r_2\,\!</math> and <math>\ldots f(x,q_k) \geq r_k\,\!</math> and <math>f(x,q_{k+1}) \leq r_{k+1}\,\!</math> and <math>f(x,q_{k+2}) \leq r_{k+2}\,\!</math> and <math>\ldots f(x,q_p) \leq r_p\,\!</math>
then <math>x \in Cl_s \cup Cl_{s+1} \cup Cl_t</math></p>
<p>

The certain, possible and approximate rules represent certain, possible and ambiguous knowledge extracted from the decision table. </p>
<p>

Each decision rule should be minimal. Since a decision rule is an
implication, by a minimal decision rule we understand such an implication that there is
no other implication with an antecedent of at least the same weakness (in other words,
rule using a subset of elementary conditions or/and weaker elementary conditions)
and a consequent of at least the same strength (in other words, rule assigning objects
to the same union or sub-union of classes).</p>
<p>

A set of decision rules is <it>complete</it> if it is able to cover all objects from the decision table in such a way that consistent objects are re-classified to their original classes and inconsistent objects are classified to clusters of classes referring to this inconsistency. We call <it>minimal</it> each set of decision rules that is complete and non-redundant, i.e. exclusion of any rule from this set makes it non-complete.
One of three induction strategies can be adopted to obtain a set of decision rules <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%224%22])">4</ref>:</p>
<p>

<list>
<entry level="1" type="bullet">

 generation of a minimal description, i.e. a minimal set of rules,</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 generation of an exhaustive description, i.e. all rules for a given data matrix,</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 generation of a characteristic description, i.e. a set of rules covering relatively many objects each, however, all together not necessarily all objects from the decision table</entry>
</list>
</p>
<p>

The most popular rule induction algorithm for dominance-based rough set approach is DOMLEM <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%225%22])">5</ref>, which generates minimal set of rules.</p>

</sec>
<sec>
<st>
Example</st>

<p>

Consider the following problem of high school students evaluations:</p>
<p>

<indent level="1">

| class="wikitable" style="text-align:center" border="1"
</indent>
|+ Table 1: Example -- High School Evaluations
! <it>object</it> (student) !! <math>q_1</math>  (Mathematics) !! <math>q_2</math>  (Physics) !! <math>q_3</math>  (Literature) !! !! <math>d</math>  (global score)
|-
!<math>x_1</math>
|medium || medium || bad || || bad
|-
!<math>x_2</math> 
|good || medium || bad || || medium
|-
!<math>x_3</math> 
|medium || good || bad || || medium
|-
!<math>x_4</math> 
|bad || medium || good || || bad
|-
!<math>x_5</math> 
|bad || bad || medium || || bad
|-
!<math>x_6</math> 
|bad || medium || medium || || medium
|-
!<math>x_7</math> 
|good || good || bad || || good
|-
!<math>x_8</math> 
|good || medium || medium || || medium
|-
!<math>x_9</math> 
|medium || medium || good || || good
|-
!<math>x_{10}</math> 
|good || medium || good || || good
|}</p>
<p>

Each object (student) is described by three criteria <math>q_1,q_2,q_3\,\!</math>, related to the levels in Mathematics, Physics and Literatire, respectively. According to the decision attribute, the students are divided into three preference-ordered classes: <math>Cl_1 = \{bad\}</math>, <math>Cl_2 = \{medium\}</math> and <math>Cl_3 = \{good\}</math>. Thus, the following unions of classes were approximated:</p>
<p>

<list>
<entry level="1" type="bullet">

 <math>Cl_1^{\leq}</math> i.e. the class of (at most) bad students,</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <math>Cl_2^{\leq}</math> i.e. the class of at most medium students,</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <math>Cl_2^{\geq}</math> i.e. the class of at least medium students,</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <math>Cl_3^{\geq}</math> i.e. the class of (at least) good students.</entry>
</list>
</p>
<p>

Notice that evaluations of objects <math>x_4\,\!</math> and <math>x_6\,\!</math> are inconsistent, because <math>x_4\,\!</math> has better evaluations on all three criteria than <math>x_6\,\!</math> but worse global score. </p>
<p>

Therefore, lower approximations of class unions consist of the following objects:</p>
<p>

<indent level="1">

<math>\underline{P}(Cl_1^{\leq}) = \{x_1,x_5\}</math> 
</indent>

<indent level="1">

<math>\underline{P}(Cl_2^{\leq}) = \{x_1,x_2,x_3,x_4,x_5,x_6,x_8\} = Cl_2^{\leq}</math> 
</indent>

<indent level="1">

<math>\underline{P}(Cl_2^{\geq}) = \{x_2,x_3,x_7,x_8,x_9,x_{10}\}</math> 
</indent>

<indent level="1">

<math>\underline{P}(Cl_3^{\geq}) = \{x_7,x_9,x_{10}\} = Cl_3^{\geq}</math> 
</indent>

Thus, only classes <math>Cl_1^{\leq}</math> and <math>Cl_2^{\geq}</math> cannot be approximated precisely. Their upper approximations are as follows:</p>
<p>

<indent level="1">

<math>\overline{P}(Cl_1^{\leq}) = \{x_1,x_4,x_5,x_6\}</math> 
</indent>

<indent level="1">

<math>\overline{P}(Cl_2^{\geq}) = \{x_2,x_3,x_4,x_6,x_7,x_8,x_9,x_{10}\}</math> 
</indent>

while their boundary regions are:</p>
<p>

<indent level="1">

<math>Bn_P(Cl_1^{\leq}) = Bn_P(Cl_2^{\geq}) = \{x_4,x_6\}</math>
</indent>

Of course, since <math>Cl_2^{\leq}</math> and <math>Cl_3^{\geq}</math> are approximated precisely, we have <math>\overline{P}(Cl_2^{\leq})=Cl_2^{\leq}</math>, <math>\overline{P}(Cl_3^{\geq})=Cl_3^{\geq}</math> and <math>Bn_P(Cl_2^{\leq}) = Bn_P(Cl_3^{\geq}) = \emptyset</math> </p>
<p>

The following minimal set of 9 rules can be induced from the decision table:</p>
<p>

<list>
<entry level="1" type="number">

 <it>if</it> <math>Physics \leq bad</math> <it>then</it> <math>student \leq bad</math></entry>
<entry level="1" type="number">

 <it>if</it> <math>Literature \leq bad</math> <it>and</it> <math>Physics \leq medium</math> <it>and</it> <math>Math \leq medium</math> <it>then</it> <math>student \leq bad</math></entry>
<entry level="1" type="number">

 <it>if</it> <math>Math \leq bad</math> <it>then</it> <math>student \leq medium</math></entry>
<entry level="1" type="number">

 <it>if</it> <math>Literature \leq medium</math> <it>then</it> <math>student \leq medium</math></entry>
<entry level="1" type="number">

 <it>if</it> <math>Literature \geq good</math> <it>and</it> <math>Math \geq medium</math> <it>then</it> <math>student \geq good</math></entry>
<entry level="1" type="number">

 <it>if</it> <math>Physics \geq good</math> <it>and</it> <math>Math \geq good</math> <it>then</it> <math>student \geq good</math></entry>
<entry level="1" type="number">

 <it>if</it> <math>Math \geq good</math> <it>then</it> <math>student \geq medium</math></entry>
<entry level="1" type="number">

 <it>if</it> <math>Physics \geq good</math> <it>then</it> <math>student \geq medium</math></entry>
<entry level="1" type="number">

 <it>if</it> <math>Math \leq bad</math> <it>and</it> <math>Physics \geq medium</math> <it>then</it> <math>student = bad \lor medium</math></entry>
</list>
</p>
<p>

The last rule is approximate, while the rest are certain.</p>

</sec>
<sec>
<st>
Extensions</st>

<ss1>
<st>
Multicriteria Choice and Ranking Problems</st>

<p>

The other two problems considered within <link>
Multicriteria Decision Analysis</link>, <link>
Multicriteria Choice</link> and <link xlink:type="simple" xlink:href="../394/1482394.xml">
Ranking</link> Problems, can also be solved using dominance-based rough set approach. This is done by converting the decision table into <link>
pairwise comparison table</link> (PCT)<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref>.</p>

</ss1>
<ss1>
<st>
Variable-consistency DRSA</st>

<p>

The definitions of rough approximations are based on a strict application of the dominance principle. However, when defining non-ambiguous objects, it is reasonable to accept a limited proportion of negative examples, particularly for large decision tables. Such extended version of DRSA is called <b><link>
Variable-Consistency DRSA</link> model (VC-DRSA)</b><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref></p>

</ss1>
<ss1>
<st>
Stochastic DRSA</st>

<p>

In real-life data, particularly for large datasets, the notions of rough approximations were found to be excessively restrictive. Therefore an extension of DRSA, based on stochastic model (<b><link>
Stochastic DRSA</link></b>), which allows inconsistencies to some degree, has been introduced<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%227%22])">7</ref>. Having stated the probabilistic model for ordinal classification problems with monotonicity constraints, the concepts of lower approximations are extended to the
stochastic case. The method is based on estimating the conditional probabilities using the nonparametric <link xlink:type="simple" xlink:href="../806/140806.xml">
maximum likelihood</link> method which leads
to the problem of <link xlink:type="simple" xlink:href="../143/2836143.xml">
isotonic regression</link>.</p>
<p>

Stochastic dominance-based rough sets can also be regarded as a sort of variable-consistency model.</p>

</ss1>
</sec>
<sec>
<st>
 Software </st>

<p>

<weblink xlink:type="simple" xlink:href="http://idss.cs.put.poznan.pl/site/software.html">
4eMka2</weblink> is a <link xlink:type="simple" xlink:href="../578/469578.xml">
decision support system</link> for multiple criteria classification problems based on dominance-based rough sets (DRSA). <weblink xlink:type="simple" xlink:href="http://idss.cs.put.poznan.pl/site/jamm.html">
JAMM</weblink> is a much more advanced successor of 4eMka2. Both systems are freely available for non-profit purposes on the <weblink xlink:type="simple" xlink:href="http://idss.cs.put.poznan.pl">
Laboratory of Intelligent Decision Support Systems (IDSS)</weblink> website.</p>

</sec>
<sec>
<st>
 See also </st>

<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../778/1634778.xml">
Rough sets</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../158/201158.xml">
Soft computing</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../204/1041204.xml">
Granular computing</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../551/1050551.xml">
 Multicriteria Decision Analysis (MCDA)</link></entry>
</list>
</p>

</sec>
<sec>
<st>
 References </st>


<p>

<reflist>
<entry id="1">
Greco, S., Matarazzo, B., Słowiński, R.: Rough sets theory for multicriteria decision analysis. European Journal of Operational Research, <b>129</b>, 1 (2001) 1--47</entry>
<entry id="2">
Greco, S., Matarazzo, B., Słowiński, R.: Multicriteria classification by
dominance-based rough set approach. In: W.Kloesgen and J.Zytkow (eds.), Handbook of Data Mining and Knowledge Discovery, Oxford University Press, New York, 2002</entry>
<entry id="3">
Słowiński, R., Greco, S., Matarazzo, B.: Rough set based decision support. Chapter 16 [in]: E.K. Burke and G. Kendall (eds.), Search Methodologies: Introductory Tutorials in Optimization and Decision Support Techniques, Springer-Verlag , New York (2005) 475-527</entry>
<entry id="4">
Stefanowski, J.: On rough set based approach to induction of decision rules. In Skowron, A., Polkowski, L. (eds.): Rough Set in Knowledge Discovering, Physica Verlag, Heidelberg (1998) 500--529</entry>
<entry id="5">
Greco S., Matarazzo, B., Słowiński, R., Stefanowski, J.: An Algorithm for Induction of Decision Rules Consistent with the Dominance Principle. In W. Ziarko, Y. Yao (eds.): Rough Sets and Current Trends in Computing. Lecture Notes in Artificial Intelligence <b>2005</b> (2001) 304--313. Springer-Verlag</entry>
<entry id="6">
Greco, S., B. Matarazzo, R. Slowinski and J. Stefanowski: Variable consistency model of dominance-based rough set approach. In W.Ziarko, Y.Yao (eds.): Rough Sets and Current Trends in Computing. Lecture Notes in Artificial Intelligence <b>2005</b> (2001) 170-181. Springer-Verlag</entry>
<entry id="7">
Dembczyński, K., Greco, S., Kotłowski, W., Słowiński, R.: Statistical model for rough set approach to multicriteria classification. In Kok, J.N., Koronacki, J., de Mantaras, R.L., Matwin, S.,
  Mladenic, D., Skowron, A. (eds.): Knowledge Discovery in Databases: PKDD 2007, Warsaw, Poland. Lecture Notes in Computer Science <b>4702</b> (2007) 164--175.</entry>
</reflist>
</p>

</sec>
<sec>
<st>
 External links </st>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.roughsets.org">
The International Rough Set Society</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://idss.cs.put.poznan.pl">
Laboratory of Intelligent Decision Support Systems (IDSS)</weblink> at <weblink xlink:type="simple" xlink:href="http://put.poznan.pl">
Poznań University of Technology</weblink>.</entry>
<entry level="1" type="bullet">

 Extensive list of DRSA references on the <weblink xlink:type="simple" xlink:href="http://idss.cs.put.poznan.pl/site/rslowinski.html">
Roman Słowiński</weblink> home page.</entry>
</list>
</p>

</sec>
</bdy>
</article>
