<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 16:19:17[mciao0827] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Algorithmic efficiency</title>
<id>145128</id>
<revision>
<id>244505930</id>
<timestamp>2008-10-11T03:40:53Z</timestamp>
<contributor>
<username>Kdakin</username>
<id>1684452</id>
</contributor>
</revision>
<categories>
<category>Information technology</category>
<category>Analysis of algorithms</category>
</categories>
</header>
<bdy>

In <link xlink:type="simple" xlink:href="../323/5323.xml">
computer science</link>, <b>efficiency</b> is used to describe properties of an <link xlink:type="simple" xlink:href="../775/775.xml">
algorithm</link> relating to how much of various types of resources it consumes. The two most frequently encountered are 
<list>
<entry level="1" type="bullet">

 speed or running time - the time it takes for an algorithm to complete, and</entry>
<entry level="1" type="bullet">

 space - the memory or 'non-volatile storage' used by the algorithm during its operation.</entry>
</list>

but also might apply to 
<list>
<entry level="1" type="bullet">

 transmission size or <link>
external memory</link> such as required bandwidth or disk space</entry>
</list>
<p>

The process of making code as efficient as possible is known as <link xlink:type="simple" xlink:href="../779/225779.xml">
Optimization</link> and in the case of automatic optimization (i.e. <link xlink:type="simple" xlink:href="../355/40355.xml">
compiler optimization</link>) - performed by compilers (on request or by default) - usually focus on space at the cost of speed, or vice versa. There are also quite simple programming techniques and 'avoidance strategies' that can actually improve both at the same time, usually irrespective of hardware, software or language. Even the re-ordering of nested conditional statements to put the least frequently occurring condition first (example: test patients for <link xlink:type="simple" xlink:href="../309/55309.xml">
blood type</link> ='AB-', before testing age &amp;gt; 18, since this type of blood occurs in only about 1 in 100 of the population - thereby eliminating the second test at <link xlink:type="simple" xlink:href="../263/192263.xml">
runtime</link> in 99% of instances), can reduce actual <link xlink:type="simple" xlink:href="../800/18839800.xml">
instruction path length</link>, something an optimizing compiler would almost certainly not be aware of but which a programmer can research relatively easily even without specialist medical knowledge.
</p>
<sec>
<st>
Speed</st>
<p>

The <b>absolute</b> speed of an algorithm for a given input can simply be measured as the duration of execution (or clock time) and the results can be averaged over several executions to eliminate possible random effects. Most modern processors operate in a <link xlink:type="simple" xlink:href="../020/64020.xml">
multi-processing</link> &amp; <link xlink:type="simple" xlink:href="../857/6857.xml">
multi-programming</link> environment so consideration must be made for parallel processes occurring on the same physical machine, eliminating these as far as possible. A <b>relative</b> measure of an algorithms performance can sometimes be gained from the total <link xlink:type="simple" xlink:href="../800/18839800.xml">
instruction path length</link> which can be determined by a run time <link xlink:type="simple" xlink:href="../791/3076791.xml">
Instruction Set Simulator</link> (where available).</p>
<p>

An <b>estimate</b> of the speed of an algorithm can be determined in various ways. The most common method uses <link xlink:type="simple" xlink:href="../543/7543.xml">
time complexity</link> to determine the <link xlink:type="simple" xlink:href="../578/44578.xml">
Big-O</link> of an algorithm. See <link xlink:type="simple" xlink:href="../ury/23rd_century.xml">
Run-time analysis</link> for estimating how fast a particular algorithm may be according to its type (example: lookup unsorted list, lookup sorted list etc) and in terms of <link xlink:type="simple" xlink:href="../529/185529.xml">
scalability</link> - its dependence on 'size of input', processor power and other factors.</p>

</sec>
<sec>
<st>
Memory</st>
<p>

Often, it is possible to make an algorithm faster at the expense of memory. This might be the case whenever the result of an 'expensive' calculation is <link xlink:type="simple" xlink:href="../829/6829.xml">
cache</link>d rather than recalculating it afresh each time. The additional memory requirement would, in this case, be considered additional <link xlink:type="simple" xlink:href="../671/2554671.xml">
overhead</link> although, in many situations, the stored result occupies very little extra space and can often be held in pre-compiled <link xlink:type="simple" xlink:href="../391/2783391.xml">
static</link> storage, reducing not just processing time but also allocation &amp; deallocation of working memory. This is a very common method of improving speed, so much so that some programming languages often add special features to support it, such as <programming_language wordnetid="106898352" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../038/72038.xml">
C++</link></programming_language>
's '<link xlink:type="simple" xlink:href="../824/197824.xml">
mutable</link>' keyword.</p>
<p>

The memory requirement of an algorithm is actually two separate but related things:-</p>
<p>

<list>
<entry level="1" type="bullet">

 The memory taken up by the compiled executable code (the <link xlink:type="simple" xlink:href="../307/337307.xml">
object code</link> or <link xlink:type="simple" xlink:href="../702/920702.xml">
binary file</link>) itself (on disk or equivalent, depending on the hardware and language). This can often be reduced by preferring run-time decision making mechanisms (such as <link xlink:type="simple" xlink:href="../664/374664.xml">
virtual function</link>s and <link xlink:type="simple" xlink:href="../913/598913.xml">
run-time type information</link>) over certain compile-time decision making mechanisms (such as <idea wordnetid="105833840" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<link xlink:type="simple" xlink:href="../560/20560.xml">
macro substitution</link></concept>
</idea>
 and <link xlink:type="simple" xlink:href="../218/31218.xml">
templates</link>). This, however, comes at the cost of speed.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 Amount of temporary "<link xlink:type="simple" xlink:href="../117/547117.xml">
dynamic memory</link>" allocated during processing. For example, dynamically pre-caching results, as mentioned earlier, improves speed at the cost of this attribute. Even the depth of sub-routine calls can impact heavily on this cost and increase path length too, especially if there are 'heavy' dynamic memory requirements for the particular functions invoked. The use of copied function parameters (rather than simply using <link xlink:type="simple" xlink:href="../018/459018.xml">
pointer</link>s to earlier, already defined, and sometimes <link xlink:type="simple" xlink:href="../365/1525365.xml">
static</link> values) actually <b>doubles</b> the memory requirement for this particular memory metric (as well as carrying its own processing <link xlink:type="simple" xlink:href="../671/2554671.xml">
overhead</link> for the copying itself. This can be particularly relevant for quite 'lengthy' parameters such as <link xlink:type="simple" xlink:href="../191/13191.xml">
html</link> script, <link xlink:type="simple" xlink:href="../845/9845.xml">
javascript</link> <link xlink:type="simple" xlink:href="../661/27661.xml">
source program</link>s or extensive freeform text such as letters or <link xlink:type="simple" xlink:href="../738/9738.xml">
email</link>s.</entry>
</list>
</p>
<p>

(See also sections <b>Choice of instruction or data type</b> and <b>Avoiding costs</b> concerning deliberate 'stretching' of data structures to force them to have a fixed length which then becomes a multiple of 2,4, 8 etc.)</p>

</sec>
<sec>
<st>
Transmission size</st>
<p>

<link xlink:type="simple" xlink:href="../013/8013.xml">
Data compression</link> algorithms can be useful because they help reduce the consumption of expensive resources, such as hard disk space or transmission bandwidth. This however also comes at a cost - which is additional processing time to compress and subsequently decompress. Depending upon the speed of the data transfer, compression may reduce overall <link xlink:type="simple" xlink:href="../662/41662.xml">
response time</link>s which, ultimately, equates to speed - even though processing within the computer itself takes longer. Transmission sizes of <link xlink:type="simple" xlink:href="../184/1191184.xml">
high resolution</link> <link xlink:type="simple" xlink:href="../925/71925.xml">
image</link>s for <link xlink:type="simple" xlink:href="../063/34063.xml">
web page</link>s can sometimes be acceptable at a much lower resolutions and this technique is one of several methods used by such commercial products as <link xlink:type="simple" xlink:href="../092/7483092.xml">
ONSPEED</link>. For audio , <format wordnetid="106636806" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../673/19673.xml">
MP3</link></format>
 is a compression method used extensively in portable sound systems. The efficiency of a data compression algorithm relates to the compression factor and speed of achieving both compression and decompression. For the purpose of archiving an extensive <link xlink:type="simple" xlink:href="../377/8377.xml">
database</link>, it might be considered worthwhile to achieve a very high compression ratio, since decompression is less likely to occur on the majority of the data.</p>

<ss1>
<st>
Rematerialization</st>
<p>

It has been argued that <change_of_state wordnetid="100199130" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<change wordnetid="100191142" confidence="0.8">
<improvement wordnetid="100248977" confidence="0.8">
<action wordnetid="100037396" confidence="0.8">
<optimization wordnetid="100260051" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<link xlink:type="simple" xlink:href="../423/1770423.xml">
Rematerialization</link></psychological_feature>
</act>
</optimization>
</action>
</improvement>
</change>
</event>
</change_of_state>
 (re-calculating) may occasionally be more efficient than holding results in cache. This is the somewhat non-intuitive belief that it can be faster to re-calculate from the input - even if the answer is already known - when it can be shown, in some special cases, to decrease "<link xlink:type="simple" xlink:href="../122/485122.xml">
register pressure</link>". Some optimizing compilers have the ability to decide when this is considered worthwhile based on a number of criteria such as complexity and no <link xlink:type="simple" xlink:href="../828/151828.xml">
side effects</link>, and works by keeping track of the expression used to compute each variable, using the concept of <link xlink:type="simple" xlink:href="../025/12274025.xml">
available expression</link>s.</p>

</ss1>
</sec>
<sec>
<st>
Optimization techniques</st>

<ss1>
<st>
Environment specific</st>
<p>

Optimization of algorithms frequently depends on the properties of the machine the algorithm will be executed on as well as the language the algorithm is written in and chosen <link xlink:type="simple" xlink:href="../817/93817.xml">
data type</link>s. For example, a programmer might optimize code for time efficiency in an application for home computers (with sizable amounts of memory), but for code destined to be embedded in small, "memory-tight" devices, the programmer may have to accept that it will run more slowly, simply because of the restricted memory available for any potential software optimization.</p>
<p>

For a discussion of <link xlink:type="simple" xlink:href="../615/13615.xml">
hardware</link> performance, see article on <link xlink:type="simple" xlink:href="../528/9007528.xml">
Computer performance</link> which covers such things as CPU clock speed, cycles per instruction and other relevant <link xlink:type="simple" xlink:href="../658/731658.xml">
metrics</link>. For a discussion on how the choice of particular instructions available on a specific machine effect efficiency, see later section 'Choice of instruction and data type'.</p>

</ss1>
<ss1>
<st>
General techniques</st>
<p>

<list>
<entry level="1" type="bullet">

 Table look-up's in particular can be very expensive in terms of execution time but can be reduced significantly through use of efficient techniques such as indexed arrays and <link xlink:type="simple" xlink:href="../266/4266.xml">
binary search</link>es. Using a look-up on 1st occurrence and indexed thereafter is an obvious compromise. </entry>
<entry level="1" type="bullet">

 Use of <link xlink:type="simple" xlink:href="../763/1603763.xml">
index</link>ed program branching, utilizing <link xlink:type="simple" xlink:href="../800/6894800.xml">
branch table</link>s to control program flow, (rather than using  multiple conditional IF statements or unoptimized <technique wordnetid="105665146" confidence="0.8">
<shell wordnetid="104190464" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<ammunition wordnetid="102703275" confidence="0.8">
<know-how wordnetid="105616786" confidence="0.8">
<method wordnetid="105660268" confidence="0.8">
<weaponry wordnetid="104566257" confidence="0.8">
<link xlink:type="simple" xlink:href="../991/780991.xml">
CASE/SWITCH</link></weaponry>
</method>
</know-how>
</ammunition>
</instrumentality>
</artifact>
</shell>
</technique>
) can drastically reduce <link xlink:type="simple" xlink:href="../800/18839800.xml">
instruction path length</link>, simultaneously reduce <link xlink:type="simple" xlink:href="../702/920702.xml">
program size</link> and even also make a program easier to read and more easily maintainable (in effect it becomes a '<link xlink:type="simple" xlink:href="../572/433572.xml">
decision table</link>' rather than repetitive <link xlink:type="simple" xlink:href="../732/28732.xml">
spaghetti code</link>).</entry>
</list>
</p>

</ss1>
<ss1>
<st>
Dependency trees and Spreadsheets</st>
<p>

<link xlink:type="simple" xlink:href="../686/27686.xml">
Spreadsheet</link>s are a 'special case' of algorithm that self optimize by virtue of their dependency trees that are inherent in the design of spreadsheets in order to reduce re-calculations when a cell changes. The results of earlier calculations are effectively cached within the workbook and only updated if a another cells changed value effects it directly.
</p>
</ss1>
<ss1>
<st>
Searching strings</st>
<p>

Searching for particular text strings in long sequences of characters potentially generates lengthy instruction paths. Several methods of reducing this cost have been examined and the "<link>
Boyer–Moore string search algorithm</link>" (or <link>
Boyer–Moore–Horspool algorithm</link>, a similar but modified version) is one solution that has been proven to give superior results to repetitive comparisons of the entire search string along the sequence <weblink xlink:type="simple" xlink:href="http://webhome.cs.uvic.ca/~nigelh/Publications/stringsearch.pdf">
http://webhome.cs.uvic.ca/~nigelh/Publications/stringsearch.pdf</weblink>.</p>

</ss1>
<ss1>
<st>
Hot spot analyzers</st>
<p>

Special system software products known as "performance analyzers" are often available from suppliers to help diagnose "<link xlink:type="simple" xlink:href="../994/13994.xml">
hot spot</link>s" - during actual execution of computer programs - using real or test data - they perform a  <link xlink:type="simple" xlink:href="../080/2310080.xml">
Performance analysis</link> under generally repeatable conditions <weblink xlink:type="simple" xlink:href="http://www-306.ibm.com/software/awdtools/apa/">
http://www-306.ibm.com/software/awdtools/apa/</weblink>. They can pinpoint sections of the program that might benefit from specifically targeted programmer optimization without necessarily spending time optimizing the rest of the code. Using program re-runs, a measure of relative improvement can then be determined to decide if the optimization was successful and by what amount. <link xlink:type="simple" xlink:href="../791/3076791.xml">
Instruction Set Simulator</link>s can be used as an alternative to measure the instruction path length at the machine code level between selected execution paths or on the entire execution.</p>

</ss1>
<ss1>
<st>
Benchmarking &amp; competitive algorithms</st>
<p>

For new versions of software or to provide comparisons with competitive systems, <standard wordnetid="107260623" confidence="0.8">
<benchmark wordnetid="107261143" confidence="0.8">
<system_of_measurement wordnetid="113577171" confidence="0.8">
<link xlink:type="simple" xlink:href="../870/1980870.xml">
benchmark</link></system_of_measurement>
</benchmark>
</standard>
s are sometimes used which assist with gauging an algorithms relative performance. If a new <link xlink:type="simple" xlink:href="../442/28442.xml">
sort</link> algorithm is produced for example it can be compared with its predecessors to ensure that at least it is efficient as before with known data - taking into consideration any functional improvements.
Benchmarks can be used by customers when comparing various products from alternative suppliers to estimate which product will best suit their specific requirements in terms of functionality and performance. For example in the <link xlink:type="simple" xlink:href="../330/20330.xml">
mainframe</link> world certain proprietary <link xlink:type="simple" xlink:href="../055/12640055.xml">
sort</link> products from independent software companies such as <company wordnetid="108058098" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../951/18431951.xml">
Syncsort</link></company>
 compete with products from the major suppliers such as <company wordnetid="108058098" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../259/18622259.xml">
IBM</link></company>
 for speed.
Some benchmarks provide opportunities for producing an analysis comparing the relative speed of various compiled and interpreted languages for example 
<weblink xlink:type="simple" xlink:href="http://freespace.virgin.net/roy.longbottom/whetstone.htm#anchorPC2">
http://freespace.virgin.net/roy.longbottom/whetstone.htm#anchorPC2</weblink>
<weblink xlink:type="simple" xlink:href="http://www.fourmilab.ch/fourmilog/archives/2005-08/000567.html">
http://www.fourmilab.ch/fourmilog/archives/2005-08/000567.html</weblink>
and <it>The Computer Language Benchmarks Game</it><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref> compares the performance of implementations of typical programming problems in several programming languages.
</p>
</ss1>
<ss1>
<st>
Compiled versus Interpreted languages</st>
<p>

A compiled algorithm will, in general, execute faster than the equivalent <link xlink:type="simple" xlink:href="../868/59868.xml">
interpreted</link> algorithm simply because some processing is required even at run time to 'understand' (i.e. interpret) the instructions to effect an execution. A compiled program will normally output an <link xlink:type="simple" xlink:href="../307/337307.xml">
object</link> or <link xlink:type="simple" xlink:href="../683/20683.xml">
machine code</link> equivalent of the algorithm that has already been processed by the compiler into a form more readily executed by <link xlink:type="simple" xlink:href="../999/19999.xml">
microcode</link> or the hardware directly. The popular <programming_language wordnetid="106898352" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../939/23939.xml">
Perl</link></programming_language>
 language is an example of an interpreted language and benchmarks indicate that it executes approximately 24 times more slowly than compiled C <weblink xlink:type="simple" xlink:href="http://www.fourmilab.ch/fourmilog/archives/2005-08/000567.html">
http://www.fourmilab.ch/fourmilog/archives/2005-08/000567.html</weblink>.</p>

</ss1>
<ss1>
<st>
Just-in-time compilers</st>
<p>

'On-the-fly' processors known today as <link xlink:type="simple" xlink:href="../632/220632.xml">
just-in-time</link> or 'JIT' compilers combine features of interpreted languages with compiled languages and may also incorporate elements of <link xlink:type="simple" xlink:href="../402/22402.xml">
optimization</link> to a greater or lesser extent. Essentially the JIT compiler can compile small sections of source code statements (or <link xlink:type="simple" xlink:href="../997/89997.xml">
bytecode</link>) as they are newly encountered and (usually) retain the result for the next time the same source is processed. In addition, pre-compiled segments of code can be in-lined or called as dynamic functions that themselves perform equally fast as the equivalent 'custom' compiled function. Because the JIT processor also has access to run-time information (that a normal compiler can't have) it is also possible for it to optimize further executions depending upon the input and also perform other run-time <link xlink:type="simple" xlink:href="../501/317501.xml">
introspective</link> optimization as execution proceeds. A JIT processor may, or may not, incorporate <link>
self modifying code</link> or its equivalent by creating 'fast path' routes through an algorithm. It may also use such techniques as dynamic <structure wordnetid="104341686" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../270/7543270.xml">
Fractional cascading</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</artifact>
</structure>
 or any other similar <link xlink:type="simple" xlink:href="../263/192263.xml">
runtime</link> device based on collected actual runtime <link xlink:type="simple" xlink:href="../658/731658.xml">
metrics</link>.
It is therefore entirely possible that a JIT compiler might (counter intuitively) execute even faster than an optimally 'optimized' compiled program.</p>

</ss1>
<ss1>
<st>
Genetic algorithm</st>
<p>

In the world of performance related algorithms it is worth mentioning the role of <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../254/40254.xml">
Genetic algorithm</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
s which compete using similar methods to the natural world in eliminating inferior algorithms in favour of more efficient versions.
</p>
</ss1>
<ss1>
<st>
Object code optimizers</st>
<p>

Some proprietary program optimizers such as the "COBOL Optimizer" developed by <company wordnetid="108058098" confidence="0.8">
<institution wordnetid="108053576" confidence="0.8">
<link xlink:type="simple" xlink:href="../249/8465249.xml">
Capex Corporation</link></institution>
</company>
 in the mid 1970's for <link xlink:type="simple" xlink:href="../799/6799.xml">
COBOL</link>, actually took the unusual step of optimizing the <link xlink:type="simple" xlink:href="../307/337307.xml">
Object code</link> (or <link xlink:type="simple" xlink:href="../702/920702.xml">
binary file</link>) <b>after</b> normal compilation. This method depended upon knowledge of 'weaknesses' in the standard IBM COBOL compiler and actually replaced (or <link xlink:type="simple" xlink:href="../153/475153.xml">
patch</link>ed) sections of the object code with more efficient code. The replacement code might replace a linear <arrangement wordnetid="107938773" confidence="0.8">
<group wordnetid="100031264" confidence="0.8">
<array wordnetid="107939382" confidence="0.8">
<link xlink:type="simple" xlink:href="../457/356457.xml">
table lookup</link></array>
</group>
</arrangement>
 with a <link xlink:type="simple" xlink:href="../266/4266.xml">
binary search</link> for example or sometimes simply replace a relatively 'slow' instruction with a known faster one that was otherwise functionally equivalent within its context. For example on the <link xlink:type="simple" xlink:href="../294/29294.xml">
IBM/360</link> hardware the <b>CLI</b> instruction was, depending on the particular model, between twice and 5 times as fast as a <b>CLC</b> instruction for single byte comparisons <weblink xlink:type="simple" xlink:href="http://www.bitsavers.org/pdf/ibm/360/A22_6825-1_360instrTiming.pdf">
http://www.bitsavers.org/pdf/ibm/360/A22_6825-1_360instrTiming.pdf</weblink> <weblink xlink:type="simple" xlink:href="http://portal.acm.org/citation.cfm?id=358732&amp;dl=GUIDE&amp;dl=ACM">
http://portal.acm.org/citation.cfm?id=358732&amp;dl=GUIDE&amp;dl=ACM</weblink>.
</p>
</ss1>
<ss1>
<st>
Choice of instruction or data type</st>
<p>

Particularly in an <link xlink:type="simple" xlink:href="../448/466448.xml">
Assembler</link> language (although also applicable to <link xlink:type="simple" xlink:href="../281/532281.xml">
HLL</link> statements), the choice of a particular 'instruction' or <link xlink:type="simple" xlink:href="../817/93817.xml">
data type</link>, can have a large impact on execution efficiency. In general, instructions that process variables such as signed or unsigned <link xlink:type="simple" xlink:href="../535/64535.xml">
16 bit</link> or <link xlink:type="simple" xlink:href="../733/80733.xml">
32 bit</link> <link xlink:type="simple" xlink:href="../563/14563.xml">
integer</link>s are faster than those that process <link xlink:type="simple" xlink:href="../376/11376.xml">
floating point</link> or <link xlink:type="simple" xlink:href="../821/3821.xml">
packed decimal</link>. If the largest integer to be encountered can be accommodated by the 'faster' data type, defining the variables as that type will result in faster execution - since even a non-<link xlink:type="simple" xlink:href="../355/40355.xml">
optimizing compiler</link> will, in-effect, be 'forced' to choose appropriate instructions that will execute faster than would have been the case with data types associated with 'slower' instructions. Assembler programmers (and optimizing compiler writers) can then also benefit from the ability to perform certain common types of arithmatic for instance - division by 2, 4, 8 etc by performing the very much faster binary shift right operations (in this case by 1,2 or 3 bits). </p>
<p>

If the choice of input data type is not under the control of the programmer, although prior conversion (outside of a loop for instance) to a faster data type carries some <link xlink:type="simple" xlink:href="../671/2554671.xml">
overhead</link>, it can often be worthwhile if the variable is then to be used as a <link xlink:type="simple" xlink:href="../422/37422.xml">
loop</link> counter, especially if the count could be quite a high value or there are many input values to process. As mentioned above, choice of individual assembler instructions (or even sometimes just their order of execution) on particular machines can effect the efficiency of an algorithm. See <weblink xlink:type="simple" xlink:href="http://mark.masmcode.com/">
Assembly Optimization Tips</weblink> for one quite numerous <link xlink:type="simple" xlink:href="../109/10109.xml">
arcane</link> list of various technical (and sometimes non-intuitive) considerations for choice of assembly instructions on different processors that also discusses the merits of each case. Sometimes <link xlink:type="simple" xlink:href="../999/19999.xml">
microcode</link> or <link xlink:type="simple" xlink:href="../615/13615.xml">
hardware</link> <link xlink:type="simple" xlink:href="../702/4283702.xml">
quirk</link>s can result in unexpected performance differences between processors that assembler programmers can actively code for - or else specifically avoid if penalties result - something even the best optimizing compiler may not be designed to handle.</p>

</ss1>
<ss1>
<st>
Software validation versus hardware validation</st>
<p>

An optimization technique that was frequently taken advantage of on '<link xlink:type="simple" xlink:href="../295/18295.xml">
legacy</link>' platforms was that of allowing the hardware (or <link xlink:type="simple" xlink:href="../999/19999.xml">
microcode</link>) to perform validation on <link xlink:type="simple" xlink:href="../891/10143891.xml">
numeric</link> data fields such as those coded in <link xlink:type="simple" xlink:href="../821/3821.xml">
packed decimal</link> (or packed BCD).
The choice was to either spend processing time checking each field for a valid numeric content in the particular internal representation chosen or simply assume the data was correct and let the <link xlink:type="simple" xlink:href="../615/13615.xml">
hardware</link> detect the error upon execution. The choice was highly significant because in order to to check for validity on multiple fields (for sometimes many millions of input records), it could occupy valuable computer resources. Since input data fields were in any case frequently built from the output earlier computer processing, the actual probability of a field containing invalid data was exceedingly low and usually the result of some 'corruption'.
The solution was to incorporate an 'event handler' for the hardware detected condition ('<abnormality wordnetid="114501726" confidence="0.8">
<condition wordnetid="113920835" confidence="0.8">
<state wordnetid="100024720" confidence="0.8">
<physical_condition wordnetid="114034177" confidence="0.8">
<anomaly wordnetid="114505821" confidence="0.8">
<link xlink:type="simple" xlink:href="../231/59231.xml">
data exception</link></anomaly>
</physical_condition>
</state>
</condition>
</abnormality>
)' that would intercept the occasional errant data field and either 'report, correct and continue' or, more usually, <link xlink:type="simple" xlink:href="../478/60478.xml">
abort</link> the run with a <link xlink:type="simple" xlink:href="../721/49721.xml">
core dump</link> to try to determine the reason for the bad data.
Similar event handlers are frequently utilized in today's web based applications to handle other exceptional conditions but repeatedly parsing data input,in order to ensure its validity before execution, has nevertheless become much more commonplace - partly because processors have become faster (and the perceived need for efficiency in this area less significant) but, predominantly - because <link xlink:type="simple" xlink:href="../519/8519.xml">
data structure</link>s have become less 'formalized' (eg. <message wordnetid="106598915" confidence="0.8">
<information wordnetid="106634376" confidence="0.8">
<format wordnetid="106636806" confidence="0.8">
<link xlink:type="simple" xlink:href="../645/2084645.xml">
.csv</link></format>
</information>
</message>
 and <link xlink:type="simple" xlink:href="../109/1116109.xml">
.tsv</link> files) or uniquely identifiable (eg. <link xlink:type="simple" xlink:href="../821/3821.xml">
packed decimal</link>). The potential savings using this type of technique may have therefore fallen into general dis-use as a consequence and therefore repeated data validations and repeated data conversions have become an accepted <link xlink:type="simple" xlink:href="../399/1932399.xml">
overhead</link>. Ironically, one consequence of this move to less formalized data structures  is that a corruption of say, a numeric binary <link xlink:type="simple" xlink:href="../563/14563.xml">
integer</link> value, will not be detected at all by the hardware upon execution (for instance: is an <message wordnetid="106598915" confidence="0.8">
<protocol wordnetid="106665108" confidence="0.8">
<representation wordnetid="105926676" confidence="0.8">
<direction wordnetid="106786629" confidence="0.8">
<rule wordnetid="106652242" confidence="0.8">
<link xlink:type="simple" xlink:href="../586/586.xml">
ASCII</link></rule>
</direction>
</representation>
</protocol>
</message>
 <link xlink:type="simple" xlink:href="../263/13263.xml">
hexadecimal</link> value '32323232' a valid signed or unsigned binary value - or simply a string of blanks that has corrupted it?)</p>

</ss1>
<ss1>
<st>
Avoiding costs</st>
<p>

<list>
<entry level="1" type="bullet">

 Defining variables as <link xlink:type="simple" xlink:href="../563/14563.xml">
integer</link>s for indexed arrays instead of <link xlink:type="simple" xlink:href="../376/11376.xml">
floating point</link> will result in faster execution (see above).</entry>
<entry level="1" type="bullet">

 Defining structures whose structure length is a multiple of a power of 2 (2,4,8,16 etc), will allow the compiler to calculate <link xlink:type="simple" xlink:href="../052/2052.xml">
array</link> indexes by shifting a binary index by 1, 2 or more bits to the left, instead of using a multiply instruction will result in faster execution. Adding an otherwise redundant short filler variable to 'pad out' the length of a structure element to say 8 bytes when otherwise it would have been 6 or 7 bytes may reduce overall processing time by a worthwhile amount for very large arrays. See <weblink xlink:type="simple" xlink:href="http://www.eventhelix.com/realtimemantra/Basics/CToAssemblyTranslation2.htm">
http://www.eventhelix.com/realtimemantra/Basics/CToAssemblyTranslation2.htm</weblink> for generated code differences for <programming_language wordnetid="106898352" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../021/6021.xml">
C</link></programming_language>
 as for example. </entry>
<entry level="1" type="bullet">

 Storage defined in terms of bits, when bytes would suffice, may inadvertently involve extremely long path lengths involving <link xlink:type="simple" xlink:href="../399/264399.xml">
bitwise operation</link>s instead of more efficient single instruction 'multiple byte' copy instructions. (This does not apply to 'genuine' intentional bitwise operations - used for example instead of multiplication or division by powers of 2 or for TRUE/FALSE flags).</entry>
<entry level="1" type="bullet">

 Unnecessary use of allocated <link xlink:type="simple" xlink:href="../117/547117.xml">
dynamic storage</link> when <link xlink:type="simple" xlink:href="../391/2783391.xml">
static storage</link> would suffice, can increase the processing overhead substantially - both increasing memory requirements and the associated allocation/deallocation <link xlink:type="simple" xlink:href="../749/498749.xml">
path length</link> overheads for each <link xlink:type="simple" xlink:href="../988/40988.xml">
function call</link>.</entry>
<entry level="1" type="bullet">

 Excessive use of function calls for very simple functions, rather than in-line statements, can also add substantially to <link xlink:type="simple" xlink:href="../800/18839800.xml">
instruction path length</link>s and <link xlink:type="simple" xlink:href="../993/273993.xml">
stack</link>/unstack overheads. For particularly time critical systems that are not also code size sensitive, automatic or manual <link xlink:type="simple" xlink:href="../884/216884.xml">
inline expansion</link> can reduce path length by eliminating all the instructions that call the function and return from it or .A conceptually similar method, <link xlink:type="simple" xlink:href="../647/1052647.xml">
loop unwinding</link>, eliminates the instructions required to set up and terminate a <link xlink:type="simple" xlink:href="../459/45459.xml#xpointer(//*[./st=%22Loops%22])">
loop</link> by, instead; repeating the instructions inside the loop multiple times. This of course eliminates the branch back instruction but also increases the size of the <link xlink:type="simple" xlink:href="../702/920702.xml">
binary file</link> or, in the case of <link xlink:type="simple" xlink:href="../632/220632.xml">
JIT</link> built code, <link xlink:type="simple" xlink:href="../117/547117.xml">
dynamic memory</link>. Care must be taken with this method however that re-calculating addresses for each statement for an unwound indexed loop is not more expensive than incrementing <idea wordnetid="105833840" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<category wordnetid="105838765" confidence="0.8">
<type wordnetid="105840188" confidence="0.8">
<kind wordnetid="105839024" confidence="0.8">
<link xlink:type="simple" xlink:href="../018/459018.xml">
pointer</link></kind>
</type>
</category>
</concept>
</idea>
s within the former loop.</entry>
</list>
</p>

</ss1>
<ss1>
<st>
Readability, trade offs and trends</st>
<p>

One must be careful, in the pursuit of good coding style, not to over-emphasize efficiency. Frequently, a clean, readable and 'usable' design is much more important than a fast, efficient design that is hard to understand. There are exceptions to this 'rule' (such as <link xlink:type="simple" xlink:href="../630/46630.xml">
embedded system</link>s, where space is tight, and processing power minimal) but these are rarer than one might expect.</p>
<p>

However, increasingly, for many 'time critical' applications such as air line reservation systems, <link xlink:type="simple" xlink:href="../633/220633.xml">
point-of-sale</link> applications, <link xlink:type="simple" xlink:href="../628/46628.xml">
ATM's</link> (cash-point machines), Airline <link xlink:type="simple" xlink:href="../341/319341.xml">
Guidance system</link>s, <link xlink:type="simple" xlink:href="../843/18012843.xml">
Collision avoidance systems</link> and numerous modern web based applications - operating in a <link xlink:type="simple" xlink:href="../767/25767.xml">
real-time</link> environment where speed of response is fundamental - there is little alternative.</p>

</ss1>
<ss1>
<st>
Determining if optimization is worthwhile</st>
<p>
 
The essential criteria for using optimized code is of course dependant upon the expected use of the algorithm. If it is a new algorithm and is going to be in use for many years and speed is relevant, it is worth spending some time designing the code to be as efficient as possible from the outset. If an existing algorithm is proving to be too slow or memory becoming an issue, clearly something must be done to improve it.</p>
<p>

For the average application, or for one-off applications, avoiding inefficient coding techniques and encouraging the compiler to optimize where possible may be sufficient.</p>
<p>

One simple way (at least for mathematicians!) to determine whether an optimization is worthwhile is as follows: Let the original time and space requirements (generally in Big-O notation) of the algorithm be <math>O_1</math> and <math>O_2</math>. Let the new code require <math>N_1</math> and <math>N_2</math> time and space respectively. If <math>N_1 N_2 &amp;lt; O_1 O_2 </math>, the optimization should be carried out. However, as mentioned above, this may not always be true.
</p>
</ss1>
<ss1>
<st>
Implications for algorithmic efficiency</st>
<p>

A recent report, published in December 2007, from Global Action Plan <weblink xlink:type="simple" xlink:href="http://www.globalactionplan.org.uk/">
http://www.globalactionplan.org.uk/</weblink>, a UK-based environmental organisation found that computer <generic wordnetid="107899976" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../116/42116.xml">
server</link></generic>
s are "at least as great a threat to the <link xlink:type="simple" xlink:href="../999/5999.xml">
climate</link> as <link xlink:type="simple" xlink:href="../696/47696.xml">
SUV</link>s or the global <link xlink:type="simple" xlink:href="../422/58422.xml">
aviation</link> industry" drawing attention to the carbon footprint of the <link xlink:type="simple" xlink:href="../340/15340.xml">
IT</link> industry in the UK. <weblink xlink:type="simple" xlink:href="http://environment.newscientist.com/article/dn12992-computer-servers-as-bad-for-climate-as-suvs.html">
http://environment.newscientist.com/article/dn12992-computer-servers-as-bad-for-climate-as-suvs.html</weblink> <weblink xlink:type="simple" xlink:href="http://www.sierraclub.org/sierra/200703/innovators.asp">
http://www.sierraclub.org/sierra/200703/innovators.asp</weblink>. 
According to an <periodical wordnetid="106593296" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../974/13416974.xml">
Environmental Research Letters</link></periodical>
 report published in September 2008, "Total power used by information technology equipment in data centers represented about 0.5% of world   electricity consumption in 2005.When cooling and auxiliary infrastructure are included, that figure is about 1%. The total data center power demand in 2005 is equivalent (in capacity terms) to about seventeen 1000 MW power plants for the world."<weblink xlink:type="simple" xlink:href="http://www.iop.org/EJ/article/1748-9326/3/3/034008/erl8_3_034008.html#erl280630s6">
http://www.iop.org/EJ/article/1748-9326/3/3/034008/erl8_3_034008.html#erl280630s6</weblink></p>
<p>

Computers having become increasingly more powerful over the past few decades, emphasis was on a 'brute force' mentality. This may have to be reconsidered in the light of these reports and more effort placed in future on reducing <link xlink:type="simple" xlink:href="../904/2263904.xml">
carbon footprint</link>s through optimization. It is a timely reminder that algorithmic efficiency is just another aspect of the more general <link xlink:type="simple" xlink:href="../093/4024093.xml">
thermodynamic efficiency</link>. The genuine economic benefits of an optimized algorithm are, in any case, that more processing can be done for the same cost or that useful results can be shown in a more timely manner and ultimately, acted upon sooner.</p>

</ss1>
</sec>
<sec>
<st>
See also</st>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www-sr.informatik.uni-tuebingen.de/~buehler/BM/BM1.html">
Animation of the Boyer-Moore algorithm</weblink></entry>
<entry level="1" type="bullet">

 <algorithm wordnetid="105847438" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../266/4266.xml">
Binary search algorithm</link></algorithm>
 - a simple and efficient technique for searching sorted <link xlink:type="simple" xlink:href="../052/2052.xml">
array</link>s</entry>
<entry level="1" type="bullet">

 <standard wordnetid="107260623" confidence="0.8">
<benchmark wordnetid="107261143" confidence="0.8">
<system_of_measurement wordnetid="113577171" confidence="0.8">
<link xlink:type="simple" xlink:href="../870/1980870.xml">
Benchmark</link></system_of_measurement>
</benchmark>
</standard>
 - a method for measuring comparative execution times in defined cases</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../956/37956.xml">
Best, worst and average case</link> - considerations for estimating execution times in three scenarios</entry>
<entry level="1" type="bullet">

 <idea wordnetid="105833840" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<link xlink:type="simple" xlink:href="../800/6894800.xml">
Branch table</link></concept>
</idea>
 - a technique for reducing instruction path-length, size of <link xlink:type="simple" xlink:href="../683/20683.xml">
machine code</link>, (and often also memory}</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../355/40355.xml">
Compiler optimization</link> - compiler derived optimization</entry>
<entry level="1" type="bullet">

 also <link xlink:type="simple" xlink:href="../355/40355.xml">
Optimizing compiler</link> - a specifically designed compiler for <link xlink:type="simple" xlink:href="../779/225779.xml">
optimization</link> at compile time</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../543/7543.xml">
Computational complexity theory</link> </entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../528/9007528.xml">
Computer performance</link>, - computer hardware metrics</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../013/8013.xml">
Data compression</link>, - reducing transmission bandwidth and disk storage</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../763/1603763.xml">
Index (information technology)</link> - a technique for fast lookup using <link xlink:type="simple" xlink:href="../763/1603763.xml">
index</link>es</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../028/64028.xml">
Locality of reference</link> - for avoidance of <link xlink:type="simple" xlink:href="../829/6829.xml">
caching</link> delays caused by non-local memory access</entry>
<entry level="1" type="bullet">

 <change_of_state wordnetid="100199130" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<change wordnetid="100191142" confidence="0.8">
<improvement wordnetid="100248977" confidence="0.8">
<action wordnetid="100037396" confidence="0.8">
<optimization wordnetid="100260051" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<link xlink:type="simple" xlink:href="../754/1837754.xml">
Loop optimization</link></psychological_feature>
</act>
</optimization>
</action>
</improvement>
</change>
</event>
</change_of_state>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../779/225779.xml">
Optimization (computer science)</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../080/2310080.xml">
Performance analysis</link>, methods of measuring actual performance of an algorithm at run-time</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../767/25767.xml">
Real-time computing</link>, for further examples of time critical applications</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../ury/23rd_century.xml">
Run-time analysis</link>, estimation of expected run-times and an algorithms scalability</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../080/930080.xml">
Virtual method table</link> branch table with dynamically assigned pointers for dispatching</entry>
</list>
</p>

</sec>
<sec>
<st>
References</st>

<p>

<reflist>
<entry id="1">
<weblink xlink:type="simple" xlink:href="http://shootout.alioth.debian.org/">
The Computer Language Benchmarks Game</weblink></entry>
</reflist>
</p>


</sec>
</bdy>
</article>
