<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 17.04.2009 02:28:58[mciao0828] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Segmentation based object categorization</title>
<id>14681852</id>
<revision>
<id>231954623</id>
<timestamp>2008-08-14T19:04:33Z</timestamp>
<contributor>
<username>Wikited</username>
<id>963368</id>
</contributor>
</revision>
<categories>
<category>Computer vision</category>
<category>Object recognition and categorization</category>
</categories>
</header>
<bdy>

The image segmentation problem is concerned with partitioning an image into multiple regions according to some homogeneity criterion. This article is primarily concerned with graph theoretic approaches to image segmentation.












<sec>
<st>
Applications of Image Segmentation</st>
<p>

<list>
<entry level="1" type="bullet">

 <b>Image Compression</b></entry>
<entry level="2" type="bullet">

 Segment the image into homogeneous components, and use the most suitable compression algorithm for each component to improve compression.</entry>
<entry level="1" type="bullet">

 <b>Medical Diagnosis</b></entry>
<entry level="2" type="bullet">

 Automatic segmentation of MRI images for identification of  cancerous regions.</entry>
<entry level="1" type="bullet">

 <b>Mapping and Measurement</b></entry>
<entry level="2" type="bullet">

 Automatic analysis of remote sensing data from satellites to identify and measure regions of interest.</entry>
</list>
</p>

</sec>
<sec>
<st>
Segmentation using Normalized Cuts</st>

<ss1>
<st>
Graph theoretic formulation</st>
<p>

The set of points in an arbitrary feature space can be represented as a weighted undirected complete graph G = (V, E), where the nodes of the graph are the points in the feature space. The weight <math>w_{ij}</math> of an edge <math>(i, j) \in E</math> is a function of the similarity between the nodes <math>i</math> and <math>j</math>. In this context, we can formulate the image segmentation problem as a graph partitioning problem that asks for a partition <math>V_1, \cdots, V_k</math> of the vertex set <math>V</math>, where, according to some measure, the vertices in any set <math>V_i</math> have high similarity, and the vertices in two different sets <math>V_i, V_j</math> have low similarity. </p>

</ss1>
<ss1>
<st>
Normalized Cuts</st>
<p>

Let G = (V, E) be a weighted graph. Let <math>A</math> and <math>B</math> be two subsets of vertices.</p>
<p>

Let:</p>
<p>

<math>w(A, B) = \sum \limits_{i \in A, j \in B} w_{ij}</math></p>
<p>

<math>ncut(A, B) = \frac{w(A, B)}{w(A, V)} + \frac{w(A, B)}{w(B, V)}</math></p>
<p>

<math>nassoc(A, B) = \frac{w(A, A)}{w(A, V)} + \frac{w(B, B)}{w(B, V)}</math></p>
<p>

In the normalized cuts approach<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref>, for any cut <math>(S, \overline{S})</math> in <math>G</math>, <math>ncut(S, \overline{S})</math> measures the similarity between different parts, and <math>nassoc(S, \overline{S})</math> measures the total similarity of vertices in the same part.</p>
<p>

Since <math>ncut(S, \overline{S}) = 2 - nassoc(S, \overline{S})</math>, a cut <math>(S^{*}, {\overline{S}}^{*})</math> that minimizes <math>ncut(S, \overline{S})</math> also maximizes <math>nassoc(S, \overline{S})</math>. </p>
<p>

Computing a cut <math>(S^{*}, {\overline{S}}^{*})</math> that minimizes <math>ncut(S, \overline{S})</math> is an <class wordnetid="107997703" confidence="0.8">
<collection wordnetid="107951464" confidence="0.8">
<group wordnetid="100031264" confidence="0.8">
<link xlink:type="simple" xlink:href="../681/54681.xml">
NP-hard</link></group>
</collection>
</class>
 problem. However, we can find in polynomial time a cut <math>(S, \overline{S})</math> of small normalized weight <math>ncut(S, \overline{S})</math> using <statement wordnetid="106722453" confidence="0.8">
<message wordnetid="106598915" confidence="0.8">
<theorem wordnetid="106752293" confidence="0.8">
<proposition wordnetid="106750804" confidence="0.8">
<link xlink:type="simple" xlink:href="../914/534914.xml">
spectral techniques</link></proposition>
</theorem>
</message>
</statement>
.</p>

</ss1>
<ss1>
<st>
The Ncut Algorithm</st>
<p>

Let D be an <math>n \times n</math> diagonal matrix with <math>d</math> on the diagonal, and let <math>W</math> be an <math>n \times n</math> symmetrical matrix with <math>W_{ij} = w_{ij}</math>. </p>
<p>

After some algebraic manipulations, we get:</p>
<p>

<math>\min \limits_{(S, \overline{S})} ncut(S, \overline{S}) = \min \limits_y \frac{y^T (D - W) y}{y^T D y}</math></p>
<p>

subject to the constraints:
<list>
<entry level="1" type="bullet">

 <math>y_i \in \{1, -b \}</math>, for some constant <math>-b</math></entry>
<entry level="1" type="bullet">

 <math>y^t D 1 = 0 </math></entry>
</list>
</p>
<p>

Minimizing <math>\frac{y^T (D - W) y}{y^T D y}</math> subject to the constraints above is <class wordnetid="107997703" confidence="0.8">
<collection wordnetid="107951464" confidence="0.8">
<group wordnetid="100031264" confidence="0.8">
<link xlink:type="simple" xlink:href="../681/54681.xml">
NP-hard</link></group>
</collection>
</class>
. To make the problem tractable, we relax the constraints on <math>y</math>, and allow it to take real values. The relaxed problem can be solved by solving the generalized eigenvalue problem <math>(D - W)y = \lambda D y</math>for the second smallest generalized eigenvalue.</p>
<p>

<b>The partitioning algorithm:</b>
<list>
<entry level="1" type="number">

 Given a set of features, set up  a weighted graph <math>G = (V, E)</math>, compute the weight of each edge, and summarize the information in <math>D</math> and <math>W</math>.</entry>
<entry level="1" type="number">

 Solve <math>(D - W)y = \lambda D y</math> for eigenvectors with the smallest eigenvalues.</entry>
<entry level="1" type="number">

 Use the eigenvector with the smallest eigenvalue to bipartition the graph.</entry>
<entry level="1" type="number">

 Decide if the current partition should be subdivided.</entry>
<entry level="1" type="number">

 Recursively partition the segmented parts, if necessary.</entry>
</list>
</p>

</ss1>
<ss1>
<st>
Example</st>
<p>

Figures 1-7 exemplify the Ncut algorithm.</p>

</ss1>
<ss1>
<st>
Limitations</st>
<p>

Solving a standard eigenvalue problem for all eigenvectors (using the <link xlink:type="simple" xlink:href="../072/594072.xml">
QR algorithm</link>, for instance) takes <math>O(n^3)</math> time. This is impractical for image segmentation applications where <math>n</math> is the number of pixels in the image.</p>

</ss1>
</sec>
<sec>
<st>
OBJ CUT</st>

<p>

OBJ CUT<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref> is an efficient method that automatically segments an object. The OBJ CUT method is a generic method, and therefore it is applicable to any object category model.
Given an image D containing an instance of a known object category, e.g. cows, the OBJ CUT algorithm computes a segmentation of the object, that is, it infers a set of labels m. </p>
<p>

Let m be a set of binary labels, and let <math>\Theta</math> be a shape parameter(<math>\Theta</math> is a shape prior on the labels from a <link>
Layered Pictorial Structure</link> (LPS) model). We define an energy function <math>E(m, \Theta)</math> as follows.</p>
<p>

<math>E(m, \Theta) = \sum \phi_x(D|m_x) + \phi_x(m_x|\Theta) + \sum \Psi_{xy}(m_x, m_y) + \phi(D|m_x, m_y)</math>  (1)</p>
<p>

The term <math>\phi_x(D|m_x) + \phi_x(m_x|\Theta)</math> is called a unary term, and the term <math>\Psi_{xy}(m_x, m_y) + \phi(D|m_x, m_y)</math> is called a pairwise term.
An unary term consists of the likelihood <math>\phi_x(D|m_x)</math> based on color, and the unary potential <math>\phi_x(m_x|\Theta)</math> based on the distance from <math>\Theta</math>. A pairwise term consists of a prior <math>\Psi_{xy}(m_x, m_y)</math> and a contrast term <math>\phi(D|m_x, m_y)</math>.</p>
<p>

The best labeling <math>m^{*}</math> minimizes <math>\sum \limits_i w_i E(m, \Theta_i)</math>, where <math>w_i</math> is the weight of the parameter <math>\Theta_i</math>.</p>
<p>

<math>m^{*} = \arg \min \limits_m \sum \limits_i w_i E(m, \Theta_i)</math>  (2)</p>

<ss1>
<st>
The OBJ CUT algorithm</st>
<p>

<list>
<entry level="1" type="number">

 Given an image D, an object category is chosen, e.g. cows or horses.</entry>
<entry level="1" type="number">

 The corresponding LPS model is matched to D to obtain the samples <math>\Theta_1, \cdots, \Theta_s</math></entry>
<entry level="1" type="number">

 The objective function given by equation (2) is determined by computing <math>E(m, \Theta_i)</math> and using <math>w_i = g(\Theta_i|Z)</math></entry>
<entry level="1" type="number">

 The objective function is minimized using a single <statement wordnetid="106722453" confidence="0.8">
<message wordnetid="106598915" confidence="0.8">
<theorem wordnetid="106752293" confidence="0.8">
<proposition wordnetid="106750804" confidence="0.8">
<link xlink:type="simple" xlink:href="../130/78130.xml">
MINCUT</link></proposition>
</theorem>
</message>
</statement>
 operation to obtain the segmentation <b>m</b>.</entry>
</list>
</p>

</ss1>
<ss1>
<st>
Example</st>
<p>

Figures 8-11 exemplify the OBJ CUT algorithm.</p>

</ss1>
</sec>
<sec>
<st>
Other approaches</st>
<p>

<list>
<entry level="1" type="bullet">

 Jigsaw approach<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%223%22])">3</ref></entry>
<entry level="1" type="bullet">

 Image parsing <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%224%22])">4</ref></entry>
<entry level="1" type="bullet">

 Interleaved segmentation <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%225%22])">5</ref></entry>
<entry level="1" type="bullet">

 LOCUS <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref></entry>
<entry level="1" type="bullet">

 LayoutCRF <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%227%22])">7</ref></entry>
</list>
</p>

</sec>
<sec>
<st>
References</st>

<p>

<reflist>
<entry id="1">
Jianbo Shi and Jitendra Malik (1997): "Normalized Cuts and Image Segmentation", IEEE Conference on Computer Vision and Pattern Recognition, pp 731-737 </entry>
<entry id="2">
M. P. Kumar, P. H. S. Torr, and A. Zisserman. Obj cut. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, San Diego, pages 18-25, 2005.</entry>
<entry id="3">
 E. Borenstein, S. Ullman: Class-specic, top-down segmentation. In Proceedings of the 7th European Conference on Computer Vision, Copenhagen, Denmark, pages 109-124, 2002.</entry>
<entry id="4">
Z. Tu, X. Chen, A. L. Yuille, S. C. Zhu: Image Parsing: Unifying Segmentation, Detection, and Recognition. Toward Category-Level Object Recognition 2006: 545-576</entry>
<entry id="5">
B. Leibe, A. Leonardis, B. Schiele: An Implicit Shape Model for Combined Object Categorization and Segmentation. Toward Category-Level Object Recognition 2006: 508-524</entry>
<entry id="6">
 J. Winn, N. Joijic. Locus: Learning object classes with unsupervised segmentation. In Proceedings of the IEEE International Conference on Computer Vision, Beijing,  2005.</entry>
<entry id="7">
J. M. Winn, J. Shotton: The Layout Consistent Random Field for Recognizing and Segmenting Partially Occluded Objects. CVPR (1) 2006: 37-44</entry>
</reflist>
</p>

</sec>
</bdy>
</article>
