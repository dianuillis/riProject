<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 17.04.2009 03:22:15[mciao0826] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<event  confidence="0.8" wordnetid="100029378">
<rule  confidence="0.8" wordnetid="105846932">
<act  confidence="0.8" wordnetid="100030358">
<psychological_feature  confidence="0.8" wordnetid="100023100">
<procedure  confidence="0.8" wordnetid="101023820">
<activity  confidence="0.8" wordnetid="100407535">
<algorithm  confidence="0.8" wordnetid="105847438">
<header>
<title>Evolutionary Acquisition of Neural Topologies</title>
<id>15702071</id>
<revision>
<id>240975576</id>
<timestamp>2008-09-25T20:01:08Z</timestamp>
<contributor>
<username>SmackBot</username>
<id>433328</id>
</contributor>
</revision>
<categories>
<category>Evolutionary algorithms</category>
<category>Neural networks</category>
<category>Evolutionary computation</category>
</categories>
</header>
<bdy>

<b>Evolutionary Acquisition of Neural Topologies</b> (EANT/EANT2)  is an evolutionary reinforcement learning method that evolves both the topology and weights of neural networks. It is closely related to the works of Angeline et al. <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref> and Stanley and Miikkulainen <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref>. Like the work of Angeline et al., the method uses a type of parametric mutation that comes from evolution strategies and evolutionary programming (now using the most advanced form of the evolution strategies <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../131/8143131.xml">
CMA-ES</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
 in EANT2), in which adaptive step sizes are used for optimizing the weights of the neural networks.  Similar to the work of Stanley, the method starts with minimal structures, which are complexified along the evolution path.
<sec>
<st>
Contribution of EANT to Neuroevolution</st>

<p>

Despite sharing these two properties, the method has the following important features which distinguish it from previous works in <link xlink:type="simple" xlink:href="../706/440706.xml">
neuroevolution</link>:</p>
<p>

It introduces a genetic encoding called Common Genetic Encoding (CGE) that handles both direct and indirect encoding of neural networks with in the same theoretical framework. The encoding has important properties that makes it suitable for evolving neural networks: (1) It is <it>complete</it> in that it is able to represent all types of valid phenotype networks. (2) It is <it>closed</it>, i.e. every valid genotype represents a valid phenotype. Similarly, the encoding is <it>closed under genetic operators</it> such as structural mutation and crossover. These properties have been formally proven in <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%223%22])">3</ref>.</p>
<p>

For evolving the structure and weights of neural networks, an evolutionary process is used, where the exploration of structures is executed at a larger timescale (structural exploration), and the exploitation of existing structures is done at a smaller timescale (structural exploitation). In the structural exploration phase, new neural structures are developed by gradually adding new structures to an initially minimal network that is used as a starting point. In the structural exploitation phase, the weights of the currently available structures are optimized using an <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../033/940033.xml">
Evolution Strategy</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
.</p>

</sec>
<sec>
<st>
Performance</st>

<p>

EANT has been tested on some benchmark problems such as the double-pole balancing problem <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%224%22])">4</ref>, and the RoboCup Keepaway benchmark <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%225%22])">5</ref>. In all the tests, EANT was found to perform very well. Moreover, a newer version of EANT, called EANT2, was tested on a visual servoing task and found to outperform NEAT and the traditional iterative Gauss-Newton method<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref>.</p>

</sec>
<sec>
<st>
References</st>

<p>

<reflist>
<entry id="1">
Peter J Angeline, Gregory M Saunders, and Jordan B Pollack. An evolutionary algorithm that constructs recurrent neural networks. IEEE Transactions on Neural Networks, 5:54–65, 1994. <weblink xlink:type="simple" xlink:href="http://demo.cs.brandeis.edu/papers/ieeenn.pdf">
http://demo.cs.brandeis.edu/papers/ieeenn.pdf</weblink></entry>
<entry id="2">
NeuroEvolution of Augmented Topologies (NEAT) by Stanley and Miikkulainen, 2005 http://nn.cs.utexas.edu/downloads/papers/stanley.ieeetec05.pdf</entry>
<entry id="3">
Yohannes Kassahun, Mark Edgington, Jan Hendrik Metzen, Gerald Sommer and Frank Kirchner.  Common Genetic Encoding for Both Direct and Indirect Encodings of Networks. In Proceedings of the Genetic and Evolutionary Computation Conference (GECCO 2007), London, UK, 1029-1036, 2007.<weblink xlink:type="simple" xlink:href="http://portal.acm.org/citation.cfm?id=1277162">
http://portal.acm.org/citation.cfm?id=1277162</weblink></entry>
<entry id="4">
Yohannes Kassahun and Gerald Sommer. Efficient reinforcement learning through evolutionary acquisition of neural topologies. In Proceedings of the 13th European Symposium on Artificial Neural Networks (ESANN 2005), pages 259–266, Bruges, Belgium, April 2005. <weblink xlink:type="simple" xlink:href="http://www.ks.informatik.uni-kiel.de/~yk/ESANN2005EANT.pdf">
http://www.ks.informatik.uni-kiel.de/~yk/ESANN2005EANT.pdf</weblink></entry>
<entry id="5">
 Jan Hendrik Metzen, Mark Edgington, Yohannes Kassahun and Frank Kirchner. Performance Evaluation of EANT in the RoboCup Keepaway Benchmark. In Proceedings of the Sixth International Conference on Machine Learning and Applications (ICMLA 2007), pages 342-347, USA, 2007 <weblink xlink:type="simple" xlink:href="http://portal.acm.org/citation.cfm?id=1336953.1337145&amp;coll=GUIDE&amp;dl=GUIDE">
http://portal.acm.org/citation.cfm?id=1336953.1337145&amp;coll=GUIDE&amp;dl=GUIDE</weblink></entry>
<entry id="6">
Nils T Siebel and Gerald Sommer. Evolutionary reinforcement learning of artificial neural networks.  International Journal of Hybrid Intelligent Systems 4(3): 171-183, October 2007. <weblink xlink:type="simple" xlink:href="http://www.ks.informatik.uni-kiel.de/~vision/doc/Publications/nts/SiebelSommer-IJHIS2007.pdf">
http://www.ks.informatik.uni-kiel.de/~vision/doc/Publications/nts/SiebelSommer-IJHIS2007.pdf</weblink>
</entry>
</reflist>
</p>

</sec>
</bdy>
</algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</article>
