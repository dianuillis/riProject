<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 17.04.2009 03:43:42[mciao0826] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Open domain</title>
<id>16431750</id>
<revision>
<id>216614390</id>
<timestamp>2008-06-02T12:54:51Z</timestamp>
<contributor>
<username>Leolaursen</username>
<id>1803593</id>
</contributor>
</revision>
<categories>
<category>Information retrieval</category>
<category>Natural language processing</category>
<category>Computational linguistics</category>
</categories>
</header>
<bdy>

An <b>open domain question answering system</b> aims at returning an answer in response to the user’s question. The returned answer is in the form of short texts rather than a list of relevant documents. The system uses a combination of techniques from <link xlink:type="simple" xlink:href="../561/5561.xml">
computational linguistics</link>, <link xlink:type="simple" xlink:href="../271/15271.xml">
information retrieval</link> and <link xlink:type="simple" xlink:href="../920/16920.xml">
knowledge representation</link> for finding answers.<p>

The system takes a <link xlink:type="simple" xlink:href="../173/21173.xml">
natural language</link> question as an input rather than a set of keywords, for example, “When is the national day of China?” The sentence is then transformed into a query through its Logical Form. Having the input in the form of a natural language question makes the system more user-friendly, but harder to implement, as there are various question types and the system will have to identify the correct one in order to give a sensible answer. Assigning a question type to the question is a crucial task, the entire answer extraction process relies on finding the correct question type and hence the correct answer type.</p>
<p>

Keyword <link xlink:type="simple" xlink:href="../860/12097860.xml">
extraction</link> is the first step for identifying the input question type. In some cases, there are clear words that indicate the question type directly. i.e. “Who”, “Where” or “How many”, these words tell the system that the answers should be of type “Person”, “Location”, “Number” respectively. In the example above, the word “When” indicates that the answer should be of type “Date”. POS tagging and syntactic parsing techniques can also be used to determine the answer type. In this case, the subject is “Chinese National Day”, the predicate is “is” and the adverbial modifier is “when”, therefore the answer type is “Date”. Unfortunately, some interrogative words like “Which”, “What” or “How” do not give clear answer types. Each of these words can represent more than one type. In situations like this, other words in the question need to be considered. First thing to do is to find the words that can indicate the meaning of the question. A lexical dictionary such as <link xlink:type="simple" xlink:href="../955/33955.xml">
WordNet</link> can then be used for understanding the context.</p>
<p>

Once the question type has been identified, an IR system is used to find a set of documents containing the correct key words. A tagger and NP/Verb Group chunker can be used to verify whether the correct entities and relations are mentioned in the found documents. For questions such as “Who” or “Where”, a Named Entity Recogniser is used to find relevant “Person” and “Location” names from the retrieved documents. Only the relevant paragraphs are selected for ranking. </p>
<p>

A <link xlink:type="simple" xlink:href="../134/1256134.xml">
vector space model</link> can be used as a strategy for classifying the candidate answers. Check if the answer is of the correct type as determined in the question type analysis stage. Inference technique can also be used to validate the candidate answers. A score is then given to each of these candidates according to the number of question words it contains and how close these words are to the candidate, the more and the closer the better. The answer is then translated into a compact and meaningful representation by parsing. In the previous example, the expected output answer is “1st Oct.”</p>

<sec>
<st>
 References </st>
<p>

<list>
<entry level="1" type="bullet">

 <cite id="Reference-Hutchins-1992" style="font-style:normal" class="book"><physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<intellectual wordnetid="109621545" confidence="0.8">
<alumnus wordnetid="109786338" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<adult wordnetid="109605289" confidence="0.8">
<professional wordnetid="110480253" confidence="0.8">
<lawyer wordnetid="110249950" confidence="0.8">
<scholar wordnetid="110557854" confidence="0.8">
<link xlink:type="simple" xlink:href="../690/11631690.xml">
Hutchins, W. John</link></scholar>
</lawyer>
</professional>
</adult>
</causal_agent>
</alumnus>
</intellectual>
</person>
</physical_entity>
;&#32;and Harold L. Somers&#32;(1992). <weblink xlink:type="simple" xlink:href="http://www.hutchinsweb.me.uk/IntroMT-TOC.htm">
An Introduction to Machine Translation</weblink>.&#32;London:&#32;Academic Press. ISBN 0-12-362830-X.</cite>&nbsp;</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 L. Fortnow, Steve Homer (2002/2003).   <weblink xlink:type="simple" xlink:href="http://people.cs.uchicago.edu/~fortnow/papers/history.pdf">
A Short History of Computational Complexity</weblink>.  In D. van Dalen, J. Dawson, and A. Kanamori, editors, <it>The History of Mathematical Logic</it>. North-Holland, Amsterdam.</entry>
</list>
</p>

</sec>
</bdy>
</article>
