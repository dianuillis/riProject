<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 18:51:19[mciao0826] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Cognitive architecture</title>
<id>1700176</id>
<revision>
<id>229681527</id>
<timestamp>2008-08-04T01:02:50Z</timestamp>
<contributor>
<username>Lordvolton</username>
<id>3289007</id>
</contributor>
</revision>
<categories>
<category>Cognitive architecture</category>
</categories>
</header>
<bdy>

A <b>cognitive architecture</b> is a blueprint for <link xlink:type="simple" xlink:href="../317/2711317.xml">
intelligent agent</link>s. It proposes (artificial) <link xlink:type="simple" xlink:href="../926/5926.xml">
computation</link>al processes that act like certain cognitive systems, most often, like a person, or acts <link xlink:type="simple" xlink:href="../280/519280.xml">
intelligent</link> under some definition. Cognitive architectures form a subset of general <link xlink:type="simple" xlink:href="../677/4510677.xml">
agent architecture</link>s. The term 'architecture' implies an approach that attempts to model not only behavior, but also structural properties of the modelled system. These need not be physical properties: they can be properties of <link xlink:type="simple" xlink:href="../353/32353.xml">
virtual machine</link>s implemented in physical machines (e.g. brains or computers).
<sec>
<st>
Characterization</st>
<p>

Common to most researchers on cognitive architectures is the belief that understanding (human, animal or machine) cognitive processes means being able to implement them in a working system, though opinions differ as to what form such a system can have: some researchers assume that it will necessarily be a <link xlink:type="simple" xlink:href="../956/1002956.xml">
computational</link> system whereas others argue for alternative models such as <link xlink:type="simple" xlink:href="../087/9087.xml">
dynamical system</link>s. Cognitive architectures can be characterized by certain properties or goals, as follows, though there is not general agreement on all aspects: 
<list>
<entry level="1" type="number">

Implementation of not just various different aspects of cognitive behavior but of cognition as a whole (<link xlink:type="simple" xlink:href="../358/206358.xml">
Holism</link>, e.g. <link xlink:type="simple" xlink:href="../053/1804053.xml">
Unified theory of cognition</link>). This is in contrast to <link xlink:type="simple" xlink:href="../240/355240.xml">
cognitive model</link>s, which focus on a particular competence, such as a kind of <link xlink:type="simple" xlink:href="../948/1467948.xml">
problem solving</link> or a kind of <link xlink:type="simple" xlink:href="../403/183403.xml">
learning</link>.</entry>
<entry level="1" type="number">

The architecture often tries to reproduce the behavior of the modelled system (human), in a way that timely <link xlink:type="simple" xlink:href="../801/540801.xml">
behavior</link> (<link xlink:type="simple" xlink:href="../306/568306.xml">
reaction time</link>s) of the architecture and modelled cognitive systems can be compared in detail. </entry>
<entry level="1" type="number">

<link xlink:type="simple" xlink:href="../849/926849.xml">
Robust behavior</link> in the face of error, the unexpected, and the unknown. <it>(see <link xlink:type="simple" xlink:href="../729/2573729.xml">
Graceful degradation</link>)</it>. </entry>
<entry level="1" type="number">

<link xlink:type="simple" xlink:href="../403/183403.xml">
Learning</link> (not for all cognitive architectures)</entry>
<entry level="1" type="number">

<link xlink:type="simple" xlink:href="../065/25065.xml">
Parameter</link>-free: The system does not depend on parameter tuning (in contrast to <link xlink:type="simple" xlink:href="../523/21523.xml">
Artificial neural networks</link>) (not for all cognitive architectures)</entry>
<entry level="1" type="number">

Some early theories such as <link xlink:type="simple" xlink:href="../751/729751.xml">
SOAR</link> and <link xlink:type="simple" xlink:href="../071/821071.xml">
ACT-R</link> originally focused only on the 'internal' information processing of an intelligent agent, including tasks like reasoning, planning, solving problems, learning concepts. More recently many architectures (including SOAR, ACT-R, ICARUS, <link xlink:type="simple" xlink:href="../938/13550938.xml">
 CLARION</link>) have expanded to include <link xlink:type="simple" xlink:href="../140/25140.xml">
perception</link>, <link xlink:type="simple" xlink:href="../524/317524.xml">
action</link> and also <link xlink:type="simple" xlink:href="../186/3471186.xml">
affective</link> states and processes including <link xlink:type="simple" xlink:href="../495/232495.xml">
motivation</link>, <link xlink:type="simple" xlink:href="../996/363996.xml">
attitudes</link>, and <link xlink:type="simple" xlink:href="../406/10406.xml">
emotions</link>.</entry>
<entry level="1" type="number">

On some theories the architecture may be composed of different kinds of sub-architectures (often described as 'layers' or 'levels') where the layers may be distinguished by types of function, types of mechanism and representation used, types of information manipulated, or possibly evolutionary origin. These are <link>
hybrid architecture</link>s (e.g., <link xlink:type="simple" xlink:href="../938/13550938.xml">
 CLARION</link>).</entry>
<entry level="1" type="number">

Some theories allow different architectural components to be active concurrently, whereas others assume a switching mechanism that selects one component or module at a time, depending on the current task. Concurrency is normally required for an architecture for an animal or <link xlink:type="simple" xlink:href="../781/25781.xml">
robot</link> that has multiple sensors and effectors in a complex and dynamic environment, but not in all <link xlink:type="simple" xlink:href="../351/3206351.xml">
robotic paradigms</link>.</entry>
<entry level="1" type="number">

Most theories assume that an architecture is fixed and only the information stored in various subsystems can change over time (e.g. Langley et al., below), whereas others allow architectures to grow, e.g. by acquiring new subsystems or new links between subsystems (e.g. Minsky and Sloman, below).</entry>
</list>
</p>
<p>

It is important to note that cognitive architectures don't have to follow a top-down approach to cognition (cf. <link xlink:type="simple" xlink:href="../635/45635.xml">
Top-down and bottom-up design</link>).</p>

</sec>
<sec>
<st>
Distinctions</st>
<p>

Cognitive architectures can be <link xlink:type="simple" xlink:href="../576/443576.xml">
symbolic</link>, <link xlink:type="simple" xlink:href="../636/263636.xml">
connectionist</link>, or <link xlink:type="simple" xlink:href="../246/2932246.xml">
hybrid</link>. Some cognitive architectures or models are based on a set of <process wordnetid="105701363" confidence="0.8">
<thinking wordnetid="105770926" confidence="0.8">
<explanation wordnetid="105793000" confidence="0.8">
<theory wordnetid="105989479" confidence="0.8">
<higher_cognitive_process wordnetid="105770664" confidence="0.8">
<link xlink:type="simple" xlink:href="../565/313565.xml">
generic rules</link></higher_cognitive_process>
</theory>
</explanation>
</thinking>
</process>
, as, e.g., the <link xlink:type="simple" xlink:href="../031/303031.xml">
Information Processing Language</link> (such as e.g. <link xlink:type="simple" xlink:href="../751/729751.xml">
Soar</link> based on the <link xlink:type="simple" xlink:href="../053/1804053.xml">
unified theory of cognition</link>, or similarly <link xlink:type="simple" xlink:href="../071/821071.xml">
ACT</link>). Many of these architectures are based on the-mind-is-like-a-computer analogy. In contrast subsymbolic processing specifies no such rules a priori and relies on emergent properties of processing units (e.g. nodes). Hybrid architectures combine both types of processing (such as <link xlink:type="simple" xlink:href="../938/13550938.xml">
 CLARION</link>). A further distinction is whether the architecture is <link xlink:type="simple" xlink:href="../090/323090.xml">
centralized</link> with a neural correlate of a <link xlink:type="simple" xlink:href="../218/5218.xml">
processor</link> at its core, or <link xlink:type="simple" xlink:href="../139/49139.xml">
decentralized</link> (distributed). The decentralized flavor, has become popular under the name of <link xlink:type="simple" xlink:href="../636/263636.xml">
parallel distributed processing</link> in mid-1980s and <link xlink:type="simple" xlink:href="../636/263636.xml">
connectionism</link>, a prime example being <link xlink:type="simple" xlink:href="../542/1729542.xml">
neural network</link>s. A further design issue is additionally a decision between <link xlink:type="simple" xlink:href="../358/206358.xml">
holistic</link> and <link xlink:type="simple" xlink:href="../554/5756554.xml">
atomism</link>, or (more concrete) <link xlink:type="simple" xlink:href="../133/939133.xml">
modular</link> in structure. By analogy, this extends to issues of <link xlink:type="simple" xlink:href="../920/16920.xml">
knowledge representation</link>. </p>
<p>

In traditional <link xlink:type="simple" xlink:href="../164/1164.xml">
AI</link>, <link xlink:type="simple" xlink:href="../280/519280.xml">
intelligence</link> is often programmed from above: the programmer is the <link xlink:type="simple" xlink:href="../326/5326.xml">
creator</link>, and makes something and imbues it with its intelligence, though many traditional AI systems were also designed to learn (e.g. improving their game-playing or problem-solving competence).  <link xlink:type="simple" xlink:href="../157/361157.xml">
Biologically-inspired computing</link>, on the other hand, takes sometimes a more <link xlink:type="simple" xlink:href="../635/45635.xml">
bottom-up</link>, <link xlink:type="simple" xlink:href="../139/49139.xml">
decentralised</link> approach; bio-inspired techniques often involve the method of specifying a set of simple generic rules or a set of simple nodes, from the interaction of which <link xlink:type="simple" xlink:href="../436/37436.xml">
emerges</link> the overall behavior. It is hoped to build up <link xlink:type="simple" xlink:href="../363/7363.xml">
complexity</link> until the end result is something markedly complex (see <link xlink:type="simple" xlink:href="../438/37438.xml">
complex system</link>s). However, it is also arguable that systems designed <link xlink:type="simple" xlink:href="../635/45635.xml">
top-down</link> on the basis of observations of what humans and other animals can do rather than on observations of brain mechanisms, are also biologically inspired, though in a different way.</p>

</sec>
<sec>
<st>
Some famous cognitive architectures</st>
<p>
  
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../071/821071.xml">
ACT-R</link>, developed at <university wordnetid="108286163" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../093/48093.xml">
Carnegie Mellon University</link></university>
 under <link xlink:type="simple" xlink:href="../950/3239950.xml">
John R. Anderson</link>.</entry>
<entry level="1" type="bullet">

 <link>
Apex</link> developed under <link>
Michael Freed</link> at <artifact wordnetid="100021939" confidence="0.8">
<science_museum wordnetid="104147364" confidence="0.8">
<facility wordnetid="103315023" confidence="0.8">
<depository wordnetid="103177349" confidence="0.8">
<museum wordnetid="103800563" confidence="0.8">
<link xlink:type="simple" xlink:href="../477/47477.xml">
NASA Ames Research Center</link></museum>
</depository>
</facility>
</science_museum>
</artifact>
.</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../281/12632281.xml">
CHREST</link>, developed under Fernand Gobet at <university wordnetid="108286163" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../199/155199.xml">
Brunel University</link></university>
 and Peter C. Lane at the <university wordnetid="108286163" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../360/503360.xml">
University of Hertfordshire</link></university>
.</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../938/13550938.xml">
 CLARION</link> the cognitive architecture, developed under <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<research_worker wordnetid="110523076" confidence="0.8">
<psychologist wordnetid="110488865" confidence="0.8">
<link xlink:type="simple" xlink:href="../946/17651946.xml">
Ron Sun</link></psychologist>
</research_worker>
</scientist>
</causal_agent>
</person>
</physical_entity>
 at <university wordnetid="108286163" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../026/194026.xml">
Rensselaer Polytechnic Institute</link></university>
 and University of Missouri.</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../239/1757239.xml">
Copycat</link>, by <person wordnetid="100007846" confidence="0.9508927676800064">
<professor wordnetid="110480730" confidence="0.9173553029164789">
<writer wordnetid="110794014" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../758/8758.xml">
Douglas Hofstadter</link></writer>
</professor>
</person>
 and <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<link xlink:type="simple" xlink:href="../681/4559681.xml">
Melanie Mitchell</link></scientist>
</causal_agent>
</person>
</physical_entity>
 at the <university wordnetid="108286163" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../242/292242.xml">
Indiana University</link></university>
. </entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../731/3559731.xml">
DUAL</link>, developed at the <body wordnetid="107965085" confidence="0.8">
<university wordnetid="108286163" confidence="0.8">
<social_group wordnetid="107950920" confidence="0.8">
<group wordnetid="100031264" confidence="0.8">
<link xlink:type="simple" xlink:href="../170/4879170.xml">
New Bulgarian University</link></group>
</social_group>
</university>
</body>
 under <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<link xlink:type="simple" xlink:href="../389/3559389.xml">
Boicho Kokinov</link></scientist>
</causal_agent>
</person>
</physical_entity>
.</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../228/6945228.xml">
EPIC</link>, developed under David E. Kieras and David E. Meyer at the <university wordnetid="108286163" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../740/31740.xml">
University of Michigan</link></university>
.</entry>
<entry level="1" type="bullet">

 The <link>
H-Cogaff</link> architecture, which is a special case of the <link>
CogAff</link> schema. (See Taylor &amp; Sayda, and Sloman refs below).</entry>
<entry level="1" type="bullet">

<link>
IDA and LIDA</link>, developed under <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<academician wordnetid="109759069" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<adult wordnetid="109605289" confidence="0.8">
<professional wordnetid="110480253" confidence="0.8">
<research_worker wordnetid="110523076" confidence="0.8">
<educator wordnetid="110045713" confidence="0.8">
<link xlink:type="simple" xlink:href="../705/1456705.xml">
Stan Franklin</link></educator>
</research_worker>
</professional>
</adult>
</scientist>
</academician>
</causal_agent>
</person>
</physical_entity>
 at the <university wordnetid="108286163" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../169/628169.xml">
University of Memphis</link></university>
.</entry>
<entry level="1" type="bullet">

 <link>
PRODIGY</link>, by Veloso et al. </entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../911/8233911.xml">
PRS</link> 'Procedural Reasoning System', developed by <link>
Michael Georgeff</link> and <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<research_worker wordnetid="110523076" confidence="0.8">
<link xlink:type="simple" xlink:href="../424/9200424.xml">
Amy Lansky</link></research_worker>
</scientist>
</causal_agent>
</person>
</physical_entity>
 at <institute wordnetid="108407330" confidence="0.8">
<think_tank wordnetid="108478702" confidence="0.8">
<association wordnetid="108049401" confidence="0.8">
<company wordnetid="108058098" confidence="0.8">
<institution wordnetid="108053576" confidence="0.8">
<link xlink:type="simple" xlink:href="../262/481262.xml">
SRI International</link></institution>
</company>
</association>
</think_tank>
</institute>
.</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../631/15311631.xml">
Psi-Theory</link> developed under <link>
Dietrich Dörner</link> at the <link xlink:type="simple" xlink:href="../313/530313.xml">
Otto-Friedrich University</link> in <site wordnetid="108651247" confidence="0.9508927676800064">
<location wordnetid="100027167" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../896/4896.xml">
Bamberg</link></location>
</site>
, <country wordnetid="108544813" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../867/11867.xml">
Germany</link></country>
.</entry>
<entry level="1" type="bullet">

 <system wordnetid="104377057" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<link xlink:type="simple" xlink:href="../235/7827235.xml">
R-CAST</link></instrumentality>
</artifact>
</system>
, developed at the <university wordnetid="108286163" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../509/1209509.xml">
Pennsylvania State University</link></university>
.</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../751/729751.xml">
Soar</link>, developed under <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../300/287300.xml">
Allen Newell</link></scientist>
</person>
 and <physical_entity wordnetid="100001930" confidence="0.8">
<peer wordnetid="109626238" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<colleague wordnetid="109935990" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<associate wordnetid="109816771" confidence="0.8">
<link xlink:type="simple" xlink:href="../853/12314853.xml">
John Laird</link></associate>
</scientist>
</causal_agent>
</colleague>
</person>
</peer>
</physical_entity>
 at <university wordnetid="108286163" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../093/48093.xml">
Carnegie Mellon University</link></university>
 and the <university wordnetid="108286163" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../740/31740.xml">
University of Michigan</link></university>
.</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../320/295320.xml">
Society of mind</link> and its successor the <link>
Emotion machine</link> proposed by <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../639/19639.xml">
Marvin Minsky</link></scientist>
</person>
.</entry>
<entry level="1" type="bullet">

 <structure wordnetid="104341686" confidence="0.8">
<building wordnetid="102913152" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<architecture wordnetid="102734725" confidence="0.8">
<link xlink:type="simple" xlink:href="../552/83552.xml">
Subsumption architecture</link></architecture>
</artifact>
</building>
</structure>
s, developed e.g. by <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../498/632498.xml">
Rodney Brooks</link></scientist>
</person>
 (though it could be argued whether they are <it>cognitive</it>).</entry>
</list>
</p>

</sec>
<sec>
<st>
 See also</st>
<p>

<list>
<entry level="1" type="bullet">

 <work wordnetid="100575741" confidence="0.8">
<examination wordnetid="100635850" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<survey wordnetid="100644503" confidence="0.8">
<investigation wordnetid="100633864" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<link xlink:type="simple" xlink:href="../552/195552.xml">
Artificial consciousness</link></activity>
</psychological_feature>
</act>
</investigation>
</survey>
</event>
</examination>
</work>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../626/1456626.xml">
Autonomous agent</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../626/5626.xml">
Cognitive science</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../877/3054877.xml">
Intelligent system</link></entry>
<entry level="1" type="bullet">

 <idea wordnetid="105833840" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<component wordnetid="105868954" confidence="0.8">
<part wordnetid="105867413" confidence="0.8">
<link xlink:type="simple" xlink:href="../162/14246162.xml">
Memristor</link></part>
</component>
</concept>
</idea>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../457/3157457.xml">
production system</link></entry>
<entry level="1" type="bullet">

 <work wordnetid="100575741" confidence="0.8">
<argument wordnetid="106648724" confidence="0.8">
<scientific_research wordnetid="100641820" confidence="0.8">
<subject wordnetid="106599788" confidence="0.8">
<evidence wordnetid="106643408" confidence="0.8">
<indication wordnetid="106797169" confidence="0.8">
<research wordnetid="100636921" confidence="0.8">
<message wordnetid="106598915" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<experiment wordnetid="100639556" confidence="0.8">
<investigation wordnetid="100633864" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<link xlink:type="simple" xlink:href="../365/247365.xml">
Simulated reality</link></activity>
</psychological_feature>
</act>
</investigation>
</experiment>
</event>
</message>
</research>
</indication>
</evidence>
</subject>
</scientific_research>
</argument>
</work>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../746/387746.xml">
Social simulation</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../357/586357.xml">
Strong AI</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../053/1804053.xml">
unified theory of cognition</link></entry>
<entry level="1" type="bullet">

 <system wordnetid="104377057" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<link xlink:type="simple" xlink:href="../395/1908395.xml">
Artificial brain</link></instrumentality>
</artifact>
</system>
</entry>
</list>
</p>

</sec>
<sec>
<st>
External links</st>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.cogsci.rpi.edu/~rsun/arch.html">
 a comprehensive set of pointers to cognitive architectures and related issues</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://act-r.psy.cmu.edu/publications/index.php">
categorized publications about ACT-R</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://people.brunel.ac.uk/~hsstffg/bibliography-by-topic.html#Modelling_CHREST">
  categorized publications about CHREST</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.cogsci.rpi.edu/~rsun/clarion-pub.html">
  categorized publications about CLARION</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://ai.eecs.umich.edu/cogarch0/">
A Survey of Cognitive and Agent Architectures</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.cs.bham.ac.uk/research/projects/cogaff/00-02.html#57">
Architecture-Based Conceptions of Mind</weblink> by <peer wordnetid="109626238" confidence="0.8">
<physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<intellectual wordnetid="109621545" confidence="0.8">
<colleague wordnetid="109935990" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<adult wordnetid="109605289" confidence="0.8">
<professional wordnetid="110480253" confidence="0.8">
<educator wordnetid="110045713" confidence="0.8">
<associate wordnetid="109816771" confidence="0.8">
<academician wordnetid="109759069" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<research_worker wordnetid="110523076" confidence="0.8">
<scholar wordnetid="110557854" confidence="0.8">
<link xlink:type="simple" xlink:href="../162/7093162.xml">
Aaron Sloman</link></scholar>
</research_worker>
</causal_agent>
</academician>
</associate>
</educator>
</professional>
</adult>
</scientist>
</colleague>
</intellectual>
</person>
</physical_entity>
</peer>
, in: P. Gardenfors and K. Kijania-Placek and J. Wolenski, Eds., <it>In the Scope of Logic, Methodology, and Philosophy of Science (Vol II)</it>, (Synthese Library Vol. 316), Kluwer, Dordrecht, pp. 403--427, 2002. (The ideas are summarised in this <weblink xlink:type="simple" xlink:href="http://www.cs.bham.ac.uk/research/projects/cogaff/talks/#talk6">
PDF presentation</weblink> on Architectures for Human-like Agents.)</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://teachrose.com">
Teach Rose: an artificial cognitive learning experiment</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://cll.stanford.edu/~langley/papers/final.arch.pdf">
Cognitive architectures: Research issues and challenges</weblink> by Langley, P., Laird, J. E., &amp; Rogers, S. (2006)</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.ai.sri.com/pubs/files/1364.pdf">
Reactive reasoning and planning</weblink> by Georgeff, M. P. and Lansky, A. L. (1987). In <it>Proceedings of the Sixth National Conference on Artificial Intelligence</it> (AAAI-87), pages 677-682, Seattle, WA.</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.cs.bham.ac.uk/research/projects/cogaff/gc/">
UK Computing Research Grand Challenge 5 (GC-5)</weblink> 'Architecture of brain and mind.'</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.cs.bham.ac.uk/research/projects/cogaff/00-02.html#89">
A Framework for comparing agent architectures</weblink>, Aaron Sloman and Matthias Scheutz, in Proceedings of the UK Workshop on Computational Intelligence, Birmingham, UK, September 2002.</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://ieeexplore.ieee.org/iel5/9900/31471/01467219.pdf">
An Intelligent Architecture for Integrated Control and Asset Management for Industrial Processes</weblink> Taylor, J.H.   Sayda, A.F. in <it>Intelligent Control</it>, 2005. Proceedings of the 2005 IEEE International Symposium on, Mediterrean Conference on Control and Automation. pp 1397- 1404</entry>
<entry level="1" type="bullet">

 The <weblink xlink:type="simple" xlink:href="http://www.aslab.org/public/projects/SOUL/">
SOUL Cognitive Architecture</weblink> website</entry>
</list>
</p>


</sec>
</bdy>
</article>
