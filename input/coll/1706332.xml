<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 18:50:18[mciao0827] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Feedforward neural network</title>
<id>1706332</id>
<revision>
<id>227321716</id>
<timestamp>2008-07-23T01:16:52Z</timestamp>
<contributor>
<username>Cesarsouza</username>
<id>7518554</id>
</contributor>
</revision>
<categories>
<category>Neural networks</category>
</categories>
</header>
<bdy>

<image location="right" width="400px" src="Feed_forward_neural_net.gif" type="thumb">
<caption>

In a feed forward network information always moves one direction; it never goes backwards.
</caption>
</image>
<p>

A <b>feedforward neural network</b> is an <link xlink:type="simple" xlink:href="../523/21523.xml">
artificial neural network</link> where connections between the units do <it>not</it> form a <link xlink:type="simple" xlink:href="../962/878962.xml">
directed cycle</link>. This is different from <link xlink:type="simple" xlink:href="../303/1706303.xml">
recurrent neural networks</link>.</p>
<p>

The feedforward neural network was the first and arguably simplest type of artificial neural network devised. In this network, the information moves in only one direction, forward, from the input nodes, through the hidden nodes (if any) and to the output nodes. There are no cycles or loops in the network.</p>

<sec>
<st>
Single-layer perceptron</st>

<p>

<indent level="1">

<it>Main article: <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../777/172777.xml">
Perceptron</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</it>
</indent>

The earliest kind of neural network is a <it>single-layer perceptron</it> network, which consists of a single layer of output nodes; the inputs are fed directly to the outputs via a series of weights. In this way it can be considered the simplest kind of feed-forward network. The sum of the products of the weights and the inputs is calculated in each node, and if the value is above some threshold (typically 0) the neuron fires and takes the activated value (typically 1); otherwise it takes the deactivated value (typically -1). Neurons with this kind of <link xlink:type="simple" xlink:href="../835/14179835.xml">
activation function</link> are also called <it><link xlink:type="simple" xlink:href="../771/349771.xml">
Artificial neurons</link></it> or <it>linear threshold units</it>. In the literature the term <it><link xlink:type="simple" xlink:href="../777/172777.xml">
perceptron</link></it> often refers to networks consisting of just one of these units. A similar neuron was described by <link xlink:type="simple" xlink:href="../508/44508.xml">
Warren McCulloch</link> and <link xlink:type="simple" xlink:href="../949/302949.xml">
Walter Pitts</link> in the 1940s.</p>
<p>

A perceptron can be created using any values for the activated and deactivated states as long as the threshold value lies between the two. Most perceptrons have outputs of 1 or -1 with a threshold of 0 and there is some evidence that such networks can be trained more quickly than networks created from nodes with different activation and deactivation values.</p>
<p>

Perceptrons can be trained by a simple learning algorithm that is usually called the <it><link xlink:type="simple" xlink:href="../612/1237612.xml">
delta rule</link></it>. It calculates the errors between calculated output and sample output data, and uses this to create an adjustment to the weights, thus implementing a form of <link xlink:type="simple" xlink:href="../489/201489.xml">
gradient descent</link>.</p>
<p>

Single-unit perceptrons are only capable of learning <link xlink:type="simple" xlink:href="../173/523173.xml">
linearly separable</link> patterns; in 1969 in a famous <link xlink:type="simple" xlink:href="../841/653841.xml">
monograph</link> entitled <it><link xlink:type="simple" xlink:href="../777/172777.xml">
Perceptrons</link></it> <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../639/19639.xml">
Marvin Minsky</link></scientist>
</person>
 and <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../802/27802.xml">
Seymour Papert</link></scientist>
</person>
 showed that it was impossible for a single-layer perceptron network to learn an <link xlink:type="simple" xlink:href="../979/105979.xml">
XOR function</link>. They conjectured (incorrectly) that a similar result would hold for a multi-layer perceptron network. Although a single threshold unit is quite limited in its computational power, it has been shown that networks of parallel threshold units can approximate any continuous function from a compact interval of the real numbers into the interval [-1,1]. This very recent result can be found in [Auer, Burgsteiner, Maass: The p-delta learning rule for parallel perceptrons, 2001 (state Jan 2003: submitted for publication)].</p>
<p>

A single-layer neural network can compute a continuous output instead of a <link xlink:type="simple" xlink:href="../939/170939.xml">
step function</link>. A common choice is the so-called <link xlink:type="simple" xlink:href="../563/84563.xml">
logistic function</link>:</p>
<p>

<indent level="1">

 <math>y = \frac{1}{1+e^{-x}}</math>
</indent>

(In general form, f(X) is in place of x, where f(X) is an <link xlink:type="simple" xlink:href="../478/61478.xml">
analytic function</link> in set of x's.) With this choice, the single-layer network is identical to the <link xlink:type="simple" xlink:href="../631/226631.xml">
logistic regression</link> model, widely used in <link xlink:type="simple" xlink:href="../576/27576.xml">
statistical modelling</link>. The <link xlink:type="simple" xlink:href="../563/84563.xml">
logistic function</link> is also known as the <link xlink:type="simple" xlink:href="../210/87210.xml">
sigmoid function</link>. It has a continuous derivative, which allows it to be used in backpropagation. This function is also preferred because its derivative is easily calculated: </p>
<p>

<indent level="1">

 <math>y' = y(1-y)</math>    (times <math>df/dX</math>, in general form, according to the <link xlink:type="simple" xlink:href="../113/6113.xml">
Chain Rule</link>)
</indent>

</p>
</sec>
<sec>
<st>
Multi-layer perceptron</st>

<p>

<indent level="1">

<it>Main article: <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../644/2266644.xml">
Multilayer perceptron</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</it>
</indent>
<image location="right" width="250px" src="XOR_perceptron_net.png" type="thumb">
<caption>

A two-layer neural network capable of calculating XOR. The numbers within the neurons represent each neuron's explicit threshold (which can be factored out so that all neurons have the same threshold, usually 1). The numbers that annotate arrows represent the weight of the inputs. This net assumes that if the threshold is not reached, zero (not -1) is output. Note that the bottom layer of inputs is not always considered a real neural network layer
</caption>
</image>
</p>
<p>

This class of networks consists of multiple layers of computational units, usually interconnected in a feed-forward way. Each neuron in one layer has directed connections to the neurons of the subsequent layer. In many applications the units of these networks apply a sigmoid function as an activation function.</p>
<p>

The <it><link xlink:type="simple" xlink:href="../448/18543448.xml">
universal approximation theorem</link></it> for neural networks states that every continuous function that maps intervals of real numbers to some output interval of real numbers can be approximated arbitrarily closely by a multi-layer perceptron with just one hidden layer. This result holds only for restricted classes of activation functions, e.g. for the sigmoidal functions.</p>
<p>

Multi-layer networks use a variety of learning techniques, the most popular being <it><link xlink:type="simple" xlink:href="../091/1360091.xml">
back-propagation</link></it>. Here, the output values are compared with the correct answer to compute the value of some predefined error-function. By various techniques, the error is then fed back through the network. Using this information, the algorithm adjusts the weights of each connection in order to reduce the value of the error function by some small amount. After repeating this process for a sufficiently large number of training cycles, the network will usually converge to some state where the error of the calculations is small. In this case, one would say that the network has <it>learned</it> a certain target function. To adjust weights properly, one applies a general method for non-linear <link xlink:type="simple" xlink:href="../033/52033.xml">
optimization</link> that is called <link xlink:type="simple" xlink:href="../489/201489.xml">
gradient descent</link>. For this, the derivative of the error function with respect to the network weights is calculated, and the weights are then changed such that the error decreases (thus going downhill on the surface of the error function). For this reason, back-propagation can only be applied on networks with differentiable activation functions.</p>
<p>

In general, the problem of teaching a network to perform well, even on samples that were not used as training samples, is a quite subtle issue that requires additional techniques. This is especially important for cases where only very limited numbers of training samples are available. The danger is that the network <link xlink:type="simple" xlink:href="../332/173332.xml">
overfits</link> the training data and fails to capture the true statistical process generating the data.  <link xlink:type="simple" xlink:href="../537/387537.xml">
Computational learning theory</link> is concerned with training classifiers on a limited amount of data.  In the context of neural networks a simple <link xlink:type="simple" xlink:href="../452/63452.xml">
heuristic</link>, called <link xlink:type="simple" xlink:href="../214/213214.xml">
early stopping</link>, often ensures that the network will generalize well to examples not in the training set.</p>
<p>

Other typical problems of the back-propagation algorithm are the speed of convergence and the possibility of ending up in a <link>
local minimum</link> of the error function. Today there are practical solutions  that make back-propagation in multi-layer perceptrons the solution of choice for many <link xlink:type="simple" xlink:href="../488/233488.xml">
machine learning</link> tasks.</p>

</sec>
<sec>
<st>
ADALINE</st>
<p>

ADALINE stands for <b>Ada</b>ptive <b>Li</b>near <b>Ne</b>uron. or later called <b>Ada</b>ptive <b>Lin</b>ear <b>E</b>lement. It was developed by Professor <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<research_worker wordnetid="110523076" confidence="0.8">
<link xlink:type="simple" xlink:href="../636/4793636.xml">
Bernard Widrow</link></research_worker>
</scientist>
</causal_agent>
</person>
</physical_entity>
 and his graduate student <link>
Ted Hoff</link> at <university wordnetid="108286163" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../977/26977.xml">
Stanford University</link></university>
 in 1960. It's based on the McCulloch-Pitts model. It consists of a weight, a bias and a summation function.</p>
<p>

Operation: <math>y_i=wx_i+b</math></p>
<p>

Its adaptation is defined through a cost function (error metric) of the residual <math>e=d_i-(b+wx_i)</math> where <math>d_i</math> is the desired input. With the <link xlink:type="simple" xlink:href="../816/201816.xml">
MSE</link> error metric <math>E=\frac{1}{2N}\sum_i^N e_i^2</math> the adapted weight and bias become:
<math>b=\frac{\sum_i x_i^2\sum_i d_i - \sum_i x_i \sum_i x_i d_i}{N(\sum_i(x_i - \bar x)^2)}</math> and <math>w=\frac{\sum_i(x_i - \bar x)(d_i - \bar d)}{\sum_i(x_i - \bar x)^2}</math></p>
<p>

The Adaline has practical applications in the controls area.  A single neuron with tap delayed inputs (the number of inputs is bounded by the lowest frequency present and the Nyquist rate) can be used to determine the higher order transfer function of a physical system via the bi-linear z-transform.  This is done as the Adaline is, functionally, an adaptive FIR filter. Like the single-layer perceptron, ADALINE has a counterpart in statistical modelling, in this case <link xlink:type="simple" xlink:href="../359/82359.xml">
least squares</link> <link xlink:type="simple" xlink:href="../568/26568.xml">
regression</link>.</p>
<p>

There is an extension of the Adaline, called the Multiple Adaline (MADALINE) that consists of two or more adalines serially connected.</p>

</sec>
<sec>
<st>
 See also </st>
<p>

<list>
<entry level="1" type="bullet">

 <idea wordnetid="105833840" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<link xlink:type="simple" xlink:href="../759/574759.xml">
Feed-forward</link></concept>
</idea>
</entry>
<entry level="1" type="bullet">

 <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../523/21523.xml">
Artificial neural network</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../091/1360091.xml">
Backpropagation</link></entry>
</list>
</p>

</sec>
</bdy>
</article>
