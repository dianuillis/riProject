<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 16:25:23[mciao0826] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<event  confidence="0.8" wordnetid="100029378">
<rule  confidence="0.8" wordnetid="105846932">
<act  confidence="0.8" wordnetid="100030358">
<psychological_feature  confidence="0.8" wordnetid="100023100">
<procedure  confidence="0.8" wordnetid="101023820">
<activity  confidence="0.8" wordnetid="100407535">
<algorithm  confidence="0.8" wordnetid="105847438">
<header>
<title>Simulated annealing</title>
<id>172244</id>
<revision>
<id>238823098</id>
<timestamp>2008-09-16T15:35:26Z</timestamp>
<contributor>
<username>Appraiser</username>
<id>1910434</id>
</contributor>
</revision>
<categories>
<category>Heuristics</category>
<category>Optimization algorithms</category>
</categories>
</header>
<bdy>

<b>Simulated annealing (SA)</b> is a generic <link xlink:type="simple" xlink:href="../383/495383.xml">
probabilistic</link> <link xlink:type="simple" xlink:href="../458/774458.xml">
meta-algorithm</link> for the <link xlink:type="simple" xlink:href="../854/563854.xml">
global optimization</link> problem, namely locating a good approximation to the <link xlink:type="simple" xlink:href="../285/914285.xml">
global optimum</link> of a given <link xlink:type="simple" xlink:href="../427/185427.xml">
function</link> in a large <link xlink:type="simple" xlink:href="../707/389707.xml">
search space</link>.  It is often used when the search space is discrete (e.g., all tours that visit a given set of cities).  For certain problems, simulated annealing may be more effective than <link>
exhaustive enumeration</link> — provided that the goal is merely to find an acceptably good solution in a fixed amount of time, rather than the best possible solution.<p>

The name and inspiration come from <link xlink:type="simple" xlink:href="../459/3424459.xml">
annealing</link> in <link xlink:type="simple" xlink:href="../722/19722.xml">
metallurgy</link>, a technique involving heating and controlled cooling of a material to increase the size of its <link xlink:type="simple" xlink:href="../015/6015.xml">
crystal</link>s and reduce their <link xlink:type="simple" xlink:href="../849/7849.xml">
defects</link>.  The heat causes the <link xlink:type="simple" xlink:href="../902/902.xml">
atom</link>s to become unstuck from their initial positions (a local minimum of the <link xlink:type="simple" xlink:href="../757/340757.xml">
internal energy</link>) and wander randomly through states of higher energy; the slow cooling gives them more chances of finding configurations with lower internal energy than the initial one.</p>
<p>

By analogy with this physical process, each step of the SA algorithm replaces the current solution by a random "nearby" solution, chosen with a probability that depends on the difference between the corresponding function values and on a global parameter  <it>T</it> (called the <it>temperature</it>), that is gradually decreased during the process.  The dependency is such that the current solution changes almost randomly when <it>T</it> is large, but increasingly "downhill" as <it>T</it> goes to zero. The allowance for "uphill" moves saves the method from becoming stuck at <link>
local minima</link>—which are the bane of <link xlink:type="simple" xlink:href="../247/89247.xml">
greedier</link> methods. </p>
<p>

The method was independently described by S. Kirkpatrick, C. D. Gelatt and M. P. Vecchi in 1983, and by V. Černý in 1985.   The method is an adaptation of  the <link xlink:type="simple" xlink:href="../107/56107.xml">
Metropolis-Hastings algorithm</link>, a <technique wordnetid="105665146" confidence="0.8">
<know-how wordnetid="105616786" confidence="0.8">
<method wordnetid="105660268" confidence="0.8">
<link xlink:type="simple" xlink:href="../098/56098.xml">
Monte Carlo method</link></method>
</know-how>
</technique>
 to generate sample states of a thermodynamic system, invented by <physical_entity wordnetid="100001930" confidence="0.8">
<physicist wordnetid="110428004" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<academician wordnetid="109759069" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<adult wordnetid="109605289" confidence="0.8">
<professional wordnetid="110480253" confidence="0.8">
<mathematician wordnetid="110301261" confidence="0.8">
<educator wordnetid="110045713" confidence="0.8">
<link xlink:type="simple" xlink:href="../326/504326.xml">
N. Metropolis</link></educator>
</mathematician>
</professional>
</adult>
</scientist>
</academician>
</causal_agent>
</person>
</physicist>
</physical_entity>
 et al in 1953.</p>

<sec>
<st>
Overview</st>
<p>

In the simulated annealing (SA) method, each point <it>s</it> of the search space is analogous to a <link xlink:type="simple" xlink:href="../642/658642.xml">
state</link> of some <link xlink:type="simple" xlink:href="../322/773322.xml">
physical system</link>, and the function <it>E</it>(<it>s</it>) to be minimized is analogous to the <link xlink:type="simple" xlink:href="../757/340757.xml">
internal energy</link> of the system in that state. The goal is to bring the system, from an arbitrary <it>initial state</it>, to a state with the minimum possible energy.</p>

<ss1>
<st>
The basic iteration</st>
<p>

At each step, the SA heuristic considers some neighbour <it>s' </it>of the current state <it>s</it>, and <link xlink:type="simple" xlink:href="../934/22934.xml">
probabilistic</link>ally decides between moving the system to state <it>s' </it>or staying in state <it>s</it>.  The probabilities are chosen so that the system ultimately tends to move to states of lower energy.  Typically this step is repeated until the system reaches a state that is good enough for the application, or until a given computation budget has been exhausted.</p>

</ss1>
<ss1>
<st>
The neighbours of a state</st>
<p>

The neighbours of each state (the <it>candidate moves</it>) are specified by the user, usually in an application-specific way.    For example, in the <link xlink:type="simple" xlink:href="../248/31248.xml">
traveling salesman problem</link>, each state is typically defined as a particular <it>tour</it> (a <link xlink:type="simple" xlink:href="../027/44027.xml">
permutation</link> of the cities to be visited); and one could define the neighbours of a tour as those tours that can be obtained from it by exchanging any pair of consecutive cities.</p>

</ss1>
<ss1>
<st>
Acceptance probabilities</st>
<p>

The probability of making the <link xlink:type="simple" xlink:href="../857/548857.xml">
transition</link> from the current state <math>s</math> to a candidate new state <math>s'</math> is specified by an <it>acceptance probability function</it> <math>P(e, e', T)</math>, that depends on the energies <math>e = E(s)</math> and <math>e' = E(s')</math> of the two states, and on a global time-varying parameter <math>T</math> called the <it>temperature</it>.</p>
<p>

One essential requirement for the probability function <math>P</math> is that it must be nonzero when <math>e' &amp;gt; e</math>, meaning that the system may move to the new state even when it is <it>worse</it> (has a higher energy) than the current one.  It is this feature that prevents the method from becoming stuck in a <it>local minimum</it>—a state that is worse than the global minimum, yet better than any of its neighbours.</p>
<p>

On the other hand, when <math>T</math> goes to zero, the probability <math>P(e, e', T)</math> must tend to zero if <math>e' &amp;gt; e</math>, and to a positive value if <math>e' &amp;lt; e</math>. That way, for sufficiently small values of <math>T</math>, the system will increasingly favor moves that go "downhill" (to lower energy values), and avoid those that go "uphill". In particular,  when <math>T</math> becomes 0, the procedure will reduce to the <link xlink:type="simple" xlink:href="../247/89247.xml">
greedy algorithm</link>—which makes the move only if it goes downhill.  </p>
<p>

In the original description of SA, the probability <math>P(e, e', T)</math> was defined as 1 when <math>e' &amp;lt; e</math> — i.e., the procedure always moved downhill when it found a way to do so, irrespective of the temperature.  Many descriptions and implementations of SA still take this condition as part of the method's definition.  However, this condition is not essential for the method to work, and one may argue that it is both counterproductive and contrary to its spirit.</p>
<p>

The <math>P</math> function is usually chosen so that the probability of accepting a move decreases when the difference
<math>e'-e</math> increases—that is, small uphill moves are more likely than large ones.  However, this requirement is not strictly necessary, provided that the above requirements are met.</p>
<p>

Given these properties, the evolution of the state <math>s</math> depends crucially on the temperature <math>T</math>.  Roughly speaking, the evolution of <math>s</math> is sensitive to coarser energy variations when <math>T</math> is large, and to finer variations when <math>T</math> is small.</p>

</ss1>
<ss1>
<st>
The annealing schedule</st>
<p>

Another essential feature of the SA method is that the temperature is gradually reduced as the simulation proceeds. Initially, <math>T</math> is set to a high value (or infinity), and it is decreased at each step according to some <it>annealing schedule</it>—which may be specified by the user, but must end with <math>T=0</math> towards the end of the allotted time budget.  In this way, the system is expected to wander initially towards a broad region of the search space containing good solutions, ignoring small features of the energy function; then drift towards low-energy regions that become narrower and narrower; and finally move downhill according to the <link xlink:type="simple" xlink:href="../489/201489.xml">
steepest descent</link> heuristic.</p>


<p>

<table width="90%" border="0">
<row>
<col>
<image location="center" width="200px" src="SimulatedAnnealingFast.jpg" type="thumb">
</image>
</col>
<col>
<image location="center" width="200px" src="SimulatedAnnealingSlow.jpg" type="thumb">
</image>
</col>
</row>
<row>
<col colspan="2">
Example illustrating the effect of cooling schedule on the performance of simulated annealing.  The problem is to rearrange the <link xlink:type="simple" xlink:href="../665/23665.xml">
pixel</link>s of an image so as to minimize a certain <link xlink:type="simple" xlink:href="../703/23703.xml">
potential energy</link> function, which causes similar <link xlink:type="simple" xlink:href="../925/5925.xml">
colour</link>s to attract at short range and repel at slightly larger distance.  The elementary moves swap two adjacent pixels.  The images were obtained with fast cooling schedule (left) and slow cooling schedule (right), producing results similar to <link xlink:type="simple" xlink:href="../889/2889.xml">
amorphous</link> and <link xlink:type="simple" xlink:href="../015/6015.xml">
crystalline solid</link>s, respectively.</col>
</row>
</table>
</p>


<p>

It can be shown that for any given finite problem, the probability that the simulated annealing algorithm terminates with the <link xlink:type="simple" xlink:href="../285/914285.xml">
global optimal</link> solution approaches 1 as the annealing schedule is extended. This theoretical result, however, is not particularly helpful, since the time required to ensure a significant probability of success will usually exceed the time required for a complete search of the <link xlink:type="simple" xlink:href="../808/1556808.xml">
solution space</link>.</p>

</ss1>
</sec>
<sec>
<st>
Pseudocode</st>
<p>

The following pseudocode implements the simulated annealing heuristic, as described above, starting from state s0 and continuing to a maximum of kmax steps or until a state with energy emax or less is found. The call neighbour(s) should generate a randomly chosen neighbour of a given state s; the call random() should return a random value in the range <math>[0, 1)</math>. The annealing schedule is defined by the call temp(r), which should yield the temperature to use, given the fraction r of the time budget that has been expended so far.</p>

<p>

s := s0; e := E(s)                           // <it>Initial state, energy.</it>
sb := s; eb := e                             // <it>Initial "best" solution</it>
k := 0                                       // <it>Energy evaluation count.</it>
<b>while</b> k &amp;lt; kmax <b>and</b> e &amp;gt; emax                  // <it>While time remains &amp; not good enough:</it>
sn := neighbour(s)                         //   <it>Pick some neighbour.</it>
en := E(sn)                                //   <it>Compute its energy.</it>
<b>if</b> en  eb <b>then</b>                            //   <it>Is this a new best?</it>
sb := sn; eb := en                       //     <it>Yes, save it.</it>
<b>if</b> P(e, en, temp(k/kmax)) &amp;gt; random() <b>then</b>  //   <it>Should we move to it?</it>
s := sn; e := en                         //     <it>Yes, change state.</it>
k := k + 1                                 //   <it>One more evaluation done</it>
<b>return</b> sb                                    // <it>Return the best solution found.</it></p>

<p>

Actually, the "pure" SA algorithm does not keep track of the best solution found so far: it does not use the variables sb and eb, it lacks the first <b>if</b> inside the loop, and, at the end,  it returns the current state s instead of sb.  While saving the best state is a standard optimization, that can be used in any <link xlink:type="simple" xlink:href="../458/774458.xml">
metaheuristic</link>, it breaks the analogy with physical annealing — since a physical system can "store" a single state only.</p>
<p>

Saving the best state is not necessarily an improvement, since one may have to specify a smaller kmax in order to compensate for the higher cost per iteration.  However, the step sb := sn happens only on a small fraction of the moves. Therefore, the optimization is usually worthwhile, even when state-copying is an expensive operation.</p>

</sec>
<sec>
<st>
Selecting the parameters</st>
<p>

In order to apply the SA method to a specific problem, one must specify the following parameters: the state space, the energy (goal) function E(), the candidate generator procedure neighbour(), the acceptance probability function P(), and the annealing schedule temp(). These choices can have a significant impact on the method's effectiveness.  Unfortunately, there are no choices of these parameters that will be good for all problems, and there is no general way to find the best choices for a given problem.  The following sections give some general guidelines.</p>

<ss1>
<st>
Diameter of the search graph</st>
<p>

Simulated annealing may be modeled as a random walk on a <it>search <link xlink:type="simple" xlink:href="../401/12401.xml">
graph</link></it>, whose vertices are all possible states, and whose edges are the candidate moves. An essential requirement for the  neighbour() function is that it must provide a sufficiently short path on this graph from the initial state to any state which may be the global optimum.  (In other words, the <link xlink:type="simple" xlink:href="../021/1020021.xml">
diameter</link> of the search graph must be small.)  In the traveling salesman example above, for instance, the search space for <math>n=20</math> cities has <link xlink:type="simple" xlink:href="../606/10606.xml">
<math>n! = 2 432 902 008 176 640 000</math></link> (2.5 <link xlink:type="simple" xlink:href="../403/682403.xml">
quintillion</link>) states; yet the neighbour generator function that swaps two consecutive cities can get from any state (tour) to any other state in <math>n(n-1)/2 = 190</math> steps.</p>

</ss1>
<ss1>
<st>
Transition probabilities</st>
<p>

For each edge <math>(s,s')</math> of the search graph, one defines a <it>transition probability</it>, which is the probability that the SA algorithm will move to state  <math>s'</math> when its current state is <math>s</math>.  This probability depends on the current temperature as specified by temp(), by the order in which the candidate moves are generated by the neighbour() function, and by the acceptance probability function P(). (Note that the transition probability is <b>not</b> simply <math>P(e, e', T)</math>, because the candidates are tested serially.)</p>

</ss1>
<ss1>
<st>
Acceptance probabilities</st>
<p>

The specification of neighbour(), P(), and temp() is partially redundant.  In practice, it's common to use the same acceptance function P() for many problems, and adjust the other two functions according to the specific problem.</p>
<p>

In the formulation of the method by Kirkpatrick et al., the acceptance probability <math>P(e, e', T)</math> was defined as 1 if <math>e' &amp;lt; e</math>, and <math>\exp((e-e')/T)</math> otherwise. This formula corresponds to the  <link xlink:type="simple" xlink:href="../107/56107.xml">
Metropolis-Hastings algorithm</link>, in the case where the proposal distribution of Metropolis-Hastings is symmetric. However, this acceptance probability is often used for simulated annealing even when the neighbour() function, which is analogous to the proposal distribution in Metropolis-Hastings, is not symmetric, or not probabilistic at all. Individual transitions of the simulated annealing algorithm do not correspond to the short-term evolution of a physical system, but rather the long-term distribution over states of the algorithm at a particular temperature corresponds to the probability distribution over states of a physical system at a particular temperature.</p>

</ss1>
<ss1>
<st>
Efficient candidate generation</st>
<p>

When choosing the candidate generator neighbour(), one must consider that after a few iterations of the SA algorithm, the current state is expected to have much lower energy than a random state.  Therefore, as a general rule, one should skew the generator towards candidate moves where the energy of the destination state <math>s'</math> is likely to be similar to that of the current state.  This <link xlink:type="simple" xlink:href="../452/63452.xml">
heuristic</link> (which is the main principle of the <link xlink:type="simple" xlink:href="../107/56107.xml">
Metropolis-Hastings algorithm</link>) tends to exclude "very good" candidate moves as well as "very bad" ones; however, the latter are much more common than the former, so the heuristic is generally quite effective.</p>
<p>

In the traveling salesman problem above, for example, swapping two <it>consecutive</it> cities in a low-energy tour is expected to have a modest effect on its energy (length); whereas swapping two <it>arbitrary</it> cities is far more likely to increase its length than to decrease it.  Thus, the consecutive-swap neighbour generator is expected to perform better than the arbitrary-swap one, even though the latter could provide a somewhat shorter path to the optimum (with <math>n-1</math> swaps, instead of <math>n(n-1)/2</math>).</p>
<p>

A more precise statement of the heuristic is that one should try first candidate states <math>s'</math> for which <math>P(E(s), E(s'), T)</math> is large.  For the "standard" acceptance function <math>P</math> above, it means that <math>E(s') - E(s)</math> is on the order of <math>T</math> or less. Thus, in the traveling salesman example above, one could use a neighbour() function that swaps two random cities, where the probability of choosing a city pair vanishes as their distance increases beyond <math>T</math>.</p>

</ss1>
<ss1>
<st>
Barrier avoidance</st>
<p>

When choosing the candidate generator neighbour() one must also try to reduce the number of "deep" local minima — states (or sets of connected states) that have much lower energy than all its neighbouring states.  Such "closed <link xlink:type="simple" xlink:href="../207/1268207.xml">
catchment</link> basins" of the energy function may trap the SA algorithm with high probability (roughly proportional to the number of states in the basin) and for a very long time (roughly exponential on the energy difference between the surrounding state and the bottom of the basin).</p>
<p>

As a rule, it is impossible to design a candidate generator that will satisfy this goal and also prioritize candidates with similar energy.  On the other hand, one can often vastly improve the efficiency of SA by relatively simple changes to the generator.  In the traveling salesman problem, for instance, it is not hard to exhibit two tours <math>A</math>, <math>B</math>, with nearly equal lengths, such that (0) <math>A</math> is optimal, (1) every sequence of city-pair swaps that converts <math>A</math> to <math>B</math> goes through tours that are much longer than both, and (2) <math>A</math> can be transformed into <math>B</math> by flipping (reversing the order of) a set of consecutive cities.  In this example, <math>A</math> and <math>B</math> lie in different "deep basins" if the generator performs only random pair-swaps; but they will be in the same basin if the generator performs random segment-flips.</p>

</ss1>
<ss1>
<st>
Cooling schedule</st>
<p>

The physical analogy that is used to justify SA assumes that the cooling rate is low enough for the probability distribution of the current state to be near <link xlink:type="simple" xlink:href="../823/265823.xml">
thermodynamic equilibrium</link> at all times.  Unfortunately, the <it>relaxation time</it>—the time one must wait for the equilibrium to be restored after a change in temperature—strongly depends on the "topography" of the energy function and on the current temperature.  In the SA algorithm, the relaxation time also depends on the candidate generator, in a very complicated way.  Note that all these parameters are usually provided as <link xlink:type="simple" xlink:href="../778/3957778.xml">
black box functions</link> to the SA algorithm.</p>
<p>

Therefore, in practice the ideal cooling rate cannot be determined beforehand, and should be empirically adjusted for each problem.  The variant of SA known as <link>
thermodynamic simulated annealing</link> tries to avoid this problem by dispensing with the cooling schedule, and instead automatically adjusting the temperature at each step based on the energy difference between the two states, according to the laws of thermodynamics.</p>

</ss1>
</sec>
<sec>
<st>
Restarts</st>
<p>

Sometimes it is better to move back to a solution that was significantly better rather than always moving from the current state.  This is called <it>restarting</it>.  To do this we set s and e to sb and eb and perhaps restart the annealing schedule.  The decision to restart could be based on a fixed number of steps, or based on the current energy being too high from the best energy so far.</p>

</sec>
<sec>
<st>
Related methods </st>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../389/5219389.xml">
Quantum annealing</link> uses "quantum fluctuations" instead of thermal fluctuations get through high but thin barriers in the target function. </entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../897/563897.xml">
Stochastic tunneling</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
 attempts to overcome the increasing difficulty simulated annealing runs have in escaping from local minima as the temperature decreases, by 'tunneling' through barriers.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../937/381937.xml">
Tabu search</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
 normally moves to neighbouring states of lower energy, but will take uphill moves when it finds itself stuck in a local minimum; and avoids cycles by keeping a "taboo list" of solutions already seen.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../641/1180641.xml">
Stochastic gradient descent</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
 runs many greedy searches from random initial locations.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../254/40254.xml">
Genetic algorithms</link> maintain a pool of solutions rather than just one. New candidate solutions are generated not only by "mutation" (as in SA), but also by "combination" of two solutions from the pool. Probabilistic criteria, similar to those used in SA, are used to select the candidates for mutation or combination, and for discarding excess solutions from the pool.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../615/588615.xml">
Ant colony optimization</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
 (ACO) uses many ants (or agents) to traverse the solution space and find locally productive areas.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 The <link xlink:type="simple" xlink:href="../980/5767980.xml">
cross-entropy method</link> (CE) generates candidates solutions via a parameterized probability distribution. The parameters are updated via cross-entropy minimization, so as to generate better samples in the next iteration.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../902/9485902.xml">
Harmony search</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
 mimics musicians in improvisation process where each musician plays a note for finding a best harmony all together.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../543/7325543.xml">
Stochastic optimization</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
 is an umbrella set of methods that includes simulated annealing and numerous other approaches.</entry>
</list>
</p>

</sec>
<sec>
<st>
See also</st>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../037/3568037.xml">
Adaptive simulated annealing</link></entry>
<entry level="1" type="bullet">

 <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../876/60876.xml">
Markov chain</link></causal_agent>
</worker>
</assistant>
</model>
</person>
</physical_entity>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../555/420555.xml">
Combinatorial optimization</link> </entry>
<entry level="1" type="bullet">

 <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../025/320025.xml">
Automatic label placement</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../743/547743.xml">
Multidisciplinary optimization</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../341/1072341.xml">
Place and route</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../248/31248.xml">
Traveling salesman problem</link></entry>
<entry level="1" type="bullet">

 <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../290/3607290.xml">
Reactive search</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../718/10531718.xml">
Graph cuts in computer vision</link></entry>
</list>
</p>

</sec>
<sec>
<st>
References</st>
<p>

<list>
<entry level="1" type="bullet">

 S. Kirkpatrick and C. D. Gelatt and M. P. Vecchi, Optimization by Simulated Annealing, Science, Vol 220, Number 4598, pages 671-680, 1983. http://www.cs.virginia.edu/cs432/documents/sa-1983.pdf or http://citeseer.ist.psu.edu/kirkpatrick83optimization.html .</entry>
<entry level="1" type="bullet">

 V. Cerny, A thermodynamical approach to the travelling salesman problem: an efficient simulation algorithm. Journal of Optimization Theory and Applications, 45:41-51, 1985</entry>
<entry level="1" type="bullet">

 N. Metropolis, A.W. Rosenbluth, M.N. Rosenbluth, A.H. Teller, and E. Teller. "<link xlink:type="simple" xlink:href="../194/18381194.xml">
Equations of State Calculations by Fast Computing Machines</link>". <it>Journal of Chemical Physics</it>, 21(6):1087-1092, 1953. <weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1063/1.1699114">
http://dx.doi.org/10.1063/1.1699114</weblink></entry>
<entry level="1" type="bullet">

 A. Das and B. K. Chakrabarti (Eds.), <it>Quantum Annealing and Related Optimization Methods,</it> Lecture Note in Physics, Vol. 679, Springer, Heidelberg (2005)</entry>
<entry level="1" type="bullet">

 E. Weinberger, Correlated and Uncorrelated Fitness Landscapes and How to Tell the Difference, Biological Cybernetics, 63, No. 5, 325-336 (1990).</entry>
<entry level="1" type="bullet">

 J. De Vicente, J. Lanchares, R. Hermida, "Placement by Thermodynamic Simulated Annealing”, Physics Letters A,Vol. 317, Issue 5-6, pp.415-423, 2003.</entry>
</list>
</p>

</sec>
<sec>
<st>
External links</st>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://paradiseo.gforge.inria.fr/">
ParadisEO</weblink> An open-source C++ framework for simulated annealing and other metaheuristic algorithms.</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.heatonresearch.com/articles/64/page1.html">
Simulated Annealing</weblink> A Java applet that allows you to experiment with simulated annealing. Source code included.</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.mathworks.com/matlabcentral/fileexchange/loadFile.do?objectId=10548&amp;objectType=file">
"General Simulated Annealing Algorithm"</weblink> An open-source MATLAB program for general simulated annealing exercises.</entry>
<entry level="1" type="bullet">

  <link xlink:type="simple" xlink:href="../037/3568037.xml">
Adaptive Simulated Annealing</link> (ASA) <weblink xlink:type="simple" xlink:href="http://www.ingber.com/#ASA">
http://www.ingber.com/#ASA</weblink> Free C-language simulated annealing code with many tuning options.</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://en.wikiversity.org/wiki/Simulated_Annealing_Project">
Self-Guided Lesson on Simulated Annealing</weblink> A Wikiversity project.</entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://biomath.ugent.be/~brecht/downloads.html">
Some MATLAB implementations of global optimization algorithms</weblink>: SIMPSA (combination of SA and SIMPLEX), SCA, PSO</entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://funymath.blogspot.com/2008/09/mathematical-description-of-simulated.html">
Arsen Zahray's blog entry on mathematical foundations of simulated annealing</weblink>: Mathematical properties of simulated annealing algorithm</entry>
</list>
</p>


</sec>
</bdy>
</algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</article>
