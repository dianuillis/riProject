<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 17.04.2009 04:27:05[mciao0828] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<psychiatrist  confidence="0.9511911446218017" wordnetid="110488016">
<header>
<title>Kenneth Colby</title>
<id>18306196</id>
<revision>
<id>239326309</id>
<timestamp>2008-09-18T17:00:47Z</timestamp>
<contributor>
<username>Lightbot</username>
<id>7178666</id>
</contributor>
</revision>
<categories>
<category>American psychiatrists</category>
<category>2001 deaths</category>
<category>1920 births</category>
</categories>
</header>
<bdy>

<b>Kenneth Mark Colby, M.D.</b> (1920 to 2001) was an American <link xlink:type="simple" xlink:href="../004/25004.xml">
psychiatrist</link> dedicated to the theory and application of <link xlink:type="simple" xlink:href="../323/5323.xml">
computer science</link> and <link xlink:type="simple" xlink:href="../164/1164.xml">
artificial intelligence</link> to <link xlink:type="simple" xlink:href="../869/18973869.xml">
psychiatry</link>.  Colby was a pioneer in the development of <link xlink:type="simple" xlink:href="../457/7878457.xml">
computer technology</link> as a tool to try to understand cognitive functions and to assist both patients and doctors in the treatment process.  He is perhaps best known for the development of a computer program called <link xlink:type="simple" xlink:href="../447/405447.xml">
PARRY</link>, which mimicked a paranoid schizophrenic and could "converse" with others.  PARRY sparked serious debate about the possibility and nature of <link xlink:type="simple" xlink:href="../164/1164.xml">
machine intelligence</link>. 
<sec>
<st>
Early Life and Education</st>
<p>

Colby was born in <link xlink:type="simple" xlink:href="../965/256965.xml">
Waterbury</link>, <symbol wordnetid="106806469" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../466/6466.xml">
Connecticut</link></symbol>
 in 1920. He graduated from <university wordnetid="108286163" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../273/34273.xml">
Yale University</link></university>
 in 1941 and from <link xlink:type="simple" xlink:href="../207/874207.xml">
Yale Medical School</link> in 1943.</p>

</sec>
<sec>
<st>
Career</st>
<p>

Colby began his career in <link xlink:type="simple" xlink:href="../585/23585.xml">
psychoanalysis</link> as a clinical associate at the San Francisco Institute of Psychoanalysis in 1951.  During this time, he published <it>A Primer for Psychotherapists,</it> an introduction to psychodynamic <link xlink:type="simple" xlink:href="../931/24931.xml">
psychotherapy</link>. He joined the Department of <link xlink:type="simple" xlink:href="../323/5323.xml">
Computer Science</link> at <university wordnetid="108286163" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../977/26977.xml">
Stanford University</link></university>
 in the early sixties, beginning his pioneering work in the relatively new field of <link xlink:type="simple" xlink:href="../164/1164.xml">
artificial intelligence</link>. In 1967 the <agency wordnetid="108337324" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../909/455909.xml">
National Institute of Mental Health</link></agency>
 recognized his research potential when he was awarded a Career Research Scientist Award. Colby came to <link xlink:type="simple" xlink:href="../765/37765.xml">
UCLA</link> as a professor of <link xlink:type="simple" xlink:href="../869/18973869.xml">
psychiatry</link> in 1974, and was jointly appointed professor in the Department of Computer Science a few years later. Over the course of his career, he wrote numerous books and articles on psychiatry, psychology, psychotherapy and artificial intelligence. </p>

</sec>
<sec>
<st>
Psychoanalysis</st>
<p>

Early in his career, in 1955, Colby published <it>Energy and Structure in Psychoanalysis,</it> an effort to bring Freud's basic doctrines into line with modern concepts of <link xlink:type="simple" xlink:href="../939/22939.xml">
physics</link> and <link xlink:type="simple" xlink:href="../010/37010.xml">
philosophy of science</link>. <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref> This, however, would be one of the last attempts by Colby to reconcile psychoanalysis with what he saw as important developments in science and philosophical thought.  Central to Freud's method is his employment of a <link xlink:type="simple" xlink:href="../603/70603.xml">
hermeneutics</link> of suspicion, a method of inquiry that refuses to take the subject at his or her word about internal processes. <link xlink:type="simple" xlink:href="../743/26743.xml">
Freud</link> sets forth explanations for a patient's mental state without regard for whether the patient agrees or not. If the patient does not agree, s/he has repressed the truth, that truth that the psychoanalyst alone can be entrusted with unfolding. The psychoanalyst's authority for deciding the nature or validity of a patient's state and the lack of empirical verifiability for making this decision was not acceptable to Colby. </p>
<p>

Colby's disenchantment with <link xlink:type="simple" xlink:href="../585/23585.xml">
psychoanalysis</link> would be further expressed in several publications, including his 1958 book, <it>A Skeptical Psychoanalyst</it>. He began to vigorously criticize psychoanalysis for failing to satisfy the most fundamental requirement of a science, that being the generation of reliable data. In his 1983 book, <it>Fundamental Crisis in Psychiatry</it>, he wrote, “Reports of clinical findings are mixtures of facts, fabulations, and fictives so intermingled that one cannot tell where one begins and the other leaves off. …we never know how the reports are connected to the events that actually happened in the treatment sessions, and so they fail to qualify as acceptable scientific data.”<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref>. </p>
<p>

Likewise, in <it>Cognitive Science and Psychoanalysis</it>, he stated, "In arguing that psychoanalysis is not a science, we shall show that few scholars studying this question get to the bottom of the issue. Instead, they start by accepting, as do psychoanalytic theorists, that the reports of what happens in psychoanalytic treatment -- the pri­mary source of the data -- are factual, and then they lay out their interpretations of the significance of facts for theory. We, on the other hand, question the status of the facts." <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%223%22])">3</ref>  These issues would shape his approach to psychiatry and guide his research efforts.</p>

</sec>
<sec>
<st>
Computer Science</st>
<p>

In the 1960s Colby began thinking about the ways in which <link xlink:type="simple" xlink:href="../402/30402.xml">
computer theory</link> and application could contribute to the understanding of <link xlink:type="simple" xlink:href="../165/7267165.xml">
brain function</link> and <link xlink:type="simple" xlink:href="../356/19356.xml">
mental illness</link>. One early project involved an Intelligent Speech <link xlink:type="simple" xlink:href="../750/72750.xml">
Prosthesis</link> which allowed individuals suffering from <link xlink:type="simple" xlink:href="../80s/2080s.xml">
aphasia</link> to “speak” by helping them search for and articulate words using whatever <link xlink:type="simple" xlink:href="../980/22980.xml">
phonemic</link> or <link xlink:type="simple" xlink:href="../107/29107.xml">
semantic</link> clues they were able to generate. <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%224%22])">4</ref> </p>
<p>

Later, Colby would be one of the first to explore the possibilities of computer-assisted <link xlink:type="simple" xlink:href="../931/24931.xml">
psychotherapy</link>.  In 1989, with his son Peter Colby, he formed the company Malibu Artificial Intelligence Works to develop and market a <link xlink:type="simple" xlink:href="../173/21173.xml">
natural language</link> version of <link xlink:type="simple" xlink:href="../750/5750.xml">
cognitive behavioral therapy</link> for <link xlink:type="simple" xlink:href="../460/90460.xml">
depression</link>, called <it>Overcoming Depression.</it> <it>Overcoming Depression</it> would go on to be used as a therapeutic learning program by the <link xlink:type="simple" xlink:href="../083/32083.xml">
U.S. Navy</link> and <link xlink:type="simple" xlink:href="../405/212405.xml">
Department of Veteran Affairs</link> and would be distributed to individuals who used it without supervision from a psychiatrist.  Needless to say, this practice was challenged by the media. To one journalist Colby replied that the program could be better than human therapists because "After all, the computer doesn't burn out, look down on you or try to have sex with you." <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%225%22])">5</ref></p>

</sec>
<sec>
<st>
Artificial Intelligence</st>
<p>

In the 1960s at Stanford University, Colby embarked on the creation of software programs known as "chatterbots," which simulate conversations with people. One well known <link xlink:type="simple" xlink:href="../349/148349.xml">
chatterbot</link> at the time was <link xlink:type="simple" xlink:href="../235/10235.xml">
ELIZA</link>, a computer program developed by <link xlink:type="simple" xlink:href="../003/16003.xml">
Joseph Weizenbaum</link> in 1966 to parody a psychologist.  ELIZA, by Weizenbaum's own admission, was developed more as a language-parsing tool than as an exercise in human intelligence. Named for the Eliza Doolittle character in "Pygmalion," it was the first conversational computer program, designed to imitate a psychotherapist asking questions instead of giving advice. It appeared to give conversational answers, although it could be led to lapse into obtuse nonsense.</p>
<p>

In 1972, at the <point wordnetid="108620061" confidence="0.8">
<institute wordnetid="108407330" confidence="0.8">
<geographic_point wordnetid="108578706" confidence="0.8">
<location wordnetid="100027167" confidence="0.8">
<association wordnetid="108049401" confidence="0.8">
<workplace wordnetid="104602044" confidence="0.8">
<lab wordnetid="103629986" confidence="0.8">
<link xlink:type="simple" xlink:href="../358/310358.xml">
Stanford Artificial Intelligence Laboratory</link></lab>
</workplace>
</association>
</location>
</geographic_point>
</institute>
</point>
, Colby built upon the idea of ELIZA to create a natural language program called PARRY that simulated the thinking of a <link xlink:type="simple" xlink:href="../028/2329028.xml">
paranoid</link> individual. This thinking entails the consistent misinterpretation of others' motives – others must be up to no good, they must have concealed motives that are dangerous, or their inquiries into certain areas must be deflected - which PARRY achieved via a complex system of assumptions, attributions, and “emotional responses” triggered by shifting weights assigned to verbal inputs.</p>

</sec>
<sec>
<st>
PARRY: A Computer Model of Paranoia</st>
<p>

Colby's aim in writing PARRY had been practical as well as theoretical.  He thought of PARRY as a virtual reality teaching system for students before they were let loose on real patients. <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref> However, PARRY's design was driven by Colby's own theories about paranoia.  Colby saw paranoia as a degenerate mode of processing symbols where the patient's remarks "are produced by an underlying organized structure of rules and not by a variety of random and unconnected mechanical failures." <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%227%22])">7</ref>  This underlying structure was an algorithm, not unlike a set of computer processes or procedures, which is accessible and can be reprogrammed, in other words "cured."</p>
<p>

Shortly after it was introduced, PARRY would go on to create intense discussion and controversy over the possibility or nature of machine intelligence.  PARRY was the first program to pass the “<link xlink:type="simple" xlink:href="../840/43840.xml">
Turing Test</link>," named for the British mathematician <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../208/1208.xml">
Alan Turing</link></scientist>
</person>
, who in 1950 suggested that if a computer could successfully impersonate a human by carrying on a typed conversation with a person, it could be called intelligent. PARRY succeeded in passing this test when human interrogators, interacting with the program via remote keyboard, were unable with more than random accuracy to distinguish PARRY from an actual paranoid individual.</p>
<p>

As philosopher D.C. Dennett stated in <it>Alan Turing:Life and Legacy of a Great Thinker,</it> "To my knowledge, the only serious and interesting attempt by any program designer to win even a severely modified Turing test has been Kenneth Colby.  He had genuine psychiatrists interview PARRY.  He did not suggest that they might be talking or typing to a computer; rather he made up some plausible story about why they were communicating with a real live patient via teletype.  Then he took the PARRY transcript, inserted it into a group of teletype transcripts and gave them to another group of experts -- more psychiatrists -- and said, 'One of these was a conversation with a computer.  Can you figure out which one it was?'  They couldn't."  <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%228%22])">8</ref></p>
<p>

Much of the criticism of ELIZA as a model for artificial intelligence focused on the program's lack of an internal world model that influenced and tracked the conversation. PARRY simulates paranoid behavior by tracking its own internal emotional state on a few different dimensions. To illustrate this, Colby created another program called RANDOM-PARRY which chose responses at random.  Responses from RANDOM-PARRY did not model the human patients' responses as well as standard PARRY. Some have argued that PARRY fooled its judges because paranoid behavior makes inappropriate responses or <link xlink:type="simple" xlink:href="../388/2493388.xml">
non sequitur</link>s appropriate. But there is still a certain logic to them that PARRY simulates effectively. It is simpler to simulate paranoid behavior, perhaps, but it is not trivial. <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%229%22])">9</ref></p>
<p>

The two computer programs, ELIZA and the paranoid PARRY, eventually met for series of "talks," executing different programs. One exchange such went like this:</p>
<p>

PARRY: I know the mob controls the big rackets.</p>
<p>

ELIZA: Who are you really talking about?</p>
<p>

PARRY: Have you ever really thought about the Mafia?</p>
<p>

ELIZA: Suppose you ever really thought about the Mafia?</p>
<p>

PARRY: Let's talk about something else.</p>
<p>

ELIZA: I am not sure I understand you fully.</p>
<p>

PARRY: You keep asking me the same things, why not change the topic?</p>
<p>

ELIZA: In what way? <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2210%22])">10</ref></p>
<p>

Colby would claim that PARRY mimics the natural process by which a person (in this case a paranoid schizophrenic) engages in conversation.  The structure of the program that makes the linguistic decisions in PARRY is isomorphic to the 'deep structure' of the mind of the paranoiac. As Colby stated: "Since we do not know the structure of the 'real' simulative processes used by the mind-brain, our posited structure stands as an imagined theoretical analogue, a possible and plausible organization of processes analogous to the unknown processes and serving as an attempt to explain their workings" <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2211%22])">11</ref>.  </p>
<p>

Yet, some critics of PARRY expressed the concern that this computer program does not in actuality "understand" the way a person understands and continued to assert that the idiosyncratic, partial and idiolectic responses from PARRY cover up its limitations. <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2212%22])">12</ref>  Colby attempted to answer these and other criticisms in a 1974 publication entitled, "Ten Criticisms of Parry." <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2213%22])">13</ref>  </p>
<p>

Colby also raised his own ethical concerns over the application of his work to real life situations. In 1984, he wrote, "With the great amount of attention now being paid by the media to artificial intelligence, it would be naive, shortsighted, and even self-deceptive to think that there will not be public interest in scrutinizing, monitoring, regulating, and even constraining our efforts. What we do can affect people’s lives as they understand them. People are going to ask not only what we are doing but also whether it should be done. Some might feel we are meddling in areas best left alone. We should be prepared to participate in open discussion and debate on such ethical issues."<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2214%22])">14</ref></p>
<p>

Still, PARRY has withstood the test of time and for many years has continued to be acknowledged by researchers in computer science for its apparent achievements. In a 1999 review of human-computer conversation, Yorick Wilks and Roberta Catizone from the University of Sheffield comment: "The best performance overall in HMC (Human-machine conversation) has almost certainly been Colby’s PARRY program since its release on the net around 1973. It was robust, never broke down, always had something to say and, because it was intended to model paranoid behaviour, its zanier misunderstandings could always be taken as further evidence of mental disturbance, rather than the processing failures they were." <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2215%22])">15</ref></p>

</sec>
<sec>
<st>
Other Areas of Study</st>
<p>

During his career, Colby ventured into other, more esoteric areas of research including classifying dreams in "primitive tribes." His findings suggested that men and women of <link xlink:type="simple" xlink:href="../281/45281.xml">
primitive tribes</link> differ in their dream life, these differences possibly contributing an empirical basis to our theoretical constructs of <link xlink:type="simple" xlink:href="../058/240058.xml">
masculinity</link> and <link xlink:type="simple" xlink:href="../059/240059.xml">
femininity</link>. <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2216%22])">16</ref></p>

</sec>
<sec>
<st>
Books</st>
<p>

<list>
<entry level="1" type="bullet">

 (1951) <it>A Primer for Psychotherapists.</it> (ISBN 978-0826020901) </entry>
<entry level="1" type="bullet">

 (1955) <it>Energy and Structure in Psychoanalysis.''</it></entry>
<entry level="1" type="bullet">

 (1957) <it>An exchange of views on psychic energy and psychoanalysis.''</it></entry>
<entry level="1" type="bullet">

 (1958) <it>A Skeptical Psychoanalyst.''</it></entry>
<entry level="1" type="bullet">

 (1960) <it>Introduction to Psychoanalytic Research''</it></entry>
<entry level="1" type="bullet">

 (1973) <it>Computer Models of Thought and Language.''</it></entry>
<entry level="1" type="bullet">

 (1975) <it>Artificial Paranoia : A Computer Simulation of Paranoid Processes</it> (ISBN 9780080181622)</entry>
<entry level="1" type="bullet">

 (1983) <it>Fundamental Crisis in Psychiatry: Unreliability of Diagnosis</it> (ISBN 9780398047887)</entry>
<entry level="1" type="bullet">

 (1988) <it>Cognitive Science and Psychoanalysis</it> (ISBN 9780805801774)</entry>
</list>
</p>

</sec>
<sec>
<st>
Publications</st>
<p>

<list>
<entry level="1" type="bullet">

 "Sex Differences in Dreams of Primitive Tribes" <b>American Anthropologist, New Series,</b> Vol. 65, No. 5, Selected Papers in Method and Technique (Oct., 1963), pp. 1116-1122 </entry>
<entry level="1" type="bullet">

 "Computer Simulation of Change in Personal Belief Systems." <b>Behavioral Science,</b> 12 (1967), pp. 248-253 </entry>
<entry level="1" type="bullet">

 "Dialogues Between Humans and an Artificial Belief System." <b>IJCAI</b> (1969), pp. 319-324 </entry>
<entry level="1" type="bullet">

 "Experiments with a Search Algorithm for the Data Base of a Human Belief System." <b>IJCAI</b> (1969), pp. 649-654 </entry>
<entry level="1" type="bullet">

 "Artificial Paranoia." <b>Artif. Intell.</b> 2(1) (1971), pp. 1-25  </entry>
<entry level="1" type="bullet">

 "Turing-like Indistinguishability Tests for the Validation of a Computer Simulation of Paranoid Processes." <b>Artif. Intell.</b> 3(1-3) (1972), pp. 199-221 </entry>
<entry level="1" type="bullet">

 "Idiolectic Language-Analysis for Understanding Doctor-Patient Dialogues." <b>IJCAI</b> (1973), pp. 278-284 </entry>
<entry level="1" type="bullet">

 "Pattern-matching rules for the recognition of natural language dialogue expressions." Stanford University, Stanford, CA, 1974 </entry>
<entry level="1" type="bullet">

 "Appraisal of four psychological theories of paranoid phenomena." <b>Journal of Abnormal Psychology.</b> Vol 86(1) (1977), pp. 54-59</entry>
<entry level="1" type="bullet">

 "Conversational Language Comprehension Using Integrated Pattern-Matching and Parsing." <b>Artif. Intell.</b> 9(2) (1977), pp. 111-134   </entry>
<entry level="1" type="bullet">

 "Cognitive therapy of paranoid conditions: Heuristic suggestions based on a computer simulation model." <b>Journal Cognitive Therapy and Research</b> Vol 3 (1) (March 1979) </entry>
<entry level="1" type="bullet">

 "A Word-Finding Algorithm with a Dynamic Lexical-Semantic Memory for Patients with Anomia Using a Speech Prosthesis." <b>AAAI</b> (1980), pp. 289-291 </entry>
<entry level="1" type="bullet">

 "Reloading a Human Memory: A New Ethical Question for Artificial Intelligence Technology." <b>AI Magazine</b> 6(4) (1986), pp. 63-64  </entry>
</list>
</p>

</sec>
<sec>
<st>
See also</st>
<p>

<list>
<entry level="1" type="bullet">

 <link>
Artificial Intelligence</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../349/148349.xml">
Chatterbot</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../626/5626.xml">
Cognitive Science</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../235/10235.xml">
ELIZA</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../652/21652.xml">
natural language processing</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../585/23585.xml">
Psychoanalysis</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../840/43840.xml">
Turning Test</link></entry>
</list>
</p>

</sec>
<sec>
<st>
References</st>

<p>

<reflist>
<entry id="1">
<it>Energy and Structure in Psychoanalysis</it> (1958)</entry>
<entry id="2">
<it>Fundamental Crisis in Psychiatry</it> (1983)</entry>
<entry id="3">
<it>Cognitive Science and Psychoanalysis</it> (1988)</entry>
<entry id="4">
<weblink xlink:type="simple" xlink:href="http://www.universityofcalifornia.edu/senate/inmemoriam/KennethMarkColby.htm">
Kenneth Mark Colby</weblink></entry>
<entry id="5">
quoted in <it>Mind as Machine: A History of Cognitive Science</it> By Margaret A. Boden</entry>
<entry id="6">
<it>Mind as Machine: A History of Cognitive Science</it> By Margaret A. Boden p. 370</entry>
<entry id="7">
<it>Artificial Paranoia : A Computer Simulation of Paranoid Processes</it> p. 99-100</entry>
<entry id="8">
In: <it>Alan Turing: Life and Legacy of a Great Thinker</it> By Christof Teuscher, Douglas Hofstadter, p 304</entry>
<entry id="9">
http://robot-club.com/lti/pub/aaai94.html "Chatterbots, Tinymuds, And The Turing Test: Entering The Loebner Prize Competition" by Michael L. Mauldin</entry>
<entry id="10">
http://www.stanford.edu/group/SHR/4-2/text/dialogues.html  "Dialogues with colorful personalities of early AI"</entry>
<entry id="11">
<it>Artificial Paranoia: A Computer Simulation of Paranoid Processes.</it> p.21</entry>
<entry id="12">
 http://cultronix.eserver.org/sengers/ "Wallowing in the Quagmire of Language: Artificial Intelligence, Psychiatry, and the Search for the Subject". Phoebe Sangers, Cultronix. </entry>
<entry id="13">
http://portal.acm.org/citation.cfm?doid=1045200.1045202 "Ten Criticisms of Parry" by Kenneth Colby</entry>
<entry id="14">
"Reloading a Human Memory: A New Ethical Question for Artificial Intelligence Technology." <b>AI Magazine</b> 6(4) (1986), pp. 63-64 </entry>
<entry id="15">
arXiv:cs.CL/9906027 v1 25 Jun 1999 "Human-Computer Conversation" by Yorick Wilks and Roberta Catizone</entry>
<entry id="16">
"Sex Differences in Dreams of Primitive Tribes," <b>American Anthropologist, New Series,</b> Vol. 65, No. 5: 1116-1122</entry>
</reflist>
</p>

</sec>
<sec>
<st>
External links</st>
<p>

<list>
<entry level="1" type="bullet">

 http://query.nytimes.com/gst/fullpage.html?res=9501E7DD1E3BF931A25756C0A9679C8B63</entry>
<entry level="1" type="bullet">

 http://www.stanford.edu/group/SHR/4-2/text/dialogues.html</entry>
</list>
</p>

</sec>
</bdy>
</psychiatrist>
</article>
