<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 17.04.2009 04:56:15[mciao0825] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Computational trust</title>
<id>18715559</id>
<revision>
<id>242483009</id>
<timestamp>2008-10-02T12:38:03Z</timestamp>
<contributor>
<username>Dquercia</username>
<id>7951928</id>
</contributor>
</revision>
<categories>
<category>Access control</category>
<category>All pages needing to be wikified</category>
<category>Wikify from July 2008</category>
<category>Online social networking</category>
<category>Key management</category>
</categories>
</header>
<bdy>

<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-content" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="40x40px" src="Ambox_content.png">
</image>
</p>
</col>
<col style="" class="mbox-text">
 <p>

This article or section has multiple issues. Please help <b><weblink xlink:type="simple" xlink:href="http://localhost:18088/wiki/index.php?title=Computational_trust&amp;action=edit">
improve the article</weblink></b> or discuss these issues on the .
<list>
<entry level="1" type="bullet">

 It may need to be <b>
Articles that need to be wikified|wikified</b> to meet Wikipedia's . Tagged since August 2008.</entry>
</list>
</p>
</col>
</row>
</table>

<p>

In <link xlink:type="simple" xlink:href="../036/15036.xml">
Information security</link>, <b>computational trust</b> is the generation of trusted authorities or user trust through <link xlink:type="simple" xlink:href="../432/18934432.xml">
cryptography</link>. In centralised systems, security is typically based on the authenticated identity of external parties. Rigid authentication mechanisms, such as Public Key Infrastructures (PKIs) 
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref> or Kerberos 
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref>
have allowed this model to be extended to distributed systems within a few closely collaborating domains or within a single administrative domain. During the last years, Computer Science has moved from centralised computer systems to distributed computing. This evolution has several implications on the security models, the policies and the mechanisms needed to protect users’ information and resources in an increasingly interconnected
computing infrastructure <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%223%22])">3</ref>. </p>
<p>

Identity-based security mechanisms cannot authorise an operation without authenticating the claiming entity. This means that no interaction can occur unless both parties known their authentication frameworks. Spontaneous interactions would, therefore, require a single, or a few trusted Certificate Authorities (CAs). In the present context, PKI has not been considered since they have shown difficulties to emerge, thus it is not so probable that they will establish themselves as a reference standard in the near future. In the present, a user who wishes to join spontaneous collaboration with another party can choose between enabling security and thereby disabling spontaneous collaboration, or disabling security and enabling spontaneous collaboration. It is fundamental that mobile users and devices can authenticate in an autonomous way without relying on a common authentication infrastructure. In order to face this problem, we need to examine the challenges introduced by ”Global Computing“ <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%224%22])">4</ref>, a term coined by the EU for the future of the global information society, and to identify their impact on security.</p>

<sec>
<st>
History</st>

<p>

Computational Trust applies the human notion of trust into the digital world, that is seen as malicious rather than cooperative. The expected benefits, according to Marsh et al., result in an exploitation of others' ability through delegation and in an achievement of more cooperation in an open and less protected environment. The scientiﬁc research in the area of computational mechanism for trust and reputation in virtual societies is oriented to increase the reliability and performance of electronic communities<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%225%22])">5</ref>.</p>
<p>

A trust-based decision in a specific domain is a multi-stage process. The first step of this process consists in identifying and selecting the proper input data, that is, the trust evidences. In general, these are domain-specific and they result from an analysis conducted over the application involved. In the next step, a trust computation is performed over evidences to produce Trust values, that means the estimation of the trustworthiness of entities in that particular domain. The selection of evidences and the subsequent trust computation are informed by a notion of Trust, defined in the Trust model. Finally, the trust decision is taken by considering the computed values and exogenous factors, like disposition or risk assessments</p>

</sec>
<sec>
<st>
Defining Trust</st>

<p>

These concepts have been acquiring a great relevance in the last decade in the Computer Science field, mostly in the area of distributed Artificial Intelligence. The multi-agent system paradigm and the huge evolution of e-commerce are factors that contributed to the increase of interest on trust
and reputation. In fact, Trust and reputation systems have been recognized as the key factors for a successful electronic commerce adoption. These systems are used by intelligent software agents bots as an incentive in decision-making, when deciding whether or not to honor contracts, and as a mechanism to search trustworthy exchange partners. In particular, reputation is used in electronic markets as a trust-enforcing mechanism or as a method to avoid cheaters and frauds <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref>. </p>
<p>

Another area of application of these concepts, in agent technology, is teamwork and cooperation <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%227%22])">7</ref>.
Several definitions of the human notion of trust have been proposed during the last years in different domains from sociology, psychology to political and business science. These definitions may even change in accordance with the application domain. For example, Romano’s recent definition <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%228%22])">8</ref> tries to encompass the previous work in all these domains:</p>
<p>

Trust is a subjective assessment of another’s influence in terms of the extent of one’s perception about the quality and significance of another’s impact over one’s outcomes in a given situation, such that one’s expectation of, openness to, and inclination toward such influence provide a sense of control over the potential outcomes of the situation.</p>
<p>

Trust and reputation both have a social value. When someone is trustworthy, that person may be expected to perform in a beneficial or at least not in a suspicious way that assure others, with high probability, good collaborations with him. On the contrary, when someone appears not to be trustworthy, others refrain from collaborating since there is a lower level of probability that these collaborations will be successful <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%229%22])">9</ref>.</p>
<p>

Trust is a particular level of the subjective probability with which an agent assesses that another agent or group of agents will perform a particular action, both before he can monitor such action (or independently or his capacity ever to be able to monitor it) and in a context in which it affects his own action.</p>
<p>

Trust is strongly connected to confidence and it implies some degrees of uncertainty, hopefulness or optimism. Eventually, Marsh <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2210%22])">10</ref> addressed the issue of formalizing trust as a computational concept in his Phd thesis. His trust model is based on social and psychological factors. </p>

<ss1>
<st>
Trust model classification</st>
<p>

A lot of proposals have appeared in the literature and here a selection of Computational Trust and reputation models, that represent a good sample of the current research, is presented <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2211%22])">11</ref>.</p>
<p>

Trust and reputation can be analysed from different points of view and can be applied in many situations. The next classification is based considering the peculiar characteristics of these models and the environment where they evolve.</p>

<ss2>
<st>
Conceptual model</st>
<p>

Trust and reputation model can be characterized as:
<list>
<entry level="1" type="bullet">

 Cognitive. </entry>
</list>

In models based on a cognitive approach, Trust and reputation are made up of underlying beliefs and are a function of the degree of these beliefs <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2212%22])">12</ref>. 
The mental states, that lead to trust another agent or to assign a reputation, are an essential part of the model, as well as the mental consequences of the decision and the act of relying on another agent;
<list>
<entry level="1" type="bullet">

 Game-theoretical. </entry>
</list>

Trust and reputation are considered subjective probabilities by which the individual A, expects the individual B to perform a given action on which its welfare depends <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2213%22])">13</ref>.</p>
<p>

In this approach, trust and reputation are not the result of a mental state of the agent in a cognitive sense, but the result of a more pragmatic game with utility functions and numerical aggregation of past interactions.</p>

</ss2>
<ss2>
<st>
Information sources</st>
<p>

It is possible to sort out models by considering the information sources used to compute Trust and reputation values. The traditional information sources are direct experiences and witness information, but recent models have started to consider the connection between information and the sociological aspect of agent’s behavior. When the model contains several information sources it can increase the reliability of the results, but conversely, it can increases the complexity of the model.</p>
<p>

<list>
<entry level="1" type="bullet">

 Direct experiences</entry>
</list>

Direct experience is the most relevant and reliable information source for a Trust/reputation model. Two types of direct experiences can be recognizable:</p>
<p>

- the experience based on the direct interaction with the interlocutor;</p>
<p>

- the experience based on the observed interaction of the other members of a community.</p>
<p>

<list>
<entry level="1" type="bullet">

 Witness information</entry>
</list>

Witness information, also called indirect information, is what comes from the experience of other members of community. It can be based on their own direct experiences or on other data they gathered from others’ experience. Witness information is usually the most abundant but its use is complex for
Trust and reputation model. In fact, it introduces uncertainty and agents can manipulate or hide parts of the information for their own benefit.</p>
<p>

<list>
<entry level="1" type="bullet">

 Sociological information</entry>
</list>

In real world, people that belong to a community establish different types of relations among them. Each individual plays one or several roles in that society, influencing their behavior and the interaction with other people. In a multy-agent system, where there is plenty of interactions, the social relations among agents are a simplified reflection of a more complex relation which is among their human counterparts. Only a few Trust and reputation models adopt this sociological information, using techniques like social network analysis. These methods study social relationships among individuals in a society that emerged as a set of methods for the analysis of social structures, methods that specifically allow an investigation of the relational aspects of these structures
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2214%22])">14</ref>.</p>
<p>

<list>
<entry level="1" type="bullet">

 Prejudice</entry>
</list>

Prejudice is another, though uncommon, mechanism that has a sensible influence on trust and reputation. According to this method, an individual is given properties that are peculiar of a particular group and that make him recognisable as a member of this group. These signs can be everything like a uniform, a concrete behavior, etc <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2215%22])">15</ref>.</p>
<p>

As most people today use the word, “prejudice” refers to a negative or hostile attitude towards another social group, usually racially defined. However, this negative connotation has to be revised when applied to agent communities. The set of signs used in Computational Trust and reputations models are usually out of the ethical discussion, differently from the signs used in human societies, like skin color or sex.</p>

</ss2>
</ss1>
</sec>
<sec>
<st>
Discussion on Trust/Reputation models</st>
<p>

The most relevant sources of information considered by the trust and reputation models presented before, are direct experiences and witness information. In the actual e-markets, the sociological information is almost non-existent and, in order to increase the efficiency of actual Trust and reputation models, it should be considered. However, it has non sense to increase the complexity of models introducing trust evidences if, later, they have to be used in an environment where it is not possible to exploit their capabilities. The aggregation of more Trust and reputation evidences is useful in a computational model but it can increase its complexity and so it is difficult to find
a general solution. Several models are extremely dependent on the characteristics of the environment and a possible solution could be the use of adaptive mechanisms that can modify how to combine different sources of information in a given environment. A lot of trust and reputation definitions have been presented and there are several works that help to give a precise and distinct meaning
of both concepts <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2216%22])">16</ref>, <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2217%22])">17</ref>, 
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2218%22])">18</ref>. There is a relation between both the concepts that should be considered in depth: reputation is a concept that helps to build trust on others. Nowadays, the game theory is the predominant paradigm considered to design computational trust and reputation model. In all likelihood, this theory is taken into account because the huge amount of economists and computer scientists, with a strong background in game theory and Artificial Intelligence techniques, who are working in multi-agent and e-commerce contexts. Game theoretical models produce good results but, when the complexity of the agents, in terms of social relations and interaction increases, they become too restrictive. The exploration of new possibilities should be considered and, for example, there should be an aggregation between cognitive approaches with game theoretical ones. In the end, in the light of last models, it is clear that there is a complete absence of test and frameworks to evaluate and compare the models under a set of representative and common conditions. More trust evidences should be considered and trust metrics more sensitive to time <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2219%22])">19</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2220%22])">20</ref>, represent the first step to encourage the improvement of Computational Trust <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2221%22])">21</ref>.</p>

</sec>
<sec>
<st>
References</st>

<p>

<reflist>
<entry id="1">
Weise J.&#32;(August 2001).&#32;"<it>Public Key Infrastructure Overview.</it>". &#32;SunPs Global Security Practice, SunMicrosystems..</entry>
<entry id="2">
Kohl J. &amp; B. C. Neuman&#32;(1993).&#32;"<it>The Kerberos Network Authentication Service(Version 5).</it>". &#32;Internet Request for Comments RFC-1510..</entry>
<entry id="3">
Seigneur J.M&#32;(2005).&#32;"<it>Trust, Security and Privacy in Global Computing.</it>". &#32;PhD Thesis, University of Dublin, Trinity College.</entry>
<entry id="4">
&#32;(2004).&#32;"<it>IST, Global Computing, EU</it>". &#32;http://www.cordis.lu/ist/fet/gc.htm..</entry>
<entry id="5">
Longo L., Dondio P., Barrett S.&#32;(2007).&#32;"<it>Temporal Factors to evaluate trustworthiness of virtual identities</it>". &#32;Third International Workshop on the Value of Security through Collaboration, SECURECOMM.</entry>
<entry id="6">
Dellarocas C.&#32;(2003).&#32;"<it>The digitalization of Word-Of-Mouth: Promise and
Challenges of Online Reputation Mechanism</it>". &#32;Management Science,.</entry>
<entry id="7">
Montaner M., Lopez B., De La Rosa J.&#32;(2002).&#32;"<it>Developing Trust in Recom-
mender Agents.</it>". &#32;Proceedings of the First International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS-02).</entry>
<entry id="8">
Romano D.M.&#32;(2003).&#32;"<it>The Nature of Trust: Conceptual and Operational Clarification</it>". &#32;Louisiana State University, PhD Thesis.</entry>
<entry id="9">
Gambetta D..&#32;"<it>Can We Trust Trust.</it>". &#32;Trust: Making and Breaking Cooperative Relations. Chapt. Can We Trust Trust? Basil Blackwell, Oxford, pp. 213-237..</entry>
<entry id="10">
Marsh S.&#32;(1994).&#32;"<it>Formalizing Trust as a Computational Concept.</it>". &#32;PhD thesis, University of Stirling, Department of Computer Science and Mathematics..</entry>
<entry id="11">
Sabater J., Sierra C.&#32;(2005).&#32;"<it>Review on Computational Trust and Reputation Models.</it>". &#32;Artificial Intelligence Review, 24:33-60, Springer..</entry>
<entry id="12">
Esfandiari B., Chandrasekharan S.&#32;(2001).&#32;"<it>On How Agents Make Friends:
Mechanism for Trust Acquisition.</it>". &#32;In proocedings of the Fourth Workshop on Deception Fraud and Trust in Agent Societies, Montreal, Canada. pp. 27-34..</entry>
<entry id="13">
Gambetta D..&#32;"<it>Can We Trust Trust?</it>". &#32;In. Trust: Making and Breaking Cooperative Relations. Chapt. Can We Trust Trust? Basil Blackwell, Oxford, pp. 213-237..</entry>
<entry id="14">
Scott J..&#32;"<it>Social Network Analysis.</it>". &#32;SAGE Publications. http://www.analytictech.com/mb119/tableof.htm.</entry>
<entry id="15">
Bacharach M., Gambetta D.,&#32;(2001).&#32;"<it>Trust in Society.</it>". &#32;Chapt. Trust in signs. Russel Sage Foundation, ..</entry>
<entry id="17">
McKnight D.H., Chervany N.L.,&#32;(2002).&#32;"<it>Notions of Reputation in Multi-Agent Systems: a Review</it>". &#32;In: Proceedings of the 34th Hawaii International Conference on System Sciences..</entry>
<entry id="16">
McKnight D.H., Chervany N.L.,&#32;(1996).&#32;"<it>The meanings of trust. Technical report</it>". &#32;niversity of Minnesota Management Information Systems Research Center.</entry>
<entry id="19">
Longo L.&#32;(2007).&#32;"<it>Security Through Collaboration in Global Computing: a Computational Trust Model Based on Temporal Factors to Evaluate Trustworthiness of Virtual Identities</it>". &#32;Master Degree, Insubria University.</entry>
<entry id="18">
Mui L., Halberstadt A, Mohtashemi M.&#32;(2002).&#32;"<it>Notions of Reputation in Multi-Agent Systems: a Review.</it>". &#32;In: Proceedings of the First International Joint Conference on Autonomous Agents and Multi-Agent Systems (AAMAS-02), Bologna, Italy, pp. 280-287,.</entry>
<entry id="21">
Seigneur J.M.,&#32;(2006).&#32;"<it>Seigneur J.M., Ambitrust? Immutable and Context Aware Trust Fusion.</it>". &#32;Technical Report, Univ. of Geneva,.</entry>
<entry id="20">
D. Quercia, S. Hailes, L. Capra&#32;(2006).&#32;"<it><weblink xlink:type="simple" xlink:href="http://www.cs.ucl.ac.uk/staff/d.quercia/publications/querciaB-trust06.pdf">
B-trust: Bayesian Trust Framework for Pervasive Computing</weblink></it>". &#32;iTrust.</entry>
</reflist>
</p>

</sec>
<sec>
<st>
External links</st>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://ants.dif.um.es/~felixgm/research/trmsim-wsn">
TRMSim-WSN, a Trust and Reputation Models Simulator for Wireless Sensor Networks </weblink></entry>
</list>
</p>

</sec>
</bdy>
</article>
