<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 16:27:26[mciao0828] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Reconfigurable computing</title>
<id>188371</id>
<revision>
<id>244181040</id>
<timestamp>2008-10-09T17:57:47Z</timestamp>
<contributor>
<username>Rjwilmsi</username>
<id>203434</id>
</contributor>
</revision>
<categories>
<category>Reconfigurable computing</category>
<category>Digital electronics</category>
</categories>
</header>
<bdy>

<b>Reconfigurable computing</b> is a computing paradigm combining some of the flexibility of software with the high performance of hardware by processing with very flexible high speed computing fabrics like <link xlink:type="simple" xlink:href="../814/592814.xml">
FPGA</link>s. The principal difference when compared to using ordinary <link xlink:type="simple" xlink:href="../553/19553.xml">
microprocessor</link>s is the ability to make substantial changes to the <link xlink:type="simple" xlink:href="../889/8232889.xml">
datapath</link> itself in addition to the control flow. On the other hand, the main difference with custom hardware (<link xlink:type="simple" xlink:href="../845/147845.xml">
ASIC</link>s) is the possibility to adapt the hardware during runtime by "loading" a new circuit on the reconfigurable fabric.
<sec>
<st>
History and properties</st>

<p>

The concept of reconfigurable computing has existed since the 1960s, when <scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../516/17696516.xml">
Gerald Estrin</link></scientist>
's landmark paper proposed the concept of a computer made of a standard processor and an array of “reconfigurable” 
hardware.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref> The main processor would control the behavior of the reconfigurable hardware. The latter would then be tailored to perform a specific task, such as image processing or pattern matching, as quickly as a dedicated piece of hardware. Once the task was done, the hardware could be adjusted to do some other task. This resulted in a hybrid computer structure combining the flexibility of software with the speed of hardware; unfortunately this idea was far ahead of its time in needed electronic technology.</p>
<p>

In the eighties and nineties, there was a renaissance in this area of research with many proposed reconfigurable architectures developed in industry and academia, such as: Matrix, <weblink xlink:type="simple" xlink:href="http://brass.cs.berkeley.edu/garp.html">
Garp</weblink>,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%223%22])">3</ref> Elixent, PACT XPP, Silicon Hive, Montium, Pleiades, Morphosys, PiCoGA. Such designs were feasible due to the constant progress of silicon technology that let complex designs be implemented on one chip. The world's first commercial reconfigurable computer, the Algotronix CHS2X4, was completed in 1991. It was not a commercial success, but was promising enough that <company wordnetid="108058098" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../732/816732.xml">
Xilinx</link></company>
 (the inventor of the <link xlink:type="simple" xlink:href="../814/592814.xml">
Field-Programmable Gate Array</link>, FPGA) bought the technology and hired the Algotronix staff.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%224%22])">4</ref></p>

</sec>
<sec>
<st>
 Current systems </st>

<p>

Currently there are a number of vendors with commercially available reconfigurable computers aimed at the <link xlink:type="simple" xlink:href="../153/37153.xml">
high performance computing</link> market; including <company wordnetid="108058098" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../315/217315.xml">
Cray</link></company>
, <link xlink:type="simple" xlink:href="../013/28013.xml">
SGI</link> and <link xlink:type="simple" xlink:href="../136/2887136.xml">
SRC Computers, Inc.</link> . The reconfigurable computers are "Estrin" hybrid computers with microprocessors that can be used in traditional CPU cluster computers or coupled to user-programmable FPGAs for hybrid computing. Cray supercomputer company (not affiliated with SRC Computers) acquired OctigaBay and its reconfigurable computing platform, which Cray marketed as the <link xlink:type="simple" xlink:href="../925/1049925.xml">
XD1</link> until recently. <link xlink:type="simple" xlink:href="../013/28013.xml">
SGI</link> sells the <link>
RASC</link> platform with their <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<dining-room_attendant wordnetid="110013614" confidence="0.8">
<employee wordnetid="110053808" confidence="0.8">
<waiter wordnetid="110763383" confidence="0.8">
<link xlink:type="simple" xlink:href="../607/1129607.xml">
Altix</link></waiter>
</employee>
</dining-room_attendant>
</causal_agent>
</worker>
</person>
</physical_entity>
 series of supercomputers.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%225%22])">5</ref> <link xlink:type="simple" xlink:href="../136/2887136.xml">
SRC Computers, Inc.</link> has developed a family of reconfigurable computers based on their IMPLICIT+EXPLICIT architecture and MAP processor.   </p>
<p>

The XD1 and SGI FPGA reconfiguration can be accomplished either via the traditional <link xlink:type="simple" xlink:href="../554/74554.xml">
Hardware Description Languages</link> (HDL), which can be generated directly or by using electronic design automation (“EDA”) or electronic system level (“ESL”) tools, employing high level languages like the graphical tool <link xlink:type="simple" xlink:href="../801/16969801.xml">
Starbridge</link> <link xlink:type="simple" xlink:href="../789/544789.xml">
Viva</link> or <programming_language wordnetid="106898352" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../021/6021.xml">
C</link></programming_language>
-based languages like for example <language wordnetid="106282651" confidence="0.8">
<link xlink:type="simple" xlink:href="../144/4244144.xml">
Handel-C</link></language>
 from <link>
Celoxica</link>, <arrangement wordnetid="107938773" confidence="0.8">
<group wordnetid="100031264" confidence="0.8">
<array wordnetid="107939382" confidence="0.8">
<link xlink:type="simple" xlink:href="../148/9750148.xml">
DIME-C</link></array>
</group>
</arrangement>
 from <company wordnetid="108058098" confidence="0.8">
<institution wordnetid="108053576" confidence="0.8">
<link xlink:type="simple" xlink:href="../135/5892135.xml">
Nallatech</link></institution>
</company>
, <programming_language wordnetid="106898352" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../879/8715879.xml">
Impulse C</link></programming_language>
 from <company wordnetid="108058098" confidence="0.8">
<institution wordnetid="108053576" confidence="0.8">
<link xlink:type="simple" xlink:href="../370/8807370.xml">
Impulse Accelerated Technologies</link></institution>
</company>
 or <link>
Mitrion-C</link> from <company wordnetid="108058098" confidence="0.8">
<institution wordnetid="108053576" confidence="0.8">
<link xlink:type="simple" xlink:href="../153/11714153.xml">
Mitrionics</link></institution>
</company>
. </p>
<p>

In addition, <company wordnetid="108058098" confidence="0.8">
<institution wordnetid="108053576" confidence="0.8">
<link xlink:type="simple" xlink:href="../153/11714153.xml">
Mitrionics</link></institution>
</company>
 has developed a Software Acceleration Platform that enables software written using a single assignment language to be compiled and executed on FPGA-based computers, such as those from Cray and SGI. The <link>
Mitrion-C</link> software language and <link>
Mitrion Virtual Processor</link> enable software developers to write and execute applications on FPGA-based computers in the same manner as with other computing technologies, such as graphical processing units (“GPUs”), cell-based processors, parallel processing units (“PPUs”), multi-core CPUs, and traditional single-core CPU clusters. </p>
<p>

SRC has developed a <it>"Carte"</it> compiler that takes an existing high-level languages like <programming_language wordnetid="106898352" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../021/6021.xml">
C</link></programming_language>
 or <programming_language wordnetid="106898352" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../168/11168.xml">
Fortran</link></programming_language>
, and with a few modifications, compiles them for execution on both the FPGA and microprocessor. According to SRC literature, "...application algorithms are written in a high-level language such as C or Fortran. Carte extracts the maximum parallelism from the code and generates pipelined hardware logic that is instantiated in the MAP. It also generates all the required interface code to manage the movement of data to and from the MAP and to coordinate the microprocessor with the logic running in the MAP." (note that SRC also allows a traditional HDL flow to be used). The SRC systems communicate via the SNAP memory interface, and/or the (optional) Hi-Bar switch.</p>
<p>

The Research community is also acting on the subject with projects like MORPHEUS <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref> in Europe which implements on a single 100mm² 90nm chip an ARM9 processor, a M2000 FPGA, a DREAM picoGA and a PACT XPP matrix.</p>

</sec>
<sec>
<st>
 Comparison of systems </st>

<p>

As an emerging field, classifications of reconfigurable architectures are still being developed and refined as new architectures are developed; no unifying taxonomy has been suggested to date. However, several recurring parameters can be used to classify these systems.</p>

<ss1>
<st>
Granularity</st>

<p>

The granularity of the reconfigurable logic is defined as the size of the smallest functional unit (<link xlink:type="simple" xlink:href="../718/988718.xml">
CLB</link>) that is addressed by the mapping tools. Low granularity, which can also be known as fine-grained, often implies a greater flexibility when implementing algorithms into the hardware. However, there is a penalty associated with this in terms of increased power, area and delay due to greater quantity of routing required per computation. Fine-grained architectures work at the bit-level manipulation level; whilst coarse grained processing elements (<link xlink:type="simple" xlink:href="../371/188371.xml">
rDPU</link>) are better optimised for standard data path applications. One of the drawbacks of coarse grained architectures are that they tend to lose some of their utilisation and performance if they need to perform smaller computations than their granularity provides, for example for a one bit add on a four bit wide functional unit would waste three bits. This problem can be solved by having a coarse grain array  (<link xlink:type="simple" xlink:href="../714/2505714.xml">
rDPA</link>) and a <link xlink:type="simple" xlink:href="../814/592814.xml">
FPGA</link> on the same chip.</p>
<p>

Coarse-grained architectures (<link xlink:type="simple" xlink:href="../714/2505714.xml">
rDPA</link>) are intended for the implementation for algorithms needing word-width data paths (<link xlink:type="simple" xlink:href="../371/188371.xml">
rDPU</link>). As their functional blocks are optimized for large computations and typically comprise word wide ALUs. They will perform these operations more quickly and power efficiently than a smaller set of functional units connected together with some interconnect, this is due to the connecting wires are shorter, meaning less wire capacitance and hence faster and lower power designs. A potential undesirable consequence of having larger computational blocks is that when the size of operands may not match the algorithm an inefficient utilisation of resources can result. Often the type of applications to be run are known in advance allowing the logic, memory and routing resources to be tailored (for instance, see <link>
KressArray Xplorer</link>) to enhance the performance of the device whilst still providing a certain level of flexibility for future adaptation. Examples of this are domain specific arrays aimed at gaining better performance in terms of power, area, throughput than their more generic finer grained <link xlink:type="simple" xlink:href="../814/592814.xml">
FPGA</link> cousins by reducing their flexibility.</p>

</ss1>
<ss1>
<st>
Rate of reconfiguration</st>

<p>

Configuration of these reconfigurable systems can happen at deployment time, between execution phases or during execution. In a typical reconfigurable system, a bit stream is used to program the device at deployment time. Fine grained systems by their own nature requires greater configuration time than more coarse-grained architectures due to more elements needing to be addressed and programmed. Therefore more coarse-grained architectures gain from potential lower energy requirements, as less information is transferred and utilised. Intuitively, the slower the rate of reconfiguration the smaller the energy consumption as the associated energy cost of reconfiguration are amortised over a longer period of time. Partial reconfiguration aims to allow part of the device to be reprogrammed while another part is still performing active computation. Partial reconfiguration allows smaller reconfigurable bit streams thus not wasting energy on transmitting redundant information in the bit stream. Compression of the bit stream is possible but careful analysis is to be carried out to insure that the energy saved by using smaller bit streams is not outweighed by the computation needed to decompress the data.</p>

</ss1>
<ss1>
<st>
Host coupling</st>

<p>

Often the reconfigurable array is used as a processing accelerator attached to a host processor. The level of coupling determines the type of data transfers, latency, power, throughput and overheads involved when utilising the reconfigurable logic. Some of the most intuitive designs use a peripheral bus to provide a coprocessor like arrangement for the reconfigurable array. However, there have also been implementations where the reconfigurable fabric is much closer to the processor, some are even implemented into the data path, utilising the processor registers. The job of the host processor is to perform the control functions, configure the logic, schedule data and to provide external interfacing.</p>

</ss1>
<ss1>
<st>
Routing/interconnects</st>

<p>

The flexibility in reconfigurable devices mainly comes from their routing interconnect. One style of interconnect made popular by <link xlink:type="simple" xlink:href="../814/592814.xml">
FPGA</link>s vendors, Xilinx and Altera are the island style layout, where blocks are arranged in an array with vertical and horizontal routing. A layout with inadequate routing may suffer from poor flexibility and resource utilisation, therefore providing limited performance. If too much interconnect is provided this requires more transistors than necessary and thus more silicon area, longer wires and more power consumption.</p>

</ss1>
<ss1>
<st>
Tool flow</st>

<p>

Generally, tools for configurable computing systems can be split up in two parts, <link xlink:type="simple" xlink:href="../315/37315.xml">
CAD</link> tools for reconfigurable array and compilation tools for CPU. The front-end compiler is an integrated tool, and will generate a structural hardware representation that is input of hardware design flow. Hardware design flow for reconfigurable architecture can be classified by the approach adopted by three main stages of design process: technology mapping, placement algorithm and routing algorithm. The software frameworks differ in the level of the programming language.</p>
<p>

Some types of reconfigurable computers are microcoded processors where the <link xlink:type="simple" xlink:href="../999/19999.xml">
microcode</link> is stored in <link xlink:type="simple" xlink:href="../847/25847.xml">
RAM</link> or <link xlink:type="simple" xlink:href="../597/50597.xml">
EEPROM</link>, and changeable on <link>
reboot</link> or on the fly. This could be done with the <company wordnetid="108058098" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../ury/24th_century.xml">
AMD</link></company>
 2900 series <link xlink:type="simple" xlink:href="../466/3093466.xml">
bit slice processor</link>s (on reboot) and later with <arrangement wordnetid="107938773" confidence="0.8">
<group wordnetid="100031264" confidence="0.8">
<array wordnetid="107939382" confidence="0.8">
<link xlink:type="simple" xlink:href="../969/10969.xml">
FPGA</link></array>
</group>
</arrangement>
s (on the fly).</p>
<p>

Some <link xlink:type="simple" xlink:href="../364/864364.xml">
dataflow</link> processors are implemented using reconfigurable computing.</p>
<p>

To compare the effect of various ways to implement an algorithm on the runtime and energy used, some tools allow compiling the same piece of C code for a fixed CPU, a <link xlink:type="simple" xlink:href="../728/3828728.xml">
soft processor</link>, or compiling directly to FPGA <weblink xlink:type="simple" xlink:href="http://www.fpgajournal.com/articles/impulseC.htm">
http://www.fpgajournal.com/articles/impulseC.htm</weblink>.</p>

</ss1>
</sec>
<sec>
<st>
Reconfigurable computing as a paradigm shift: Hartenstein's anti machine </st>

<p>

<table align="right" class="wikitable">
<caption>
<it>Table 1: Nick Tredennick’s Paradigm Classification Scheme''</it></caption>
<row>
<col colspan="2" bgcolor="#BBBBFF">
<b>Early Historic Computers:</b></col>
</row>
<row>
<col bgcolor="#BBBBFF">
&nbsp;</col>
<header>
Programming Source</header>
</row>
<row>
<col>
Resources fixed</col>
<col>
none</col>
</row>
<row>
<col>
Algorithms fixed</col>
<col>
none</col>
</row>
<row>
<col colspan="2" bgcolor="#ffebad">
<b>von Neumann Computer:</b></col>
</row>
<row>
<col bgcolor="#ffebad">
&nbsp;</col>
<header>
Programming Source</header>
</row>
<row>
<col>
Resources fixed</col>
<col>
none</col>
</row>
<row>
<col>
Algorithms variable</col>
<col>
Software (instruction streams)</col>
</row>
<row>
<col colspan="2" bgcolor="#ffbbbb">
<b>Reconfigurable Computing Systems:</b></col>
</row>
<row>
<col bgcolor="#ffbbbb">
&nbsp;</col>
<header>
Programming Source</header>
</row>
<row>
<col>
Resources variable</col>
<col>
 <link xlink:type="simple" xlink:href="../184/2151184.xml">
Configware</link>(configuration)</col>
</row>
<row>
<col>
Algorithms variable</col>
<col>
 <link>
Flowware</link>(data streams)</col>
</row>
</table>
</p>
<p>

Computer scientist <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<pioneer wordnetid="110434725" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<originator wordnetid="110383816" confidence="0.8">
<creator wordnetid="109614315" confidence="0.8">
<link xlink:type="simple" xlink:href="../802/7581802.xml">
Reiner Hartenstein</link></creator>
</originator>
</scientist>
</causal_agent>
</pioneer>
</person>
</physical_entity>
 describes reconfigurable computing in terms of an <it><link xlink:type="simple" xlink:href="../340/10050340.xml">
anti machine</link></it> that, according to him, represents a fundamental paradigm shift away from the more conventional <link xlink:type="simple" xlink:href="../986/41986.xml">
von Neumann machine</link>
.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%227%22])">7</ref>  Hartenstein describes a <b>Reconfigurable Computing Paradox:</b>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%228%22])">8</ref>
Software to <link xlink:type="simple" xlink:href="../184/2151184.xml">
configware</link> migration (software to <link xlink:type="simple" xlink:href="../814/592814.xml">
FPGA</link> migration) results in reported speed-up factors of up to almost four orders of magnitude, as well as a reduction in electricity consumption by more than one order of magnitude---although the technological parameters of FPGA's are behind the Gordon Moore curve by about four orders of magnitude, and the clock frequency is substantially lower than that of microprocessors. This paradox is due to a paradigm shift, and is also partly explained by the <link xlink:type="simple" xlink:href="../667/7660667.xml">
Von Neumann syndrome</link>.</p>
<p>

The fundamental model of the reconfigurable computing machine paradigm, the data-stream-based <link xlink:type="simple" xlink:href="../340/10050340.xml">
anti machine</link> is well illustrated by the differences to other machine paradigms that were introduced earlier, as shown by <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<intellectual wordnetid="109621545" confidence="0.8">
<alumnus wordnetid="109786338" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<inventor wordnetid="110214637" confidence="0.8">
<scholar wordnetid="110557854" confidence="0.8">
<creator wordnetid="109614315" confidence="0.8">
<link xlink:type="simple" xlink:href="../190/7804190.xml">
Nick Tredennick</link></creator>
</scholar>
</inventor>
</causal_agent>
</alumnus>
</intellectual>
</person>
</physical_entity>
's following classification scheme of computing paradigms (see "Table 1: Nick Tredennick’s Paradigm Classification Scheme")
.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%229%22])">9</ref></p>
<p>

The fundamental model of a <link xlink:type="simple" xlink:href="../340/10050340.xml">
Reconfigurable Computing Machine</link>, the data-stream-based  <link xlink:type="simple" xlink:href="../340/10050340.xml">
 anti machine</link> (also called Xputer), is the counterpart of the instruction-stream-based <link xlink:type="simple" xlink:href="../986/41986.xml">
von Neumann machine</link> paradigm. This is illustrated by a simple reconfigurable system (not <link xlink:type="simple" xlink:href="../505/2238505.xml">
<it>dynamically</it> reconfigurable</link>), which has no instruction fetch at run time. The reconfiguration (before run time) can be considered as a kind of <it>super instruction fetch</it>. An anti machine does not have a program counter. The anti machine has data counters instead, since it is data-stream-driven. Here the definition of the term <it>data streams</it> is adopted from the <link xlink:type="simple" xlink:href="../517/351517.xml">
systolic array</link> scene, which defines, at which time which data item has to enter or leave which port, here of the reconfigurable system, which may be fine-grained (e. g. using FPGAs) or coarse-grained, or a mixture of both.</p>
<p>

The systolic array scene, originally (early 1980s) mainly mathematicians, only defined one half of the anti machine: the data path: the <link xlink:type="simple" xlink:href="../517/351517.xml">
Systolic array</link> (also see <link xlink:type="simple" xlink:href="../517/351517.xml">
Super Systolic Array</link>). But they did not define nor model the data sequencer methodology, considering that this is not their job to take care where the data streams come from or end up. The data sequencing part of the anti machine is modeled as distributed memory, preferably on chip, which consists of <link xlink:type="simple" xlink:href="../340/10050340.xml">
auto-sequencing memory</link> blocks (<link xlink:type="simple" xlink:href="../340/10050340.xml">
ASM</link> blocks). Each ASM block has a sequencer including a data counter. An example is the <link xlink:type="simple" xlink:href="../340/10050340.xml">
Generic Address Generator</link> (GAG), which is a generalization of the <link xlink:type="simple" xlink:href="../717/57717.xml">
DMA</link>.</p>

</sec>
<sec>
<st>
 References </st>

<p>

<reflist>
<entry id="1">
Estrin, G. 2002. 
Reconfigurable computer origins: the UCLA fixed-plus-variable (F+V) structure computer. 
<it>IEEE Ann. Hist. Comput.</it>
 24, 4 (Oct. 2002), 3–9. DOI=http://dx.doi.org/10.1109/MAHC.2002.1114865
</entry>
<entry id="2">
Estrin, G.,
"Organization of Computer Systems—The Fixed Plus Variable Structure Computer," 
<it>Proc. Western Joint Computer Conf.</it>, 
Western Joint Computer Conference, New York, 1960, pp. 33–40.
</entry>
<entry id="3">
Hauser, John R. and Wawrzynek, John,
"Garp: A MIPS Processor with a Reconfigurable Coprocessor,"
<it>Proceedings of the IEEE Symposium on Field-Programmable Custom Computing Machines</it>
(FCCM '97, April 16–18, 1997), pp. 24–33.
</entry>
<entry id="4">
<weblink xlink:type="simple" xlink:href="http://www.algotronix.com/people/tom/album.html">
Algotronix History</weblink></entry>
<entry id="5">
<weblink xlink:type="simple" xlink:href="http://www.sgi.com/products/rasc/">
RASC</weblink></entry>
<entry id="6">
<weblink xlink:type="simple" xlink:href="http://www.morpheus.arces.unibo.it/pages/int.htm">
MORPHEUS project home page</weblink></entry>
<entry id="7">
Hartenstein, R. 2001. 
A decade of reconfigurable computing: a visionary retrospective. 
In <it>Proceedings of the Conference on Design, Automation and Test in Europe (DATE 2001)</it> (Munich, Germany). 
W. Nebel and A. Jerraya, Eds. Design, Automation, and Test in Europe. 
IEEE Press, Piscataway, NJ, 642–649.
</entry>
<entry id="8">
Hartenstein, Reiner,
"RAW keynote 2: new horizons of very high performance computing (VHPC): hurdles and chances."
<it>Parallel and Distributed Processing Symposium, 2006. IPDPS 2006. 20th International</it>
Publication Date: 25–29 April 2006, p. 1.
ISBN 1-4244-0054-6
</entry>
<entry id="9">
N. Tredennick: The Case for Reconfigurable Computing; Microprocessor Report, Vol. 10 No. 10, 5 August 1996, pp 25–27.
</entry>
</reflist>
</p>

</sec>
<sec>
<st>
 References (not yet linked to text) </st>
<p>

<list>
<entry level="1" type="bullet">

 S. Hauck and A. DeHon, <it>Reconfigurable Computing: The Theory and Practice of FPGA-Based Computing</it>, Morgan Kaufman, 2008.</entry>
<entry level="1" type="bullet">

 J. Henkel, S. Parameswaran (editors): Designing Embedded Processors. A Low Power Perspective; Springer Verlag, March 2007</entry>
<entry level="1" type="bullet">

 J. Teich (editor) et al.: Reconfigurable Computing Systems. Special Topic Issue of Journal <it>it - Information Technology</it>, Oldenbourg Verlag, Munich. <weblink xlink:type="simple" xlink:href="http://www.atypon-link.com/OLD/toc/itit/49/3">
Vol. 49(2007) Issue 3</weblink></entry>
<entry level="1" type="bullet">

 T.J. Todman, G.A. Constantinides, S.J.E. Wilton, O. Mencer, W. Luk and P.Y.K. Cheung, "Reconfigurable Computing: Architectures and Design Methods", IEE Proceedings: Computer &amp; Digital Techniques, Vol. 152, No. 2, March 2005, pp. 193–208.</entry>
<entry level="1" type="bullet">

 A. Zomaya (editor): Handbook of Nature-Inspired and Innovative Computing: Integrating Classical Models with Emerging Technologies; Springer Verlag, 2006</entry>
</list>
</p>

</sec>
<sec>
<st>
See also</st>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../294/11421294.xml">
Reconfigurable computing terminology</link></entry>
<entry level="1" type="bullet">

 <creation wordnetid="103129123" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<remake wordnetid="104074329" confidence="0.8">
<link xlink:type="simple" xlink:href="../009/105009.xml">
Sprinter</link></remake>
</artifact>
</creation>
</entry>
<entry level="1" type="bullet">

 <computer wordnetid="103082979" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../664/8995664.xml">
1chipMSX</link></computer>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../773/4248773.xml">
PSoC</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../048/8861048.xml">
Stanford Smart Memories Project</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../481/7569481.xml">
PipeRench</link></entry>
</list>
</p>

</sec>
<sec>
<st>
External links</st>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://scale.engin.brown.edu/classes/EN2911XF07/">
Reconfigurable Computing Lectures and Tutorials at Brown University</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.ics.uci.edu/~dutt/ics212-wq05/hartenstein-recongtut-date01.pdf">
A Decade of Reconfigurable Computing: a Visionary Retrospective</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://pw1.netcom.com/~optmagic/reconfigure/fawcett.html">
Reconfigurable Computing: Coming of Age</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.ccm.ece.vt.edu/">
The Virginia Tech Configurable Computing Laboratory</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://rssi.ncsa.uiuc.edu/">
Reconfigurable Systems Summer Institute (RSSI)</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.fccm.org/">
IEEE Symposium on Field-Programmable Custom Computing Machines (FCCM)</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://fpl.org/">
International Conference on Field-Programmable Logic and Applications (FPL)</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.jhdl.org/">
BYU Configurable Computing Laboratory's FPGA CAD tool set</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://morphware.net/">
The Morphware Forum</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.chrec.org/">
NSF Center for High-Performance Reconfigurable Computing (CHREC)</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.openfpga.org/">
The OpenFPGA effort</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://helios.informatik.uni-kl.de/RCeducation/">
RC Education Workshop</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://xputers.informatik.uni-kl.de/raw/index_raw.html#raw_06">
Reconfigurable Architectures Workshop</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://hpcl.seas.gwu.edu/">
The George Washington University High Performance Computing Laboratory</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.hcs.ufl.edu/">
The University of Florida High-Performance Computing &amp; Simulation Research Laboratory</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.ittc.ku.edu/hybridthreads">
The University of Kansas Hybridthreads Project - OS for Hybrid CPU/FPGA chips</weblink> </entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.ece.wisc.edu/~kati/research.html">
Reconfigurable Computing Tools and O/S Support from the University of Wisconsin</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://cas.ee.ic.ac.uk">
Circuits and Systems Group, Imperial College London</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://isvlsi06.itiv.uni-karlsruhe.de/RCe-i1.pdf">
Why we need Reconfigurable Computing Education</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://proteas.ee.duth.gr">
The on-line version of the MEANDER FPGA Design Framework</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.fhpca.org/">
FHPCA: FPGA High Performance Computing Alliance</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.dresd.org/">
Website of the DRESD (Dynamic Reconfigurability in Embedded System Design) research project</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.stanford.edu/class/ee392c/">
Advanced Topics in Computer Architecture: Chip Multiprocessors &amp; Polymorphic Processors (2003)</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.cs.utexas.edu/users/cart/trips/">
UT Austin TRIPS multiprocessor</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://rcs.uncc.edu/wiki/index.php/Main_Page">
UNC Charlotte Reconfigurable Computing Cluster</weblink></entry>
</list>
</p>


</sec>
</bdy>
</article>
