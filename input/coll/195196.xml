<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 16:28:27[mciao0828] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Examples of Markov chains</title>
<id>195196</id>
<revision>
<id>225213750</id>
<timestamp>2008-07-12T14:24:10Z</timestamp>
<contributor>
<username>DragonBot</username>
<id>5466012</id>
</contributor>
</revision>
<categories>
<category>Stochastic processes</category>
</categories>
</header>
<bdy>

This page contains examples of <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../876/60876.xml">
Markov chain</link></causal_agent>
</worker>
</assistant>
</model>
</person>
</physical_entity>
s in action.
<sec>
<st>
 Board games played with dice </st>

<p>

A game of <link>
Monopoly</link>, <link xlink:type="simple" xlink:href="../372/38372.xml">
snakes and ladders</link> or any other game whose moves are determined entirely by <link xlink:type="simple" xlink:href="../244/8244.xml">
dice</link> is a Markov chain.  This is in contrast to card games such as poker or blackjack, where the cards represent a 'memory' of the past moves.  To see the difference, consider the probability for a certain event in the game.  In the above mentioned dice games, the only thing that matters is the current state of the board.  The next state of the board depends on the current state, and the next roll of the dice.  It doesn't depend on how things got to their current state.  In a game such as poker or blackjack, a player can gain an advantage by remembering which cards have already been shown (and hence which cards are no longer in the deck), so the next state (or hand) of the game is not independent of the past states.</p>

</sec>
<sec>
<st>
 A very simple weather model </st>

<p>

The probabilities of weather conditions, given the weather on the preceding day,
can be represented by a <link xlink:type="simple" xlink:href="../313/217313.xml">
transition matrix</link>:</p>
<p>

<indent level="1">

 <math>
    P = \begin{bmatrix}
        0.9 &amp; 0.1 \\
        0.5 &amp; 0.5
    \end{bmatrix}
</math>
</indent>
The matrix <it>P</it> represents the weather model in which a sunny day is 90%
likely to be followed by another sunny day, and a rainy day is 50% likely to
be followed by another rainy day.  The columns can be labelled "sunny" and
"rainy" respectively, and the rows can be labelled in the same order.  </p>
<p>

(<it>P</it>)<it>i j</it> is the probability that, if a given day is of type <it>i</it>, it will be
followed by a day of type <it>j</it>.</p>
<p>

Notice that the rows of <it>P</it> sum to 1: this is because <it>P</it> is a <link xlink:type="simple" xlink:href="../313/217313.xml">
stochastic matrix</link>.</p>

<ss1>
<st>
 Predicting the weather </st>

<p>

The weather on day 0 is known to be sunny.  This is represented by a vector in which the "sunny" entry is 100%, and the "rainy" entry is 0%:</p>
<p>

<indent level="1">

 <math>
    \mathbf{x}^{(0)} = \begin{bmatrix}
        1 &amp; 0
    \end{bmatrix}
</math>
</indent>

The weather on day 1 can be predicted by:</p>
<p>

<indent level="1">

 <math>
    \mathbf{x}^{(1)} = \mathbf{x}^{(0)} P  = 
    \begin{bmatrix}
        1 &amp; 0
    \end{bmatrix}
    \begin{bmatrix}
        0.9 &amp; 0.1 \\
        0.5 &amp; 0.5
    \end{bmatrix}
    
    = \begin{bmatrix}
        0.9 &amp; 0.1
    \end{bmatrix} 
</math>
</indent>

Thus, there is an 90% chance that day 1 will also be sunny.</p>
<p>

The weather on day 2 can be predicted in the same way:</p>
<p>

<indent level="1">

 <math>
    \mathbf{x}^{(2)} =\mathbf{x}^{(1)} P  = \mathbf{x}^{(0)} P^2 
    = \begin{bmatrix}
        1 &amp; 0
    \end{bmatrix}
    \begin{bmatrix}
        0.9 &amp; 0.1 \\
        0.5 &amp; 0.5
    \end{bmatrix}^2
    
    = \begin{bmatrix}
        0.86 &amp; 0.14
    \end{bmatrix} 
</math>
</indent>
or
<indent level="1">

 <math>
    \mathbf{x}^{(2)} =\mathbf{x}^{(1)} P 
    = \begin{bmatrix}
        0.9 &amp; 0.1
    \end{bmatrix}
    \begin{bmatrix}
        0.9 &amp; 0.1 \\
        0.5 &amp; 0.5
    \end{bmatrix}
    
    = \begin{bmatrix}
        0.86 &amp; 0.14
    \end{bmatrix} 
</math>
</indent>

General rules for day <it>n</it> are:</p>
<p>

<indent level="1">

 <math>
    \mathbf{x}^{(n)} = \mathbf{x}^{(n-1)} P 
</math>
</indent>

<indent level="1">

 <math>
    \mathbf{x}^{(n)} = \mathbf{x}^{(0)} P^n 
</math>
</indent>

</p>
</ss1>
<ss1>
<st>
 Steady state of the weather </st>

<p>

In this example, predictions for the weather on more distant days are increasingly
inaccurate and tend towards a <link>
steady state vector</link>.  This vector represents
the probabilities of sunny and rainy weather on all days, and is independent
of the initial weather.</p>
<p>

The steady state vector is defined as:</p>
<p>

<math>
    \mathbf{q} = \lim_{n \to \infty} \mathbf{x}^{(n)}
</math></p>
<p>

but only converges to a strictly positive vector if <it>P</it> is a <link xlink:type="simple" xlink:href="../122/217122.xml">
regular</link> transition matrix (that is, there
is at least one <it>Pn</it> with all non-zero entries).</p>
<p>

Since the <b>q</b> is independent from initial conditions, it must be unchanged when transformed by <it>P</it>.  This makes it an <link xlink:type="simple" xlink:href="../429/2161429.xml">
eigenvector</link> (with <link xlink:type="simple" xlink:href="../429/2161429.xml">
eigenvalue</link> 1), and means it can be derived from <it>P</it>.  For the weather example:</p>
<p>

<math>
    \begin{matrix}
        P &amp; = &amp; \begin{bmatrix}
            0.9 &amp; 0.1 \\
            0.5 &amp; 0.5
        \end{bmatrix}
        \\
       \mathbf{q} P  &amp; = &amp; \mathbf{q}
        &amp; \mbox{(} \mathbf{q} \mbox{ is unchanged by } P \mbox{.)}
        \\
        &amp; = &amp; \mathbf{q}I 
        \\
       \mathbf{q} (P - I)  &amp; = &amp; \mathbf{0} \\
        &amp; = &amp; \mathbf{q} \left( \begin{bmatrix}
            0.9 &amp; 0.1 \\
            0.5 &amp; 0.5
        \end{bmatrix}
        -
        \begin{bmatrix}
            1 &amp; 0 \\
            0 &amp; 1
        \end{bmatrix}
        \right) 
        \\
        &amp; = &amp; \mathbf{q} \begin{bmatrix}
            -0.1 &amp; 0.1 \\
            0.5 &amp; -0.5
        \end{bmatrix} 
    \end{matrix}
</math>
<math>
     \begin{bmatrix}
        q_1 &amp; q_2
    \end{bmatrix}
    \begin{bmatrix}
        -0.1 &amp; 0.1 \\
        0.5 &amp; -0.5
    \end{bmatrix}
    = \begin{bmatrix}
        0 &amp; 0
    \end{bmatrix}
</math></p>

<p>

So 
<math>
    -0.1 q_1 + 0.5 q_2 = 0
</math>
and since they are a probability vector we know that 
<math>
q_1 + q_2 = 1.
</math></p>
<p>

Solving this pair of simultaneous equations gives the steady state distribution:</p>
<p>

<math>
    \begin{bmatrix}
        q_1 &amp; q_2
    \end{bmatrix}
    = \begin{bmatrix}
        0.833 &amp; 0.167
    \end{bmatrix}
</math></p>
<p>

In conclusion, in the long term, 83% of days are sunny.</p>

</ss1>
</sec>
<sec>
<st>
 Citation ranking </st>

<p>

<company wordnetid="108058098" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../923/1092923.xml">
Google</link></company>
's page rank algorithm is essentially a Markov chain over the graph of
the Internet.  More information can be found in <weblink xlink:type="simple" xlink:href="http://citeseer.ist.psu.edu/page98pagerank.html">
"The PageRank Citation Ranking: Bringing Order to the Web"</weblink>
by Larry Page, Sergey Brin, R. Motwani, and T. Winograd.</p>

</sec>
<sec>
<st>
 References </st>
<p>


</p>


</sec>
<sec>
<st>
See also</st>
<p>

<list>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../091/174091.xml">
Mark V. Shaney</link></entry>
</list>
</p>

</sec>
<sec>
<st>
 External links </st>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.bewersdorff-online.de/amonopoly/">
Monopoly as a Markov chain</weblink></entry>
</list>
</p>

</sec>
</bdy>
</article>
