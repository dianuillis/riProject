<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 16:30:05[mciao0827] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<work  confidence="0.8" wordnetid="100575741">
<examination  confidence="0.8" wordnetid="100635850">
<event  confidence="0.8" wordnetid="100029378">
<survey  confidence="0.8" wordnetid="100644503">
<investigation  confidence="0.8" wordnetid="100633864">
<act  confidence="0.8" wordnetid="100030358">
<psychological_feature  confidence="0.8" wordnetid="100023100">
<activity  confidence="0.8" wordnetid="100407535">
<header>
<title>Artificial consciousness</title>
<id>195552</id>
<revision>
<id>237903309</id>
<timestamp>2008-09-12T09:55:28Z</timestamp>
<contributor>
<username>Richwil</username>
<id>3658486</id>
</contributor>
</revision>
<categories>
<category>Consciousness studies</category>
<category>Miscellaneous articles needing expert attention</category>
<category>All pages needing cleanup</category>
<category>Wikipedia articles needing style editing from December 2007</category>
<category>Artificial intelligence</category>
<category>Articles to be expanded since January 2007</category>
<category>All articles needing style editing</category>
<category>Articles that may contain original research since September 2007</category>
<category>Philosophy articles needing expert attention</category>
<category>Philosophy of mind</category>
<category>Wikipedia articles with off-topic sections</category>
<category>Articles needing expert attention</category>
<category>Cleanup from November 2007</category>
<category>All articles that may contain original research</category>
<category>Articles with invalid date parameter in template</category>
<category>Wikipedia articles needing style editing from November 2007</category>
<category>All articles to be expanded</category>
<category>Pages needing expert attention</category>
</categories>
</header>
<bdy>
<p>

<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-content" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="40x40px" src="Ambox_content.png">
</image>
</p>
</col>
<col style="" class="mbox-text">
 <b>This article or section is in need of attention from an expert on the subject.</b><p>

  may be able to help recruit one.
If a more appropriate  or 
portalexists, please adjust this template accordingly.</p>
</col>
</row>
</table>

</p>

<p>

<indent level="1">

<it>See also: <link xlink:type="simple" xlink:href="../357/586357.xml">
strong AI</link></it>
</indent>
<b>Artificial consciousness</b> (AC), also known as <b>machine consciousness</b> (MC) or <b>synthetic consciousness</b>, is a field related to <link xlink:type="simple" xlink:href="../164/1164.xml">
artificial intelligence</link> and <link xlink:type="simple" xlink:href="../910/2934910.xml">
cognitive robotics</link> whose aim is to define that which would have to be synthesized were consciousness to be found in an engineered artifact.  <cite class="inline">(<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFAleksander1995%22])">
Aleksander 1995</link>)</cite></p>
<p>

<link xlink:type="simple" xlink:href="../245/21245.xml">
Neuroscience</link> hypothesizes that consciousness is generated by the interoperation of various parts of the <link xlink:type="simple" xlink:href="../717/3717.xml">
brain</link>, called the <link xlink:type="simple" xlink:href="../264/18345264.xml">
neural correlates of consciousness</link> or NCC. Proponents of AC believe <link xlink:type="simple" xlink:href="../457/7878457.xml">
computer</link>s can emulate this interoperation, which is not yet fully understood.</p>

<sec>
<st>
 The nature of consciousness </st>

<p>

<indent level="1">

<it>Main article: <link xlink:type="simple" xlink:href="../664/5664.xml">
Consciousness</link></it>
</indent>
</p>
<p>

<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-style" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="40x40px" src="Ambox_style.png">
</image>
</p>
</col>
<col style="" class="mbox-text">
 <b>This section or article contains too much  and may need simplification or further explanation.</b><p>

Please discuss this issue on the , and/or remove or explain jargon terms used in the article. is available. <it>(November 2007)''</it></p>
</col>
</row>
</table>

</p>
<p>

According to <link>
naïve realism</link> and <link xlink:type="simple" xlink:href="../889/7889.xml">
direct realism</link>, humans perceive directly while brains perform processing.  According to <link xlink:type="simple" xlink:href="../052/613052.xml">
indirect realism</link> and <link xlink:type="simple" xlink:href="../135/8135.xml">
dualism</link>, brains contain data obtained by processing but what people perceive is a mental model or state appearing to overlay physical things as a result of projective geometry (such as the point observation in <link>
René Descartes</link>' dualism). Which of these approaches to consciousness is correct is fiercely debated.</p>
<p>

Direct perception problematically requires a new physical theory allowing conscious experience to <link xlink:type="simple" xlink:href="../990/350990.xml">
supervene</link> directly on the world outside the brain.  But if people perceive indirectly through a world model in the brain, then a new physical phenomenon, other than the endless further flow of data, would be needed to explain how the model becomes experience.</p>
<p>

If people perceive directly, <link xlink:type="simple" xlink:href="../247/422247.xml">
self-awareness</link> is difficult to explain because one of the principal reasons for proposing direct perception is to avoid <argument wordnetid="106648724" confidence="0.8">
<indication wordnetid="106797169" confidence="0.8">
<evidence wordnetid="106643408" confidence="0.8">
<link xlink:type="simple" xlink:href="../836/1013836.xml">
Ryle's regress</link></evidence>
</indication>
</argument>
 where internal processing <link xlink:type="simple" xlink:href="../407/25407.xml">
recurses</link> infinitely.  Direct perception also demands that one cannot really be aware of dreams, imagination, mental images or any inner life because these would involve recursion.  </p>
<p>

Self awareness is less problematic for entities that perceive indirectly because, by definition, they are perceiving their own state. However, as mentioned above, proponents of indirect perception must suggest some phenomenon, either physical or dualist to prevent Ryle's regress.  If people perceive indirectly then self awareness might result from the extension of experience in time described by <person wordnetid="100007846" confidence="0.9508927676800064">
<philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../631/14631.xml">
Immanuel Kant</link></philosopher>
</person>
, <philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../682/90682.xml">
William James</link></philosopher>
 and Descartes.  Unfortunately this extension in time may not be consistent with our current understanding of physics.</p>

</sec>
<sec>
<st>
 Information processing and consciousness </st>



<p>

<link xlink:type="simple" xlink:href="../578/315578.xml">
Information processing</link> consists of encoding a state, such as the geometry of an image, on a carrier such as a stream of electrons, and then submitting this encoded state to a series of transformations specified by a set of instructions called a <link xlink:type="simple" xlink:href="../783/5783.xml">
program</link>.  In principle the carrier could be anything, even steel balls or onions, and the machine that implements the instructions need not be electronic, it could be mechanical or fluidic.</p>
<p>

Digital computers implement information processing. From the earliest days of digital computers people have suggested that these devices may one day be conscious.  One of the earliest workers to consider this idea seriously was <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../208/1208.xml">
Alan Turing</link></scientist>
</person>
.</p>
<p>

If technologists were limited to the use of the principles of digital computing when creating a conscious entity they would have the problems associated with the philosophy of <link xlink:type="simple" xlink:href="../357/586357.xml">
strong AI</link>. The most serious problem is <philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../079/147079.xml">
John Searle</link></philosopher>
's controversial <work wordnetid="100575741" confidence="0.8">
<argument wordnetid="106648724" confidence="0.8">
<scientific_research wordnetid="100641820" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<indication wordnetid="106797169" confidence="0.8">
<experiment wordnetid="100639556" confidence="0.8">
<evidence wordnetid="106643408" confidence="0.8">
<investigation wordnetid="100633864" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<research wordnetid="100636921" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<link xlink:type="simple" xlink:href="../216/6216.xml">
Chinese room</link></activity>
</psychological_feature>
</research>
</act>
</investigation>
</evidence>
</experiment>
</indication>
</event>
</scientific_research>
</argument>
</work>
 argument which seeks to demonstrate that the act of computation does not necessarily produce a conscious experience of understanding.</p>
<p>

Searle's objection does not convince everybody. Direct perception proponents maintain that 'meaning' is only to be found in objects of perception. Many philosophers have abandoned <it>intrinsic</it> meaning for
<link xlink:type="simple" xlink:href="../741/17741.xml">
Wittgenstein</link>ian approaches, <link xlink:type="simple" xlink:href="../043/910043.xml">
conceptual role semantics</link>, and so on. The objection is also countered by the concept of <it><link xlink:type="simple" xlink:href="../828/1710828.xml">
strong emergentism</link></it> which proposes some unspecified new physical phenomenon arises from processor complexity.</p>
<p>

The debate about whether a machine could be conscious under any circumstances is usually described as the conflict between <link xlink:type="simple" xlink:href="../479/23479.xml">
physicalism</link> and <link xlink:type="simple" xlink:href="../135/8135.xml">
dualism</link>.  Dualists believe that there is something non-physical about consciousness whilst physicalists hold that all things are physical.</p>

</sec>
<sec>
<st>
Consciousness in digital computers</st>

<p>

There are various aspects of consciousness generally deemed necessary for a machine to be artificially conscious. A variety of functions in which consciousness plays a role were suggested by <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<biologist wordnetid="109855630" confidence="0.8">
<neurobiologist wordnetid="110353928" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<neuroscientist wordnetid="110354580" confidence="0.8">
<link xlink:type="simple" xlink:href="../116/1176116.xml">
Bernard Baars</link></neuroscientist>
</scientist>
</causal_agent>
</neurobiologist>
</biologist>
</person>
</physical_entity>
. The aim of AC is to define whether and how these and other aspects of consciousness can be synthesized in an engineered artefact such as digital computer. This list is not exhaustive; there are many others not covered.</p>
<p>

<list>
<entry level="1" type="definition">

Awareness</entry>
</list>
</p>
<p>

<link xlink:type="simple" xlink:href="../696/491696.xml">
Awareness</link> could be one required aspect, but there are many problems with the exact definition of <it>awareness</it>.  The results of the experiments of neuroscanning on monkeys suggest that a process, not a state or object activates neurons <weblink xlink:type="simple" xlink:href="http://www-inst.eecs.berkeley.edu/~cs182/readings/ns/article.html">
http://www-inst.eecs.berkeley.edu/~cs182/readings/ns/article.html</weblink>. For such reaction there must be created a model of the process based on the information received through the senses in such a way demands a lot of flexibility, and is also useful for making predictions.</p>
<p>

<list>
<entry level="1" type="definition">

Learning</entry>
</list>
</p>
<p>

Learning is also considered necessary for AC. An interesting article about learning is Implicit learning and consciousness <weblink xlink:type="simple" xlink:href="http://srsc.ulb.ac.be/axcWWW/papers/pdf/01-AXCLJ.pdf">
http://srsc.ulb.ac.be/axcWWW/papers/pdf/01-AXCLJ.pdf</weblink> by <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<research_worker wordnetid="110523076" confidence="0.8">
<link xlink:type="simple" xlink:href="../234/9125234.xml">
Axel Cleeremans</link></research_worker>
</scientist>
</causal_agent>
</person>
</physical_entity>
, University of Brussels and Luis Jiménez, University of Santiago, where learning is defined as “a set of philogenetically [''sic''] advanced adaptation processes that critically depend on an evolved sensitivity to subjective experience so as to enable agents to afford flexible control over their actions in complex, unpredictable environments”</p>
<p>

<list>
<entry level="1" type="definition">

Anticipation</entry>
</list>
</p>
<p>

The ability to predict (or anticipate) foreseeable events is considered important for AC by <physical_entity wordnetid="100001930" confidence="0.8">
<peer wordnetid="109626238" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<colleague wordnetid="109935990" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<academician wordnetid="109759069" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<adult wordnetid="109605289" confidence="0.8">
<professional wordnetid="110480253" confidence="0.8">
<research_worker wordnetid="110523076" confidence="0.8">
<educator wordnetid="110045713" confidence="0.8">
<associate wordnetid="109816771" confidence="0.8">
<link xlink:type="simple" xlink:href="../583/632583.xml">
Igor Aleksander</link></associate>
</educator>
</research_worker>
</professional>
</adult>
</scientist>
</academician>
</causal_agent>
</colleague>
</person>
</peer>
</physical_entity>
. The emergentist <work wordnetid="100575741" confidence="0.8">
<examination wordnetid="100635850" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<survey wordnetid="100644503" confidence="0.8">
<investigation wordnetid="100633864" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<link xlink:type="simple" xlink:href="../103/795103.xml">
multiple drafts principle</link></activity>
</psychological_feature>
</act>
</investigation>
</survey>
</event>
</examination>
</work>
 proposed by <person wordnetid="100007846" confidence="0.9508927676800064">
<philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../756/8756.xml">
Daniel Dennett</link></philosopher>
</person>
 in <it><book wordnetid="106410904" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../212/157212.xml">
Consciousness Explained</link></book>
</it> may be useful for prediction:  It involves the evaluation and selection of the most appropriate "draft" to fit the current environment.</p>
<p>

Anticipation is a characteristic that could possibly be used to make a machine appear conscious. An artificially conscious machine should be able to anticipate events correctly in order to be ready to respond to them when they occur. The implication here is that the machine needs real-time components, making it possible to demonstrate that it possesses artificial consciousness in the present and not just in the past. In order to do this, the machine being tested must operate coherently in an unpredictable environment, to simulate the real world.</p>
<p>

<list>
<entry level="1" type="definition">

Subjective experience</entry>
</list>
</p>
<p>

Subjective experience or <link xlink:type="simple" xlink:href="../965/165965.xml">
qualia</link> is widely considered to be <it>the</it> <link xlink:type="simple" xlink:href="../216/634216.xml">
hard problem of consciousness</link>. Indeed, it is held to pose a challenge to <link xlink:type="simple" xlink:href="../479/23479.xml">
physicalism</link>, let alone <link xlink:type="simple" xlink:href="../220/3951220.xml">
computationalism</link>.</p>

</sec>
<sec>
<st>
Schools of thought</st>
<p>

There are several commonly stated views regarding the plausibility and capability of AC, and the likelihood that AC will ever be real consciousness.  Some say the thermostat is really conscious, but they do not claim the thermostat is capable of an <weblink xlink:type="simple" xlink:href="http://www.newscientist.com/news/news.jsp?id=ns99994845">
appreciation of music</weblink>. In an interview <weblink xlink:type="simple" xlink:href="http://www.users.bigpond.com/nedthefish/chalmers1.htm">
http://www.users.bigpond.com/nedthefish/chalmers1.htm</weblink> Chalmers called his statement that thermostat is conscious "very speculative" and he is not a keen proponent of <link xlink:type="simple" xlink:href="../095/593095.xml">
panpsychism</link>.  <cite class="inline">(<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFChalmers1996%22])">
Chalmers 1996</link>, p.&nbsp;298)</cite> Interpretations like that are possible because of deliberately loose definitions, but tend to be too restrictive to have any significant intellectual value.</p>
<p>

Artificial Consciousness must not be as genuine as <link xlink:type="simple" xlink:href="../357/586357.xml">
Strong AI</link>, it must be as objective as the <link xlink:type="simple" xlink:href="../833/26833.xml">
scientific method</link> demands and capable of achieving known objectively observable abilities of consciousness, except subjective experience, which  by <philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../793/192793.xml">
Thomas Nagel</link></philosopher>
 cannot be objectively observed.</p>
<p>

<list>
<entry level="1" type="definition">

 Nihilistic view</entry>
</list>
</p>
<p>

It is impossible to test if anything is conscious. To ask a thermometer to appreciate music is like asking a human to think in five dimensions. It is unnecessary for humans to think in five dimensions, as much as it is irrelevant for thermometers to understand music. According to the nihilistic view, consciousness is just a word attributed to things that appear to make their own choices and perhaps things that are too complex for our mind to comprehend. Things seem to be conscious, but that is just because our ethical attitudes require a conscious-not conscious distinction, or because of our <link xlink:type="simple" xlink:href="../319/302319.xml">
empathy</link> with other entities. Consciousness is an optional perspective or <link xlink:type="simple" xlink:href="../818/163818.xml">
social construct</link>. (Compare with <person wordnetid="100007846" confidence="0.9508927676800064">
<philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../756/8756.xml">
Daniel Dennett</link></philosopher>
</person>
's "<link xlink:type="simple" xlink:href="../561/1664561.xml">
intentional stance</link>", and <link xlink:type="simple" xlink:href="../945/350945.xml">
eliminativism</link>).</p>

<ss1>
<st>
Artificial consciousness as a field of study</st>
<p>

Artificial consciousness includes <link xlink:type="simple" xlink:href="../524/25524.xml">
research</link> aiming to create and study artificially conscious systems in order to understand corresponding natural mechanisms.</p>
<p>

The term "artificial consciousness" was used by several scientists including <physical_entity wordnetid="100001930" confidence="0.8">
<peer wordnetid="109626238" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<colleague wordnetid="109935990" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<academician wordnetid="109759069" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<adult wordnetid="109605289" confidence="0.8">
<professional wordnetid="110480253" confidence="0.8">
<research_worker wordnetid="110523076" confidence="0.8">
<educator wordnetid="110045713" confidence="0.8">
<associate wordnetid="109816771" confidence="0.8">
<link xlink:type="simple" xlink:href="../583/632583.xml">
Professor Igor Aleksander</link></associate>
</educator>
</research_worker>
</professional>
</adult>
</scientist>
</academician>
</causal_agent>
</colleague>
</person>
</peer>
</physical_entity>
, a faculty member at the <link xlink:type="simple" xlink:href="../116/61116.xml">
Imperial College</link> in <village wordnetid="108672738" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../867/17867.xml">
London</link></village>
, <country wordnetid="108544813" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../316/9316.xml">
England</link></country>
, who stated in his book <it>Impossible Minds</it> that the principles for creating a conscious machine already existed but that it would take forty years to train such a machine to understand <link xlink:type="simple" xlink:href="../524/17524.xml">
language</link>.  Understanding a language does not mean understand the language you are using.  Dogs may understand up to 200 words, but may not be able to demonstrate to everyone that they can do so.</p>
<p>

At this time analog holographic sentience modeled after humans is more likely to be a successful approach.&#91;&#93;</p>

</ss1>
</sec>
<sec>
<st>
Practical approaches</st>
<p>

AC research has moved beyond the realm of philosophy; several serious attempts are underway to instill consciousness in machines. four of these are described below.</p>

<ss1>
<st>
Franklin’s Intelligent Distribution Agent</st>
<p>

<physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<academician wordnetid="109759069" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<adult wordnetid="109605289" confidence="0.8">
<professional wordnetid="110480253" confidence="0.8">
<research_worker wordnetid="110523076" confidence="0.8">
<educator wordnetid="110045713" confidence="0.8">
<link xlink:type="simple" xlink:href="../705/1456705.xml">
Stan Franklin</link></educator>
</research_worker>
</professional>
</adult>
</scientist>
</academician>
</causal_agent>
</person>
</physical_entity>
 (1995, 2003) defines an <link xlink:type="simple" xlink:href="../626/1456626.xml">
autonomous agent</link> as possessing <link xlink:type="simple" xlink:href="../664/5664.xml">
functional consciousness</link> when it is capable of several of the functions of consciousness as identified by <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<biologist wordnetid="109855630" confidence="0.8">
<neurobiologist wordnetid="110353928" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<neuroscientist wordnetid="110354580" confidence="0.8">
<link xlink:type="simple" xlink:href="../116/1176116.xml">
Bernard Baars</link></neuroscientist>
</scientist>
</causal_agent>
</neurobiologist>
</biologist>
</person>
</physical_entity>
’ <work wordnetid="100575741" confidence="0.8">
<examination wordnetid="100635850" confidence="0.8">
<explanation wordnetid="105793000" confidence="0.8">
<theory wordnetid="105989479" confidence="0.8">
<process wordnetid="105701363" confidence="0.8">
<thinking wordnetid="105770926" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<survey wordnetid="100644503" confidence="0.8">
<investigation wordnetid="100633864" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<higher_cognitive_process wordnetid="105770664" confidence="0.8">
<link xlink:type="simple" xlink:href="../765/1456765.xml">
Global Workspace Theory</link></higher_cognitive_process>
</activity>
</psychological_feature>
</act>
</investigation>
</survey>
</event>
</thinking>
</process>
</theory>
</explanation>
</examination>
</work>
  <cite class="inline">(<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFBaars1988%22])">
Baars 1988</link>)</cite>,  <cite class="inline">(<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFBaars1997%22])">
Baars 1997</link>)</cite>. His brain child IDA (Intelligent Distribution Agent) is a software implementation of GWT, which makes it functionally conscious by definition. IDA’s task is to negotiate new assignments for sailors in the US Navy after they end a tour of duty, by matching each individual’s skills and preferences with the Navy’s needs. IDA interacts with Navy databases and communicates with the sailors via natural language email dialog while obeying a large set of Navy policies. The IDA computational model was developed during 1996-2001 at Stan Franklin’s "Conscious" Software Research Group at the <weblink xlink:type="simple" xlink:href="http://www.memphis.edu/">
University of Memphis</weblink>. It "consists of approximately a quarter-million lines of <message wordnetid="106598915" confidence="0.8">
<request wordnetid="106513366" confidence="0.8">
<link xlink:type="simple" xlink:href="../881/15881.xml">
Java</link></request>
</message>
 code, and almost completely consumes the resources of a 2001 high-end workstation." It relies heavily on <it>codelets</it>, which are "special purpose, relatively independent, mini-agent[s] typically implemented as a small piece of code running as a separate thread." In IDA’s top-down architecture, high-level cognitive functions are explicitly modeled; see <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFFranklin1995%22])">
Franklin (1995)</link> and <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFFranklin2003%22])">
Franklin (2003)</link> for details. While IDA is functionally conscious by definition, Franklin does “not attribute <link xlink:type="simple" xlink:href="../664/5664.xml">
phenomenal consciousness</link> to his own 'conscious' software agent, IDA, in spite of her many human-like behaviours. This in spite of watching several US Navy detailers repeatedly nodding their heads saying 'Yes, that’s how I do it' while watching IDA’s internal and external actions as she performs her task."</p>

</ss1>
<ss1>
<st>
Ron Sun's cognitive architecture CLARION</st>

<p>

<link xlink:type="simple" xlink:href="../938/13550938.xml">
CLARION</link> posits a two-level representation that explains the distinction between conscious and unconscious mental processes.</p>
<p>

<link xlink:type="simple" xlink:href="../938/13550938.xml">
CLARION</link> has been successful in accounting for a variety of psychological data. A number of well-known skill learning tasks have been simulated using CLARION that span the spectrum ranging from simple reactive skills to complex cognitive skills. The tasks include serial reaction time (SRT) tasks, artificial grammar learning (AGL) tasks, process control (PC) tasks, the categorical inference (CI) task, the alphabetical arithmetic (AA) task, and the Tower of Hanoi (TOH) task  <cite class="inline">(<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFSun2002%22])">
Sun 2002</link>)</cite>. Among them, SRT, AGL, and PC are typical implicit learning tasks, very much relevant to the issue of consciousness as they operationalized the notion of consciousness in the context of psychological experiments .</p>
<p>

The simulations using CLARION provide detailed, process-based interpretations of experimental data related to consciousness, in the context of a broadly scoped cognitive architecture and a unified theory of cognition. Such interpretations are important for a precise, process-based understanding of consciousness and other aspects of cognition, leading up to better appreciations of the role of consciousness in human cognition  <cite class="inline">(<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFSun1999%22])">
Sun 1999</link>)</cite>. CLARION also makes quantitative and qualitative predictions regarding cognition in the areas of memory, learning, motivation, meta-cognition, and so on. These predictions either have been experimentally tested already or are in the process of being tested.</p>

</ss1>
<ss1>
<st>
Haikonen’s cognitive architecture</st>
<p>

Pentti <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFHaikonen2003%22])">
Haikonen (2003)</link> considers classical rule-based computing inadequate for achieving AC: "the brain is definitely not a computer. Thinking is not an execution of programmed strings of commands. The brain is not a numerical calculator either. We do not think by numbers." Rather than trying to achieve <link xlink:type="simple" xlink:href="../378/19378.xml">
mind</link> and <link xlink:type="simple" xlink:href="../664/5664.xml">
consciousness</link> by identifying and implementing their underlying computational rules, Haikonen proposes "a special <link xlink:type="simple" xlink:href="../176/1700176.xml">
cognitive architecture</link> to reproduce the <link xlink:type="simple" xlink:href="../766/4746766.xml">
processes</link> of <link xlink:type="simple" xlink:href="../140/25140.xml">
perception</link>, <link>
inner imagery</link>, <link>
inner speech</link>, <link xlink:type="simple" xlink:href="../373/24373.xml">
pain</link>, <link xlink:type="simple" xlink:href="../407/169407.xml">
pleasure</link>, <link xlink:type="simple" xlink:href="../406/10406.xml">
emotions</link> and the <link xlink:type="simple" xlink:href="../238/106238.xml">
cognitive</link> functions behind these. This bottom-up architecture would produce higher-level functions by the power of the elementary processing units, the <link xlink:type="simple" xlink:href="../771/349771.xml">
artificial neuron</link>s, without <link xlink:type="simple" xlink:href="../775/775.xml">
algorithms</link> or <link xlink:type="simple" xlink:href="../783/5783.xml">
programs</link>". Haikonen believes that, when implemented with sufficient complexity, this architecture will develop consciousness, which he considers to be "a style and way of operation, characterized by distributed signal representation, perception process, cross-modality reporting and availability for retrospection." Haikonen is not alone in this process view of consciousness, or the view that AC will spontaneously emerge in <link xlink:type="simple" xlink:href="../626/1456626.xml">
autonomous agent</link>s that have a suitable neuro-inspired architecture of complexity; these are shared by many, e.g. <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFFreeman1999%22])">
Freeman (1999)</link> and <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCotterill2003%22])">
Cotterill (2003)</link>. A low-complexity implementation of the architecture proposed by <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFHaikonen2004%22])">
Haikonen (2004)</link> was reportedly not capable of AC, but did exhibit emotions as expected.</p>

</ss1>
<ss1>
<st>
Takeno's self-awareness research</st>
<p>

Self-awareness in robots is being investigated by Junichi Takeno <weblink xlink:type="simple" xlink:href="http://robonable.typepad.jp/robot/2_/index.html">
http://robonable.typepad.jp/robot/2_/index.html</weblink> at <university wordnetid="108286163" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../989/1605989.xml">
Meiji University</link></university>
 in Japan. Takeno is asserting that he has developed a robot capable of discriminating between a self-image in a mirror and any other having an identical image to it<weblink xlink:type="simple" xlink:href="http://www.rs.cs.meiji.ac.jp/Takeno_Archive/DiscoveryNewsAwareRobot211205.pdf">
http://www.rs.cs.meiji.ac.jp/Takeno_Archive/DiscoveryNewsAwareRobot211205.pdf</weblink><weblink xlink:type="simple" xlink:href="http://www.mimed.mw.tum.de/06-12-18_MIMED_LUETH-002918.PDF">
http://www.mimed.mw.tum.de/06-12-18_MIMED_LUETH-002918.PDF</weblink>, and this claim has been already reviewed.  <cite class="inline">(<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFTakenoInabaSuzuki2005%22])">
Takeno, Inaba &amp; Suzuki 2005</link>)</cite></p>

</ss1>
</sec>
<sec>
<st>
Testing for artificial consciousness</st>


<p>

<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-style" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="40x40px" src="Ambox_style.png">
</image>
</p>
</col>
<col style="" class="mbox-text">
 <b>This article or section may contain too much repetition.</b>
Please help <weblink xlink:type="simple" xlink:href="http://localhost:18088/wiki/index.php?title=Artificial_consciousness&amp;action=edit">
improve this article</weblink>, or discuss the issue on its . is available.
<it>(December 2007)''</it></col>
</row>
</table>

</p>
<p>

Unless artificial consciousness can be proven formally, judgments of the success of any implementation will depend on observation. </p>
<p>

The <link xlink:type="simple" xlink:href="../840/43840.xml">
Turing test</link> is a proposal for identifying machine <link xlink:type="simple" xlink:href="../280/519280.xml">
intelligence</link> as determined by a machine's ability to interact with a person.  In the Turing test one has to guess whether the entity one is interacting with is a machine or a human, without any visual clues &mdash; the conversation is usually held over a <link xlink:type="simple" xlink:href="../792/460792.xml">
terminal</link>. An artificially conscious entity could only pass an equivalent test when it had itself passed beyond the imaginations of observers and entered into a meaningful relationship with them, and perhaps with fellow instances of itself.</p>
<p>

A cat or dog would not be able to pass this test.  It is highly likely that consciousness is not an exclusive property of humans.  Therefore, it is possible that a machine could be conscious and not be able to pass the Turing test. However, it would probably be a <link xlink:type="simple" xlink:href="../006/27006.xml">
serendipitous</link> occurrence because most efforts in <link xlink:type="simple" xlink:href="../164/1164.xml">
artificial intelligence</link> are focussed on <link xlink:type="simple" xlink:href="../280/519280.xml">
intelligence</link> and <link xlink:type="simple" xlink:href="../238/106238.xml">
cognition</link> rather than consciousness.</p>
<p>

As mentioned above, the <work wordnetid="100575741" confidence="0.8">
<argument wordnetid="106648724" confidence="0.8">
<scientific_research wordnetid="100641820" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<indication wordnetid="106797169" confidence="0.8">
<experiment wordnetid="100639556" confidence="0.8">
<evidence wordnetid="106643408" confidence="0.8">
<investigation wordnetid="100633864" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<research wordnetid="100636921" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<link xlink:type="simple" xlink:href="../216/6216.xml">
Chinese room</link></activity>
</psychological_feature>
</research>
</act>
</investigation>
</evidence>
</experiment>
</indication>
</event>
</scientific_research>
</argument>
</work>
 argument seeks to debunk the validity of the Turing Test by showing that a machine can pass the test and yet not have human-style semantics.</p>
<p>

Since there is an enormous range of human behaviours, all of which are deemed to be conscious, it is difficult to lay down all the criteria by which to determine whether a machine manifests consciousness. </p>
<p>

Furthermore, many would argue that no test of <it>behaviour</it> can prove or disprove the existence of consciousness because a conscious entity can have <link xlink:type="simple" xlink:href="../785/44785.xml">
dreams</link>, <link xlink:type="simple" xlink:href="../965/165965.xml">
qualia</link> and other features of an inner life.  This point is made forcibly by those who stress the subjective nature of conscious experience such as <philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../793/192793.xml">
Thomas Nagel</link></philosopher>
 who, in his essay, <it><weblink xlink:type="simple" xlink:href="http://members.aol.com/NeoNoetics/Nagel_Bat.html">
What is it like to be a bat?</weblink></it>, argues that <link xlink:type="simple" xlink:href="../965/165965.xml">
subjective experience</link> cannot be reduced, because it cannot be objectively observed, but subjective experience is not in contradiction with physicalism.  </p>
<p>

Although objective criteria are being proposed as prerequisites for testing the consciousness of a machine,  the failure of any particular test would not disprove consciousness.  Ultimately it will only be possible to assess whether a machine is conscious when a universally accepted understanding of consciousness is available.</p>
<p>

Another test of AC, in the opinion of some, should include a demonstration that machine can learn the ability to filter out certain <link xlink:type="simple" xlink:href="../399/569399.xml">
stimuli</link> in its environment, to focus on certain stimuli, and to show attention toward its environment in general. The <link xlink:type="simple" xlink:href="../107/395107.xml">
mechanism</link>s that govern how human attention is driven are not yet fully understood by scientists. This absence of knowledge could be exploited by engineers of AC; since we don't understand attentiveness in humans, we do not have specific and known criteria to measure it in machines. Since unconsciousness in humans equates to total inattentiveness, an AC should have outputs that indicate where its attention is focused at any one time, at least during the aforementioned test. By Antonio Chella from University of Palermo [https://bandura.sbs.arizona.edu/login/consciousness/report_web_detail.aspx?abs=315] "The mapping between the conceptual and the linguistic areas gives the interpretation of linguistic symbols in terms of conceptual structures. It is achieved through a focus of attention mechanism implemented by means of suitable recurrent neural networks with internal states. A sequential attentive mechanism is hypothesized that suitably scans the conceptual representation and, according to the hypotheses generated on the basis of previous knowledge, it predicts and detects the interesting events occurring in the scene. Hence, starting from the incoming information, such a mechanism generates expectations and it makes contexts in which hypotheses may be verified and, if necessary, adjusted."</p>
<p>

Another test for consciousness, commonly proposed by some futurists such as <link xlink:type="simple" xlink:href="../299/30299.xml">
transhumanists</link>, is to hook the human brain up to a machine in an integral way. Presently, <link xlink:type="simple" xlink:href="../686/623686.xml">
brain-computer interfaces</link> are fairly primitive, and only allow for information to be channeled in to or out of the human brain, but not both ways due to the massive computational complexity this would require of the computer and bandwidth restrictions. However, as BCIs continue to progress in complexity and functionality along with the continuing study of AC, it may be perfectly reasonable to propose to hook two human brains together in such a way that both individuals would be able to share their conscious experiences. This technique might be described as the ultimate test of subjective sentience, because unlike the development of an objective definition of consciousness, this sort of integral cognition would allow one subjectively conscious human to report the existence or non-existence of a conscious mind in a computer.</p>

</sec>
<sec>
<st>
 The ethics of artificial consciousness </st>

<p>

<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-notice" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="36px" src="Wiki_letter_w.svg">
</image>
</p>
</col>
<col style="" class="mbox-text">
 <b>Please help <weblink xlink:type="simple" xlink:href="http://localhost:18088/wiki/index.php?title=Artificial_consciousness&amp;action=edit">
improve this section</weblink> by expanding it.</b> Further information might be found on the  or at . 
<it>(January 2007)''</it></col>
</row>
</table>

</p>
<p>

If it was certain that a particular machine was conscious its rights would be an <link xlink:type="simple" xlink:href="../258/9258.xml">
ethical</link> issue that would need to be assessed (e.g. what rights it would have under law). For example a conscious computer that was owned and used as a tool or central computer of a building or large machine is a particular ambiguity. Should <link xlink:type="simple" xlink:href="../668/18949668.xml">
law</link>s be made for such a case, consciousness would also require a legal definition (for example a machine's ability to experience <link xlink:type="simple" xlink:href="../407/169407.xml">
pleasure</link> or <link xlink:type="simple" xlink:href="../373/24373.xml">
pain</link>). Because artificial consciousness is still largely a theoretical subject such ethics have not been discussed or developed to a great extent, though it has often been a theme in fiction (see below).</p>
<p>

<b>
Rights as of 2003:</b></p>
<p>

The rules for the 2003 <link xlink:type="simple" xlink:href="../725/238725.xml">
Loebner Prize</link> competition explicitly addressed the question of "Robot Rights."</p>
<p>

<it>61. If, in any given year, a publicly available open source Entry entered by the University of Surrey or the Cambridge Center wins the Silver Medal or the Gold Medal, then the Medal and the Cash Award will be awarded to the body responsible the development of that Entry. If no such body can be identified, or if there is disagreement among two or more claimants, the Medal and the Cash Award will be held in trust until such time as the Entry may legally possess, either in the United States of America or in the venue of the contest, the Cash Award and Gold Medal in its own right</it>.</p>
<p>

http://loebner03.hamill.co.uk/docs/LPC%20Official%20Rules%20v2.0.pdf</p>
<p>

The competition was directed by David Hamill and the rules were developed by members of the Robitron Yahoo group.  The suggestion for granting rights to the AI was made in http://tech.groups.yahoo.com/group/Robitron/message/687</p>

</sec>
<sec>
<st>
Artificial consciousness in literature and movies</st>

<p>

<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-content" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="40x40px" src="Ambox_content.png">
</image>
</p>
</col>
<col style="" class="mbox-text">
 <b>This section contains information which may be of unclear or questionable  or  to the article's subject matter.</b>
Please help <weblink xlink:type="simple" xlink:href="http://localhost:18088/wiki/index.php?title=Artificial_consciousness&amp;action=edit">
improve this article</weblink>by clarifying or removing superfluous information.</col>
</row>
</table>
</p>

<p>

<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-content" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="40x40px" src="Ambox_content.png">
</image>
</p>
</col>
<col style="" class="mbox-text">
 <b>This section may  of the article</b>&nbsp;into the topic of another article, <it><link xlink:type="simple" xlink:href="../227/11746227.xml">
artificial intelligence in fiction</link></it>.
Please help <weblink xlink:type="simple" xlink:href="http://localhost:18088/wiki/index.php?title=Artificial_consciousness&amp;action=edit">
improve this section</weblink> or discuss this issue on the .</col>
</row>
</table>

 </p>
<p>

Fictional <link xlink:type="simple" xlink:href="../970/42970.xml">
future history</link> instances of artificial consciousness:
<list>
<entry level="1" type="bullet">

Neuromancer and Wintermute from William Gibson's "Neuromancer".</entry>
<entry level="1" type="bullet">

Aura from the .hack// series.</entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../658/14305658.xml">
Chii</link> from the <change_of_state wordnetid="100199130" confidence="0.8">
<beginning wordnetid="100235435" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<change wordnetid="100191142" confidence="0.8">
<action wordnetid="100037396" confidence="0.8">
<part wordnetid="113809207" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<introduction wordnetid="100238022" confidence="0.8">
<morpheme wordnetid="106306233" confidence="0.8">
<language_unit wordnetid="106284225" confidence="0.8">
<ending wordnetid="106308765" confidence="0.8">
<link xlink:type="simple" xlink:href="../500/3630500.xml">
Chobits</link></ending>
</language_unit>
</morpheme>
</introduction>
</psychological_feature>
</act>
</part>
</action>
</change>
</event>
</beginning>
</change_of_state>
 anime series.</entry>
<entry level="1" type="bullet">

<fictional_character wordnetid="109587565" confidence="0.8">
<imaginary_being wordnetid="109483738" confidence="0.8">
<intelligence wordnetid="105617606" confidence="0.8">
<link xlink:type="simple" xlink:href="../112/10054112.xml">
Skynet</link></intelligence>
</imaginary_being>
</fictional_character>
 from <it><album wordnetid="106591815" confidence="0.9508927676800064">
<movie wordnetid="106613686" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../327/30327.xml">
The Terminator</link></movie>
</album>
</it> series of films.</entry>
<entry level="1" type="bullet">

The <link xlink:type="simple" xlink:href="../274/1188274.xml">
Netnavi</link>s from <it><link xlink:type="simple" xlink:href="../759/921759.xml">
Megaman NT Warrior</link>''</it></entry>
<entry level="1" type="bullet">

<link>
Vanamonde</link> in <person wordnetid="100007846" confidence="0.9508927676800064">
<inventor wordnetid="110214637" confidence="0.9173553029164789">
<writer wordnetid="110794014" confidence="0.9173553029164789">
<link xlink:type="simple" xlink:href="../148/18598148.xml">
Arthur C. Clarke</link></writer>
</inventor>
</person>
's <it><link xlink:type="simple" xlink:href="../721/600721.xml">
The City and the Stars</link>''</it></entry>
<entry level="1" type="bullet">

The Ship (the result of a large-scale AC experiment) in <person wordnetid="100007846" confidence="0.9508927676800064">
<writer wordnetid="110794014" confidence="0.9508927676800064">
<novelist wordnetid="110363573" confidence="0.9173553029164789">
<link xlink:type="simple" xlink:href="../852/10852.xml">
Frank Herbert</link></novelist>
</writer>
</person>
's  and sequels, despite past edicts warning against "Making a Machine in the Image of a Man's Mind."</entry>
<entry level="1" type="bullet">

<fictional_character wordnetid="109587565" confidence="0.8">
<imaginary_being wordnetid="109483738" confidence="0.8">
<intelligence wordnetid="105617606" confidence="0.8">
<link xlink:type="simple" xlink:href="../262/1145262.xml">
Jane</link></intelligence>
</imaginary_being>
</fictional_character>
 in <person wordnetid="100007846" confidence="0.9508927676800064">
<professor wordnetid="110480730" confidence="0.9173553029164789">
<writer wordnetid="110794014" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../209/6097209.xml">
Orson Scott Card</link></writer>
</professor>
</person>
's <it><literary_composition wordnetid="106364329" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<fiction wordnetid="106367107" confidence="0.8">
<novel wordnetid="106367879" confidence="0.8">
<link xlink:type="simple" xlink:href="../230/28230.xml">
Speaker for the Dead</link></novel>
</fiction>
</writing>
</written_communication>
</literary_composition>
</it>, <it><literary_composition wordnetid="106364329" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<fiction wordnetid="106367107" confidence="0.8">
<novel wordnetid="106367879" confidence="0.8">
<link xlink:type="simple" xlink:href="../701/200701.xml">
Xenocide</link></novel>
</fiction>
</writing>
</written_communication>
</literary_composition>
</it>, <it><literary_composition wordnetid="106364329" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<fiction wordnetid="106367107" confidence="0.8">
<novel wordnetid="106367879" confidence="0.8">
<link xlink:type="simple" xlink:href="../211/184211.xml">
Children of the Mind</link></novel>
</fiction>
</writing>
</written_communication>
</literary_composition>
</it>, and <it><short_story wordnetid="106371999" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../718/14731718.xml">
Investment Counselor</link></short_story>
''</it></entry>
<entry level="1" type="bullet">

<fictional_character wordnetid="109587565" confidence="0.8">
<imaginary_being wordnetid="109483738" confidence="0.8">
<intelligence wordnetid="105617606" confidence="0.8">
<link xlink:type="simple" xlink:href="../384/14384.xml">
HAL 9000</link></intelligence>
</imaginary_being>
</fictional_character>
 in <it>''</it></entry>
<entry level="1" type="bullet">

David in <person wordnetid="100007846" confidence="0.9508927676800064">
<actor wordnetid="109765278" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../940/26940.xml">
Steven Spielberg</link></actor>
</person>
's <it>''</it></entry>
<entry level="1" type="bullet">

<fictional_character wordnetid="109587565" confidence="0.8">
<imaginary_being wordnetid="109483738" confidence="0.8">
<intelligence wordnetid="105617606" confidence="0.8">
<link xlink:type="simple" xlink:href="../676/47676.xml">
Data</link></intelligence>
</imaginary_being>
</fictional_character>
 in <it><dish wordnetid="107557434" confidence="0.8">
<music wordnetid="107020895" confidence="0.8">
<music_genre wordnetid="107071942" confidence="0.8">
<snack_food wordnetid="107712382" confidence="0.8">
<classical_music wordnetid="107025900" confidence="0.8">
<substance wordnetid="100020090" confidence="0.8">
<sandwich wordnetid="107695965" confidence="0.8">
<auditory_communication wordnetid="107109019" confidence="0.8">
<food wordnetid="100021265" confidence="0.8">
<opera wordnetid="107026352" confidence="0.8">
<western wordnetid="107698672" confidence="0.8">
<nutriment wordnetid="107570720" confidence="0.8">
<expressive_style wordnetid="107066659" confidence="0.8">
<link xlink:type="simple" xlink:href="../886/17157886.xml">
Star Trek</link></expressive_style>
</nutriment>
</western>
</opera>
</food>
</auditory_communication>
</sandwich>
</substance>
</classical_music>
</snack_food>
</music_genre>
</music>
</dish>
''</it></entry>
<entry level="1" type="bullet">

P-1 in the 1970s book <it>The Adolescence of P-1''</it></entry>
<entry level="1" type="bullet">

Robots in <person wordnetid="100007846" confidence="0.9508927676800064">
<humorist wordnetid="110191943" confidence="0.9173553029164789">
<biochemist wordnetid="109854915" confidence="0.9173553029164789">
<writer wordnetid="110794014" confidence="0.9173553029164789">
<historian wordnetid="110177150" confidence="0.9173553029164789">
<novelist wordnetid="110363573" confidence="0.9173553029164789">
<essayist wordnetid="110064405" confidence="0.9173553029164789">
<link xlink:type="simple" xlink:href="../573/14573.xml">
Isaac Asimov</link></essayist>
</novelist>
</historian>
</writer>
</biochemist>
</humorist>
</person>
's <it><work wordnetid="104599396" confidence="0.8">
<product wordnetid="104007894" confidence="0.8">
<creation wordnetid="103129123" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<book wordnetid="106410904" confidence="0.8">
<publication wordnetid="106589574" confidence="0.8">
<link xlink:type="simple" xlink:href="../134/60134.xml">
Robot Series</link></publication>
</book>
</artifact>
</creation>
</product>
</work>
''</it></entry>
<entry level="1" type="bullet">

Andrew Martin in <it><short_story wordnetid="106371999" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../525/331525.xml">
The Bicentennial Man</link></short_story>
''</it></entry>
<entry level="1" type="bullet">

<it><movie wordnetid="106613686" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../745/IB$M$_3745.xml">
Blade Runner</link></movie>
''</it></entry>
<entry level="1" type="bullet">

<it><movie wordnetid="106613686" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../007/30007.xml">
The Matrix</link></movie>
''</it></entry>
<entry level="1" type="bullet">

The Technocore in <person wordnetid="100007846" confidence="0.9508927676800064">
<writer wordnetid="110794014" confidence="0.9508927676800064">
<novelist wordnetid="110363573" confidence="0.9173553029164789">
<link xlink:type="simple" xlink:href="../875/8875.xml">
Dan Simmons</link></novelist>
</writer>
</person>
' <it>Hyperion</it> and <it>Endymion</it> series (see <music wordnetid="107020895" confidence="0.8">
<classical_music wordnetid="107025900" confidence="0.8">
<auditory_communication wordnetid="107109019" confidence="0.8">
<opera wordnetid="107026352" confidence="0.8">
<music_genre wordnetid="107071942" confidence="0.8">
<expressive_style wordnetid="107066659" confidence="0.8">
<link xlink:type="simple" xlink:href="../995/228995.xml">
Hyperion Cantos</link></expressive_style>
</music_genre>
</opera>
</auditory_communication>
</classical_music>
</music>
)</entry>
<entry level="1" type="bullet">

<computer wordnetid="103082979" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<device wordnetid="103183080" confidence="0.8">
<machine wordnetid="103699975" confidence="0.8">
<intelligence wordnetid="105617606" confidence="0.8">
<link xlink:type="simple" xlink:href="../827/447827.xml">
The Minds</link></intelligence>
</machine>
</device>
</instrumentality>
</artifact>
</computer>
 in <link xlink:type="simple" xlink:href="../858/14858.xml">
Iain M. Bank's</link> <music wordnetid="107020895" confidence="0.8">
<series wordnetid="108457976" confidence="0.8">
<society wordnetid="107966140" confidence="0.8">
<music_genre wordnetid="107071942" confidence="0.8">
<classical_music wordnetid="107025900" confidence="0.8">
<arrangement wordnetid="107938773" confidence="0.8">
<social_group wordnetid="107950920" confidence="0.8">
<auditory_communication wordnetid="107109019" confidence="0.8">
<civilization wordnetid="108111783" confidence="0.8">
<ordering wordnetid="108456993" confidence="0.8">
<opera wordnetid="107026352" confidence="0.8">
<group wordnetid="100031264" confidence="0.8">
<expressive_style wordnetid="107066659" confidence="0.8">
<link xlink:type="simple" xlink:href="../623/58623.xml">
Culture</link></expressive_style>
</group>
</opera>
</ordering>
</civilization>
</auditory_communication>
</social_group>
</arrangement>
</classical_music>
</music_genre>
</society>
</series>
</music>
 novels.</entry>
<entry level="1" type="bullet">

The Sentient Intelligence in <person wordnetid="100007846" confidence="0.9508927676800064">
<writer wordnetid="110794014" confidence="0.9173553029164789">
<link xlink:type="simple" xlink:href="../050/24050.xml">
Peter F. Hamilton</link></writer>
</person>
's <it><book wordnetid="106410904" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../492/2682492.xml">
Commonwealth Saga</link></book>
</it> and sequel.</entry>
<entry level="1" type="bullet">

Johnny 5 in <it><link xlink:type="simple" xlink:href="../266/736266.xml">
Short Circuit</link></it> and sequel.</entry>
<entry level="1" type="bullet">

Many of <person wordnetid="100007846" confidence="0.9508927676800064">
<screenwriter wordnetid="110564400" confidence="0.9173553029164789">
<writer wordnetid="110794014" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../389/25389.xml">
Robert A. Heinlein</link></writer>
</screenwriter>
</person>
's short stories and novels feature AI/AC plots and discussion.  See <it><literary_composition wordnetid="106364329" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<fiction wordnetid="106367107" confidence="0.8">
<novel wordnetid="106367879" confidence="0.8">
<link xlink:type="simple" xlink:href="../597/53597.xml">
The Moon Is a Harsh Mistress</link></novel>
</fiction>
</writing>
</written_communication>
</literary_composition>
</it> (co-starring a networked supercomputer named Mike), <it><literary_composition wordnetid="106364329" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<fiction wordnetid="106367107" confidence="0.8">
<novel wordnetid="106367879" confidence="0.8">
<link xlink:type="simple" xlink:href="../139/60139.xml">
Time Enough for Love</link></novel>
</fiction>
</writing>
</written_communication>
</literary_composition>
</it> (Minerva/Athena, another world-spanning computer), <it><link xlink:type="simple" xlink:href="../178/9086178.xml">
The Number of the Beast</link></it> (The Gay Deceiver, a supernaturally-altered personal flying craft) and, arguably, the eponymous heroine in <it><literary_composition wordnetid="106364329" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<fiction wordnetid="106367107" confidence="0.8">
<novel wordnetid="106367879" confidence="0.8">
<link xlink:type="simple" xlink:href="../786/59786.xml">
Friday</link></novel>
</fiction>
</writing>
</written_communication>
</literary_composition>
</it>.</entry>
<entry level="1" type="bullet">

The Bomb in <link xlink:type="simple" xlink:href="../per/Scout_S$niper.xml">
Dark Star</link></entry>
<entry level="1" type="bullet">

Kryten and Holly in <link xlink:type="simple" xlink:href="../721/25721.xml">
Red Dwarf</link></entry>
<entry level="1" type="bullet">

Durandal, Tycho, and Leela from the <marble wordnetid="103721047" confidence="0.8">
<game_equipment wordnetid="103414162" confidence="0.8">
<ball wordnetid="102778669" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<taw wordnetid="104396093" confidence="0.8">
<equipment wordnetid="103294048" confidence="0.8">
<link xlink:type="simple" xlink:href="../133/49133.xml">
Marathon Trilogy</link></equipment>
</taw>
</instrumentality>
</artifact>
</ball>
</game_equipment>
</marble>
</entry>
<entry level="1" type="bullet">

Many of the characters in <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<energizer wordnetid="110056103" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<artist wordnetid="109812338" confidence="0.8">
<actor wordnetid="109767197" confidence="0.8">
<creator wordnetid="109614315" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/19994.xml">
Masamune Shirow</link></creator>
</actor>
</artist>
</causal_agent>
</energizer>
</person>
</physical_entity>
's <link xlink:type="simple" xlink:href="../914/12914.xml">
Ghost in the Shell</link></entry>
<entry level="1" type="bullet">

<car wordnetid="102958343" confidence="0.8">
<conveyance wordnetid="103100490" confidence="0.8">
<physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<wheeled_vehicle wordnetid="104576211" confidence="0.8">
<vehicle wordnetid="104524313" confidence="0.8">
<relative wordnetid="110235549" confidence="0.8">
<twin wordnetid="110734394" confidence="0.8">
<self-propelled_vehicle wordnetid="104170037" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<container wordnetid="103094503" confidence="0.8">
<sibling wordnetid="110595164" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<motor_vehicle wordnetid="103791235" confidence="0.8">
<link xlink:type="simple" xlink:href="../947/1829947.xml">
KITT</link></motor_vehicle>
</causal_agent>
</sibling>
</container>
</instrumentality>
</artifact>
</self-propelled_vehicle>
</twin>
</relative>
</vehicle>
</wheeled_vehicle>
</person>
</physical_entity>
</conveyance>
</car>
 and <conveyance wordnetid="103100490" confidence="0.8">
<car wordnetid="102958343" confidence="0.8">
<automaton wordnetid="102761392" confidence="0.8">
<self-propelled_vehicle wordnetid="104170037" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<wheeled_vehicle wordnetid="104576211" confidence="0.8">
<container wordnetid="103094503" confidence="0.8">
<vehicle wordnetid="104524313" confidence="0.8">
<device wordnetid="103183080" confidence="0.8">
<mechanism wordnetid="103738472" confidence="0.8">
<motor_vehicle wordnetid="103791235" confidence="0.8">
<link xlink:type="simple" xlink:href="../189/1941189.xml">
KARR</link></motor_vehicle>
</mechanism>
</device>
</vehicle>
</container>
</wheeled_vehicle>
</instrumentality>
</artifact>
</self-propelled_vehicle>
</automaton>
</car>
</conveyance>
 from <series wordnetid="108457976" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../274/43274.xml">
Knight Rider</link></series>
 (Note that it was only hinted that K.I.T.T. had essentially a mind of his own and can 'think'. However K.A.R.R. was to be exactly like K.I.T.T. but was said to be more 'animalistic' in nature.)</entry>
<entry level="1" type="bullet">

All characters of the two first <literary_composition wordnetid="106364329" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<fiction wordnetid="106367107" confidence="0.8">
<novel wordnetid="106367879" confidence="0.8">
<link xlink:type="simple" xlink:href="../739/2289739.xml">
Ring</link></novel>
</fiction>
</writing>
</written_communication>
</literary_composition>
 novels by <physical_entity wordnetid="100001930" confidence="0.8">
<communicator wordnetid="109610660" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<writer wordnetid="110794014" confidence="0.8">
<link xlink:type="simple" xlink:href="../628/833628.xml">
Koji Suzuki</link></writer>
</causal_agent>
</person>
</communicator>
</physical_entity>
.</entry>
<entry level="1" type="bullet">

WALL-E and EVE in <it><movie wordnetid="106613686" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../330/8980330.xml">
WALL-E</link></movie>
</it> (2008).</entry>
</list>
</p>

</sec>
<sec>
<st>
See also</st>
<p>

<list>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../686/623686.xml">
Brain-computer interface</link></entry>
<entry level="1" type="bullet">

<philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../221/258221.xml">
David Chalmers</link></philosopher>
</entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../496/9496.xml">
Epiphenomenalism</link></entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../395/189395.xml">
Greedy reductionism</link></entry>
<entry level="1" type="bullet">

<law wordnetid="108441203" confidence="0.8">
<collection wordnetid="107951464" confidence="0.8">
<group wordnetid="100031264" confidence="0.8">
<link xlink:type="simple" xlink:href="../398/630398.xml">
Identity of indiscernibles</link></group>
</collection>
</law>
</entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../877/3054877.xml">
Intelligent system</link></entry>
<entry level="1" type="bullet">

<personality wordnetid="104617562" confidence="0.8">
<link xlink:type="simple" xlink:href="../605/705605.xml">
Jabberwacky</link></personality>
 </entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../599/629599.xml">
Kismet (robot)</link></entry>
<entry level="1" type="bullet">

<idea wordnetid="105833840" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<component wordnetid="105868954" confidence="0.8">
<part wordnetid="105867413" confidence="0.8">
<link xlink:type="simple" xlink:href="../162/14246162.xml">
Memristor</link></part>
</component>
</concept>
</idea>
</entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../060/377060.xml">
Morgan's Canon</link></entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../483/6880483.xml">
Philosophy of mind</link></entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../631/15311631.xml">
Psi-Theory</link></entry>
<entry level="1" type="bullet">

<event wordnetid="100029378" confidence="0.8">
<social_event wordnetid="107288639" confidence="0.8">
<contest wordnetid="107456188" confidence="0.8">
<game wordnetid="100456199" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<link xlink:type="simple" xlink:href="../171/6383171.xml">
Virtual Woman</link></psychological_feature>
</game>
</contest>
</social_event>
</event>
</entry>
<entry level="1" type="bullet">

<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../410/310410.xml">
William Grey Walter</link></scientist>
</entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../427/1079427.xml">
Homunculus fallacy</link></entry>
</list>
</p>

</sec>
<sec>
<st>
References</st>
<p>

<list>
<entry level="1" type="bullet">

 <cite id="CITEREFAleksander1995" style="font-style:normal">Aleksander, Igor&#32;(1995),&#32;<it>Artificial Neuroconsciousness: An Update</it>, IWANN</cite>&nbsp; <weblink xlink:type="simple" xlink:href="http://dblp.uni-trier.de/rec/bibtex/conf/iwann/Aleksander95">
BibTex</weblink> <weblink xlink:type="simple" xlink:href="http://web.archive.org/web/19970302014628/http://www.ee.ic.ac.uk/research/neural/publications/iwann.html">
Internet Archive</weblink></entry>
<entry level="1" type="bullet">

 <cite id="CITEREFBaars1988" style="font-style:normal">Baars, Bernard&#32;(1988),&#32;<it><weblink xlink:type="simple" xlink:href="http://www.nsi.edu/users/baars/BaarsConsciousnessBook1988/CTC_ch01.html">
A Cognitive Theory of Consciousness</weblink></it>, Cambridge, MA: Cambridge University Press, </cite>&nbsp;</entry>
<entry level="1" type="bullet">

 <cite id="CITEREFBaars1997" style="font-style:normal">Baars, Bernard&#32;(1997),&#32;<it>In the Theater of Consciousness</it>, New York, NY: Oxford University Press</cite>&nbsp;</entry>
<entry level="1" type="bullet">

 <cite id="CITEREFChalmers1996" style="font-style:normal">Chalmers, David&#32;(1996),&#32;<it>The Conscious Mind</it>, Oxford University Press.</cite>&nbsp;</entry>
<entry level="1" type="bullet">

 <cite id="CITEREFCotterill2003" style="font-style:normal">Cotterill, Rodney&#32;(2003),&#32;"Cyberchild: a Simulation Test-Bed for Consciousness Studies", in&#32;Holland, Owen,&#32;<it>Machine Consciousness</it>, Imprint Academic</cite>&nbsp;</entry>
<entry level="1" type="bullet">

 <cite id="CITEREFFranklin1995" style="font-style:normal">Franklin, Stan&#32;(1995),&#32;<it>Artificial Minds</it>, Boston, MA: MIT Press</cite>&nbsp;</entry>
<entry level="1" type="bullet">

 <cite id="CITEREFFranklin2003" style="font-style:normal">Franklin, Stan&#32;(2003),&#32;"IDA: A Conscious Artefact", in&#32;Holland, Owen,&#32;<it>Machine Consciousness</it>, Exeter, UK: Imprint Academic</cite>&nbsp; </entry>
<entry level="1" type="bullet">

 <cite id="CITEREFFreeman1999" style="font-style:normal">Freeman, Walter&#32;(1999),&#32;<it>How Brains make up their Minds</it>, Phoenix</cite>&nbsp;</entry>
<entry level="1" type="bullet">

 <cite id="CITEREFHaikonen2003" style="font-style:normal">Haikonen, Pentti&#32;(2003),&#32;<it>The Cognitive Approach to Conscious Machines</it>, Imprint Academic</cite>&nbsp;</entry>
<entry level="1" type="bullet">

 <cite id="CITEREFSun1999" style="font-style:normal">Sun, Ron&#32;(December 1999),&#32;"Accounting for the computational basis of consciousness: A connectionist approach",&#32;<it>Consciousness and Cognition</it>&#32;<b>8</b></cite>&nbsp; </entry>
<entry level="1" type="bullet">

 <cite id="CITEREFSun2001" style="font-style:normal">Sun, Ron&#32;(2001),&#32;"Computation, reduction, and teleology of consciousness",&#32;<it>Cognitive Systems Research</it>&#32;<b>1</b>(4):  241-249</cite>&nbsp;</entry>
<entry level="1" type="bullet">

 <cite id="CITEREFTakenoInabaSuzuki2005" style="font-style:normal">Takeno, Junichi; Inaba, K&#32;&amp;&#32;Suzuki, T.&#32;(June 27-30, 2005),&#32;"<weblink xlink:type="simple" xlink:href="http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=1554325">
Experiments and examination of 'mirror image cognition' using a small robot</weblink>",&#32;<it>The 6th IEEE International Symposium on Computational Intelligence in Robotics and Automation</it>&#32;(CIRA 2005):  493-498, </cite>&nbsp;</entry>
</list>
</p>

</sec>
<sec>
<st>
 Further reading </st>
<p>

<list>
<entry level="1" type="bullet">

Haikonen, Pentti (2004), <it>Conscious Machines and Machine Emotions</it>, presented at Workshop on Models for Machine Consciousness, Antwerp, BE, June 2004.</entry>
<entry level="1" type="bullet">

Baars, Bernard J and Stan Franklin. 2003. How conscious experience and working memory interact. Trends in Cognitive Science 7: 166–172.</entry>
<entry level="1" type="bullet">

Franklin, S, B J Baars, U Ramamurthy, and Matthew Ventura. 2005. The role of consciousness in memory. Brains, Minds and Media 1: 1–38, pdf.</entry>
<entry level="1" type="bullet">

Casti, John L. "The Cambridge Quintet: A Work of Scientific Speculation", Perseus Books Group , 1998</entry>
<entry level="1" type="bullet">

McCarthy, John (1971-1987), <it>Generality in Artificial Intelligence</it> <weblink xlink:type="simple" xlink:href="http://www-formal.stanford.edu/jmc/generality/generality.html">
http://www-formal.stanford.edu/jmc/generality/generality.html</weblink>.  Stanford University, 1971-1987.</entry>
<entry level="1" type="bullet">

Pharoah M.C. (online). <weblink xlink:type="simple" xlink:href="http://homepage.ntlworld.com/m.pharoah/">
Looking to systems theory for a reductive explanation of phenomenal experience and evolutionary foundations for higher order thought</weblink> Retrieved Dec. 13, 2007.</entry>
<entry level="1" type="bullet">

Suzuki T., Inaba K., Takeno, Junichi (2005),<it> Conscious Robot That </it>'Distinguishes Between Self and Others<b> and Implements Imitation Behavior<it>, ( </it></b><it>Best Paper of IEA/AIE2005</it>'), Innovations in Applied Artificial Intelligence, 18th International Conference on Industrial and Engineering Applications of Artificial Intelligence and Expert Systems, pp. 101-110, IEA/AIE 2005, Bari, Italy, June 22-24, 2005.</entry>
<entry level="1" type="bullet">

Takeno, Junichi (2006), <it>The </it>'Self-Aware Robot<b> -A Response to Reactions to Discovery News-<it> <weblink xlink:type="simple" xlink:href="http://www.d6.dion.ne.jp/~takenof/SAR-LAL-Takeno.pdf">
http://www.d6.dion.ne.jp/~takenof/SAR-LAL-Takeno.pdf</weblink>, HRI Press, August 2006.</it></b></entry>
<entry level="1" type="bullet">

Sternberg, Eliezer J. (2007) <it>Are You a Machine? Tha Brain the Mind and What it Means to be Human.</it> Amherst, NY: Prometheus Books.</entry>
<entry level="1" type="bullet">

</entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.senses.info">
Site</weblink> of <physical_entity wordnetid="100001930" confidence="0.8">
<communicator wordnetid="109610660" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<writer wordnetid="110794014" confidence="0.8">
<research_worker wordnetid="110523076" confidence="0.8">
<link xlink:type="simple" xlink:href="../699/10193699.xml">
Steven Ericsson-Zenith</link></research_worker>
</writer>
</scientist>
</causal_agent>
</person>
</communicator>
</physical_entity>
's <it>Explaining Experience in Nature</it> information site.</entry>
</list>
</p>

</sec>
<sec>
<st>
External links</st>
<p>

<list>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.cogsci.rpi.edu/~rsun/conscious.html">
Ron Sun's papers on consciousness</weblink></entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.inl.gov/adaptiverobotics/humanoidrobotics/ethicalconsiderations.shtml">
Humanoid Robotics Ethical Considerations</weblink></entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.intelligent-systems.com.ar/intsyst/ethics.htm">
Scientific Ethics</weblink></entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.swartzneuro.org/docs/aleksander_presentation.ppt">
Artefactual consciousness depiction by Professor Igor Aleksander</weblink></entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://consc.net/chalmers/">
David Chalmers</weblink></entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://consc.net/online/1.4a">
Online papers on the possible mechanisms of Higher-Order Thought</weblink></entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.aslab.org/public/events/moc">
ESF Models of Consciousness Workshop</weblink> and its <weblink xlink:type="simple" xlink:href="http://www.esf.org/generic/1650/EW0296Report.pdf">
Scientific Report</weblink></entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.aslab.org/public/events/mcc">
Machine Consciousness - Complexity Aspects Workshop</weblink></entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.rs.cs.meiji.ac.jp/Takeno_Archive/DiscoveryNewsRoboemotion020905.pdf">
Robot In Touch with Its Emotions 5-Sep-2005</weblink></entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.rs.cs.meiji.ac.jp/Takeno_Archive/DiscoveryNewsAwareRobot211205.pdf">
Robot Demonstrates Self-awareness 21-Dec-2005</weblink></entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.conscious-robots.com/">
Internet Portal dedicated to Machine Consciousness</weblink></entry>
</list>
</p>

<ss1>
<st>
 Open Source Software Projects </st>
<p>

<list>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://adsproject.sourceforge.net/ads-ac/index.php/Main_Page">
ADS-AC -- An experimental Open Source program which implements Absolutely Dynamic System, a proposed mechanism for AC</weblink></entry>
</list>
</p>


</ss1>
</sec>
</bdy>
</activity>
</psychological_feature>
</act>
</investigation>
</survey>
</event>
</examination>
</work>
</article>
