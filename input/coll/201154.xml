<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 16:29:08[mciao0825] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<algorithm  confidence="0.9511911446218017" wordnetid="105847438">
<header>
<title>Divide and conquer algorithm</title>
<id>201154</id>
<revision>
<id>244573207</id>
<timestamp>2008-10-11T14:26:10Z</timestamp>
<contributor>
<username>Excirial</username>
<id>5499713</id>
</contributor>
</revision>
<categories>
<category>Wikipedia articles incorporating text from public domain works of the United States Government</category>
<category>Optimization algorithms</category>
<category>Algorithms</category>
<category>Operations research</category>
</categories>
</header>
<bdy>

In <link xlink:type="simple" xlink:href="../323/5323.xml">
computer science</link>, <b>divide and conquer</b> (<b>D&amp;C</b>) is an important <link xlink:type="simple" xlink:href="../312/10433312.xml">
algorithm design</link> <link xlink:type="simple" xlink:href="../308/175308.xml">
paradigm</link>. It works by <link xlink:type="simple" xlink:href="../407/25407.xml">
recursively</link> breaking down a problem into two or more sub-problems of the same (or related) type, until these become simple enough to be solved directly. The solutions to the sub-problems are then combined to give a solution to the original problem. A divide and conquer algorithm is closely tied to a type of <link xlink:type="simple" xlink:href="../806/146806.xml">
recurrence relation</link> between functions of the data in question; data is "divided" into smaller portions and the result calculated thence.<p>

This technique is the basis of efficient <link xlink:type="simple" xlink:href="../775/775.xml">
algorithms</link> for all kinds of problems, such as <link xlink:type="simple" xlink:href="../442/28442.xml">
sorting</link> (<link xlink:type="simple" xlink:href="../249/3268249.xml">
quicksort</link>, <link xlink:type="simple" xlink:href="../039/20039.xml">
merge sort</link>) and the <link xlink:type="simple" xlink:href="../811/8811.xml">
discrete Fourier transform</link> (<link xlink:type="simple" xlink:href="../512/11512.xml">
FFTs</link>). Its application to <link xlink:type="simple" xlink:href="../506/21506.xml">
numerical algorithm</link>s is commonly known as <link xlink:type="simple" xlink:href="../251/4226251.xml">
binary splitting</link>.</p>

<sec>
<st>
 History </st>
<p>

A prominent early proposal of the core idea behind divide and conquer algorithms was by <link>
Anatolii Karatsuba</link> in 1960,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref> as an algorithm for multiplying two <it>n</it>-digit numbers with an <link xlink:type="simple" xlink:href="../543/7543.xml">
algorithmic complexity</link> of <math>O(n^{\log_2 3})</math>. This algorithm, now known as <link xlink:type="simple" xlink:href="../589/6395589.xml">
Karatsuba's algorithm</link>, thus disproved <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../161/91161.xml">
Andrey Kolmogorov</link></scientist>
</person>
's 1956 conjecture that the fastest <link xlink:type="simple" xlink:href="../411/57411.xml">
multiplication algorithm</link> was <math>O(n^2)</math>. Kolmogorov's work, together with Karatsuba's discovery, helped launch the study of the performance of algorithms.</p>
<p>

Similar ideas can also be found in earlier work, e.g. in <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../125/6125.xml">
Gauss</link></scientist>
</person>
's 1805 description of what would (much later) become known as the <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../702/352702.xml">
Cooley-Tukey FFT algorithm</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
, although this work predated modern complexity analysis and Gauss did not analyze the operation count quantitatively.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref> A related idea, focused on logical proof rather than on algorithm design, can be also found in the principle of <link xlink:type="simple" xlink:href="../881/18881.xml">
mathematical induction</link>.</p>

</sec>
<sec>
<st>
 Implementation </st>
<p>

Divide-and-conquer algorithms are naturally implemented as <link xlink:type="simple" xlink:href="../988/40988.xml">
recursive procedures</link>. In that case, the partial sub-problems leading to the one currently being solved are implicitly stored in the <link xlink:type="simple" xlink:href="../105/1718105.xml">
procedure call stack</link>.</p>
<p>

However, D&amp;C solutions can also be implemented by a non-recursive algorithm that stores the partial sub-problems in some explicit data structure, such as a <link xlink:type="simple" xlink:href="../993/273993.xml">
stack</link>, <link xlink:type="simple" xlink:href="../265/25265.xml">
queue</link>, or <link xlink:type="simple" xlink:href="../485/24485.xml">
priority queue</link>. This approach allows more freedom in the choice of the sub-problem that is to be solved next, a feature that is important in some applications — e.g. in <link xlink:type="simple" xlink:href="../026/97026.xml">
breadth-first recursion</link> and the <link xlink:type="simple" xlink:href="../580/456580.xml">
branch and bound</link> method for function optimization.</p>

</sec>
<sec>
<st>
 Variations </st>

<ss1>
<st>
 Decrease and conquer </st>
<p>

One variation of divide and conquer is called <b>decrease and conquer</b>, where the solution of a problem depends on only one subproblem. There are two advantages of treating this variant separately. Some problems do not need to solve all subproblems, and have a simpler conquer strategy. They can be generally solved with <link xlink:type="simple" xlink:href="../742/30742.xml">
tail recursion</link>. Analysis of these problems is simpler than divide and conquer.</p>
<p>

For finding the largest element in a list of numbers:</p>
<p>

<b>Algorithm</b> LargestNumber  
Input: A non-empty list of numbers <it>L</it>.
Output: The <it>largest</it> number in the list <it>L</it>.
Comment:  <b> Divide and Conquer</b>
<b>if</b> <it>L.size</it> <b>=</b> 1 <b>then</b>
<b>return</b> L.front
<it>largest1</it> ←  LargestNumber(L.front...L.mid)
<it>largest2</it> ←  LargestNumber(L.mid....L.back)
<b>if</b> <it>largest1</it> <b>&amp;gt;</b>  <it>largest2</it>, <b>then</b>
<it>largest</it> ← <it>largest1</it>
<b>else</b>
<it>largest</it> ← <it>largest2</it>
<b>return</b> <it>largest</it></p>
<p>

<b>Algorithm</b> LargestNumber 
Input: A non-empty list of numbers <it>L</it>.
Output: The <it>largest</it> number in the list <it>L</it>.
Comment: <b> Decrease and Conquer </b>
<b>if</b> <it>L.size</it> <b>=</b> 1 <b>then</b>
<b>return</b> L.front
last = L.size - 1;
<it>largest</it> ←  LargestNumber(L.front...L.last)
<b>if</b> <it>largest</it> <b>  <it>L.back</it></b>then<b>
<it>largest</it></b><b> ← <it>L.back</it></b>return<b> <it>largest</it></b></p>
<p>

Finding the maximum is solved by decreasing the problem by one element on each pass. A more popular example of decrease and conquer is the <link xlink:type="simple" xlink:href="../266/4266.xml">
binary search</link> algorithm, where the problem size will be cut down by half in each decrease phase and thus completes faster.</p>

</ss1>
<ss1>
<st>
 Divide and marriage before conquest </st>

<p>

<b>Divide and marriage before conquest</b> refers to algorithms based on the divide and conquer paradigm in which solutions to the subproblems generated by the recursion are combined to obtain a solution to the original problem. <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%223%22])">3</ref> For example, many <link xlink:type="simple" xlink:href="../442/28442.xml">
sorting algorithm</link>s merge sublists which have been sorted.</p>

</ss1>
</sec>
<sec>
<st>
 Advantages </st>

<ss1>
<st>
 Solving difficult problems </st>
<p>

Divide and conquer is a powerful tool for solving conceptually difficult problems, such as the classic <puzzle wordnetid="106784639" confidence="0.8">
<message wordnetid="106598915" confidence="0.8">
<subject wordnetid="106599788" confidence="0.8">
<problem wordnetid="106784003" confidence="0.8">
<question wordnetid="106783768" confidence="0.8">
<link xlink:type="simple" xlink:href="../990/56990.xml">
Tower of Hanoi</link></question>
</problem>
</subject>
</message>
</puzzle>
 puzzle: all it requires is a way of breaking the problem into sub-problems, of solving the trivial cases and of combining sub-problems to the original problem. Indeed, for many such problems the paradigm offers the <it>only</it> simple solution.</p>
<p>

Dividing the problem into sub-problems so that the sub-problems can be combined again is often the major difficulty in designing a new algorithm.</p>

</ss1>
<ss1>
<st>
 Algorithm efficiency </st>
<p>

Moreover, divide and conquer often provides a natural way to design <it>efficient</it> algorithms. </p>
<p>

For example, if the work of splitting the problem and combining the partial solutions is proportional to the problem's size <it>n</it>, there are a bounded number <it>p</it> of subproblems of size ~ <it>n</it>/<it>p</it> at each stage, and the base cases require O(1) (constant-bounded) time, then the divide-and-conquer algorithm will have O(<it>n</it> log <it>n</it>) complexity. This is used for problems such as sorting and FFTs to reduce the complexity from O(<it>n</it>2), although in general there may also be other approaches to designing efficient algorithms.</p>

</ss1>
<ss1>
<st>
 Parallelism </st>
<p>

Divide and conquer algorithms are naturally adapted for execution in multi-processor machines, especially shared-memory systems where the communication of data between processors does not need to be planned in advance, because distinct sub-problems can be executed on different processors.</p>

</ss1>
<ss1>
<st>
 Memory access </st>
<p>

Divide-and-conquer algorithms naturally tend to make efficient use of memory <link xlink:type="simple" xlink:href="../829/6829.xml">
cache</link>s. The reason is that once a sub-problem is small enough, it and all its sub-problems can, in principle, be solved within the cache, without accessing the slower main memory. An algorithm designed to exploit the cache in this way is called <it><link xlink:type="simple" xlink:href="../377/1773377.xml">
cache oblivious</link></it>, because it does not contain the cache size(s) as an explicit parameter.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%224%22])">4</ref></p>
<p>

Moreover, D&amp;C algorithms can be designed for many important algorithms, such as sorting, FFTs, and matrix multiplication, in such a way as to be <it>optimal cache oblivious</it> algorithms—they use the cache in a provably optimal way, in an asymptotic sense, regardless of the cache size. In contrast, the traditional approach to exploiting the cache is <it>blocking</it>, where the problem is explicitly divided into chunks of the appropriate size—this can also use the cache optimally, but only when the algorithm is tuned for the specific cache size(s) of a particular machine. </p>
<p>

The same advantage exists with regards to other hierarchical storage systems, such as <link xlink:type="simple" xlink:href="../643/40643.xml">
NUMA</link> or <link xlink:type="simple" xlink:href="../354/32354.xml">
virtual memory</link>, as well as for multiple levels of cache: once a sub-problem is small enough, it can be solved within a given level of the hierarchy, without accessing the higher (slower) levels. </p>
<p>

However, the kind of asymptotic optimality described here, analogous to <link xlink:type="simple" xlink:href="../578/44578.xml">
big O notation</link>, ignores constant factors, and additional machine/cache-specific tuning is in general required to achieve optimality in an absolute sense.</p>

</ss1>
</sec>
<sec>
<st>
 Disadvantages </st>
<p>

One commonly argued disadvantage of a divide-and-conquer approach is that recursion is slow: the overhead of the repeated subroutine calls, along with that of storing the call stack (the state at each point in the recursion), can outweigh any advantages of the approach. This, however, depends upon the implementation style: with large enough recursive base cases, the overhead of recursion can become negligible for many problems.</p>
<p>

Another problem of a divide-and-conquer approach is that, for simple problems, it may be more complicated than an iterative approach, especially if large base cases are to be implemented for performance reasons. For example, to add <it>N</it> numbers, a simple loop to add them up in sequence is much easier to code than a divide-and-conquer approach that breaks the set of numbers into two halves, adds them recursively, and then adds the sums.  (On the other hand, there may be compensating advantages&mdash;for example, this recursive summation process is generally considerably more accurate in <link xlink:type="simple" xlink:href="../376/11376.xml">
floating-point arithmetic</link> than a simple loop-based sum.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%225%22])">5</ref>)</p>
<p>

For some problems, many of the subproblems overlap. In such cases it is better to reuse the solutions to these overlapping subproblems. This approach is commonly known as <link xlink:type="simple" xlink:href="../483/723483.xml">
memoization</link> and is the recursive version of <link xlink:type="simple" xlink:href="../297/125297.xml">
dynamic programming</link>.</p>

</sec>
<sec>
<st>
 See also </st>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../881/18881.xml">
Mathematical induction</link></entry>
<entry level="1" type="bullet">

 The <statement wordnetid="106722453" confidence="0.8">
<message wordnetid="106598915" confidence="0.8">
<theorem wordnetid="106752293" confidence="0.8">
<proposition wordnetid="106750804" confidence="0.8">
<link xlink:type="simple" xlink:href="../585/561585.xml">
Master theorem</link></proposition>
</theorem>
</message>
</statement>
</entry>
<entry level="1" type="bullet">

 The <statement wordnetid="106722453" confidence="0.8">
<message wordnetid="106598915" confidence="0.8">
<theorem wordnetid="106752293" confidence="0.8">
<proposition wordnetid="106750804" confidence="0.8">
<link xlink:type="simple" xlink:href="../982/230982.xml">
Akra-Bazzi method</link></proposition>
</theorem>
</message>
</statement>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../153/201153.xml">
Divide and rule</link> (politics and sociology)</entry>
<entry level="1" type="bullet">

 <algorithm wordnetid="105847438" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../266/4266.xml">
Binary search algorithm</link></algorithm>
 (an example of a divide and conquer algorithm)</entry>
</list>
</p>

</sec>
<sec>
<st>
 References </st>
<p>

<reflist>
<entry id="1">
A. Karatsuba and Yu Ofman, <it>Multiplication of Many-Digital Numbers by Automatic Computers.</it> Doklady Akad. Nauk SSSR, Vol. 145 (1962), pp. 293–294. Translation in Physics-Doklady, 7 (1963), pp. 595–596.</entry>
<entry id="2">
Heideman, M. T., D. H. Johnson, and C. S. Burrus, "Gauss and the history of the fast Fourier transform," IEEE ASSP Magazine, 1, (4), 14&ndash;21 (1984)</entry>
<entry id="3">
Paul E. Black, <weblink xlink:type="simple" xlink:href="http://www.nist.gov/dads/HTML/dividemarrig.html">
Divide and marriage before conquest</weblink> at the <link xlink:type="simple" xlink:href="../888/21888.xml">
NIST</link> <link xlink:type="simple" xlink:href="../551/1661551.xml">
Dictionary of Algorithms and Data Structures</link>.</entry>
<entry id="4">
M. Frigo, C. E. Leiserson, and H. Prokop, "Cache-oblivious algorithms", Proc. 40th Symp. on the Foundations of Computer Science (1999).</entry>
<entry id="5">
Nicholas J. Higham, "The accuracy of floating point summation", <it>SIAM J. Scientific Computing</it> <b>14</b> (4), 783–799 (1993).</entry>
</reflist>
 </p>

</sec>
<sec>
<st>
 External links </st>
<p>

<list>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.datastructures.info/the-divide-and-conquer-algorithmmethod/">
Code example of Divide and Conquer, fast power calculation, in C++</weblink></entry>
</list>
</p>


</sec>
</bdy>
</algorithm>
</article>
