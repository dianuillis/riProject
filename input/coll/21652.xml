<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 15:31:49[mciao0828] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Natural language processing</title>
<id>21652</id>
<revision>
<id>243781972</id>
<timestamp>2008-10-08T00:35:21Z</timestamp>
<contributor>
<username>FatalError</username>
<id>1054301</id>
</contributor>
</revision>
<categories>
<category>All pages needing cleanup</category>
<category>Articles lacking reliable references from June 2008</category>
<category>Articles to be expanded since June 2008</category>
<category>Natural language processing</category>
<category>Speech recognition</category>
<category>Articles to be merged&amp;#32;since March 2008</category>
<category>Cleanup from June 2008</category>
<category>All articles to be expanded</category>
<category>All articles to be merged</category>
<category>Articles to be merged&amp;#32;since July 2008</category>
<category>Computational linguistics</category>
</categories>
</header>
<bdy>

For other uses, see <link xlink:type="simple" xlink:href="../573/40573.xml">
NLP</link>.<p>

<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-content" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="40x40px" src="Ambox_content.png">
</image>
</p>
</col>
<col style="" class="mbox-text">
 <p>

This article or section has multiple issues. Please help <b><weblink xlink:type="simple" xlink:href="http://localhost:18088/wiki/index.php?title=Natural_language_processing&amp;action=edit">
improve the article</weblink></b> or discuss these issues on the .
<list>
<entry level="1" type="bullet">

 It needs <b>additional  for .</b> Tagged since June 2008.</entry>
<entry level="1" type="bullet">

 It may require  to meet Wikipedia's <b>
Wikipedia style guidelines|quality standards</b>. Tagged since June 2008.</entry>
<entry level="1" type="bullet">

 It needs to be . Tagged since June 2008.</entry>
</list>
</p>
</col>
</row>
</table>
</p>

<p>

<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-move" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="150px" src="Merge-arrows.svg">
<caption>

Merge arrows
</caption>
</image>
</p>
</col>
<col style="" class="mbox-text">
 It has been suggested that this article or section be  with . ()</col>
</row>
</table>

</p>
<p>

<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-move" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="50px" src="Mergefrom.svg">
</image>
</p>
</col>
<col style="" class="mbox-text">
 It has been suggested that  be  into this article or section. ()</col>
</row>
</table>


<b>Natural language processing</b> (<b>NLP</b>) is a subfield of <link xlink:type="simple" xlink:href="../164/1164.xml">
artificial intelligence</link> and <link xlink:type="simple" xlink:href="../561/5561.xml">
computational linguistics</link>. It studies the problems of automated generation and understanding of <link xlink:type="simple" xlink:href="../173/21173.xml">
natural human languages</link>. </p>
<p>

Natural-language-generation systems convert information from computer databases into normal-sounding human language.  Natural-language-understanding systems convert samples of human language into more formal representations that are easier for <link xlink:type="simple" xlink:href="../457/7878457.xml">
computer</link> programs to manipulate.</p>

<sec>
<st>
Tasks and limitations</st>
<p>

In theory, natural-language processing is a very attractive method of <link xlink:type="simple" xlink:href="../516/13516.xml">
human-computer interaction</link>. Early systems such as <software wordnetid="106566077" confidence="0.8">
<application wordnetid="106570110" confidence="0.8">
<program wordnetid="106568978" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106359877" confidence="0.8">
<code wordnetid="106355894" confidence="0.8">
<coding_system wordnetid="106353757" confidence="0.8">
<link xlink:type="simple" xlink:href="../791/98791.xml">
SHRDLU</link></coding_system>
</code>
</writing>
</written_communication>
</program>
</application>
</software>
, working in restricted "<link xlink:type="simple" xlink:href="../827/2995827.xml">
blocks world</link>s" with restricted vocabularies, worked extremely well, leading researchers to excessive optimism, which was soon lost when the systems were extended to more realistic situations with real-world <link xlink:type="simple" xlink:href="../677/677.xml">
ambiguity</link> and <link xlink:type="simple" xlink:href="../363/7363.xml">
complexity</link>. </p>
<p>

Natural-language understanding is sometimes referred to as an <link xlink:type="simple" xlink:href="../862/2862.xml">
AI-complete</link> problem, because natural-language recognition seems to require extensive knowledge about the outside world and the ability to manipulate it. The definition of "<link xlink:type="simple" xlink:href="../180/216180.xml">
understanding</link>" is one of the major problems in natural-language processing.</p>

</sec>
<sec>
<st>
Concrete problems</st>

<p>

<indent level="1">

<it>See also: <link xlink:type="simple" xlink:href="../421/368421.xml">
Garden path sentence</link></it>
</indent>
Some examples of the problems faced by natural-language-understanding systems:</p>
<p>

<list>
<entry level="1" type="bullet">

 The sentences <it>We gave the monkeys the bananas because they were hungry</it> and <it>We gave the monkeys the bananas because they were over-ripe</it> have the same surface grammatical structure. However, the pronoun <it>they</it> refers to <it>monkeys</it> in one sentence and <it>bananas</it> in the other, and it is impossible to tell which without a knowledge of the properties of monkeys and bananas.</entry>
<entry level="1" type="bullet">

 A string of words may be interpreted in different ways. For example, the string <it>Time flies like an arrow</it> may be interpreted in a variety of ways:</entry>
<entry level="2" type="bullet">

The common <link xlink:type="simple" xlink:href="../860/28860.xml">
simile</link>: <it><link xlink:type="simple" xlink:href="../012/30012.xml">
time</link></it> moves quickly just like an arrow does;</entry>
<entry level="2" type="bullet">

measure the speed of flies like you would measure that of an arrow (thus interpreted as an imperative) - i.e. <it>(You should) time flies as you would (time) an arrow.</it>;</entry>
<entry level="2" type="bullet">

measure the speed of flies like an arrow would - i.e. <it>Time flies in the same way that an arrow would (time them).</it>;</entry>
<entry level="2" type="bullet">

measure the speed of flies that are like arrows - i.e. <it>Time those flies that are like arrows</it>;</entry>
<entry level="2" type="bullet">

all of a type of flying insect, "time-flies," collectively enjoys a single arrow (compare <it>Fruit flies like a banana</it>);</entry>
<entry level="2" type="bullet">

each of a type of flying insect, "time-flies," individually enjoys a different arrow (similar comparison applies);</entry>
<entry level="2" type="bullet">

A concrete object, for example the magazine, <it><magazine wordnetid="106595351" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../600/31600.xml">
Time</link></magazine>
</it>, travels through the air in an arrow-like manner.</entry>
</list>
</p>
<p>

English is particularly challenging in this regard because it has little <link xlink:type="simple" xlink:href="../799/1790799.xml">
inflectional morphology</link> to distinguish between <link xlink:type="simple" xlink:href="../059/45059.xml">
parts of speech</link>.</p>
<p>

<list>
<entry level="1" type="bullet">

 English and several other languages don't specify which word an adjective applies to. For example, in the string "pretty little girls' school".</entry>
<entry level="2" type="bullet">

 Does the school look little?</entry>
<entry level="2" type="bullet">

 Do the girls look little?</entry>
<entry level="2" type="bullet">

 Do the girls look pretty?</entry>
<entry level="2" type="bullet">

 Does the school look pretty?</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 We will often imply additional information in spoken language by the way we place stress on words. The sentence "I never said she stole my money" demonstrates the importance stress can play in a sentence, and thus the inherent difficulty a natural language processor can have in parsing it. Depending on which word the speaker places the stress, this sentence could have several distinct meanings:</entry>
<entry level="2" type="bullet">

 "<b>I</b> never said she stole my money" - Someone else said it, but <it>I</it> didn't.</entry>
<entry level="2" type="bullet">

 "I <b>never</b> said she stole my money" - I simply didn't ever say it.</entry>
<entry level="2" type="bullet">

 "I never <b>said</b> she stole my money" - I might have implied it in some way, but I never explicitly said it.</entry>
<entry level="2" type="bullet">

 "I never said <b>she</b> stole my money" - I said someone took it; I didn't say it was she.</entry>
<entry level="2" type="bullet">

 "I never said she <b>stole</b> my money" - I just said she probably borrowed it.</entry>
<entry level="2" type="bullet">

 "I never said she stole <b>my</b> money" - I said she stole someone else's money.</entry>
<entry level="2" type="bullet">

 "I never said she stole my <b>money</b>" - I said she stole something, but not my money.</entry>
</list>
</p>

</sec>
<sec>
<st>
Subproblems</st>
<p>

<list>
<entry level="1" type="definition">

 <link xlink:type="simple" xlink:href="../403/4273403.xml">
Speech segmentation</link>: In most spoken languages, the sounds representing successive letters blend into each other, so the conversion of the analog signal to discrete characters can be a very difficult process.  Also, in <link xlink:type="simple" xlink:href="../173/21173.xml">
natural speech</link> there are hardly any pauses between successive words; the location of those boundaries usually must take into account <link xlink:type="simple" xlink:href="../569/12569.xml">
grammatical</link> and <link xlink:type="simple" xlink:href="../107/29107.xml">
semantic</link> constraints, as well as the <entity wordnetid="100001740" confidence="0.8">
<link xlink:type="simple" xlink:href="../834/169834.xml">
context</link></entity>
.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="definition">

 <link xlink:type="simple" xlink:href="../339/4274339.xml">
Text segmentation</link>: Some written languages like <language wordnetid="106282651" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../751/5751.xml">
Chinese</link></language>
, <language wordnetid="106282651" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../606/15606.xml">
Japanese</link></language>
 and <language wordnetid="106282651" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../647/48647.xml">
Thai</link></language>
 do not have single-word boundaries either, so any significant text <link xlink:type="simple" xlink:href="../015/310015.xml">
parsing</link> usually requires the identification of word boundaries, which is often a non-trivial task.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="definition">

 <link xlink:type="simple" xlink:href="../065/67065.xml">
Word sense disambiguation</link>: Many words have more than one <link xlink:type="simple" xlink:href="../916/18916.xml">
meaning</link>; we have to select the meaning which makes the most sense in context.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="definition">

 <link xlink:type="simple" xlink:href="../040/154040.xml">
Syntactic ambiguity</link>: The <link xlink:type="simple" xlink:href="../569/12569.xml">
grammar</link> for <link xlink:type="simple" xlink:href="../173/21173.xml">
natural language</link>s is <link xlink:type="simple" xlink:href="../677/677.xml">
ambiguous</link>, i.e. there are often multiple possible <link xlink:type="simple" xlink:href="../404/118404.xml">
parse tree</link>s for a given sentence. Choosing the most appropriate one usually requires <link xlink:type="simple" xlink:href="../107/29107.xml">
semantic</link> and contextual information. Specific problem components of syntactic ambiguity include <link xlink:type="simple" xlink:href="../062/5950062.xml">
sentence boundary disambiguation</link>.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="definition">

 Imperfect or irregular input : Foreign or regional accents and vocal impediments in speech; typing or grammatical errors, <software wordnetid="106566077" confidence="0.8">
<application wordnetid="106570110" confidence="0.8">
<program wordnetid="106568978" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106359877" confidence="0.8">
<code wordnetid="106355894" confidence="0.8">
<coding_system wordnetid="106353757" confidence="0.8">
<link xlink:type="simple" xlink:href="../091/49091.xml">
OCR</link></coding_system>
</code>
</writing>
</written_communication>
</program>
</application>
</software>
 errors in texts.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="definition">

 <link xlink:type="simple" xlink:href="../836/44836.xml">
Speech acts</link> and plans: A sentence can often be considered an action by the speaker.  The sentence structure, alone, may not contain enough information to define this action.  For instance, a question is actually the speaker requesting some sort of response from the listener.  The desired response may be verbal, physical, or some combination.  For example, "Can you pass the class?" is a request for a simple yes-or-no answer, while "Can you pass the salt?" is requesting a physical action to be performed.  It is not appropriate to respond with "Yes, I can pass the salt," without the accompanying action (although "No" or "I can't reach the salt" would explain a lack of action).</entry>
</list>
</p>

</sec>
<sec>
<st>
 Statistical NLP </st>

<p>

<indent level="1">

<it>Main article: <model wordnetid="105890249" confidence="0.8">
<idea wordnetid="105833840" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<hypothesis wordnetid="105888929" confidence="0.8">
<link xlink:type="simple" xlink:href="../160/13805160.xml">
statistical natural language processing</link></hypothesis>
</concept>
</idea>
</model>
</it>
</indent>
Statistical natural-language processing uses <link xlink:type="simple" xlink:href="../222/292222.xml">
stochastic</link>, <link xlink:type="simple" xlink:href="../934/22934.xml">
probabilistic</link> and <link xlink:type="simple" xlink:href="../685/26685.xml">
statistical</link> methods to resolve some of the difficulties discussed above, especially those which arise because longer sentences are highly ambiguous when processed with realistic grammars, yielding thousands or millions of possible analyses. Methods  for disambiguation often involve the use of <link>
 corpora</link> and <link xlink:type="simple" xlink:href="../876/60876.xml">
Markov model</link>s. Statistical NLP comprises all quantitative approaches to automated language processing, including probabilistic modeling, <link xlink:type="simple" xlink:href="../773/14773.xml">
information theory</link>, and <link xlink:type="simple" xlink:href="../422/18422.xml">
linear algebra</link><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref>. The
technology for statistical NLP comes mainly from <link xlink:type="simple" xlink:href="../488/233488.xml">
machine learning</link> and <link xlink:type="simple" xlink:href="../253/42253.xml">
data mining</link>, both of which are fields of <link xlink:type="simple" xlink:href="../164/1164.xml">
artificial intelligence</link>
that involve learning from data.</p>

</sec>
<sec>
<st>
Major tasks in NLP</st>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../199/637199.xml">
Automatic summarization</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../348/9068348.xml">
Foreign language reading aid</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../548/6727548.xml">
Foreign language writing aid</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../162/383162.xml">
Information extraction</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../271/15271.xml">
Information retrieval</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../980/19980.xml">
Machine translation</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../608/1906608.xml">
Named entity recognition</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../999/301999.xml">
Natural language generation</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../778/98778.xml">
Natural language understanding</link></entry>
<entry level="1" type="bullet">

 <software wordnetid="106566077" confidence="0.8">
<application wordnetid="106570110" confidence="0.8">
<program wordnetid="106568978" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106359877" confidence="0.8">
<code wordnetid="106355894" confidence="0.8">
<coding_system wordnetid="106353757" confidence="0.8">
<link xlink:type="simple" xlink:href="../091/49091.xml">
Optical character recognition</link></coding_system>
</code>
</writing>
</written_communication>
</program>
</application>
</software>
</entry>
<entry level="1" type="bullet">

 <software wordnetid="106566077" confidence="0.8">
<application wordnetid="106570110" confidence="0.8">
<program wordnetid="106568978" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106359877" confidence="0.8">
<code wordnetid="106355894" confidence="0.8">
<coding_system wordnetid="106353757" confidence="0.8">
<link xlink:type="simple" xlink:href="../030/360030.xml">
Question answering</link></coding_system>
</code>
</writing>
</written_communication>
</program>
</application>
</software>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../468/29468.xml">
Speech recognition</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../416/13689416.xml">
Spoken dialogue system</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../588/7794588.xml">
Text simplification</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../799/42799.xml">
Text to speech</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../637/234637.xml">
Text-proofing</link></entry>
</list>
</p>

</sec>
<sec>
<st>
 Evaluation of natural language processing </st>


<ss1>
<st>
Objectives</st>
<p>

The goal of NLP evaluation is to measure one or more <it>qualities</it> of an algorithm or a system, in order to determine if (or to what extent) the system answers the goals of its designers, or the needs of its users.  Research in NLP evaluation has received considerable attention, because the definition of proper evaluation criteria is one way to specify precisely an NLP problem, going thus beyond the vagueness of tasks defined only as <it>language understanding</it> or <it>language generation</it>.  A precise set of evaluation criteria, which includes mainly evaluation data and evaluation metrics, enables several teams to compare their solutions to a given NLP problem.</p>

</ss1>
<ss1>
<st>
Short history of evaluation in NLP</st>
<p>

The first evaluation campaign on written texts seems to be a campaign dedicated to message understanding in 1987 (Pallet 1998). Then, the Parseval/GEIG project compared phrase-structure grammars (Black 1991). A series of campaigns within Tipster project were realized on tasks like summarization, translation and searching (Hirshman 1998). In 1994, in Germany, the Morpholympics compared German taggers. Then, the Senseval  and Romanseval campaigns were conducted with the objectives of semantic disambiguation. In 1996, the Sparkle campaign compared syntactic parsers in four different languages (English, French, German and Italian). In France, the Grace project compared a set of 21 taggers for French in 1997 (Adda 1999). In 2004, during the <link xlink:type="simple" xlink:href="../546/14950546.xml">
Technolangue/Easy</link> project, 13 parsers for French were compared. Large-scale evaluation of dependency parsers were performed in the context of the CoNLL shared tasks in 2006 and 2007. In Italy, the evalita campaign was conducted in 2007 to compare various tools for Italian <weblink xlink:type="simple" xlink:href="http://evalita.itc.it">
evalita web site</weblink>. In France, within the ANR-Passage project (end of 2007), 10 parsers for French were compared <weblink xlink:type="simple" xlink:href="http://atoll.inria.fr/passage/">
passage web site</weblink>. </p>
<p>

Adda G., Mariani J., Paroubek P., Rajman M. 1999 L'action GRACE d'évaluation de l'assignation des parties du discours pour le français. Langues vol-2
Black E., Abney S., Flickinger D., Gdaniec C., Grishman R., Harrison P., Hindle D., Ingria R., Jelinek F., Klavans J., Liberman M., Marcus M., Reukos S., Santoni B., Strzalkowski T. 1991 A procedure for quantitatively comparing the syntactic coverage of English grammars. DARPA Speech and Natural Language Workshop
Hirshman L. 1998 Language understanding evaluation: lessons learned from MUC and ATIS. LREC Granada
Pallet D.S. 1998 The NIST role in automatic speech recognition benchmark tests. LREC Granada</p>

</ss1>
<ss1>
<st>
Different types of evaluation</st>
<p>

Depending on the evaluation procedures, a number of distinctions are traditionally made in NLP evaluation.</p>
<p>

<list>
<entry level="1" type="bullet">

 Intrinsic vs. extrinsic evaluation</entry>
</list>
</p>
<p>

Intrinsic evaluation considers an isolated NLP system and characterizes its performance mainly with respect to a <it>gold standard</it> result, pre-defined by the evaluators.  Extrinsic evaluation, also called <it>evaluation in use</it> considers the NLP system in a more complex setting, either as an embedded system or serving a precise function for a human user.  The extrinsic performance of the system is then characterized in terms of its utility with respect to the overall task of the complex system or the human user.</p>
<p>

<list>
<entry level="1" type="bullet">

 Black-box vs. glass-box evaluation</entry>
</list>
</p>
<p>

Black-box evaluation requires one to run an NLP system on a given data set and to measure a number of parameters related to the quality of the process (speed, reliability, resource consumption) and, most importantly, to the quality of the result (e.g. the accuracy of data annotation or the fidelity of a translation).  Glass-box evaluation looks at the design of the system, the algorithms that are implemented, the linguistic resources it uses (e.g. vocabulary size), etc.  Given the complexity of NLP problems, it is often difficult to predict performance only on the basis of glass-box evaluation, but this type of evaluation is more informative with respect to error analysis or future developments of a system.     </p>
<p>

<list>
<entry level="1" type="bullet">

 Automatic vs. manual evaluation</entry>
</list>
</p>
<p>

In many cases, automatic procedures can be defined to evaluate an NLP system by comparing its output with the gold standard (or desired) one.  Although the cost of producing the gold standard can be quite high, automatic evaluation can be repeated as often as needed without much additional costs (on the same input data).  However, for many NLP problems, the definition of a gold standard is a complex task, and can prove impossible when inter-annotator agreement is insufficient.  Manual evaluation is performed by human judges, which are instructed to estimate the quality of a system, or most often of a sample of its output, based on a number of criteria.  Although, thanks to their linguistic competence, human judges can be considered as the reference for a number of language processing tasks, there is also considerable variation across their ratings.  This is why automatic evaluation is sometimes referred to as <it>objective</it> evaluation, while the human kind appears to be more <it>subjective.</it></p>

</ss1>
<ss1>
<st>
 Shared tasks (Campaigns)</st>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../381/2948381.xml">
BioCreative</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../820/6652820.xml">
Message Understanding Conference</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../546/14950546.xml">
Technolangue/Easy</link></entry>
<entry level="1" type="bullet">

 <event wordnetid="100029378" confidence="0.8">
<social_event wordnetid="107288639" confidence="0.8">
<contest wordnetid="107456188" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<link xlink:type="simple" xlink:href="../206/1897206.xml">
Text Retrieval Conference</link></psychological_feature>
</contest>
</social_event>
</event>
</entry>
</list>
</p>

</ss1>
</sec>
<sec>
<st>
Standardization in NLP</st>
<p>

An ISO sub-committee is working in order to ease interoperability between <link xlink:type="simple" xlink:href="../288/14948288.xml">
Lexical resource</link>s and NLP programs. The sub-committee is part of <link xlink:type="simple" xlink:href="../940/11234940.xml">
ISO/TC37</link> and is called ISO/TC37/SC4. Some ISO standards are already published but most of them are under construction, mainly on lexicon representation (see <link xlink:type="simple" xlink:href="../562/14907562.xml">
LMF</link>), annotation and data category registry.</p>

</sec>
<sec>
<st>
Journals</st>
<p>

<list>
<entry level="1" type="bullet">

 <link>
Computational Linguistics</link></entry>
<entry level="1" type="bullet">

 <link>
Language Resources and Evaluation</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../063/13700063.xml">
Linguistic Issues in Language Technology</link></entry>
</list>
</p>

</sec>
<sec>
<st>
Organizations and conferences</st>

<ss1>
<st>
Associations</st>
<p>

<list>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../058/644058.xml">
Association for Computational Linguistics</link></entry>
<entry level="1" type="bullet">

<link>
Association for Machine Translation in the Americas</link></entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../758/2891758.xml">
AFNLP</link> - Asian Federation of Natural Language Processing Associations</entry>
<entry level="1" type="bullet">

<link>
Australasian Language Technology Association</link> (ALTA)</entry>
</list>

</p>
</ss1>
<ss1>
<st>
Conferences</st>
<p>

<list>
<entry level="1" type="bullet">

 <link>
 Language Resources and Evaluation</link></entry>
</list>
</p>

</ss1>
</sec>
<sec>
<st>
 Software tools </st>
<p>

<list>
<entry level="1" type="bullet">

 <software wordnetid="106566077" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../152/11270152.xml">
General Architecture for Text Engineering</link></software>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../566/1661566.xml">
Natural Language Toolkit</link> (NLTK): a <programming_language wordnetid="106898352" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../862/23862.xml">
Python</link></programming_language>
 library suite</entry>
<entry level="1" type="bullet">

 <company wordnetid="108058098" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../199/11996199.xml">
Expert System S.p.A.</link></company>
</entry>
<entry level="1" type="bullet">

 <link>
OpenNLP</link></entry>
</list>
</p>

</sec>
<sec>
<st>
 See also </st>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../178/2948178.xml">
Biomedical text mining</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../349/148349.xml">
Chatterbot</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../649/18046649.xml">
Compound term processing</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../561/5561.xml">
Computational linguistics</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../145/6227145.xml">
Computer-assisted reviewing</link></entry>
<entry level="1" type="bullet">

 <language wordnetid="106282651" confidence="0.8">
<link xlink:type="simple" xlink:href="../439/563439.xml">
Controlled natural language</link></language>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../008/252008.xml">
Human language technology</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../271/15271.xml">
Information retrieval</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../427/689427.xml">
Latent semantic indexing</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../562/14907562.xml">
Lexical markup framework</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../156/18933156.xml">
lojban</link> / <link xlink:type="simple" xlink:href="../922/17922.xml">
loglan</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../810/3005810.xml">
Transderivational search</link></entry>
</list>
</p>

<ss1>
<st>
Implementations</st>
<p>

<list>
<entry level="1" type="bullet">

 <company wordnetid="108058098" confidence="0.8">
<institution wordnetid="108053576" confidence="0.8">
<link xlink:type="simple" xlink:href="../635/17577635.xml">
Infonic</link></institution>
</company>
 Sentiment, an NLP-based news analysis software package that reads news flows and provides <link xlink:type="simple" xlink:href="../956/2852956.xml">
news sentiment</link> signals for the <link xlink:type="simple" xlink:href="../768/2484768.xml">
algorithmic trading</link> systems of <link xlink:type="simple" xlink:href="../118/163118.xml">
investment bank</link>s</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../730/3599730.xml">
LinguaStream</link>, a generic platform for NLP experimentation</entry>
<entry level="1" type="bullet">

 <work wordnetid="100575741" confidence="0.8">
<structure wordnetid="104341686" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<area wordnetid="102735688" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<library wordnetid="103660909" confidence="0.8">
<undertaking wordnetid="100795720" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<room wordnetid="104105893" confidence="0.8">
<link xlink:type="simple" xlink:href="../686/2069686.xml">
MARF</link></room>
</activity>
</psychological_feature>
</act>
</undertaking>
</library>
</event>
</area>
</artifact>
</structure>
</work>
, a framework for voice and <model wordnetid="105890249" confidence="0.8">
<idea wordnetid="105833840" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<hypothesis wordnetid="105888929" confidence="0.8">
<link xlink:type="simple" xlink:href="../160/13805160.xml">
statistical NLP processing</link></hypothesis>
</concept>
</idea>
</model>
</entry>
<entry level="1" type="bullet">

 <artifact wordnetid="100021939" confidence="0.8">
<merchandise wordnetid="103748886" confidence="0.8">
<commodity wordnetid="103076708" confidence="0.8">
<link xlink:type="simple" xlink:href="../930/14990930.xml">
Nortel Speech Server</link></commodity>
</merchandise>
</artifact>
, a <link xlink:type="simple" xlink:href="../448/28448.xml">
speech processing</link> system primarily used for large-vocabulary <link xlink:type="simple" xlink:href="../468/29468.xml">
speech recognition</link>, natural-language understanding, <link xlink:type="simple" xlink:href="../799/42799.xml">
text-to-speech</link>, and <link xlink:type="simple" xlink:href="../254/1032254.xml">
speaker verification</link></entry>
</list>
</p>

</ss1>
</sec>
<sec>
<st>
References</st>

<p>

<reflist>
<entry id="1">
 Christopher D. Manning, Hinrich Schutze <it>Foundations of Statistical Natural Language Processing</it>, MIT Press (1999), ISBN 978-0262133609, p. xxxi</entry>
</reflist>
</p>

<ss1>
<st>
Related academic articles</st>
<p>

<list>
<entry level="1" type="bullet">

 Bates, M. (1995). Models of natural language understanding.  Proceedings of the National Academy of Sciences of the United States of America, Vol. 92, No. 22 (Oct. 24, 1995), pp. 9977-9982.</entry>
</list>
</p>

</ss1>
</sec>
<sec>
<st>
External links</st>


<ss1>
<st>
Resources</st>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.cs.technion.ac.il/~gabr/resources/resources.html">
Resources for Text, Speech and Language Processing</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.proxem.com/Resources/tabid/54/Default.aspx">
A comprehensive list of resources, classified by category</weblink></entry>
<entry level="1" type="bullet">

 [https://kitwiki.csc.fi/twiki/bin/view/FiLT/FiLTWikiEn Language Technology Documentation Centre in Finland (FiLT)]</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://specgram.com/CLIII.4/08.phlogiston.cartoon.zhe.html">
Some simple examples of NLP-hard utterances.</weblink></entry>
</list>
</p>

</ss1>
<ss1>
<st>
Organizations</st>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://nlp.stanford.edu/">
The Stanford Natural Language Processing Group</weblink></entry>
</list>
</p>



</ss1>
</sec>
</bdy>
</article>
