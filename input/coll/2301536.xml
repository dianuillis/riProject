<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 19:34:28[mciao0827] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Coupling Facility</title>
<id>2301536</id>
<revision>
<id>225986133</id>
<timestamp>2008-07-16T09:45:02Z</timestamp>
<contributor>
<username>MartinPackerIBM</username>
<id>3587591</id>
</contributor>
</revision>
<categories>
<category>IBM mainframe technology</category>
</categories>
</header>
<bdy>

In <company wordnetid="108058098" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../259/18622259.xml">
IBM</link></company>
 <link xlink:type="simple" xlink:href="../266/20266.xml">
mainframe computer</link>s, a <b>Coupling Facility</b> or <b>CF</b> is a piece of <link xlink:type="simple" xlink:href="../310/5310.xml">
computer hardware</link> which allows multiple processors to access the same data.  <p>

A <link>
Parallel Sysplex</link> relies on one or more Coupling Facilities (CFs). A coupling facility is a mainframe processor, with memory and special channels (CF Links), and a specialised operating system called Coupling Facility Control Code (CFCC). It has no I/O devices, other than the CF links. The information in the CF resides entirely in memory as CFCC is not a <link xlink:type="simple" xlink:href="../354/32354.xml">
virtual memory</link> operating system. A CF typically has a large memory - of the order of several gigabytes. In principle any IBM mainframe can serve as a coupling facility. The CF runs no application software.</p>
<p>

Supported by CFs, a Sysplex cluster scales very well up to several hundreds of CPUs (in up to 32 members, each with up to 64 CPUs) running transaction and data base applications. Using the CF links, data can be directly exchanged between the CF memory and the memory of the attached systems, using a <link xlink:type="simple" xlink:href="../717/57717.xml">
direct memory access</link> like mechanism, without interrupting a running program. Systems in a Sysplex cluster store CF information in local memory in an area called a bit vector. This enables them to locally query critical state information of other systems in the Sysplex without the need for issuing requests to the CF. The System z Architecture includes 18 special machine instructions and additional hardware features supporting CF operation.
</p>
<ss1>
<st>
Coupling Facility Structures</st>
<p>

A CF is used for three purposes:
<list>
<entry level="1" type="bullet">

Locking information that is shared among all attached systems</entry>
<entry level="1" type="bullet">

Cache information (such as for a data base) that is shared among all attached systems (or maintaining coherency between local buffer pools in each system).</entry>
<entry level="1" type="bullet">

Data list information that is shared among all attached systems</entry>
</list>

These three purposes are catered for by three types of structure:
<list>
<entry level="1" type="bullet">

<b>Lock</b></entry>
<entry level="1" type="bullet">

<b>Cache</b></entry>
<entry level="1" type="bullet">

<b>List</b> (and the variant <b>Serialised List</b>)</entry>
</list>

A structure is a dedicated portion of CF memory. It is said to be connected to by specific CF-exploiting applications on the coupled <link xlink:type="simple" xlink:href="../122/39122.xml">
z/OS</link> systems. A typical <link>
Parallel Sysplex</link> contains several structures of each type. Each software exploiter may use several structures of each type. For example each <system wordnetid="104377057" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<link>
DB2</link></instrumentality>
</artifact>
</system>
 <b>Data Sharing Group</b> uses one Lock structure, one List structure and several cache structures (one for each Group Buffer Pool (GBP)).</p>

</ss1>
<ss1>
<st>
Structure Duplexing</st>
<p>

Structures may be <b>duplexed</b> across <b>different</b> CFs, allowing two copies of the same structure to be kept synchronised. Duplexing is often used as part of an installation's drive to remove single points of failure, with the aim of reducing the incidence and duration of application outages. In the event of the failure of one CF, the other copy of the structure is used to satisfy all requests.</p>

</ss1>
<ss1>
<st>
Coupling Facility Requests</st>
<p>

A request to a CF structure is of one of two kinds:
<list>
<entry level="1" type="bullet">

<b>Synchronous</b> (sync) requests. When a <link xlink:type="simple" xlink:href="../122/39122.xml">
z/OS</link> system issues a request it waits for the request to complete, actively "spinning" on one of its own processors. Sync requests are quick but the response time is the same as the  coupled system's "spinning" CPU loss. So Sync requests are relatively expensive in CPU terms - from the coupled system's perspective.</entry>
<entry level="1" type="bullet">

<b>Asynchronous</b> (async) requests. When a <link xlink:type="simple" xlink:href="../122/39122.xml">
z/OS</link> system issues a request it doesn't wait for the request to complete. Async requests are slower than sync requests (as they have a lower priority in the CF) but don't lead to the coupled system's processor "spinning".</entry>
</list>

Exploiting z/OS applications explicitly issue CF requests as synch or asynch.</p>

<ss2>
<st>
Dynamic Request Conversion</st>
<p>

In <link xlink:type="simple" xlink:href="../122/39122.xml">
z/OS</link> Release 2, the "Dynamic Request Conversion" heuristic algorithm was introduced. This uses sampled response times to decide whether to convert Sync requests to Async or not. These decisions are based on such criteria as coupled processor speed. The greater the distance between the coupled <link xlink:type="simple" xlink:href="../122/39122.xml">
z/OS</link> system and the CF the greater the likelihood requests will be converted to Async from Sync.</p>
<p>

Async requests are never converted to Sync.</p>
<p>

This heuristic algorithm complements a previously-existing algorithm that automatically (but not heuristically) converted requests, based on conditions such as path busy and on request data size. The difference is the new algorithm samples response times dynamically.</p>
<p>

CFs are unique to S/390, zSeries and System z mainframes. They are key to <link xlink:type="simple" xlink:href="../356/2301356.xml">
Parallel Sysplex</link> technology.</p>

</ss2>
</ss1>
<ss1>
<st>
Coupling Facility Levels and Exploiting Software Levels</st>

<p>

The CFCC code is released as "Levels", usually denoted by their "CFLEVEL". For example, CFLEVEL 15 was announced in April 2007. Each level brings new function and sometimes improved performance. In most cases the new function or performance improvement requires a corequisite release of <link xlink:type="simple" xlink:href="../122/39122.xml">
z/OS</link> and perhaps new function in some subsystem (such as <system wordnetid="104377057" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<link xlink:type="simple" xlink:href="../983/142983.xml">
DB2</link></instrumentality>
</artifact>
</system>
). One such example is Coupling Facility Structure Duplexing. (Sometimes support from the operating system and subsystems is available via PTFs rather than a full release.)</p>


</ss1>
</bdy>
</article>
