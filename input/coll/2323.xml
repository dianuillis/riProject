<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 15:21:12[mciao0825] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<idea  confidence="0.8" wordnetid="105833840">
<concept  confidence="0.8" wordnetid="105835747">
<rule  confidence="0.8" wordnetid="105846054">
<header>
<title>Amdahl&apos;s law</title>
<id>2323</id>
<revision>
<id>240690194</id>
<timestamp>2008-09-24T15:14:07Z</timestamp>
<contributor>
<username>Ryankindelan</username>
<id>2353037</id>
</contributor>
</revision>
<categories>
<category>Parallel computing</category>
<category>Rules of thumb</category>
</categories>
</header>
<bdy>

<image location="right" width="300px" src="AmdahlsLaw.svg" type="thumb">
<caption>

The speedup of a program using multiple processors in parallel computing is limited by the sequential fraction of the program. For example, if 95% of the program can be parallelized, the theoretical maximum speedup using parallel computing would be 20x as shown in the diagram, no matter how many processors are used. 
</caption>
</image>
<p>

<b>Amdahl's law</b>, also known as <b>Amdahl's argument</b>,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref> is named after <link xlink:type="simple" xlink:href="../509/6509.xml">
computer architect</link> <physical_entity wordnetid="100001930" confidence="0.8">
<peer wordnetid="109626238" confidence="0.8">
<physicist wordnetid="110428004" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<pioneer wordnetid="110434725" confidence="0.8">
<engineer wordnetid="109615807" confidence="0.8">
<colleague wordnetid="109935990" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<originator wordnetid="110383816" confidence="0.8">
<creator wordnetid="109614315" confidence="0.8">
<associate wordnetid="109816771" confidence="0.8">
<link xlink:type="simple" xlink:href="../897/247897.xml">
Gene Amdahl</link></associate>
</creator>
</originator>
</scientist>
</causal_agent>
</colleague>
</engineer>
</pioneer>
</person>
</physicist>
</peer>
</physical_entity>
, and is used to find the maximum expected improvement to an overall system when only part of the system is improved. It is often used in <link xlink:type="simple" xlink:href="../162/145162.xml">
parallel computing</link> to predict the theoretical maximum <link xlink:type="simple" xlink:href="../612/1448612.xml">
speedup</link> using multiple processors.</p>
<p>

The speedup of a program using multiple processors in parallel computing is limited by the time needed for the sequential fraction of the program. For example, if a program needs 20 hours using a single processor core, and a particular portion of 1 hour can not be parallelized, while the remaining promising portion of 19 hours (95%) can be parallelized, then regardless of how many processors we devote to a parallelized execution of this program, the minimal execution time can not be less than that critical 1 hour.  Hence the speed up is limited up to 20x, as shown in the diagram on the right.</p>

<sec>
<st>
Description</st>
<p>

Amdahl's law is a model for the relationship between the expected speedup of parallelized implementations of an algorithm relative to the serial algorithm, under the assumption that the problem size remains the same when parallelized. For example, if for a given problem size a parallelized implementation of an algorithm can run 12% of the algorithm's operations arbitrarily fast (while the remaining 88% of the operations are not parallelizable), Amdahl's law states that the maximum speedup of the parallelized version is 1/(1 - 0.12) = 1.136 times faster than the non-parallelized implementation.</p>
<p>

More technically, the law is concerned with the speedup achievable from an improvement to a computation that affects a proportion <it>P</it> of that computation where the improvement has a speedup of <it>S</it>. (For example, if an improvement can speed up 30% of the computation, <it>P</it> will be 0.3; if the improvement makes the portion affected twice as fast, <it>S</it> will be 2.) Amdahl's law states that the overall speedup of applying the improvement will be</p>
<p>

<indent level="1">

<math>\frac{1}{(1 - P) + \frac{P}{S}}</math>.
</indent>

To see how this formula was derived, assume that the running time of the old computation was 1, for some unit of time. The running time of the new computation will be the length of time the unimproved fraction takes, (which is 1 &amp;minus; <it>P</it>), plus the length of time the improved fraction takes. The length of time for the improved part of the computation is the length of the improved part's former running time divided by the speedup, making the length of time of the improved part <it>P</it>/<it>S</it>. The final speedup is computed by dividing the old running time by the new running time, which is what the above formula does.</p>
<p>

Here's another example. We are given a task which is split up into four parts: P1 = 11%, P2 = 18%, P3 = 23%, P4 = 48%, which add up to 100%. Then we say P1 is not sped up, so S1 = 1 or 100%, P2 is sped up 5x, so S2 = 500%, P3 is sped up 20x, so S3 = 2000%, and P4 is sped up 1.6x, so S4 = 160%. By using the formula
P1/S1 + P2/S2 + P3/S3 + P4/S4,
we find the running time is
<indent level="1">

0.11/1 + 0.18/5 + 0.23/20 + 0.48/1.6 = 0.4575
</indent>
or a little less than Â½ the original running time which we know is 1. Therefore the overall speed boost is
1/0.4575 = 2.186
or a little more than double the original speed using the formula
(P1/S1 + P2/S2 + P3/S3 + P4/S4)&amp;minus;1.
Notice how the 20x and 5x speedup don't have much effect on the overall speed boost and running time when over half of the task is only sped up 1x, (i.e. not sped up), or 1.6x.</p>

</sec>
<sec>
<st>
 Parallelization </st>
<p>

In the case of parallelization, Amdahl's law states that if <it>P</it> is the proportion of a program that can be made parallel (i.e. benefit from parallelization), and <it>(1 &amp;minus; P)</it> is the proportion that cannot be parallelized (remains serial), then the maximum speedup that can be achieved by using <it>N</it> processors is</p>
<p>

<indent level="1">

<math>\frac{1}{(1-P) + \frac{P}{N}}</math>
</indent>

In the limit, as <it>N</it> tends to <link xlink:type="simple" xlink:href="../698/51698.xml">
infinity</link>, the maximum speedup tends to <it>1 / (1-P)</it>. In practice, performance/price falls rapidly as <it>N</it> is increased once there is even a small component of <it>(1 &amp;minus; P)</it>.</p>
<p>

As an example, if <it>P</it> is 90%, then <it>(1 &amp;minus;  P)</it> is 10%, and the problem can be sped up by a maximum of a factor of 10, no matter how large the value of <it>N</it> used. For this reason, parallel computing is only useful for either small numbers of <link xlink:type="simple" xlink:href="../218/5218.xml">
processor</link>s, or problems with very high values of <it>P</it>: so-called <link xlink:type="simple" xlink:href="../712/1738712.xml">
embarrassingly parallel</link> problems. A great part of the craft of <link xlink:type="simple" xlink:href="../162/145162.xml">
parallel programming</link> consists of attempting to reduce <it>(1-P)</it> to the smallest possible value.</p>

</sec>
<sec>
<st>
Relation to law of diminishing returns</st>
<p>

Amdahl's law is often conflated with the <law wordnetid="108441203" confidence="0.8">
<social_science wordnetid="106143154" confidence="0.8">
<knowledge_domain wordnetid="105999266" confidence="0.8">
<economics wordnetid="106149484" confidence="0.8">
<collection wordnetid="107951464" confidence="0.8">
<group wordnetid="100031264" confidence="0.8">
<discipline wordnetid="105996646" confidence="0.8">
<science wordnetid="105999797" confidence="0.8">
<link xlink:type="simple" xlink:href="../048/762048.xml">
law of diminishing returns</link></science>
</discipline>
</group>
</collection>
</economics>
</knowledge_domain>
</social_science>
</law>
, whereas only a special case of applying Amdahl's law demonstrates 'law of diminishing returns'.  If one picks optimally (in terms of the achieved speed-up) what to improve you will see monotonically decreasing improvements as you improve.  If, however, one picks non-optimally, after improving a sub-optimal component and moving on to improve a more optimal improvement one can see an increase in return. Consider, for instance, the illustration.  If one picks to work on B then A you find an increase in return.  If, instead, one works on improving A then B you will find a diminishing return.  Thus, strictly speaking, only one (optimal case) can appropriately be said to demonstrate 'law of diminishing returns'. Note that it is often rational to improve a system in an order that is "non-optimal" in this sense, given that some improvements are more difficult or consuming of development time than others.</p>
<p>

Amdahl's law does represent the law of diminishing returns if you are considering what sort of return you get by adding more processors to a machine, if you are running a fixed-size computation that will use all available processors to their capacity. Each new processor you add to the system will add less usable power than the previous one. Each time you double the number of processors the speedup ratio will diminish, as the total throughput heads toward the limit of</p>
<p>

<indent level="1">

<math>\frac{1}{(1 - P)}</math>.
</indent>

This analysis neglects other potential bottlenecks such as <link xlink:type="simple" xlink:href="../199/3486199.xml">
memory bandwidth</link> and I/O bandwidth, if they do not scale with the number of processors; however taking into account such bottlenecks would tend to further demonstrate the diminishing returns of only adding processors.</p>

</sec>
<sec>
<st>
 Speedup in a sequential program </st>
<p>

<image width="400px" src="optimizing-different-parts.png" type="thumb">
<caption>

Assume that a task has two independent parts, A and B.  B takes roughly 25% of the time of the whole computation.  By working very hard, one may be able to make this part 5 times faster, but this only reduces the time for the whole computation by a little.  In contrast, one may need to perform less work to make part A be twice as fast.  This will make the computation much faster than by optimizing part B, even though B got a bigger speed-up, (5x versus 2x).
</caption>
</image>

The maximum speedup in an improved sequential program, where some part was sped up by <math>p</math> times is</p>
<p>

<indent level="1">

Max. Speedup <math>\le \frac{p}{1 + f * (p - 1)}</math>
</indent>

where <math>f</math> (<math>0.0 &amp;lt; f &amp;lt; 1.0</math>) is the fraction of time (before the improvement) spent in the part that was not improved. For example,</p>
<p>

<list>
<entry level="1" type="bullet">

If part B (blue) is made five times faster, p = 5.0, <math>t_n</math> (red) = 3 seconds, <math>t_i</math> (blue) = 1 second and</entry>
<entry level="2" type="indent">

<math>f = t_n / (t_n + t_i) = 0.75</math></entry>
<entry level="2" type="indent">

Max. Speedup <math>\le \frac{5}{1 + 0.75 * (5 - 1)} = 1.25</math></entry>
<entry level="1" type="bullet">

If part A (red) is made to run twice as fast, p = 2.0, <math>t_n</math> (blue) = 1 second, <math>t_i</math> (red) = 3 seconds and</entry>
<entry level="2" type="indent">

<math>f = t_n / (t_n + t_i) = 0.25</math></entry>
<entry level="2" type="indent">

Max. Speedup <math>\le \frac{2}{1 + 0.25 * (2 - 1)} = 1.60</math> (better!)</entry>
</list>
</p>
<p>

Therefore, making A twice faster is better than making B five times faster.</p>
<p>

<list>
<entry level="1" type="bullet">

Improving part A by a factor of two will result in a <b>+60%</b> increase in overall program speed.</entry>
<entry level="1" type="bullet">

However, improving part B by a factor of 5 (which presumably requires more effort) will only achieve an overall speedup of <b>+25%</b>.</entry>
</list>
</p>

</sec>
<sec>
<st>
Limitations</st>
<p>

According to Amdahl's law, the theoretical maximum speedup of using N processors would be N, namely <it>linear <link xlink:type="simple" xlink:href="../612/1448612.xml">
speedup</link></it>. However, it is not uncommon to observe more than N speedup on a machine with N processors in practice, namely <it>super linear speedup</it>. One possible reason is the effect of cache aggregation. In parallel computers, not only does the number of processors change, but so does the size of accumulated caches from different processors. With the larger accumulated cache size, more or even the entire data set can fit into caches, dramatically reducing memory access time and producing an additional speedup beyond that arising from pure computation.</p>
<p>

Amdahl's law also doesn't take into account that problem sizes may be scaled with increased number of processors, which typically reduces the relative amount of non-parallelizable tasks.</p>

</sec>
<sec>
<st>
Amdahl's Rule of Thumb</st>



<p>

<b>Amdahl's Rule of Thumb</b> is that 1 byte of <link xlink:type="simple" xlink:href="../844/18844.xml">
memory</link> and 1 byte per second of <link xlink:type="simple" xlink:href="../558/14558.xml">
I/O</link> are required for each <link xlink:type="simple" xlink:href="../801/3149801.xml">
instruction</link> per second supported by a computer.  This also goes by the title <it>Amdahl's Other Law.</it></p>

</sec>
<sec>
<st>
 See also </st>

<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../612/1448612.xml">
Speedup</link></entry>
<entry level="1" type="bullet">

 <company wordnetid="108058098" confidence="0.8">
<institution wordnetid="108053576" confidence="0.8">
<link xlink:type="simple" xlink:href="../650/483650.xml">
Amdahl Corporation</link></institution>
</company>
</entry>
<entry level="1" type="bullet">

 <idea wordnetid="105833840" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<rule wordnetid="105846054" confidence="0.8">
<link xlink:type="simple" xlink:href="../877/42877.xml">
Ninety-ninety rule</link></rule>
</concept>
</idea>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../252/4243252.xml">
Gustafson's Law</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../042/9453042.xml">
Karp-Flatt Metric</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../070/229070.xml">
Brooks's law</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../418/39418.xml">
Moore's Law</link></entry>
</list>
</p>

</sec>
<sec>
<st>
Notes</st>

<p>

<reflist>
<entry id="1">
Rodgers 85, p.226</entry>
</reflist>
</p>

</sec>
<sec>
<st>
References</st>
<p>

<list>
<entry level="1" type="bullet">

 Gene Amdahl, "<weblink xlink:type="simple" xlink:href="http://www-inst.eecs.berkeley.edu/~n252/paper/Amdahl.pdf">
http://www-inst.eecs.berkeley.edu/~n252/paper/Amdahl.pdf</weblink> Validity of the Single Processor Approach to Achieving Large-Scale Computing Capabilities", AFIPS Conference Proceedings, (30), pp. 483-485, 1967. Note: Gene Amdahl has approved the use of his complete text in the Usenet comp.sys.super news group FAQ which goes out on the 20th of each month. </entry>
<entry level="1" type="bullet">

Rodgers, David P. (1985) <it><weblink xlink:type="simple" xlink:href="http://portal.acm.org/citation.cfm?id=327215">
Improvements in multiprocessor system design</weblink></it> ACM SIGARCH Computer Architecture News  archive Volume 13 ,  Issue 3  (June 1985) table of contents Special Issue: Proceedings of the 12th annual <link xlink:type="simple" xlink:href="../099/10029099.xml">
International Symposium on Computer Architecture</link> (ISCA '85) Pages: 225 - 231 Year of Publication: 1985 ISSN:0163-5964. Also published in International Symposium on Computer Architecture, Proceedings of the 12th annual international symposium on Computer architecture, 1985 , Boston, Massachusetts, United States</entry>
</list>
</p>

</sec>
<sec>
<st>
External links</st>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.cbi.umn.edu/oh/display.phtml?id=59">
Gene Amdahl. Oral history interview.</weblink> Charles Babbage Institute, University of Minnesota, Minneapolis.</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.scl.ameslab.gov/Publications/Gus/AmdahlsLaw/Amdahls.html">
Reevaluating Amdahl's Law</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.cis.temple.edu/~shi/docs/amdahl/amdahl.html">
Reevaluating Amdahl's Law and Gustafson's Law</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.julianbrowne.com/article/viewer/amdahls-law">
A simple interactive Amdahl's Law calculator</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://demonstrations.wolfram.com/AmdahlsLaw/">
"Amdahl's Law"</weblink> by Joel F. Klein, <link xlink:type="simple" xlink:href="../109/594109.xml">
The Wolfram Demonstrations Project</link>, 2007.</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.cs.wisc.edu/multifacet/amdahl/">
Amdahl's Law in the Multicore Era</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.cilk.com/multicore-blog/bid/5365/What-the-is-Parallelism-Anyhow">
Blog Post: "What the $#@! is Parallelism, Anyhow?"</weblink></entry>
</list>
</p>

<p>

<table style=";" class="navbox" cellspacing="0">
<row>
<col style="padding:2px;">
<table style="width:100%;background:transparent;color:inherit;;" class="nowraplinks collapsible autocollapse " cellspacing="0">
<row>
<header colspan="2" style=";" class="navbox-title">
<link xlink:type="simple" xlink:href="../162/145162.xml">
Parallel computing</link>topics</header>
</row>
<row style="height:2px;">

</row>
<row>
<col style=";;" class="navbox-group">
General</col>
<col style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<condition wordnetid="113920835" confidence="0.8">
<state wordnetid="100024720" confidence="0.8">
<problem wordnetid="114410605" confidence="0.8">
<difficulty wordnetid="114408086" confidence="0.8">
<link xlink:type="simple" xlink:href="../527/832527.xml">
High-performance computing</link></difficulty>
</problem>
</state>
</condition>
</col>
</row>
<row style="height:2px">

</row>
<row>
<col style=";;" class="navbox-group">
Parallelism</col>
<col style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<link xlink:type="simple" xlink:href="../148/14229148.xml">
Bit-level parallelism</link>&nbsp;Â·  <link xlink:type="simple" xlink:href="../960/245960.xml">
Instruction level parallelism</link>&nbsp;Â·  <link xlink:type="simple" xlink:href="../420/9467420.xml">
Data parallelism</link>&nbsp;Â·  <link xlink:type="simple" xlink:href="../070/9468070.xml">
Task parallelism</link></col>
</row>
<row style="height:2px">

</row>
<row>
<col style=";;" class="navbox-group">
Threads</col>
<col style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<link xlink:type="simple" xlink:href="../877/313877.xml">
Superthreading</link>&nbsp;Â·  <link xlink:type="simple" xlink:href="../443/151443.xml">
Hyperthreading</link></col>
</row>
<row style="height:2px">

</row>
<row>
<col style=";;" class="navbox-group">
Theory</col>
<col style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<link xlink:type="simple" xlink:href="../612/1448612.xml">
Speedup</link>&nbsp;Â·  <idea wordnetid="105833840" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<rule wordnetid="105846054" confidence="0.8">
<link xlink:type="simple" xlink:href="../ury/24th_century.xml">
Amdahl's law</link></rule>
</concept>
</idea>
&nbsp;Â·  <class wordnetid="107997703" confidence="0.8">
<collection wordnetid="107951464" confidence="0.8">
<group wordnetid="100031264" confidence="0.8">
<link xlink:type="simple" xlink:href="../349/222349.xml">
Flynn's taxonomy</link></group>
</collection>
</class>
 (<link xlink:type="simple" xlink:href="../630/1103630.xml">
SISD</link>&nbsp;&amp;bull;  <link xlink:type="simple" xlink:href="../359/55359.xml">
SIMD</link>&nbsp;&amp;bull;  <link xlink:type="simple" xlink:href="../666/991666.xml">
MISD</link>&nbsp;&amp;bull;  <link xlink:type="simple" xlink:href="../139/157139.xml">
MIMD</link>)&nbsp;Â·  <link xlink:type="simple" xlink:href="../721/3505721.xml">
Cost efficiency</link>&nbsp;Â·  <idea wordnetid="105833840" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<rule wordnetid="105846054" confidence="0.8">
<link xlink:type="simple" xlink:href="../252/4243252.xml">
Gustafson's law</link></rule>
</concept>
</idea>
&nbsp;Â·  <link xlink:type="simple" xlink:href="../042/9453042.xml">
Karp-Flatt metric</link>&nbsp;Â·  <link xlink:type="simple" xlink:href="../068/15167068.xml">
Parallel slowdown</link></col>
</row>
<row style="height:2px">

</row>
<row>
<col style=";;" class="navbox-group">
Elements</col>
<col style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<link xlink:type="simple" xlink:href="../178/45178.xml">
Process</link>&nbsp;Â·  <link xlink:type="simple" xlink:href="../303/45303.xml">
Thread</link>&nbsp;Â·  <link xlink:type="simple" xlink:href="../712/5533712.xml">
Fiber</link>&nbsp;Â·  <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../675/956675.xml">
Parallel Random Access Machine</link></causal_agent>
</worker>
</assistant>
</model>
</person>
</physical_entity>
</col>
</row>
<row style="height:2px">

</row>
<row>
<col style=";;" class="navbox-group">
Coordination</col>
<col style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<link xlink:type="simple" xlink:href="../020/64020.xml">
Multiprocessing</link>&nbsp;Â·  <link xlink:type="simple" xlink:href="../679/10520679.xml">
Multithreading</link>&nbsp;Â·  <link xlink:type="simple" xlink:href="../857/6857.xml">
Multitasking</link>&nbsp;Â·  <link xlink:type="simple" xlink:href="../818/399818.xml">
Memory coherency</link>&nbsp;Â·  <link xlink:type="simple" xlink:href="../865/176865.xml">
Cache coherency</link>&nbsp;Â·  <link xlink:type="simple" xlink:href="../263/4736263.xml">
Barrier</link>&nbsp;Â·  <link xlink:type="simple" xlink:href="../017/4726017.xml">
Synchronization</link>&nbsp;Â·  <link xlink:type="simple" xlink:href="../501/8501.xml">
Distributed computing</link>&nbsp;Â·  <link xlink:type="simple" xlink:href="../373/49373.xml">
Grid computing</link></col>
</row>
<row style="height:2px">

</row>
<row>
<col style=";;" class="navbox-group">
<link xlink:type="simple" xlink:href="../311/5311.xml">
Programming</link></col>
<col style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<paradigm wordnetid="113804375" confidence="0.8">
<linguistic_relation wordnetid="113797142" confidence="0.8">
<inflection wordnetid="113803782" confidence="0.8">
<grammatical_relation wordnetid="113796779" confidence="0.8">
<link xlink:type="simple" xlink:href="../375/2242375.xml">
Programming model</link></grammatical_relation>
</inflection>
</linguistic_relation>
</paradigm>
&nbsp;Â·  <link xlink:type="simple" xlink:href="../888/3453888.xml">
Implicit parallelism</link>&nbsp;Â·  <link xlink:type="simple" xlink:href="../332/3095332.xml">
Explicit parallelism</link></col>
</row>
<row style="height:2px">

</row>
<row>
<col style=";;" class="navbox-group">
<link xlink:type="simple" xlink:href="../310/5310.xml">
Hardware</link></col>
<col style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<link xlink:type="simple" xlink:href="../896/18949896.xml">
Computer cluster</link>&nbsp;Â·  <link xlink:type="simple" xlink:href="../542/66542.xml">
Beowulf</link>&nbsp;Â·  <link xlink:type="simple" xlink:href="../318/50318.xml">
Symmetric multiprocessing</link>&nbsp;Â·  <link xlink:type="simple" xlink:href="../643/40643.xml">
Non-Uniform Memory Access</link>&nbsp;Â·  <link xlink:type="simple" xlink:href="../307/910307.xml">
Cache only memory architecture</link>&nbsp;Â·  <link xlink:type="simple" xlink:href="../506/2576506.xml">
Asymmetric multiprocessing</link>&nbsp;Â·  <link xlink:type="simple" xlink:href="../021/315021.xml">
Simultaneous multithreading</link>&nbsp;Â·  <link xlink:type="simple" xlink:href="../653/825653.xml">
Shared memory</link>&nbsp;Â·  <link xlink:type="simple" xlink:href="../887/234887.xml">
Distributed memory</link>&nbsp;Â·  <link xlink:type="simple" xlink:href="../049/584049.xml">
Massive parallel processing</link>&nbsp;Â·  <link xlink:type="simple" xlink:href="../702/51702.xml">
Superscalar processing</link>&nbsp;Â·  <link xlink:type="simple" xlink:href="../205/58205.xml">
Vector processing</link>&nbsp;Â·  <link xlink:type="simple" xlink:href="../153/37153.xml">
Supercomputer</link>&nbsp;Â·  <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<paradigm wordnetid="113804375" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<linguistic_relation wordnetid="113797142" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<inflection wordnetid="113803782" confidence="0.8">
<grammatical_relation wordnetid="113796779" confidence="0.8">
<link xlink:type="simple" xlink:href="../727/2786727.xml">
Stream processing</link></grammatical_relation>
</inflection>
</causal_agent>
</linguistic_relation>
</worker>
</paradigm>
</assistant>
</model>
</person>
</physical_entity>
&nbsp;Â·  <substance wordnetid="100019613" confidence="0.8">
<paper wordnetid="114974264" confidence="0.8">
<card wordnetid="102962545" confidence="0.8">
<part wordnetid="113809207" confidence="0.8">
<material wordnetid="114580897" confidence="0.8">
<link xlink:type="simple" xlink:href="../939/1268939.xml">
GPGPU</link></material>
</part>
</card>
</paper>
</substance>
</col>
</row>
<row style="height:2px">

</row>
<row>
<col style=";;" class="navbox-group">
<link xlink:type="simple" xlink:href="../309/5309.xml">
Software</link></col>
<col style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<link xlink:type="simple" xlink:href="../843/399843.xml">
Distributed shared memory</link> &nbsp;Â·  <link xlink:type="simple" xlink:href="../765/416765.xml">
Application checkpointing</link>&nbsp;Â·  <link xlink:type="simple" xlink:href="../129/2738129.xml">
Warewulf</link></col>
</row>
<row style="height:2px">

</row>
<row>
<col style=";;" class="navbox-group">
<link xlink:type="simple" xlink:href="../ury/24th_century.xml">
API</link>s</col>
<col style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<standard wordnetid="107260623" confidence="0.8">
<system_of_measurement wordnetid="113577171" confidence="0.8">
<link xlink:type="simple" xlink:href="../671/634671.xml">
POSIX Threads</link></system_of_measurement>
</standard>
&nbsp;Â·  <link xlink:type="simple" xlink:href="../842/381842.xml">
OpenMP</link>&nbsp;Â·  <link xlink:type="simple" xlink:href="../466/221466.xml">
Message Passing Interface (MPI)</link>&nbsp;Â·  <link xlink:type="simple" xlink:href="../616/1057616.xml">
UPC</link>&nbsp;Â·  <link xlink:type="simple" xlink:href="../077/11625077.xml">
Intel Threading Building Blocks</link>&nbsp;Â·  <structure wordnetid="104341686" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<area wordnetid="102735688" confidence="0.8">
<library wordnetid="103660909" confidence="0.8">
<room wordnetid="104105893" confidence="0.8">
<link xlink:type="simple" xlink:href="../324/711324.xml#xpointer(//*[./st=%22Multithreading+=E2=80=93+Boost.Thread%22])">
Boost.Thread</link></room>
</library>
</area>
</artifact>
</structure>
</col>
</row>
<row style="height:2px">

</row>
<row>
<col style=";;" class="navbox-group">
Problems</col>
<col style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<system wordnetid="104377057" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<link xlink:type="simple" xlink:href="../712/1738712.xml">
Embarrassingly parallel</link></instrumentality>
</artifact>
</system>
&nbsp;Â·  <condition wordnetid="113920835" confidence="0.8">
<state wordnetid="100024720" confidence="0.8">
<problem wordnetid="114410605" confidence="0.8">
<difficulty wordnetid="114408086" confidence="0.8">
<link xlink:type="simple" xlink:href="../754/439754.xml">
Grand Challenge</link></difficulty>
</problem>
</state>
</condition>
&nbsp;Â·  <plant_part wordnetid="113086908" confidence="0.8">
<natural_object wordnetid="100019128" confidence="0.8">
<kernel wordnetid="113137010" confidence="0.8">
<link xlink:type="simple" xlink:href="../798/12332798.xml">
Software lockout</link></kernel>
</natural_object>
</plant_part>
</col>
</row>
</table>
</col>
</row>
</table>
</p>



</sec>
</bdy>
</rule>
</concept>
</idea>
</article>
