<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 16:34:31[mciao0825] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Numerical stability</title>
<id>233807</id>
<revision>
<id>244230389</id>
<timestamp>2008-10-09T21:49:59Z</timestamp>
<contributor>
<username>Gl270604</username>
<id>7983767</id>
</contributor>
</revision>
<categories>
<category>Numerical analysis</category>
</categories>
</header>
<bdy>

In the <link xlink:type="simple" xlink:href="../831/18831.xml">
mathematical</link> subfield of <link xlink:type="simple" xlink:href="../506/21506.xml">
numerical analysis</link>, <b>numerical stability</b> is a desirable property of numerical <link xlink:type="simple" xlink:href="../775/775.xml">
algorithm</link>s. The precise definition of <it>stability</it> depends on the context, but it is related to the accuracy of the algorithm.<p>

Sometimes a single calculation can be achieved in several ways, all of which are algebraically equivalent in terms of ideal real or complex numbers, but in practice when performed on digital computers yield different results. Some calculations might damp out approximation errors that occur; others might magnify such errors.  Calculations that do not magnify approximation errors are called <it>numerically stable</it>.  One of the common tasks of numerical analysis is to try to select algorithms which are <it>robust</it> &mdash; that is to say, have good numerical stability.</p>

<sec>
<st>
Example</st>

<p>

As an example of an unstable algorithm, consider the task of adding an array of 100 numbers.  To simplify things, assume our computer only has two digits of precision (for example, you can only represent numbers in the hundreds as 100, 110, 120, etc.).</p>
<p>

The obvious way to do this would be the following pseudo-code:</p>
<p>

sum = 0
for i = 1 to 100 do
sum = sum + a[i]
end</p>
<p>

That looks reasonable, but suppose the first element in the array was 1.0 and the other 99 elements were 0.01.  In pure math, the answer would be 1.99.  However, on our two-digit computer, once the 1.0 was added into the sum variable, adding in 0.01 would have no effect on the sum, and so the final answer would be 1.0 – not a very good approximation of the real answer.</p>
<p>

A stable algorithm would first sort the array by the absolute values of the elements in ascending order.  This ensures that the numbers closest to zero will be taken into consideration first.  Once that change is made, all of the 0.01 elements will be added, giving 0.99, and then the 1.0 element will be added, yielding a rounded result of 2.0 – a much better approximation of the real result.</p>

</sec>
<sec>
<st>
Forward, backward, and mixed stability</st>

<p>

There are different ways to formalize the concept of stability. The following definitions of forward, backward, and mixed stability are often used in <link xlink:type="simple" xlink:href="../660/7330660.xml">
numerical linear algebra</link>.</p>
<p>

<image width="150px" src="Forward_and_backward_error.svg" type="frame">
<caption>

Diagram showing the forward error &amp;Delta;<it>y</it> and the backward error &amp;Delta;<it>x</it>, and their relation to the exact solution map <it>f</it> and the numerical solution <it>f</it>*.
</caption>
</image>
</p>
<p>

Consider the problem to be solved by the numerical algorithm as a <link xlink:type="simple" xlink:href="../427/185427.xml">
function</link> <it>f</it> mapping the data <it>x</it> to the solution <it>y</it>. The result of the algorithm, say <it>y</it>*, will usually deviate from the "true" solution <it>y</it>. The main causes of error are <link xlink:type="simple" xlink:href="../450/432450.xml">
round-off error</link>, <link xlink:type="simple" xlink:href="../097/9366097.xml">
truncation error</link> and <link>
data error</link>. The <it>forward error</it> of the algorithm is the difference between the result and the solution; in this case, &amp;Delta;<it>y</it> = <it>y</it>* &amp;minus; <it>y</it>. The <it>backward error</it> is the smallest &amp;Delta;<it>x</it> such that <it>f</it>(<it>x</it> + &amp;Delta;<it>x</it>) = <it>y</it>*; in other words, the backward error tells us what problem the algorithm actually solved. The forward and backward error are related by the <link xlink:type="simple" xlink:href="../934/6934.xml">
condition number</link>: the forward error is at most as big in magnitude as the condition number multiplied by the magnitude of the backward error.</p>
<p>

In many cases, it is more natural to consider the <link xlink:type="simple" xlink:href="../422/640422.xml">
relative error</link> 
<indent level="1">

<math> \frac{|\Delta x|}{|x|} </math>
</indent>
instead of the absolute error &amp;Delta;<it>x</it>.</p>
<p>

The algorithm is said to be <it>backward stable</it> if the backward error is small for all inputs <it>x</it>. Of course, "small" is a relative term and its definition will depend on the context. Often, we want the error to be of the same order as, or perhaps only a few <link xlink:type="simple" xlink:href="../657/22657.xml">
orders of magnitude</link> bigger than, the <link xlink:type="simple" xlink:href="../863/3076863.xml">
unit round-off</link>.</p>
<p>

<image width="150px" src="Mixed_stability_diagram.svg" type="thumb">
<caption>

Mixed stability combines the concepts of forward error and backward error.
</caption>
</image>
</p>
<p>

The usual definition of numerical stability uses a more general concept, called <it>mixed stability</it>, which combines the forward error and the backward error. An algorithm is stable in this sense if it solves a nearby problem approximately, i.e., if there exists a &amp;Delta;<it>x</it> such that both &amp;Delta;<it>x</it> is small and <it>f</it>(<it>x</it> + &amp;Delta;<it>x</it>) &amp;minus; <it>y</it>* is small. Hence, a backward stable algorithm is always stable.</p>
<p>

An algorithm is <it>forward stable</it> if its forward error divided by the condition number of the problem is small. This means that an algorithm is forward stable if it has a forward error of magnitude similar to some backward stable algorithm.</p>






</sec>
<sec>
<st>
 Error Growth </st>
<p>

<image location="right" width="300px" src="errorgrowth.jpg" type="border">
</image>

</p>
<ss2>
<st>
 Definition </st>
<p>

Suppose that Ei &amp;gt; 0 denotes an initial error and En represents the magnitude of an error after n subsequent operations. If En ≈ C*n*Ei, where C is a constant indpendent of n, then the growth of the error is said to be <b>linear</b>. If En ≈ Cn*Ei, for some C &amp;gt; 1, then the growth of the error is called <b>exponential</b>.</p>









</ss2>
</sec>
<sec>
<st>
Stability in numerical differential equations</st>

<p>

The above definitions are particularly relevant in situations where truncation errors are not important. In other contexts, for instance when solving <link xlink:type="simple" xlink:href="../309/1424309.xml">
differential equation</link>s, a different definition of numerical stability is used.</p>
<p>

In <link xlink:type="simple" xlink:href="../829/272829.xml">
numerical ordinary differential equations</link>, various concepts of numerical stability exist, for instance <link xlink:type="simple" xlink:href="../823/2091823.xml">
A-stability</link>. They are related to some concept of stability in the <link xlink:type="simple" xlink:href="../632/990632.xml">
dynamical systems</link> sense, often <link xlink:type="simple" xlink:href="../360/363360.xml">
Lyapunov stability</link>. It is important to use a stable method when solving a <link xlink:type="simple" xlink:href="../823/2091823.xml">
stiff equation</link>.</p>
<p>

Yet another definition is used in <link xlink:type="simple" xlink:href="../583/1634583.xml">
numerical partial differential equations</link>. An algorithm for solving an evolutionary <link xlink:type="simple" xlink:href="../564/52564.xml">
partial differential equation</link> is stable if the numerical solution at a fixed time remains bounded as the step size goes to zero. The <statement wordnetid="106722453" confidence="0.8">
<message wordnetid="106598915" confidence="0.8">
<equation wordnetid="106669864" confidence="0.8">
<mathematical_statement wordnetid="106732169" confidence="0.8">
<link xlink:type="simple" xlink:href="../809/7018809.xml">
Lax equivalence theorem</link></mathematical_statement>
</equation>
</message>
</statement>
 states that an algorithm converges if it is consistent and stable (in this sense). Stability is sometimes achieved by including <link xlink:type="simple" xlink:href="../898/2785898.xml">
numerical diffusion</link>.  Numerical diffusion is a mathematical term which ensures that roundoff and other errors in the calculation get spread out and do not add up to cause the calculation to "blow up".</p>

</sec>
<sec>
<st>
References</st>
<p>

<list>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../004/10011004.xml">
Nicholas J. Higham</link>, <it>Accuracy and Stability of Numerical Algorithms</it>, Society of Industrial and Applied Mathematics, Philadelphia, 1996. ISBN 0-89871-355-2.</entry>
<entry level="1" type="bullet">

Richard L. Burden and J. Douglas Faires, <it>Numerical Analysis 8th Edition</it>, Thomson Brooks/Cole, U.S., 2005. ISBN 0-534-39200-8</entry>
</list>
</p>


</sec>
</bdy>
</article>
