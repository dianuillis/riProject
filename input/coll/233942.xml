<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 16:36:17[mciao0826] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Affective computing</title>
<id>233942</id>
<revision>
<id>230295359</id>
<timestamp>2008-08-06T23:07:04Z</timestamp>
<contributor>
<username>Proteus</username>
<id>21902</id>
</contributor>
</revision>
<categories>
<category>Feeling</category>
<category>Artificial intelligence</category>
<category>Wikipedia articles needing clarification</category>
</categories>
</header>
<bdy>

<indent level="1">

<it>Affective Computing is also the title of a textbook on the subject by <physical_entity wordnetid="100001930" confidence="0.8">
<peer wordnetid="109626238" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<engineer wordnetid="109615807" confidence="0.8">
<colleague wordnetid="109935990" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<research_worker wordnetid="110523076" confidence="0.8">
<associate wordnetid="109816771" confidence="0.8">
<link xlink:type="simple" xlink:href="../761/4316761.xml">
Rosalind Picard</link></associate>
</research_worker>
</scientist>
</causal_agent>
</colleague>
</engineer>
</person>
</peer>
</physical_entity>
.</it>
</indent>

<b>Affective computing</b> is a branch of the study and development of <link xlink:type="simple" xlink:href="../164/1164.xml">
artificial intelligence</link> that deals with the design of systems and devices that can recognize, interpret, and process human <link xlink:type="simple" xlink:href="../406/10406.xml">
emotions</link>. It is an interdisciplinary field spanning <link xlink:type="simple" xlink:href="../323/5323.xml">
computer sciences</link>, <link xlink:type="simple" xlink:href="../921/22921.xml">
psychology</link>, and <link xlink:type="simple" xlink:href="../626/5626.xml">
cognitive science</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref> While the origins of the field may be traced as far back as to early philosophical enquiries into <link xlink:type="simple" xlink:href="../406/10406.xml#xpointer(//*[./st=%22The_James-Lange_Theory%22])">
emotion</link>,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref> the more modern branch of computer science originated with <physical_entity wordnetid="100001930" confidence="0.8">
<peer wordnetid="109626238" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<engineer wordnetid="109615807" confidence="0.8">
<colleague wordnetid="109935990" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<research_worker wordnetid="110523076" confidence="0.8">
<associate wordnetid="109816771" confidence="0.8">
<link xlink:type="simple" xlink:href="../761/4316761.xml">
Rosalind Picard</link></associate>
</research_worker>
</scientist>
</causal_agent>
</colleague>
</engineer>
</person>
</peer>
</physical_entity>
's 1995 paper<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%223%22])">3</ref> on affective computing.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%224%22])">4</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%225%22])">5</ref>
<sec>
<st>
Areas of affective computing</st>

<ss1>
<st>
Detecting and recognizing emotional information</st>
<p>

Detecting emotional information begins with passive <link xlink:type="simple" xlink:href="../757/235757.xml">
sensors</link> which capture data about the user's physical state or behavior without interpreting the input. The data gathered is analogous to the cues humans use to perceive emotions in others. For example, a video camera might capture facial expressions, body posture and gestures, while a microphone might capture speech. Other sensors detect emotional cues by directly measuring <link xlink:type="simple" xlink:href="../597/23597.xml">
physiological</link> data, such as skin temperature and <link xlink:type="simple" xlink:href="../343/1001343.xml">
galvanic resistance</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref></p>
<p>

Recognizing emotional information requires the extraction of meaningful patterns from the gathered data. This is done by parsing the data through various processes such as <link xlink:type="simple" xlink:href="../468/29468.xml">
speech recognition</link>, <link xlink:type="simple" xlink:href="../652/21652.xml">
natural language processing</link>, or <link xlink:type="simple" xlink:href="../595/486595.xml">
facial expression detection</link>, all of which are dependent on the human factor vis-a-vis programming.</p>

</ss1>
<ss1>
<st>
Emotion in machines</st>
<p>

Another area within affective computing is the design of computational devices proposed to exhibit either innate emotional capabilities or that are capable of convincingly simulating emotions. A more practical approach, based on current technological capabilities, is the simulation of emotions in conversational agents
&#91;&#93;. The goal of such simulation is to enrich and facilitate interactivity between human and machine
&#91;&#93;.  While human emotions are often associated with surges in hormones and other neuropeptides, emotions in machines might be associated with abstract states associated with progress (or lack of progress) in autonomous learning systems.  In this view, affective emotional states correspond to time-derivatives (perturbations) in the <link xlink:type="simple" xlink:href="../337/322337.xml">
learning curve</link> of an arbitrary learning system.</p>
<p>

<person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../639/19639.xml">
Marvin Minsky</link></scientist>
</person>
, one of the pioneering computer scientists in artificial intelligence, relates emotions to the broader issues of machine intelligence stating in <it><work wordnetid="104599396" confidence="0.8">
<product wordnetid="104007894" confidence="0.8">
<creation wordnetid="103129123" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<book wordnetid="106410904" confidence="0.8">
<publication wordnetid="106589574" confidence="0.8">
<link xlink:type="simple" xlink:href="../578/14509578.xml">
The Emotion Machine</link></publication>
</book>
</artifact>
</creation>
</product>
</work>
</it> that emotion is a "not especially different from the processes that we call 'thinking.'"<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%227%22])">7</ref></p>

</ss1>
</sec>
<sec>
<st>
 Technologies of affective computing </st>

<ss1>
<st>
Emotional speech</st>
<p>

Emotional speech processing recognizes the user's emotional state by analyzing speech patterns. Vocal parameters and <link xlink:type="simple" xlink:href="../563/214563.xml">
prosody</link> features such as pitch variables and speech rate are analyzed through pattern recognition.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%228%22])">8</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%229%22])">9</ref></p>
<p>

Emotional inflection and modulation in synthesized speech, either through phrasing or acoustic features is useful in human-computer interaction. Such capability makes speech natural and expressive. For example a dialog system might modulate its speech to be more puerile if it deems the emotional model of its current user is that of a child.</p>

</ss1>
<ss1>
<st>
Facial expression</st>
<p>

The detection and processing of facial expression is achieved through various methods such as <link xlink:type="simple" xlink:href="../825/869825.xml">
optical flow</link>, <link xlink:type="simple" xlink:href="../770/98770.xml">
hidden Markov model</link>, <link xlink:type="simple" xlink:href="../542/1729542.xml">
neural network processing</link> or active appearance model.</p>

</ss1>
<ss1>
<st>
Body gesture</st>
<p>

Body gesture is the position and the changes of the body. There are many proposed methods<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2210%22])">10</ref> to detect the body gesture. Hand gestures have been a common focus of body gesture detection, apparentness 
&#91;&#93;methods<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2211%22])">11</ref> and 3-D modeling methods are traditionally used.</p>

</ss1>
</sec>
<sec>
<st>
Potential applications</st>
<p>

In <link xlink:type="simple" xlink:href="../677/74677.xml">
e-learning</link> applications, affective computing can be used to adjust the presentation style of a computerized tutor when a learner is bored, interested, frustrated, or pleased.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2212%22])">12</ref>  Psychological health services, i.e. <link xlink:type="simple" xlink:href="../134/13139134.xml">
counseling</link>, benefit from affective computing applications when determining a client's emotional state.  Affective computing sends a message via color or sound to express an emotional state to others.</p>
<p>

<link xlink:type="simple" xlink:href="../781/25781.xml">
Robotic systems</link> capable of processing affective information exhibit higher flexibility while one works in uncertain or complex environments.  Companion devices, such as <link xlink:type="simple" xlink:href="../602/242602.xml">
digital pet</link>s, use affective computing abilities to enhance realism and provide a higher degree of autonomy.  </p>
<p>

Other potential applications are centered around social monitoring.  For example, a car can monitor the emotion of all occupants and engage in additional safety measures, such as alerting other vehicles if it detects the driver to be angry.  Affective computing has potential applications in <link xlink:type="simple" xlink:href="../516/13516.xml">
human computer interaction</link>, such as affective mirrors allowing the user to see how he or she performs; emotion monitoring agents sending a warning before one sends an angry email; or even music players selecting tracks based on mood.</p>
<p>

Affective computing is also being applied to the development of communicative technologies for use by people with autism.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2213%22])">13</ref></p>

</sec>
<sec>
<st>
Application examples</st>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../109/33109.xml">
Wearable computer</link> applications make use of affective technologies, such as detection of biosignals</entry>
<entry level="1" type="bullet">

 <link>
Human–computer interaction</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../599/629599.xml">
Kismet</link></entry>
</list>
</p>

</sec>
<sec>
<st>
See also</st>
<p>

<list>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../850/4857850.xml">
Affective design</link></entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../111/12630111.xml">
Affect control theory</link></entry>
</list>
</p>

</sec>
<sec>
<st>
References</st>

<p>

<reflist>
<entry id="1">
 <cite style="font-style:normal">Tao, Jianhua;&#32;Tieniu Tan&#32;(2005). "Affective Computing: A Review".&#32;<it>Affective Computing and Intelligent Interaction</it>&#32;<b><link xlink:type="simple" xlink:href="../159/2578159.xml">
LNCS</link> 3784</b>: 981–995, Springer. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1007/11573548">
10.1007/11573548</weblink>.</cite>&nbsp;</entry>
<entry id="2">
 <cite style="font-style:normal">James, William&#32;(1884).&#32;"What is Emotion". <it>Mind</it>&#32;<b>9</b>: 188–205.</cite>&nbsp; Cited by Tao and Tan.</entry>
<entry id="3">
<weblink xlink:type="simple" xlink:href="http://affect.media.mit.edu/pdfs/95.picard.pdf">
"Affective Computing"</weblink> MIT Technical Report #321 (<weblink xlink:type="simple" xlink:href="http://vismod.media.mit.edu/pub/tech-reports/TR-321-ABSTRACT.html">
Abstract</weblink>), 1995</entry>
<entry id="4">
Kleine-Cosack, Christian&#32;(October 2006).&#32;"<weblink xlink:type="simple" xlink:href="http://ls12-www.cs.tu-dortmund.de//~fink/lectures/SS06/human-robot-interaction/Emotion-RecognitionAndSimulation.pdf">
Recognition and Simulation of Emotions</weblink>"&#32;(PDF).&#32;Retrieved on May 13, 2008.&nbsp;"The introduction of emotion to computer science was done by Pickard (sic)
who created the field of affective computing."
</entry>
<entry id="5">
Diamond, David&#32;(December 2003).&#32;"<weblink xlink:type="simple" xlink:href="http://www.wired.com/wired/archive/11.12/love.html">
The Love Machine; Building computers that care.</weblink>".&#32;  Wired.&#32;Retrieved on May 13, 2008.&nbsp;"Rosalind Picard, a genial MIT professor, is the field's godmother; her 1997 book, Affective Computing, triggered an explosion of interest in the emotional side of computers and their users."
</entry>
<entry id="6">
 <cite style="font-style:normal">Garay, Nestor; Idoia Cearreta, Juan Miguel López, Inmaculada Fajardo&#32;(April 2006).&#32;"<weblink xlink:type="simple" xlink:href="http://www.humantechnology.jyu.fi/articles/volume2/number1/2006/humantechnology-april-2006.pdf">
Assistive Technology and Affective Mediation</weblink>". <it>Human Technology: An Interdisciplinary Journal on Humans in ICT Environments</it>&#32;<b>2</b>&#32;(1): 55–83. Retrieved on <link>
2008-05-12</link>.</cite>&nbsp;</entry>
<entry id="7">
Restak, Richard&#32;(2006-12-17).&#32;"<weblink xlink:type="simple" xlink:href="http://www.washingtonpost.com/wp-dyn/content/article/2006/12/14/AR2006121401554.html">
Mind Over Matter</weblink>", <it>The Washington Post</it>.&#32;Retrieved on <link>
2008-05-13</link>.&nbsp;</entry>
<entry id="8">
Dellaert, F., Polizin, t., and Waibel, A., Recognizing Emotion in Speech", In Proc. Of ICSLP 1996, Philadelphia, PA, pp.1970-1973, 1996</entry>
<entry id="9">
Lee, C.M.; Narayanan, S.; Pieraccini, R., Recognition of Negative Emotion in the Human Speech Signals, Workshop on Auto. Speech Recognition and Understanding, Dec 2001</entry>
<entry id="10">
J. K. Aggarwal, Q. Cai, Human Motion Analysis: A Review, Computer Vision and Image Understanding, Vol. 73, No. 3, 1999</entry>
<entry id="11">
Vladimir I. Pavlovic, Rajeev Sharma, Thomas S. Huang, Visual Interpretation of Hand Gestures for Human-Computer Interaction; A Review, IEEE Transactions on Pattern Analysis and Machine Intelligence, 1997</entry>
<entry id="12">
<weblink xlink:type="simple" xlink:href="http://www.autotutor.org/">
AutoTutor</weblink></entry>
<entry id="13">
<weblink xlink:type="simple" xlink:href="http://affect.media.mit.edu/projects.php">
Projects in Affective Computing</weblink></entry>
</reflist>
</p>

</sec>
<sec>
<st>
External links</st>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://affect.media.mit.edu/">
Affective Computing Research Group at the MIT Media Laboratory</weblink></entry>
</list>
</p>


</sec>
</bdy>
</article>
