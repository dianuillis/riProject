<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 16:35:25[mciao0825] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Edmonds-Karp algorithm</title>
<id>239230</id>
<revision>
<id>235524522</id>
<timestamp>2008-09-01T04:57:48Z</timestamp>
<contributor>
<username>Jamelan</username>
<id>3529454</id>
</contributor>
</revision>
<categories>
<category>Network flow</category>
</categories>
</header>
<bdy>

In <link xlink:type="simple" xlink:href="../323/5323.xml">
computer science</link> and <link xlink:type="simple" xlink:href="../401/12401.xml">
graph theory</link>, the <b>Edmonds-Karp algorithm</b> is an implementation of the <link xlink:type="simple" xlink:href="../777/53777.xml">
Ford-Fulkerson method</link> for computing the <link xlink:type="simple" xlink:href="../165/403165.xml">
maximum flow</link> in a <link xlink:type="simple" xlink:href="../676/645676.xml">
flow network</link> in <math>\mathcal{O}(|V| \cdot |E|^2)</math>. It is asymptotically slower than the <link xlink:type="simple" xlink:href="../072/3444072.xml">
relabel-to-front algorithm</link>, which runs in <math>\mathcal{O}(|V|^3)</math>, but it is often faster in practice for <link xlink:type="simple" xlink:href="../546/963546.xml">
sparse graph</link>s. The algorithm was first published by a Russian scientist, Dinic, in 1970<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref>, and independently by <link xlink:type="simple" xlink:href="../459/3625459.xml">
Jack Edmonds</link> and <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../763/298763.xml">
Richard Karp</link></scientist>
</person>
 in 1972<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref> (discovered earlier).  Dinic's algorithm includes additional techniques that reduce the running time to <math>\mathcal{O}(|V|^2 \cdot |E|)</math>. 
<sec>
<st>
Algorithm</st>

<p>

The algorithm is identical to the <link xlink:type="simple" xlink:href="../777/53777.xml">
Ford-Fulkerson algorithm</link>,
except that the search order when finding the <link>
augmenting path</link> is
defined. The path found must be the shortest path which has
available capacity. This can be found by a <link xlink:type="simple" xlink:href="../026/97026.xml">
breadth-first search</link>, as we let edges have unit length. The running time of
<math>\mathcal{O}(|V| \cdot |E|^2)</math> is found by showing that each augmenting path
can be found in <math>\mathcal{O}(|E|)</math> time, that every time at least one of the
<math>E</math> edge becomes saturated, that the distance from the
saturated edge to the source along the augmenting path must be
longer than last time it was saturated, and that the distance is
at most <math>V</math> long. Another property of this algorithm is
that the length of the shortest augmenting path increases
monotonically. There is an accessible proof in <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%223%22])">3</ref>.</p>

</sec>
<sec>
<st>
Pseudocode</st>


<p>

<indent level="1">

<it>For a more high level description, see <link xlink:type="simple" xlink:href="../777/53777.xml">
Ford-Fulkerson algorithm</link>.
</it></indent>

<b>algorithm</b> EdmondsKarp
<b>input</b>:
C[1..n, 1..n] <it>(Capacity matrix)</it>
E[1..n, 1..?] <it>(Neighbour lists)</it>
s             <it>(Source)</it>
t             <it>(Sink)</it>
<b>output</b>:
f             <it>(Value of maximum flow)</it>
F             <it>(A matrix giving a legal flow with the maximum value)</it>
f := 0 <it>(Initial flow is zero)</it>
F := <b>array</b>(1..n, 1..n) <it>(Residual capacity from u to v is C[u,v] - F[u,v])</it>
<b>forever</b>
m, P := BreadthFirstSearch(C, E, s, t)
<b>if</b> m = 0
<b>break</b>
f := f + m
<it>(Backtrack search, and write flow)</it>
v := t
<b>while</b> v &amp;ne; s
u := P[v]
F[u,v] := F[u,v] + m
F[v,u] := F[v,u] - m
v := u
<b>return</b> (f, F)</p>
<p>

<b>algorithm</b> BreadthFirstSearch
<b>input</b>:
C, E, s, t
<b>output</b>:
M[t]          <it>(Capacity of path found)</it>
P             <it>(Parent table)</it>
P := <b>array</b>(1..n)
<b>for</b> u <b>in</b> 1..n
P[u] := -1
P[s] := -2 <it>(make sure source is not rediscovered)</it> 
M := <b>array</b>(1..n) <it>(Capacity of found path to node)</it>
M[s] := &amp;infin;
Q := queue()
Q.push(s)
<b>while</b> Q.size() &amp;gt; 0
u := Q.pop()
<b>for</b> v <b>in</b> E[u]
<it>(If there is available capacity, and v is not seen before in search)</it>
<b>if</b> C[u,v] - F[u,v] &amp;gt; 0 <b>and</b> P[v] = -1
P[v] := u
M[v] := min(M[u], C[u,v] - F[u,v])
<b>if</b> v &amp;ne; t
Q.push(v)
<b>else</b>
<b>return</b> M[t], P
<b>return</b> 0, P</p>

</sec>
<sec>
<st>
Example</st>

<p>

Given a network of seven nodes, source A, sink G, and capacities as shown below:</p>
<p>

<image width="300px" src="Edmonds-Karp_flow_example_0.svg">
</image>
</p>
<p>

In the pairs <math>f/c</math> written on the edges, <math>f</math> is the current flow, and <math>c</math> is the capacity. The residual capacity from <math>u</math> to <math>v</math> is <math>c_f(u,v)=c(u,v)-f(u,v)</math>, the total capacity, minus the flow that is already used. If the net flow from <math>u</math> to <math>v</math> is negative, it <it>contributes</it> to the residual capacity.</p>
<p>

<table class="wikitable">
<row>
<header rowspan="2">
Capacity</header>
<header>
Path</header>
</row>
<row>
<header>
Resulting network</header>
</row>
<row>
<col rowspan="2">
<math>\min(c_f(A,D),c_f(D,E),c_f(E,G)) = </math>
<math>\min(3-0,2-0,1-0) = </math>
<math>\min(3,2,1) = 1</math></col>
<col align="center">
<math>A,D,E,G</math></col>
</row>
<row>
<col>
 <image width="300px" src="Edmonds-Karp_flow_example_1.svg">
</image>
</col>
</row>
<row>
<col rowspan="2">
<math>\min(c_f(A,D),c_f(D,F),c_f(F,G)) = </math>
<math>\min(3-1,6-0,9-0) = </math>
<math>\min(2,6,9) = 2</math></col>
<col align="center">
<math>A,D,F,G</math></col>
</row>
<row>
<col>
 <image width="300px" src="Edmonds-Karp_flow_example_2.svg">
</image>
</col>
</row>
<row>
<col rowspan="2">
<math>\min(c_f(A,B),c_f(B,C),c_f(C,D),c_f(D,F),c_f(F,G)) = </math>
<math>\min(3-0,4-0,1-0,6-2,9-2) = </math>
<math>\min(3,4,1,4,7) = 1</math></col>
<col align="center">
<math>A,B,C,D,F,G</math></col>
</row>
<row>
<col>
 <image width="300px" src="Edmonds-Karp_flow_example_3.svg">
</image>
</col>
</row>
<row>
<col rowspan="2">
<math>\min(c_f(A,B),c_f(B,C),c_f(C,E),c_f(E,D),c_f(D,F),c_f(F,G)) = </math>
<math>\min(3-1,4-1,2-0,0--1,6-3,9-3) = </math>
<math>\min(2,3,2,1,3,6) = 1</math></col>
<col align="center">
<math>A,B,C,E,D,F,G</math></col>
</row>
<row>
<col>
 <image width="300px" src="Edmonds-Karp_flow_example_4.svg">
</image>
</col>
</row>
</table>
</p>
<p>

Notice how the length of the <link>
augmenting path</link> found by the algorithm (in red) never decreases. The paths found are the shortest possible. The flow found is equal to the capacity across the <link xlink:type="simple" xlink:href="../130/78130.xml">
minimum cut</link> in the graph separating the source and the sink. There is only one minimal cut in this graph, partitioning the nodes into the sets <math>\{A,B,C,E\}</math> and <math>\{D,F,G\}</math>, with the capacity <math>c(A,D)+c(C,D)+c(E,G)=3+1+1=5</math>.</p>

</sec>
<sec>
<st>
Java Implementation</st>

<p>

import java.io.*;</p>
<p>

class FlowGraph
{
public static final int WHITE = 0, GRAY = 1, BLACK = 2;
private double flow, capacity, res_capacity;
private int parent, color, queue;
private double min_capacity;
private int size, source, sink, first, last;
private double max_flow;</p>
<p>

public FlowGraph(String fileName)
{
.. // Read "size" value, "capacity[size][size]" matrix,
// as well as "source" and "sink" node indexes (0-based)
// from an input text file.
maxFlow();
}</p>
<p>

private void maxFlow()  // Edmonds-Karp algorithm with O(V³E) complexity
{
flow = new double[size][size];
res_capacity = new double[size][size];
parent = new int[size];
min_capacity = new double[size];
color = new int[size];
queue = new int[size];</p>
<p>

for (int i = 0; i  size; i++)
for (int j = 0; j  size; j++)
res_capacity[i][j] = capacity[i][j];</p>
<p>

while (BFS(source))
{
max_flow += min_capacity[sink];
int v = sink, u;
while (v != source)
{
u = parent[v];
flow[u][v] += min_capacity[sink];
flow[v][u] -= min_capacity[sink];
res_capacity[u][v] -= min_capacity[sink];
res_capacity[v][u] += min_capacity[sink];
v = u;
}
}
}</p>
<p>

private boolean BFS(int source)  // Breadth First Search in O(V²)
{
for (int i = 0; i  size; i++)
{
color[i] = WHITE;
min_capacity[i] = Double.MAX_VALUE;
}</p>
<p>

first = last = 0;
queue[last++] = source;
color[source] = GRAY;</p>
<p>

while (first != last)  // While "queue" not empty..
{
int v = queue[first++];
for (int u = 0; u  size; u++)
if (color[u] == WHITE &amp;&amp; res_capacity[v][u] &amp;gt; 0)
{
min_capacity[u] = Math.min(min_capacity[v], res_capacity[v][u]);
parent[u] = v;
color[u] = GRAY;
if (u == sink) return true;
queue[last++] = u;
}
}
return false;
}</p>
<p>

public void toFile(String fileName)
{
.. // Write the results ("flow" matrix and "max_flow" value) to output file.
// To be called in the "main()" method.
}
}</p>

</sec>
<sec>
<st>
References</st>

<p>

<reflist>
<entry id="1">
 <cite style="font-style:normal">E. A. Dinic&#32;(1970).&#32;"Algorithm for solution of a problem of maximum flow in a network with power estimation". <it>Soviet Math. Doklady</it>&#32;<b>Vol 11</b>: 1277–1280.&#32;Doklady.</cite>&nbsp;</entry>
<entry id="2">
 <cite style="font-style:normal"><link xlink:type="simple" xlink:href="../459/3625459.xml">
Jack Edmonds</link> and <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../763/298763.xml">
Richard M. Karp</link></scientist>
</person>
&#32;(1972).&#32;"<weblink xlink:type="simple" xlink:href="http://www.akira.ruc.dk/~keld/teaching/algoritmedesign_f03/Artikler/08/Edmonds72.pdf">
Theoretical improvements in algorithmic efficiency for network flow problems</weblink>". <it>Journal of the <organization wordnetid="108008335" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../ury/30th_century.xml">
ACM</link></organization>
</it>&#32;<b>19</b>&#32;(2): 248–264.</cite>&nbsp;</entry>
<entry id="3">
 <cite style="font-style:normal" class="book"><scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../475/4108475.xml">
Thomas H. Cormen</link></scientist>
, <scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../884/1400884.xml">
Charles E. Leiserson</link></scientist>
, <link xlink:type="simple" xlink:href="../057/68057.xml">
Ronald L. Rivest</link> and <scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../993/3489993.xml">
Clifford Stein</link></scientist>
&#32;(2001).&#32;"26.2", <work wordnetid="104599396" confidence="0.8">
<product wordnetid="104007894" confidence="0.8">
<creation wordnetid="103129123" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<book wordnetid="106410904" confidence="0.8">
<publication wordnetid="106589574" confidence="0.8">
<link xlink:type="simple" xlink:href="../226/3499226.xml">
Introduction to Algorithms</link></publication>
</book>
</artifact>
</creation>
</product>
</work>
, second edition,&#32;MIT Press and McGraw-Hill,&#32;660-663. ISBN 0-262-53196-8.</cite>&nbsp;</entry>
</reflist>

<list>
<entry level="1" type="number">

 Algorithms and Complexity (see pages 63 - 69).  http://www.cis.upenn.edu/~wilf/AlgComp3.html</entry>
</list>
</p>


</sec>
</bdy>
</article>
