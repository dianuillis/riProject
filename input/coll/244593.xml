<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 16:37:36[mciao0827] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Lock (computer science)</title>
<id>244593</id>
<revision>
<id>242216501</id>
<timestamp>2008-10-01T10:45:55Z</timestamp>
<contributor>
<username>Lisatwo</username>
<id>4460024</id>
</contributor>
</revision>
<categories>
<category>Concurrency control</category>
</categories>
</header>
<bdy>
<p>

In <link xlink:type="simple" xlink:href="../323/5323.xml">
computer science</link>, a <b>lock</b> is a <link xlink:type="simple" xlink:href="../017/4726017.xml">
synchronization</link> mechanism for enforcing limits on access to a resource in an environment where there are many <link>
threads of execution</link>. Locks are one way of enforcing <link xlink:type="simple" xlink:href="../356/217356.xml">
concurrency control</link> policies. </p>

<sec>
<st>
Types</st>
<p>

Generally, locks are <b>advisory locks</b>, where each thread cooperates by acquiring the lock before accessing the corresponding data.  Some systems also implement <b>mandatory locks</b>, where attempting unauthorized access to a locked resource will force an <link xlink:type="simple" xlink:href="../231/59231.xml">
exception</link> in the entity attempting to make the access.</p>
<p>

A (binary) <link xlink:type="simple" xlink:href="../557/164557.xml">
semaphore</link> is the simplest type of lock.  In terms of <b>access to the data</b>, no distinction is made between shared (read only) or exclusive (read and write) modes.  Other schemes provide for a shared mode, where several threads can acquire a shared lock for read-only access to the data.  Other modes such as exclusive, intend-to-exclude and intend-to-upgrade are also widely implemented.</p>
<p>

Independent of the type of lock chosen above, locks can be classified by what happens when the <link>
lock strategy</link> prevents <b>progress of a thread</b>. Most locking designs block the <link xlink:type="simple" xlink:href="../206/418206.xml">
execution</link> of the <link xlink:type="simple" xlink:href="../303/45303.xml">
thread</link> requesting the lock until it is allowed to access the locked resource. A <link xlink:type="simple" xlink:href="../603/244603.xml">
spinlock</link> is a lock where the thread simply waits ("spins") until the lock becomes available.  It is very efficient if threads are only likely to be blocked for a short period of time, as it avoids the overhead of operating system process re-scheduling.  It is wasteful if the lock is held for a long period of time.</p>
<p>

Locks typically require hardware support for efficient implementation. This usually takes the form of one or more <link xlink:type="simple" xlink:href="../560/2114560.xml">
atomic</link> instructions such as "<link xlink:type="simple" xlink:href="../099/394099.xml">
test-and-set</link>", "<link xlink:type="simple" xlink:href="../276/2050276.xml">
fetch-and-add</link>" or "<link xlink:type="simple" xlink:href="../224/632224.xml">
compare-and-swap</link>". These instructions allow a single process to test if the lock is free, and if free, acquire the lock in a single atomic operation.</p>
<p>

<link xlink:type="simple" xlink:href="../718/2782718.xml">
Uniprocessor</link> architectures have the option of using <link>
uninterruptable sequence</link>s of instructions, using special instructions or instruction prefixes to disable interrupts temporarily, but this technique does not work for <link xlink:type="simple" xlink:href="../020/64020.xml">
multiprocessor</link> shared-memory machines. Proper support for locks in a multiprocessor environment can require quite complex hardware and/or software support, with substantial <link xlink:type="simple" xlink:href="../738/28738.xml">
synchronization</link> issues.</p>
<p>

The reason an atomic operation is required is because of concurrency, where more than one task executes the same logic.  For example, consider the following <programming_language wordnetid="106898352" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../021/6021.xml">
C</link></programming_language>
 code:</p>
<p>

if (lock == 0) lock = myPID; /* lock free - set it */</p>
<p>

The above example does not guarantee that the task has the lock, since more than one task can be testing the lock at the same time.  Since both tasks will detect that the lock is free, both tasks will attempt to set the lock, not knowing that the other task is also setting the lock.  <system wordnetid="104377057" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../826/36826.xml">
Dekker's</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</instrumentality>
</artifact>
</system>
 or <system wordnetid="104377057" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../891/331891.xml">
Peterson's algorithm</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</instrumentality>
</artifact>
</system>
 are possible substitutes if atomic locking operations are not available.</p>
<p>

Careless use of locks can result in <link xlink:type="simple" xlink:href="../181/105181.xml">
deadlock</link> or <link>
livelock</link>. Deadlock occurs when a process holds a lock and then attempts to acquire a second lock. If the second lock is already held by another process, the first process will be blocked. If the second process then attempts to acquire the lock held by the first process, the system has "deadlocked": no progress will ever be made.  A number of strategies can be used to avoid or recover from deadlocks, both at design-time and at run-time.  (The most common is to standardize the lock acquisition sequences so that combinations of inter-dependent locks are always acquired and released in a specifically defined "cascade" order).</p>

</sec>
<sec>
<st>
Granularity</st>
<p>

Before introducing lock granularity, one needs to understand three concepts about locks.
<list>
<entry level="1" type="bullet">

 <b>lock overhead</b>: The extra resources for using locks, like the memory space allocated for locks, the CPU time to initialize and destroy locks, and the time for acquiring or releasing locks. The more locks a program uses, the more overhead associated with the usage.</entry>
<entry level="1" type="bullet">

 <b>lock contention</b>: This occurs whenever one process or thread attempts to acquire a lock held by another process or thread. The more granular the available locks, the less likely one process/thread will request a lock held by the other.  (For example, locking a row rather than the entire table, or locking a cell rather than the entire row.)</entry>
<entry level="1" type="bullet">

 <b>deadlock</b>: The situation when two tasks that are waiting on locks, each holding a lock that the other is waiting for.  Unless something is done, the two tasks will wait forever.</entry>
</list>
</p>
<p>

So there is a tradeoff between decreasing lock overhead and decreasing lock contention when choosing the number of locks in synchronization.</p>
<p>

An important property of a lock is its <b>granularity</b>. The granularity is a measure of the amount of data the lock is protecting. In general, choosing a coarse granularity (a small number of locks, each protecting a large segment of data) results in less <b>lock overhead</b> when a single process is accessing the protected data, but worse performance when multiple processes are running concurrently. This is because of increased <b>lock contention</b> the more coarse the lock, the higher the likelihood that the lock will stop an unrelated process from proceeding. Conversely, using a fine granularity (a larger number of locks, each protecting a fairly small amount of data) increases the overhead of the locks themselves but reduces lock contention. More locks also increase the risk of deadlock.</p>
<p>

In a <link xlink:type="simple" xlink:href="../513/8513.xml">
database management system</link>, for example, a lock could protect, in order of increasing granularity, a record, a data page, or an entire table. Coarse granularity, such as using table locks, tends to give the best performance for a single user, whereas fine granularity, such as record locks, tends to give the best performance for multiple users.</p>

</sec>
<sec>
<st>
 Database locks </st>

<p>

<link xlink:type="simple" xlink:href="../805/2230805.xml">
Database locks</link> can be used as a means of ensuring transaction synchronicity. i.e. when making transaction processing concurrent (interleaving transactions), using <link xlink:type="simple" xlink:href="../363/217363.xml">
2-phased locks</link> ensures that the concurrent execution of the transaction turns out equivalent to some serial ordering of the transaction. However, deadlocks become an unfortunate side-effect of locking in databases. Deadlocks are either prevented by pre-determining the locking order between transactions or are detected using waits-for graphs. An alternate to locking for database synchronicity while avoiding deadlocks involves the use of totally ordered global timestamps.</p>
<p>

There are mechanisms employed to manage the actions of multiple concurrent users on a database - the purpose is to prevent lost updates and dirty reads. The two types of locking are Pessimistic and Optimistic Locking. </p>
<p>

<list>
<entry level="1" type="bullet">

 <b>Pessimistic Locking</b>: this is whereby a user who reads a record with the intention of updating it, places an exclusive lock on the record to prevent other users from manipulating it. This means no one else can manipulate that record until the user releases the lock. The downside is that users can be locked out for a very long time thereby causing frustration.</entry>
<entry level="2" type="bullet">

 <b>Where To Use Pessimistic Locking</b>: This is mainly used in environments where data-contention (the degree of users request to the database system at any one time) is heavy; where the cost of protecting data through locks is less than the cost of rolling back transactions if concurrency conflicts occur. Pessimistic concurrency is best implemented when lock times will be short, as in programmatic processing of records. Pessimistic concurrency requires a persistent connection to the database and is not a scalable option when users are interacting with data, because records might be locked for relatively large periods of time. It is not appropriate for use in web application development.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <b>Optimistic Locking</b>: this allows multiple concurrent users access to the database whilst the system keeps a copy of the initial-read made by each user. When a user wants to update a record, the application determines whether another user has changed the record since it was last read. The application does this by comparing the initial-read held in memory to the database record to verify any changes made to the record. Any discrepancies between the initial-read and the database record violates concurrency rules and hence causes the system to drop any update request. An error messages is generated and the user is asked to start the update process again. It improves database performance by reducing the amount of locking required, thereby reducing the load on the database server. It works efficiently with tables that require limited updates since no users are locked out. However, some updates may fail. The downside is constant update failures due to high volumes of update requests from multiple concurrent users - it can be frustrating for users.</entry>
<entry level="2" type="bullet">

<b>Where To Use Optimistic Locking</b>: This is appropriate in environments where there is low contention for data, or where read-only access to data is required. Optimistic concurrency is used extensively in .NET to address the needs of mobile and disconnected applications<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref>, where locking data rows for prolonged periods of time would be infeasible. Also, maintaining record locks requires a persistent connection to the database server, which is not possible in disconnected applications.</entry>
</list>
</p>

</sec>
<sec>
<st>
The problems with locks </st>
<p>

Lock-based resource protection and thread/process synchronization has many disadvantages:
<list>
<entry level="1" type="bullet">

 They cause blocking, which means some threads/processes have to wait until a lock (or a whole set of locks) is released.</entry>
<entry level="1" type="bullet">

 Lock handling adds overhead for all access to a resource, even when the chances for collision are very rare. (However, any chance for such collisions is a <link xlink:type="simple" xlink:href="../661/98661.xml">
race condition</link>).</entry>
<entry level="1" type="bullet">

 Locks  can be vulnerable to failures and faults. If one thread holding a lock dies, stalls/blocks or goes into any sort of infinite loop, other threads waiting for the lock may wait forever. </entry>
<entry level="1" type="bullet">

 Programming using locks is extremely error-prone, like the notorious <link xlink:type="simple" xlink:href="../181/105181.xml">
deadlock</link>.  Bugs are often very subtle and may be almost impossible to reliably reproduce.  (See: <link xlink:type="simple" xlink:href="../661/98661.xml">
race condition</link>).</entry>
<entry level="1" type="bullet">

 Lock contention limits scalability and adds complexity.</entry>
<entry level="1" type="bullet">

 Balances between lock overhead and contention can be unique to given problem domains (applications) as well as sensitive to design, implementation, and even low-level system architectural changes.  These balances may change over the life cycle of any given application/implementation and may entail tremendous changes to update (re-balance). </entry>
<entry level="1" type="bullet">

 Locks are only composable (i.e., managing multiple concurrent locks in order to atomically delete Item X from Table A and insert X into Table B) with relatively elaborate (overhead) software support and perfect adherence by applications programming to rigorous conventions.</entry>
<entry level="1" type="bullet">

 Priority inversion. High priority threads/processes cannot proceed if a low priority thread/process is holding the common lock.</entry>
<entry level="1" type="bullet">

 Convoying. All other threads have to wait if a thread holding a lock is descheduled due to a time-slice interrupt or page fault (<it>See <link xlink:type="simple" xlink:href="../755/6318755.xml">
lock convoy</link></it>)</entry>
<entry level="1" type="bullet">

 Hard to debug: Bugs associated with locks are time dependent. They are extremely hard to repeat.</entry>
</list>
</p>
<p>

One strategy is to avoid locks entirely by using non-blocking synchronization methods, like <link xlink:type="simple" xlink:href="../864/554864.xml">
lock-free</link> programming techniques and <link xlink:type="simple" xlink:href="../429/4006429.xml">
transactional memory</link>.</p>

</sec>
<sec>
<st>
Language support</st>

<p>

<indent level="1">

<it>See also: <link xlink:type="simple" xlink:href="../263/4736263.xml">
Barrier (computer science)</link></it>
</indent>
Language support for locking depends on the language used:
<list>
<entry level="1" type="bullet">

 There is no standard  <programming_language wordnetid="106898352" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../021/6021.xml">
C</link></programming_language>
 or <programming_language wordnetid="106898352" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../038/72038.xml">
C++</link></programming_language>
 <link xlink:type="simple" xlink:href="../ury/24th_century.xml">
API</link> to handle <link xlink:type="simple" xlink:href="../827/36827.xml">
mutex</link>. However, the <standard wordnetid="107260623" confidence="0.8">
<system_of_measurement wordnetid="113577171" confidence="0.8">
<link xlink:type="simple" xlink:href="../671/634671.xml">
POSIX pthread</link></system_of_measurement>
</standard>
 API provide lock support, but its use is not straightforward<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref>. <software wordnetid="106566077" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../204/166204.xml">
Visual C++</link></software>
 allows to adds a <it>synchronize</it> attribute in the code to mark methods that must be synchronized, but this is specific to the <link xlink:type="simple" xlink:href="../890/18890.xml">
Windows</link> architecture and <software wordnetid="106566077" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../204/166204.xml">
Visual C++</link></software>
 compiler<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%223%22])">3</ref>.</entry>
<entry level="1" type="bullet">

 The <message wordnetid="106598915" confidence="0.8">
<request wordnetid="106513366" confidence="0.8">
<link xlink:type="simple" xlink:href="../881/15881.xml">
Java (programming language)</link></request>
</message>
 provide the keyword <it>synchronized</it> to put locks on blocks of code, <link xlink:type="simple" xlink:href="../817/232817.xml">
methods</link> or <link xlink:type="simple" xlink:href="../665/169665.xml#xpointer(//*[./st=%22Objects+in+object-oriented+programming%22])">
objects</link><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%224%22])">4</ref>.</entry>
<entry level="1" type="bullet">

 In the <programming_language wordnetid="106898352" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../196/2356196.xml">
C#</link></programming_language>
 programming language, the <it>lock</it> keyword can be used to ensure that a block of code runs to completion without interruption by other threads, similar to the <it>synchronized</it> keyword in <link xlink:type="simple" xlink:href="../446/4718446.xml">
Java</link>.</entry>
<entry level="1" type="bullet">

 <programming_language wordnetid="106898352" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../862/23862.xml">
Python</link></programming_language>
 does not provide a lock keyword, but it is possible to use a lower level <link xlink:type="simple" xlink:href="../827/36827.xml">
mutex</link> mechanism to acquire or release a lock<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%225%22])">5</ref>.</entry>
<entry level="1" type="bullet">

 <physical_entity wordnetid="100001930" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../768/25768.xml">
Ruby</link></causal_agent>
</physical_entity>
 also doesn't provide a keyword for synchronization, but it is possible to use an explicit low level <link xlink:type="simple" xlink:href="../827/36827.xml">
mutex</link> object<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref>.</entry>
<entry level="1" type="bullet">

 In Assembler, the LOCK prefix prevents another processor from doing anything in the middle of an operation: it guarantees atomicity.</entry>
</list>
</p>

</sec>
<sec>
<st>
References</st>

<p>

<reflist>
<entry id="1">
"<weblink xlink:type="simple" xlink:href="http://msdn.microsoft.com/en-us/library/ms978496.aspx">
Designing Data Tier Components and Passing Data Through Tiers</weblink>".&#32;  <company wordnetid="108058098" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../001/19001.xml">
Microsoft</link></company>
&#32;(<link xlink:type="simple" xlink:href="../491/88491.xml">
August 2002</link>).&#32;Retrieved on <link>
2008-05-30</link>.</entry>
<entry id="2">
Marshall, Dave&#32;(<link xlink:type="simple" xlink:href="../656/2693656.xml">
March 1999</link>).&#32;"<weblink xlink:type="simple" xlink:href="http://www.cs.cf.ac.uk/Dave/C/node31.html#SECTION003110000000000000000">
Mutual Exclusion Locks</weblink>".&#32;Retrieved on <link>
2008-05-30</link>.</entry>
<entry id="3">
"<weblink xlink:type="simple" xlink:href="http://msdn.microsoft.com/en-us/library/34d2s8k3(VS.80).aspx">
Synchronize</weblink>".&#32;  msdn.microsoft.com.&#32;Retrieved on <link>
2008-05-30</link>.</entry>
<entry id="4">
"<weblink xlink:type="simple" xlink:href="http://java.sun.com/docs/books/tutorial/essential/concurrency/sync.html">
Synchronization</weblink>".&#32;  <company wordnetid="108058098" confidence="0.8">
<institution wordnetid="108053576" confidence="0.8">
<link xlink:type="simple" xlink:href="../980/26980.xml">
Sun Microsystems</link></institution>
</company>
.&#32;Retrieved on <link>
2008-05-30</link>.</entry>
<entry id="5">
Lundh, Fredrik&#32;(<link xlink:type="simple" xlink:href="../650/9518650.xml">
July 2007</link>).&#32;"<weblink xlink:type="simple" xlink:href="http://effbot.org/zone/thread-synchronization.htm">
Thread Synchronization Mechanisms in Python</weblink>".&#32;Retrieved on <link>
2008-05-30</link>.</entry>
<entry id="6">
"<weblink xlink:type="simple" xlink:href="http://www.ruby-doc.org/docs/ProgrammingRuby/html/tut_threads.html">
Programming Ruby: Threads and Processes</weblink>"&#32;(<link xlink:type="simple" xlink:href="../551/34551.xml">
2001</link>).&#32;Retrieved on <link>
2008-05-30</link>.</entry>
</reflist>
</p>

</sec>
<sec>
<st>
See also</st>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../557/164557.xml">
Semaphore (programming)</link></entry>
<entry level="1" type="bullet">

 <idea wordnetid="105833840" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<link xlink:type="simple" xlink:href="../789/1367789.xml">
Monitor (synchronization)</link></concept>
</idea>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../827/36827.xml">
Mutual exclusion</link></entry>
<entry level="1" type="bullet">

 <idea wordnetid="105833840" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<link xlink:type="simple" xlink:href="../312/638312.xml">
Critical section</link></concept>
</idea>
</entry>
<entry level="1" type="bullet">

 <structure wordnetid="105726345" confidence="0.8">
<idea wordnetid="105833840" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<form wordnetid="105930736" confidence="0.8">
<link xlink:type="simple" xlink:href="../874/164874.xml">
Double-checked locking</link></form>
</concept>
</idea>
</structure>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../864/554864.xml">
Lock-free and wait-free algorithms</link></entry>
<entry level="1" type="bullet">

 <system wordnetid="104377057" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<link xlink:type="simple" xlink:href="../812/1415812.xml">
File locking</link></instrumentality>
</artifact>
</system>
</entry>
</list>
</p>


</sec>
</bdy>
</article>
