<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 19:45:03[mciao0826] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>TCP tuning</title>
<id>2584128</id>
<revision>
<id>238074542</id>
<timestamp>2008-09-13T03:38:25Z</timestamp>
<contributor>
<username>R3tr0</username>
<id>2163929</id>
</contributor>
</revision>
<categories>
<category>Network performance</category>
<category>TCP/IP</category>
</categories>
</header>
<bdy>

<b>TCP tuning</b> techniques adjust some parameters of <link xlink:type="simple" xlink:href="../538/30538.xml">
TCP</link> connection over high-bandwidth high-latency networks. Well tuned networks can perform up to 1000 times faster in some cases.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref>
<sec>
<st>
 Network and system characteristics </st>

<ss1>
<st>
 Bandwidth-delay product (BDP) </st>

<p>

<link xlink:type="simple" xlink:href="../063/3586063.xml">
Bandwidth-delay product</link> (BDP) is a term primarily used in conjunction with the <link xlink:type="simple" xlink:href="../538/30538.xml">
TCP</link> to refer to the number of bytes necessary to fill a TCP "path", i.e. it is equal to the maximum number of simultaneous packets in transit between the transmitter and the receiver. TCP has a concept of windows which are used for congestion control and for determining the optimum size of packet that is resilient to packet loss, packet truncation (due to link layer maximum transmission unit) or reordering.</p>
<p>

High performance networks have very large BDPs. To give a practical example, in the case of two satellites located 0.5 <link xlink:type="simple" xlink:href="../713/178713.xml">
light-second</link>s apart, communicating over a radio link with a bandwidth of 10 Gbit/s, there will be at most 0.5&amp;times;1010 bits, i.e., 5 Gbit = 625 <link xlink:type="simple" xlink:href="../918/19918.xml">
MB</link> of data in the space between them. Operating systems and protocols designed as recently as a few years ago when networks were slower were tuned for BDPs of orders of magnitude smaller, with implications for tuning.</p>

</ss1>
<ss1>
<st>
 Buffers </st>
<p>

The original TCP configurations supported <link xlink:type="simple" xlink:href="../183/2406183.xml">
buffer</link>s of up to 64K Bytes (64 <link xlink:type="simple" xlink:href="../755/149755.xml">
KiB</link>), which was adequate for slow links or links with small round trip times (RTTs).  Larger buffers are required by the high performance options described below.</p>
<p>

Buffering is used throughout high performance network systems to handle delays in the system.  In general, buffer size will need to be scaled proportional to the amount of data "in flight" at any time.  For very high performance applications that are not sensitive to network delays, it is possible to interpose large end to end buffering delays by putting in intermediate data storage points in an end to end system, and then to use automated and scheduled non-real-time data transfers to get the data to their final endpoints.</p>

</ss1>
</sec>
<sec>
<st>
 TCP speed limits </st>
<p>

Maximum achievable throughput for a single TCP connection is determined by different factors. One trivial limitation is the maximum bandwidth on the slowest link on the path. But there are also other, less obvious limits for TCP thoughput. Bit errors can create a limitation for the connection as well as <link xlink:type="simple" xlink:href="../672/41672.xml">
round-trip time</link>.</p>

<ss1>
<st>
 Window size </st>
<p>

In <link xlink:type="simple" xlink:href="../652/5652.xml">
computer networking</link>, <b>RWIN</b> (<link xlink:type="simple" xlink:href="../538/30538.xml">
TCP</link> Receive Window) is the amount of <information wordnetid="105816287" confidence="0.8">
<datum wordnetid="105816622" confidence="0.8">
<link xlink:type="simple" xlink:href="../333/2234333.xml">
data</link></datum>
</information>
 that a <link xlink:type="simple" xlink:href="../457/7878457.xml">
computer</link> can accept without acknowledging the sender. If sender has not received acknowledgement for the first <link xlink:type="simple" xlink:href="../734/43734.xml">
packet</link> it sent, it will stop and wait and if this wait exceeds a certain limit, it may even <message wordnetid="106598915" confidence="0.8">
<protocol wordnetid="106665108" confidence="0.8">
<direction wordnetid="106786629" confidence="0.8">
<rule wordnetid="106652242" confidence="0.8">
<link xlink:type="simple" xlink:href="../648/2667648.xml">
retransmit</link></rule>
</direction>
</protocol>
</message>
. This is how TCP achieves reliable <link xlink:type="simple" xlink:href="../168/42168.xml">
data transfer</link>.</p>
<p>

Even if there is no packet loss in the network, the <link xlink:type="simple" xlink:href="../128/2584128.xml">
windowing</link> can cause a limit for the throughput. Because TCP transmits data up to the window size before waiting for the packets, the full bandwidth of the network may not always get used. The limitation caused by window size can be calculated as follows:</p>
<p>

<math> \textit{Throughput} \le \frac {\textit{RWIN}} {\textit{RTT}}</math>,</p>
<p>

where RWIN is the maximum receive windows size and RTT is the round-trip time for the path.</p>

</ss1>
<ss1>
<st>
 Packet loss </st>
<p>

When packet loss occurs in the network, an additional limit is imposed on the connection. The limit can be calculated according to the formula (Mathis et al.):</p>
<p>

<math> \textit{Throughput} \le \frac {0.7 \textit{MSS}} {\textit{RTT} \sqrt{ \textit{Ploss} }}</math>,</p>
<p>

where MSS is the maximum segment size and Ploss is the probability of packet loss. <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref></p>

</ss1>
</sec>
<sec>
<st>
TCP Options for High Performance</st>

<p>

A number of extensions have been made to TCP over the years to increase its performance over fast high-RTT links ("long fat networks", or LFNs for short).</p>
<p>

TCP timestamps (RFC 1323) play a double role: they avoid ambiguities due to the 32-bit sequence number field wrapping around, and they allow more precise RTT estimation in the presence of multiple losses per RTT.  With those improvements, it becomes reasonable to increase the TCP window beyond 64 kB, which can be done using the window scaling option (RFC 1323).</p>
<p>

The TCP selective acknowledgment options (SACK, RFC 2018) allows a TCP receiver to precisely inform the TCP server about which segments have been lost.  This increases performance on high-RTT links, when multiple losses per window are possible.</p>
<p>

<message wordnetid="106598915" confidence="0.8">
<protocol wordnetid="106665108" confidence="0.8">
<direction wordnetid="106786629" confidence="0.8">
<rule wordnetid="106652242" confidence="0.8">
<link xlink:type="simple" xlink:href="../283/6018283.xml">
Path MTU discovery</link></rule>
</direction>
</protocol>
</message>
 avoids the need for in-network fragmentation, which increases performance in the presence of losses.</p>

</sec>
<sec>
<st>
 References </st>
<p>

<reflist>
<entry id="1">
<weblink xlink:type="simple" xlink:href="http://www.psc.edu/networking/projects/hpn-ssh/">
High Performance Enabled SSH/SCP [PSC&#93;</weblink></entry>
<entry id="2">
RFC 3155</entry>
</reflist>
</p>

</sec>
<sec>
<st>
 External links </st>
<p>

<list>
<entry level="1" type="bullet">

 RFC 1323 - TCP Extensions for High Performance</entry>
<entry level="1" type="bullet">

 RFC 2018 - TCP Selective Acknowledgment Options</entry>
<entry level="1" type="bullet">

 RFC 2582 - The NewReno Modification to TCP's Fast Recovery Algorithm</entry>
<entry level="1" type="bullet">

 RFC 2883 - An Extension to the Selective Acknowledgment (SACK) Option for TCP</entry>
<entry level="1" type="bullet">

 RFC 3517 - A Conservative Selective Acknowledgment-based Loss Recovery Algorithm for TCP</entry>
<entry level="1" type="bullet">

 RFC 4138 - Forward RTO-Recovery (F-RTO): An Algorithm for Detecting Spurious Retransmission Timeouts with TCP and the Stream Control Transmission Protocol (SCTP)</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.microsoft.com/technet/technetmag/issues/2007/01/CableGuy/default.aspx">
The Cable Guy: TCP Receive Window Auto-Tuning</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.web100.org/">
The Web100 Data Bandwidth Testing</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.dslreports.com/drtcp">
DrTCP</weblink> - a utility for <link xlink:type="simple" xlink:href="../890/18890.xml">
Microsoft Windows</link> (prior to <link xlink:type="simple" xlink:href="../869/562869.xml">
Vista</link>) which can quickly alter <link>
TCP</link> performance parameters in the registry.</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.dslreports.com/tweaks">
Information on 'Tweaking' your TCP stack</weblink>, <computer wordnetid="103082979" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<device wordnetid="103183080" confidence="0.8">
<machine wordnetid="103699975" confidence="0.8">
<web_site wordnetid="106359193" confidence="0.8">
<link xlink:type="simple" xlink:href="../167/964167.xml">
Broadband Reports</link></web_site>
</machine>
</device>
</instrumentality>
</artifact>
</computer>
</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.speedguide.net/analyzer.php">
TCP/IP Analyzer</weblink>, speedguide.net</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.inboost.com/speed-tweaks/cable-modem-tweaks.html">
TCP RWIN Tweaks</weblink>, Inbost</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://blogs.technet.com/winserverperformance/archive/2008/05/03/nt-ttcp-network-performance-test-tool-available.aspx">
NTTTCP Network Performance Test Tool</weblink>, Microsoft Windows Server Performance Team Blog</entry>
</list>

</p>
</sec>
</bdy>
</article>
