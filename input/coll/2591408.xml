<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 19:49:48[mciao0827] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<artifact  confidence="0.8" wordnetid="100021939">
<instrumentality  confidence="0.8" wordnetid="103575240">
<device  confidence="0.8" wordnetid="103183080">
<filter  confidence="0.8" wordnetid="103339643">
<header>
<title>Recursive Bayesian estimation</title>
<id>2591408</id>
<revision>
<id>228650392</id>
<timestamp>2008-07-29T18:26:07Z</timestamp>
<contributor>
<username>Radagast83</username>
<id>668752</id>
</contributor>
</revision>
<categories>
<category>Estimation theory</category>
<category>Non-linear filters</category>
<category>Signal processing</category>
<category>Linear filters</category>
<category>Articles to be merged&amp;#32;since January 2008</category>
<category>All articles to be merged</category>
<category>Bayesian statistics</category>
</categories>
</header>
<bdy>

<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-move" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="50px" src="Mergefrom.svg">
</image>
</p>
</col>
<col style="" class="mbox-text">
 It has been suggested that  be  into this article or section. ()</col>
</row>
</table>

<p>

<b>Recursive Bayesian estimation</b> is a general probabilistic approach for <link xlink:type="simple" xlink:href="../671/554671.xml">
estimating</link> an unknown <link xlink:type="simple" xlink:href="../487/43487.xml">
probability density function</link> recursively over time using incoming measurements and a mathematical process model.</p>

<sec>
<st>
 Model </st>
<p>

The true state <math>x</math> is assumed to be an unobserved <link xlink:type="simple" xlink:href="../772/98772.xml">
Markov process</link>, and the measurements <math>z</math> are the observed states of a <link xlink:type="simple" xlink:href="../770/98770.xml">
Hidden Markov Model</link> (HMM).</p>
<p>

<image location="center" width="150px" src="HMM_Kalman_Filter_Derivation.svg">
<caption>

Hidden Markov Model
</caption>
</image>
</p>
<p>

Because of the Markov assumption, the probability of the current true state given the immediately previous one is conditionally independent of the other earlier states. </p>
<p>

<indent level="1">

<math>p(\textbf{x}_k|\textbf{x}_{k-1},\textbf{x}_{k-2},\dots,\textbf{x}_0) = p(\textbf{x}_k|\textbf{x}_{k-1} )</math>
</indent>

Similarly, the measurement at the <it>k</it>-th timestep is dependent only upon the current state, so is conditionally independent of all other states given the current state.</p>
<p>

<indent level="1">

<math>p(\textbf{z}_k|\textbf{x}_k,\textbf{x}_{k-1},\dots,\textbf{x}_{0}) = p(\textbf{z}_k|\textbf{x}_{k} )</math>
</indent>

Using these assumptions the probability distribution over all states of the HMM can be written simply as:</p>
<p>

<indent level="1">

<math>p(\textbf{x}_0,\dots,\textbf{x}_k,\textbf{z}_1,\dots,\textbf{z}_k) = p(\textbf{x}_0)\prod_{i=1}^k p(\textbf{z}_i|\textbf{x}_i)p(\textbf{x}_i|\textbf{x}_{i-1})</math>
</indent>

However, when using the Kalman filter to estimate the state <b>x</b>, the probability distribution of interest is associated with the current states conditioned on the measurements up to the current timestep. (This is achieved by marginalising out the previous states and dividing by the probability of the measurement set.)</p>
<p>

This leads to the <it>predict</it> and <it>update</it> steps of the Kalman filter written probabilistically. The probability distribution associated with the predicted state is product of the probability distribution associated with the transition from the (<it>k</it> - 1)-th timestep to the <it>k</it>-th and the probability distribution associated with the previous state, with the true state at (<it>k</it> - 1) integrated out.</p>
<p>

<indent level="1">

<math> p(\textbf{x}_k|\textbf{Z}_{k-1}) = \int p(\textbf{x}_k | \textbf{x}_{k-1}) p(\textbf{x}_{k-1} | \textbf{Z}_{k-1} )  \, d\textbf{x}_{k-1} </math>
</indent>

The probability distribution of updated is proportional to the product of the measurement likelihood and the predicted state.
<indent level="1">

<math> p(\textbf{x}_k|\textbf{Z}_{k}) = \frac{p(\textbf{Z}_k|\textbf{x}_k) p(\textbf{x}_k|\textbf{Z}_{k-1})}{p(\textbf{Z}_k|\textbf{Z}_{k-1})} 
= \alpha\,p(\textbf{Z}_k|\textbf{x}_k) p(\textbf{x}_k|\textbf{Z}_{k-1})
</math>
</indent>

The denominator
<indent level="1">

<math>p(\textbf{Z}_k|\textbf{Z}_{k-1}) = \int p(\textbf{Z}_k|\textbf{x}_k) p(\textbf{x}_k|\textbf{Z}_{k-1}) d\textbf{x}_k</math>
</indent>
is constant relative to <math>x</math>, so we can always substitute it for a coefficient <math>\alpha</math>, which can usually be ignored in practice. The numerator can be calculated and then simply normalized, since its integral must be unitary.</p>

</sec>
<sec>
<st>
 Applications </st>
<p>

<list>
<entry level="1" type="bullet">

 <artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<device wordnetid="103183080" confidence="0.8">
<filter wordnetid="103339643" confidence="0.8">
<link xlink:type="simple" xlink:href="../855/180855.xml">
Kalman filter</link></filter>
</device>
</instrumentality>
</artifact>
, a recursive Bayesian filter for <link xlink:type="simple" xlink:href="../347/50347.xml">
multivariate normal distribution</link>s</entry>
<entry level="1" type="bullet">

 <know-how wordnetid="105616786" confidence="0.8">
<method wordnetid="105660268" confidence="0.8">
<link xlink:type="simple" xlink:href="../948/1396948.xml">
Particle filter</link></method>
</know-how>
, a sequential Monte Carlo (SMC) based technique, which models the PDF using a set of discrete points</entry>
<entry level="1" type="bullet">

 <b>Grid-based estimators</b>, which subdivide the PDF into a discrete grid</entry>
</list>
</p>

</sec>
<sec>
<st>
Sequential Bayesian filtering</st>
<p>

Sequential Bayesian filtering is the extension of the Bayesian estimation for the case when the observed value changes in time. It is a method to estimate the real value of an observed variable that evolves in time. The method is named filtering when we estimate the current value given past observations, <link xlink:type="simple" xlink:href="../662/4155662.xml">
smoothing</link> when estimating past value given present and past measures, and prediction when estimating a probable future value.</p>
<p>

The notion of Sequential Bayesian filtering is extensively used in <link xlink:type="simple" xlink:href="../039/7039.xml">
control</link> and <link xlink:type="simple" xlink:href="../673/46673.xml">
robotics</link>.</p>

</sec>
<sec>
<st>
 External links </st>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://citeseer.ist.psu.edu/504843.html">
A Tutorial on Particle Filters for On-line Non-linear/Non-Gaussian Bayesian Tracking</weblink>, IEEE Transactions on Signal Processing (2001)</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://julien.diard.free.fr/articles/CIRAS03.pdf">
A survey of probabilistic models, using the Bayesian Programming methodology as a unifying framework</weblink></entry>
</list>
</p>

</sec>
</bdy>
</filter>
</device>
</instrumentality>
</artifact>
</article>
