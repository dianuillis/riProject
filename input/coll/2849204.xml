<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 19:55:35[mciao0825] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<artifact  confidence="0.8" wordnetid="100021939">
<instrumentality  confidence="0.8" wordnetid="103575240">
<engine  confidence="0.8" wordnetid="103287733">
<motor  confidence="0.8" wordnetid="103789946">
<device  confidence="0.8" wordnetid="103183080">
<machine  confidence="0.8" wordnetid="103699975">
<header>
<title>Video search engine</title>
<id>2849204</id>
<revision>
<id>243387941</id>
<timestamp>2008-10-06T09:08:46Z</timestamp>
<contributor>
<username>Rick.nolan</username>
<id>7937793</id>
</contributor>
</revision>
<categories>
<category>Internet search engines</category>
</categories>
</header>
<bdy>

A <b>video search engine</b> is a web-based <link xlink:type="simple" xlink:href="../023/4059023.xml">
search engine</link> which <link xlink:type="simple" xlink:href="../451/502451.xml">
crawl</link>s the web for <link xlink:type="simple" xlink:href="../441/32441.xml">
video</link> content. Some video search engines parse externally hosted content while others allow content to be uploaded and hosted on their own servers. Some engines also allow users to search by video format type and by length of the clip. Search results are usually accompanied by a thumbnail view of the video.
<sec>
<st>
 Popular video search engines </st>

<ss2>
<st>
 Agnostic search </st>
<p>
 
Search that is not affected by the hosting of video, where results are agnostic no matter where the video is located:
<list>
<entry level="1" type="bullet">

 <b><company wordnetid="108058098" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../024/366024.xml">
AltaVista</link></company>
 Video Search</b> had one of the first video search engines with easy accessible use. Is found on a direct link called "Video" off the main page above the text block.</entry>
<entry level="1" type="bullet">

 <b><link xlink:type="simple" xlink:href="../526/2848526.xml">
blinkx</link></b> was launched in 2004 and uses speech recognition and visual analysis to process spidered video rather than rely on metadata alone.  blinkx claims to have the largest archive of video on the web and puts its collection at around 26,000,000 hours of content.</entry>
<entry level="1" type="bullet">

  <b><link xlink:type="simple" xlink:href="../579/19571579.xml">
Munax</link> Audio Video Search</b> released their first version all-content search engine in 2005 and powers both nation-wide and world-wide search engines.</entry>
<entry level="1" type="bullet">

 <b><computer wordnetid="103082979" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<engine wordnetid="103287733" confidence="0.8">
<motor wordnetid="103789946" confidence="0.8">
<device wordnetid="103183080" confidence="0.8">
<machine wordnetid="103699975" confidence="0.8">
<web_site wordnetid="106359193" confidence="0.8">
<link xlink:type="simple" xlink:href="../376/17762376.xml">
CastTV</link></web_site>
</machine>
</device>
</motor>
</engine>
</instrumentality>
</artifact>
</computer>
</b> is a Web-wide video search engine that was founded in 2006 and funded by <firm wordnetid="108059870" confidence="0.8">
<company wordnetid="108058098" confidence="0.8">
<enterprise wordnetid="108056231" confidence="0.8">
<business wordnetid="108061042" confidence="0.8">
<institution wordnetid="108053576" confidence="0.8">
<link xlink:type="simple" xlink:href="../477/878477.xml">
Draper Fisher Jurvetson</link></institution>
</business>
</enterprise>
</company>
</firm>
, <person wordnetid="100007846" confidence="0.9508927676800064">
<investor wordnetid="110216106" confidence="0.9173553029164789">
<link xlink:type="simple" xlink:href="../877/2362877.xml">
Ron Conway</link></investor>
</person>
, and <physical_entity wordnetid="100001930" confidence="0.8">
<blogger wordnetid="109860415" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<computer_user wordnetid="109951274" confidence="0.8">
<programmer wordnetid="110481268" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<engineer wordnetid="109615807" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<employee wordnetid="110053808" confidence="0.8">
<link xlink:type="simple" xlink:href="../986/331986.xml">
Marc Andreessen</link></employee>
</causal_agent>
</engineer>
</worker>
</programmer>
</computer_user>
</person>
</blogger>
</physical_entity>
.</entry>
<entry level="1" type="bullet">

 <b><company wordnetid="108058098" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../264/12550264.xml">
Dabble</link></company>
</b> is a human powered video search engine indexing 29 million videos across hundreds of videos sites. Dabble launched in July, 2006.</entry>
<entry level="1" type="bullet">

 <b><link xlink:type="simple" xlink:href="../692/12548692.xml">
Everyzing</link></b> (formerly <link xlink:type="simple" xlink:href="../692/12548692.xml">
Podzinger</link> until May, 2007) has spent $50 million building speech to text video search.  Everyzing takes the user within the actual content by using speech recognition.  This enables online video consumers to jump directly to the point in the video for which they are searching.</entry>
<entry level="1" type="bullet">

  <b><company wordnetid="108058098" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../857/1619857.xml">
Picsearch</link></company>
 Video Search</b> has been licensed to search portals since 2006. Picsearch is a search technology provider who powers image, video and audio search for over 100 major search engines around the world.</entry>
<entry level="1" type="bullet">

  <b><link>
Snipp.tv</link> </b> uses speech processing technology in order to seach the audio track of the video for spoken keywords.</entry>
<entry level="1" type="bullet">

 <b><computer wordnetid="103082979" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<engine wordnetid="103287733" confidence="0.8">
<motor wordnetid="103789946" confidence="0.8">
<device wordnetid="103183080" confidence="0.8">
<machine wordnetid="103699975" confidence="0.8">
<web_site wordnetid="106359193" confidence="0.8">
<link xlink:type="simple" xlink:href="../271/16576271.xml">
Truveo</link></web_site>
</machine>
</device>
</motor>
</engine>
</instrumentality>
</artifact>
</computer>
</b> is a Web-wide video search engine that was founded in 2004 and launched in September 2005.  Truveo claims to index over 100 million videos from thousands of sources across the Web.</entry>
<entry level="1" type="bullet">

 <b>[TVDuck http://www.tvduck.com] is also a new video content search engine.</b></entry>
</list>
</p>

</ss2>
<ss2>
<st>
 Non-agnostic Search </st>
<p>

Search results are modified, or suspect, due to the large hosted video being given preferential treatment in search results:
<list>
<entry level="1" type="bullet">

<b><company wordnetid="108058098" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../397/1397.xml">
AOL</link></company>
 Video</b> offers a leading video search engine that can be used to find video located on popular video destinations across the web. In December 2005, AOL acquired <computer wordnetid="103082979" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<engine wordnetid="103287733" confidence="0.8">
<motor wordnetid="103789946" confidence="0.8">
<device wordnetid="103183080" confidence="0.8">
<machine wordnetid="103699975" confidence="0.8">
<web_site wordnetid="106359193" confidence="0.8">
<link xlink:type="simple" xlink:href="../271/16576271.xml">
Truveo</link></web_site>
</machine>
</device>
</motor>
</engine>
</instrumentality>
</artifact>
</computer>
 Video Search.</entry>
<entry level="1" type="bullet">

 <b><software wordnetid="106566077" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../208/1520208.xml">
Google Video</link></software>
</b> is a popular video search engine which permits visitors to upload videos. It searches its own hosted content, Youtube and many other video hosting sites. </entry>
<entry level="1" type="bullet">

 <b><company wordnetid="108058098" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../213/188213.xml">
Yahoo!</link></company>
 Video Search</b> Yahoo!'s search engine examines video files on the internet using its <link xlink:type="simple" xlink:href="../640/1910640.xml">
Media RSS</link> standard. Is found on a direct link called "Video" off the main page above the text block.</entry>
</list>
</p>

</ss2>
</sec>
<sec>
<st>
 Design and algorithms </st>

<p>

Video search has evolved slowly through several basic search formats which exist today and all use <link xlink:type="simple" xlink:href="../394/460394.xml">
keywords</link>.  The keywords for each search can be found in the title of the media, any text attached to the media and content linked web pages, also defined by authors and users of video hosted resources. </p>
<p>

Some video search is performed using human powered search, others create technological systems that work automatically to detect what is in the video and match the searchers needs. Many efforts to improve video search including both human powered search as well as writing algorithm that recognize what's inside the video have meant complete redevelopment of search efforts. </p>
<p>

It is generally acknowledged that speech to text is possible, though recently Thomas Wilde, the new CEO of EveryZing, acknowledged that Everyzing works 70% of the time when there is music, ambient noise or more than one person speaking. If newscast style speaking (one person, speaking clearly, no ambient noise) is available, that can rise to 93%.  (From the Web Video Summit, San Jose, CA, June 27, 2007).</p>
<p>

Around 40 <link xlink:type="simple" xlink:href="../980/22980.xml">
phonemes</link> exist in every language with about 400 in all spoken languages. Rather than applying a text search algorithm after speech-to-text processing is completed, some engines use a phonetic search algorithm to find results within the spoken word. Others work by literally listening to the entire podcast and creating a text transcription using a sophisticated speech-to-text process. Once the text file is created, the  website lets you search the file for any number of search words and phrases. </p>
<p>

It is generally acknowledged that visual search into video does not work well and that no company is using it publicly.  Researchers at UC San Diego and Carnegie Melon University have been working on the visual search problem for more than 15 years, and admitted at a "Future of Search" conference at UC Berkeley in the Spring of 2007 that it was years away from being viable even in simple search.</p>

</sec>
</bdy>
</machine>
</device>
</motor>
</engine>
</instrumentality>
</artifact>
</article>
