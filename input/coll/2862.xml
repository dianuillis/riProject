<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 15:21:38[mciao0827] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>AI-complete</title>
<id>2862</id>
<revision>
<id>232051246</id>
<timestamp>2008-08-15T05:27:07Z</timestamp>
<contributor>
<username>Pgr94</username>
<id>1162083</id>
</contributor>
</revision>
<categories>
<category>Computational complexity theory</category>
<category>Artificial intelligence</category>
</categories>
</header>
<bdy>

In the field of <link xlink:type="simple" xlink:href="../164/1164.xml">
artificial intelligence</link>, the most difficult problems are informally known as <b>AI-complete</b> or <b>AI-hard</b>, implying that the difficulty of these computational problems is equivalent to solving the central artificial intelligence problem—making computers as intelligent as people, or <link xlink:type="simple" xlink:href="../357/586357.xml">
strong AI</link>.<p>

The term was coined by <link>
Fanya Montalvo</link> by analogy with <class wordnetid="107997703" confidence="0.8">
<collection wordnetid="107951464" confidence="0.8">
<group wordnetid="100031264" confidence="0.8">
<link xlink:type="simple" xlink:href="../466/39466.xml">
NP-complete</link></group>
</collection>
</class>
 and <class wordnetid="107997703" confidence="0.8">
<collection wordnetid="107951464" confidence="0.8">
<group wordnetid="100031264" confidence="0.8">
<link xlink:type="simple" xlink:href="../681/54681.xml">
NP-hard</link></group>
</collection>
</class>
 in <link xlink:type="simple" xlink:href="../132/6132.xml">
complexity theory</link>, which formally describes the most famous class of difficult problems.  <cite class="inline">(<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMallery1988%22])">
Mallery 1988</link>)</cite> Early uses of the term are in Erik Mueller's 1987 Ph.D. dissertation and in Eric Raymond's 1991 jargon file.  </p>
<p>

To call a problem AI-complete reflects an attitude that it won't be solved by a simple algorithm, such as those used in <link xlink:type="simple" xlink:href="../235/10235.xml">
ELIZA</link>.  Such problems are hypothesised to include:</p>
<p>

<list>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../596/6596.xml">
Computer vision</link> (and subproblems such as <link xlink:type="simple" xlink:href="../466/14661466.xml">
object recognition</link>)</entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../778/98778.xml">
Natural language understanding</link> (and subproblems such as <link xlink:type="simple" xlink:href="../439/318439.xml">
text mining</link> and <link xlink:type="simple" xlink:href="../980/19980.xml">
machine translation</link>)</entry>
<entry level="1" type="bullet">

Dealing with unexpected circumstances while solving any real world problem, whether it's <link xlink:type="simple" xlink:href="../112/623112.xml">
navigation</link> or <link xlink:type="simple" xlink:href="../641/1505641.xml">
planning</link> or even the kind of <link xlink:type="simple" xlink:href="../755/89755.xml">
reasoning</link> done by <link xlink:type="simple" xlink:href="../136/10136.xml">
expert system</link>s.</entry>
</list>
</p>

<sec>
<st>
Examples</st>
<p>

For example, consider a straight-forward, limited and specific task: <link xlink:type="simple" xlink:href="../980/19980.xml">
machine translation</link>. To translate accurately, a machine must be able to understand the text. It must be able to follow the author's argument, so it must have some ability to <link xlink:type="simple" xlink:href="../164/1164.xml#xpointer(//*[./st=%22Deduction=2C+reasoning=2C+problem+solving%22])">
reason</link>. It must have extensive <link xlink:type="simple" xlink:href="../339/2239339.xml">
world knowledge</link> so that it knows what is being discussed — it must at least be familiar with all the same commonsense facts that the average human translator knows. Some of this knowledge is in the form of facts that can be explicitly represented, but some knowledge is unconscious and closely tied to the human body: for example, the machine may need to understand how an ocean makes one <it>feel</it> to accurately translate a specific metaphor in the text. It must also model the authors' goals, intentions, and emotional states to accurately reproduce them in a new language. In short, the machine is required to have wide variety of human intellectual skills, including <link xlink:type="simple" xlink:href="../164/1164.xml#xpointer(//*[./st=%22Deduction=2C+reasoning=2C+problem+solving%22])">
reason</link>, <link xlink:type="simple" xlink:href="../339/2239339.xml">
commonsense knowledge</link> and the intuitions that underly <link xlink:type="simple" xlink:href="../673/46673.xml">
motion and manipulation</link>, <link xlink:type="simple" xlink:href="../671/11920671.xml">
perception</link>, and <link xlink:type="simple" xlink:href="../164/1164.xml#xpointer(//*[./st=%22Social+intelligence%22])">
social intelligence</link>. <link xlink:type="simple" xlink:href="../980/19980.xml">
Machine translation</link>, therefore, is believed to be AI-complete: it may require <link xlink:type="simple" xlink:href="../357/586357.xml">
strong AI</link> to be done as well as humans can do it.</p>
<p>

AI systems can solve very simple restricted versions of AI-complete problems, but never in their full generality. When AI researchers attempt to "scale up" their systems to handle more complicated, real world situations, the programs tend to become excessively <link xlink:type="simple" xlink:href="../449/1805449.xml">
brittle</link> without <link xlink:type="simple" xlink:href="../339/2239339.xml">
commonsense knowledge</link> or a rudimentary understanding of the situation: they fail as unexpected circumstances begin to appear.  When human beings are dealing with the world, they are helped immensely by the fact that they know what to expect: they know what all things around them are, why they are there, what they are likely to do and so on. They can recognize unusual situations and adjust accordingly. A machine without <link xlink:type="simple" xlink:href="../357/586357.xml">
strong AI</link> has no other skills to fall back on.  <cite class="inline">(<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLenatGuha1989%22])">
Lenat &amp; Guha 1989</link>, pp.&nbsp;1-5)</cite>  </p>

</sec>
<sec>
<st>
Formalisation</st>
<p>

<link xlink:type="simple" xlink:href="../543/7543.xml">
Computational complexity theory</link> deals with the relative computational difficulty of <link xlink:type="simple" xlink:href="../338/1139338.xml">
computable function</link>s.  By definition it does not cover problems whose solution are unknown or have not been characterised formally.  Since many AI problems have no formalisation yet, conventional complexity theory does not allow the definition of AI-completeness.</p>
<p>

To address this problem, a complexity theory for AI has been proposed.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref> It is based on a <link xlink:type="simple" xlink:href="../278/1773278.xml">
model of computation</link> that splits the computational burden between a computer and a human: one part is solved by computer and the other part solved by human.  This is formalised by a <b>human-assisted <invention wordnetid="105633385" confidence="0.8">
<know-how wordnetid="105616786" confidence="0.8">
<method wordnetid="105660268" confidence="0.8">
<link xlink:type="simple" xlink:href="../403/30403.xml">
Turing machine</link></method>
</know-how>
</invention>
</b>.  The formalisation defines algorithm complexity, problem complexity and reducibility which in turn allows <link xlink:type="simple" xlink:href="../260/9260.xml">
equivalence class</link>es to be defined.</p>
<p>

The complexity of executing an algorithm with a human-assisted Turing machine is given by a pair:
<indent level="1">

<math>\langle\Phi_{H},\Phi_{M}\rangle</math>
</indent>
where the first element represents the complexity of the human's part and the second element is the complexity of the machine's part.</p>

<ss1>
<st>
Results</st>
<p>

The complexity of solving the following problems with a human-assisted Turing machine is:<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref></p>
<p>

<list>
<entry level="1" type="bullet">

 <software wordnetid="106566077" confidence="0.8">
<application wordnetid="106570110" confidence="0.8">
<program wordnetid="106568978" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106359877" confidence="0.8">
<code wordnetid="106355894" confidence="0.8">
<coding_system wordnetid="106353757" confidence="0.8">
<link xlink:type="simple" xlink:href="../091/49091.xml">
Optical character recognition</link></coding_system>
</code>
</writing>
</written_communication>
</program>
</application>
</software>
 for printed text: <math>\langle O(1), poly(n) \rangle </math></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../840/43840.xml">
Turing test</link>: </entry>
<entry level="2" type="bullet">

 for an <math>n</math>-sentence conversation where the oracle remembers the conversation history (persistent oracle): <math>\langle O(n), O(n) \rangle </math></entry>
<entry level="2" type="bullet">

 for an <math>n</math>-sentence conversation where the conversation history must be retransmitted: <math>\langle O(n), O(n^2) \rangle </math></entry>
<entry level="2" type="bullet">

 for an <math>n</math>-sentence conversation where the conversation history must be retransmitted and the person takes linear time to read the query<math>\langle O(n^2), O(n^2) \rangle </math></entry>
<entry level="1" type="bullet">

 <message wordnetid="106598915" confidence="0.8">
<information wordnetid="106634376" confidence="0.8">
<electronic_database wordnetid="106588511" confidence="0.8">
<lexical_database wordnetid="106638868" confidence="0.8">
<wordnet wordnetid="106639428" confidence="0.8">
<database wordnetid="106637824" confidence="0.8">
<link xlink:type="simple" xlink:href="../803/3887803.xml">
ESP game</link></database>
</wordnet>
</lexical_database>
</electronic_database>
</information>
</message>
: <math>\langle O(n), O(n) \rangle </math></entry>
<entry level="1" type="bullet">

 Image labelling (based on the <link xlink:type="simple" xlink:href="../203/663203.xml">
Arthur-Merlin protocol</link>): <math>\langle O(n), O(n) \rangle </math></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../743/15261743.xml">
Image classification</link>: human only: <math>\langle O(n), O(n) \rangle </math>, and with less reliance on the human: <math>\langle O(\log n), O(n \log n) \rangle </math>.</entry>
</list>
</p>

</ss1>
</sec>
<sec>
<st>
See also</st>
<p>

<list>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../785/2376785.xml">
ASR-complete</link></entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../069/1101069.xml">
List of open problems in computer science</link></entry>
</list>
</p>

</sec>
<sec>
<st>
References</st>
<p>

<reflist>
<entry id="1">
Dafna Shahaf and Eyal Amir (2007) Towards a theory of AI completeness. <weblink xlink:type="simple" xlink:href="http://www.ucl.ac.uk/commonsense07">
Commonsense 2007,  8th International Symposium on Logical Formalizations of Commonsense Reasoning</weblink>.<weblink xlink:type="simple" xlink:href="http://www.cs.uiuc.edu/~eyal/papers/ai-complete-commonsense07.pdf">
http://www.cs.uiuc.edu/~eyal/papers/ai-complete-commonsense07.pdf
</weblink></entry>
<entry id="2">
Dafna Shahaf and Eyal Amir (2007) Towards a theory of AI completeness. <weblink xlink:type="simple" xlink:href="http://www.ucl.ac.uk/commonsense07">
Commonsense 2007,  8th International Symposium on Logical Formalizations of Commonsense Reasoning</weblink>.<weblink xlink:type="simple" xlink:href="http://www.cs.uiuc.edu/~eyal/papers/ai-complete-commonsense07.pdf">
http://www.cs.uiuc.edu/~eyal/papers/ai-complete-commonsense07.pdf
</weblink></entry>
</reflist>
</p>
<p>

<list>
<entry level="1" type="bullet">

 Engels, Robert &amp; Bremdal, Bernt (2000, July 28). <weblink xlink:type="simple" xlink:href="http://www.ontoknowledge.org/countd/countdown.cgi?del5.pdf">
<it>Information Extraction: State-of-the-Art Report''</it></weblink>.</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFLenatGuha1989" style="font-style:normal"><link>
Lenat, Douglas</link>&#32;&amp;&#32;Guha, R. V.&#32;(1989),&#32;<it>Building Large Knowledge-Based Systems</it>, Addison-Wesley</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFMallery1988" style="font-style:normal">Mallery, John C.&#32;(1988),&#32;<weblink xlink:type="simple" xlink:href="http://citeseer.ist.psu.edu/mallery88thinking.html">
"Thinking About Foreign Policy: Finding an Appropriate Role for Artificially Intelligent Computers"</weblink>,&#32;<it>The 1988 Annual Meeting of the International Studies Association.</it>, St. Louis, MO, </cite>&nbsp;.</entry>
<entry level="1" type="bullet">

 Mueller, Erik T. (1987, March). <weblink xlink:type="simple" xlink:href="ftp://ftp.cs.ucla.edu/tech-report/198_-reports/870017.pdf">
<it>Daydreaming and Computation</it> (Technical Report CSD-870017)</weblink> Ph.D. dissertation, University of California, Los Angeles. ("Daydreaming is but one more <it>AI-complete</it> problem: if we could solve any one artificial intelligence problem, we could solve all the others", p. 302)</entry>
<entry level="1" type="bullet">

 Raymond, Eric S. (1991, March 22). <weblink xlink:type="simple" xlink:href="http://catb.org/esr/jargon/oldversions/jarg282.txt">
Jargon File Version 2.8.1</weblink> (Definition of "AI-complete" first added to jargon file.)</entry>
<entry level="1" type="bullet">

 Shapiro, Stuart C. (1992). <weblink xlink:type="simple" xlink:href="http://www.cse.buffalo.edu/~shapiro/Papers/ai.ps">
Artificial Intelligence</weblink> In Stuart C. Shapiro (Ed.), <it>Encyclopedia of Artificial Intelligence</it> (Second Edition, pp. 54-57). New York: John Wiley. (Section 4 is on "AI-Complete Tasks".)</entry>
</list>
</p>


</sec>
</bdy>
</article>
