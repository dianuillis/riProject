<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 16:43:25[mciao0827] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Aspen Movie Map</title>
<id>286321</id>
<revision>
<id>220348136</id>
<timestamp>2008-06-19T12:34:16Z</timestamp>
<contributor>
<username>Walter.bender</username>
<id>573552</id>
</contributor>
</revision>
<categories>
<category>Virtual reality</category>
<category>History of computing</category>
<category>Maps</category>
<category>Laserdisc</category>
</categories>
</header>
<bdy>

The <b>Aspen Movie Map</b> was a revolutionary <link xlink:type="simple" xlink:href="../801/287801.xml">
hypermedia</link> system developed at <university wordnetid="108286163" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../879/18879.xml">
MIT</link></university>
 by a team working with <link xlink:type="simple" xlink:href="../005/7451005.xml">
Andrew Lippman</link> in <link xlink:type="simple" xlink:href="../753/34753.xml">
1978</link> with funding from <link xlink:type="simple" xlink:href="../957/8957.xml">
ARPA</link>.<p>

<image location="right" width="150px" src="Aspen.jpg" type="thumb">
<caption>

A screen shot of the Aspen Movie Map touch-screen interface
</caption>
</image>
</p>

<sec>
<st>
Features</st>
<p>

The Aspen Movie Map allowed the user to take a virtual tour&mdash;travel surrogately&mdash;through the city of <village wordnetid="108672738" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../921/48921.xml">
Aspen, Colorado</link></village>
. It is an early example of a <link xlink:type="simple" xlink:href="../801/287801.xml">
hypermedia</link> system.</p>
<p>

A gyroscopic stabilizer with four <message wordnetid="106598915" confidence="0.8">
<information wordnetid="106634376" confidence="0.8">
<format wordnetid="106636806" confidence="0.8">
<link xlink:type="simple" xlink:href="../224/46224.xml">
16mm</link></format>
</information>
</message>
 stop-frame film cameras was mounted on top of a car with an encoder that triggered the cameras every 10 feet. (The distance was measured from an optical sensor attached to the hub of a bicycle wheel dragged behind the vehicle.) The cameras were mounted in order to capture front, back, and side views as the car made its way through the city. Filming took place daily between  10 a.m. and 2 p.m. to minimize lighting discrepancies. The car was carefully driven down the center of every street in Aspen, to enable registered <link xlink:type="simple" xlink:href="../515/4671515.xml">
match cut</link>s.</p>
<p>

The film was assembled into a collection of discontinuous scenes (one segment per view per city block) and then transferred to <link xlink:type="simple" xlink:href="../849/255849.xml">
laserdisc</link>, the analog-video precursor to <medium wordnetid="106254669" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../498/11014498.xml">
DVD</link></medium>
 technology. A database was made that correlated the layout of the video on the disc with the two-dimensional street plan. Thus linked, the user was able to choose an arbitrary path through the city; the only restrictions being the necessity to stay in the center of the street; move ten feet between steps; and view the street from one of the four orthogonal views.
<image location="right" width="150px" src="Qadas.jpg" type="thumb">
<caption>

A Quick and Dirty Animation System rendering of Aspen
</caption>
</image>
</p>
<p>

The interaction was controlled through a dynamically-generated menu overlaid on top of the video image: speed and viewing angle were modified by the selection of the appropriate icon through a touch-screen interface, harbinger of the ubiquitous interactive-video kiosk. Commands were sent from the client process handling the user input and overlay graphics to a server that accessed the database and controlled the laserdisc players. Another interface feature was the ability to touch any building in the current field of view, and, in a manner similar to the <link xlink:type="simple" xlink:href="../069/157069.xml">
ISMAP</link> feature of web browsers, jump to a façade of that building. Selected building contained additional data: e.g., interior shots, historical images, menus of restaurants, video interviews of city officials, etc., allowing the user to take a virtual tour through those buildings. </p>
<p>

In a later implementation, the <link xlink:type="simple" xlink:href="../632/18933632.xml">
metadata</link>, which was in large part automatically extracted from the animation database, was encoded as a digital signal in the analog video. The data encoded in each frame contained all the necessary information to enable a full-featured surrogate-travel experience.</p>
<p>

Another feature of the system was a navigation map that was overlaid above the horizon in the top of the frame; the map both served to indicate the user’s current position in the city (as well as a trace of streets previously explored) and to allow the user to jump to a two-dimensional city map, which allowed for an alternative way of moving through the city. Additional features of the map interface included the ability to jump back and forth between correlated aerial photographic and cartoon renderings with routes and landmarks highlighted; and to zoom in and out a la <link xlink:type="simple" xlink:href="../786/14652786.xml">
Charles Eames</link>’s <it><movie wordnetid="106613686" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../025/76025.xml">
Powers of Ten</link></movie>
</it> film.</p>
<p>

Aspen was filmed in early fall and winter. The user was able to <it><link xlink:type="simple" xlink:href="../978/379978.xml">
in situ</link></it> change seasons on demand while moving down the street or looking at a façade. A three-dimensional polygonal model of the city was also generated, using the Quick and Dirty Animation System (<link>
QADAS</link>), which featured three-dimensional <link xlink:type="simple" xlink:href="../903/146903.xml">
texture-mapping</link> of the facades of landmark buildings, using an algorithm designed by <link>
Paul Heckbert</link>. These computer-graphic images, also stored on the laserdisc, were also correlated to the video, enabling the user to view an abstract rendering of the city in real time.</p>

</sec>
<sec>
<st>
Credits</st>
<p>

MIT undergraduate <link>
Peter Clay</link>, with help from <link>
Bob Mohl</link> and <physical_entity wordnetid="100001930" confidence="0.8">
<cameraman wordnetid="109889539" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<photographer wordnetid="110426749" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<academician wordnetid="109759069" confidence="0.8">
<artist wordnetid="109812338" confidence="0.8">
<adult wordnetid="109605289" confidence="0.8">
<professional wordnetid="110480253" confidence="0.8">
<educator wordnetid="110045713" confidence="0.8">
<creator wordnetid="109614315" confidence="0.8">
<link xlink:type="simple" xlink:href="../010/1881010.xml">
Michael Naimark</link></creator>
</educator>
</professional>
</adult>
</artist>
</academician>
</causal_agent>
</photographer>
</person>
</cameraman>
</physical_entity>
, filmed the hallways of MIT with a camera mounted on a cart. The film was transferred to a laserdisc as part of a collection of projects being done at the <link xlink:type="simple" xlink:href="../540/386540.xml">
Architecture Machine Group</link> (ArcMac).</p>
<p>

The Aspen Movie Map was filmed in the fall of 1978, in winter 1979, and briefly again (with an active gyro stabilizer) in the fall of 1979. The first version was operational in early spring of 1979. </p>
<p>

Many people were involved in the production, most notably: <physical_entity wordnetid="100001930" confidence="0.8">
<communicator wordnetid="109610660" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<theorist wordnetid="110706812" confidence="0.8">
<intellectual wordnetid="109621545" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<academician wordnetid="109759069" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<adult wordnetid="109605289" confidence="0.8">
<writer wordnetid="110794014" confidence="0.8">
<professional wordnetid="110480253" confidence="0.8">
<educator wordnetid="110045713" confidence="0.8">
<link xlink:type="simple" xlink:href="../271/187271.xml">
Nicholas Negroponte</link></educator>
</professional>
</writer>
</adult>
</scientist>
</academician>
</causal_agent>
</intellectual>
</theorist>
</person>
</communicator>
</physical_entity>
, founder and director of the Architecture Machine Group, who found support for the project from the Cybernetics Technology Office of DARPA; Andrew Lippman, principal investigator; Bob Mohl, who designed the map overlay system and ran user studies of the efficacy of the system for his PhD thesis; <link>
Ricky Leacock</link>, who headed the MIT Film/Video section and shot along with MS student <link>
Marek Zalewski</link> the <link>
Cinéma Vérité</link> interviews placed behind the facades of key buildings; <link>
John Borden</link>, of Peace River Films in Cambridge, MA, who designed the stabilization rig; <link>
Kristina Hooper</link>  of UCSC; <link xlink:type="simple" xlink:href="../071/7622071.xml">
Rebecca Allen</link>; <link xlink:type="simple" xlink:href="../293/5714293.xml">
Scott Fisher</link>, who matched the photos of Aspen in the silver-mining days from the historical society to the same scenes in Aspen in 1978 and who experiment with anamorphic imaging of the city (using a <link>
Volpe lens</link>); <link xlink:type="simple" xlink:href="../484/3323484.xml">
Walter Bender</link>, who designed and built the interface, the client/server model, and the animation system; <physical_entity wordnetid="100001930" confidence="0.8">
<saxophonist wordnetid="110554243" confidence="0.8">
<composer wordnetid="109947232" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<flutist wordnetid="110098245" confidence="0.8">
<performer wordnetid="110415638" confidence="0.8">
<musician wordnetid="110340312" confidence="0.8">
<musician wordnetid="110339966" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<artist wordnetid="109812338" confidence="0.8">
<entertainer wordnetid="109616922" confidence="0.8">
<creator wordnetid="109614315" confidence="0.8">
<link xlink:type="simple" xlink:href="../830/7887830.xml">
Steve Gregory</link></creator>
</entertainer>
</artist>
</causal_agent>
</musician>
</musician>
</performer>
</flutist>
</person>
</composer>
</saxophonist>
</physical_entity>
; <link>
Stan Sasaki</link>, who built the much of the electronics; <link>
Steve Yelick</link>, who worked on the laserdisc interface and anamorphic rendering; <link>
Eric "Smokehouse" Brown</link>, who built the metadata encoder/decoder; Paul Heckbert worked on the animation system; <link>
Mark Shirley</link> and <physical_entity wordnetid="100001930" confidence="0.8">
<executive wordnetid="110069645" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<leader wordnetid="109623038" confidence="0.8">
<administrator wordnetid="109770949" confidence="0.8">
<engineer wordnetid="109615807" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<head wordnetid="110162991" confidence="0.8">
<link xlink:type="simple" xlink:href="../055/10141055.xml">
Paul Trevithick</link></head>
</causal_agent>
</engineer>
</administrator>
</leader>
</person>
</executive>
</physical_entity>
, who also worked on the animation; <link xlink:type="simple" xlink:href="../433/165433.xml">
Ken Carson</link>; and Mike Naimark, who was at the Center for Advanced Visual Studies and was responsible for the cinematography design and production.</p>

</sec>
<sec>
<st>
Purpose and applications</st>
<p>

ARPA funding during the late 1970s was subject to the military application requirements of the notorious Mansfield Amendment introduced by <senator wordnetid="110578471" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../183/80183.xml">
Mike Mansfield</link></senator>
 (which had severely limited funding for <link xlink:type="simple" xlink:href="../460/13460.xml">
hypertext</link> researchers like <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../081/8081.xml">
Douglas Engelbart</link></scientist>
</person>
).  </p>
<p>

The Aspen Movie Map's military application was to solve the problem of quickly familiarizing soldiers with new territory.  The Department of Defense had been deeply impressed by the success of <accident wordnetid="107301336" confidence="0.9508927676800064">
<conflict wordnetid="100958896" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../856/66856.xml">
Operation Entebbe</link></conflict>
</accident>
 in 1976, where the Israeli commandos had quickly built a crude replica of the airport and practiced in it before attacking the real thing.  DOD hoped that the Movie Map would show the way to a future where computers could instantly create a three-dimensional simulation of a hostile environment at much lower cost and in less time (see <link xlink:type="simple" xlink:href="../612/32612.xml">
virtual reality</link>).</p>
<p>

While the Movie Map has been referred to as an early example of <link xlink:type="simple" xlink:href="../896/1794896.xml">
interactive video</link>, it is perhaps more accurate to describe it as a pioneering example of <link xlink:type="simple" xlink:href="../251/1623251.xml">
interactive computing</link>. Video, audio, still images, and metadata were retrieved from a database and assembled on the fly by the computer (an Interdata minicomputer running the <link xlink:type="simple" xlink:href="../927/14914927.xml">
MagicSix</link> operating system) redirecting its actions based upon user input; video was the principle, but not sole affordance of the interaction.</p>

</sec>
<sec>
<st>
Political response</st>
<p>

<senator wordnetid="110578471" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../979/511979.xml">
William Proxmire</link></senator>
 awarded the project one of his <link xlink:type="simple" xlink:href="../354/3432354.xml">
Golden Fleece Award</link>s.  Proxmire was later severely criticized for his shortsightedness by journalist <person wordnetid="100007846" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../341/333341.xml">
Stewart Brand</link></person>
.</p>

</sec>
<sec>
<st>
See also</st>
<p>

<list>
<entry level="1" type="bullet">

<work wordnetid="100575741" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<service wordnetid="100577525" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<link xlink:type="simple" xlink:href="../879/11546879.xml">
Google Street View</link></activity>
</psychological_feature>
</act>
</service>
</event>
</work>
</entry>
<entry level="1" type="bullet">

<software wordnetid="106566077" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../010/16685010.xml">
EveryScape</link></software>
</entry>
</list>
</p>

</sec>
<sec>
<st>
References</st>
<p>

<list>
<entry level="1" type="bullet">

 Video <it><weblink xlink:type="simple" xlink:href="http://www.media.mit.edu/speech/sig_videos.html">
 The Interactive Movie Map: A Surrogate Travel System</weblink></it>, January 1981, The Architecture Machine, at the MIT MediaLab Speech Interface Group; Youtube link: http://www.youtube.com/watch?v=Hf6LkqgXPMU.</entry>
<entry level="1" type="bullet">

 Bender, Walter, <it>Computer animation via optical video disc</it>, Thesis Arch 1980 M.S.V.S., Massachusetts Institute of Technology.</entry>
<entry level="1" type="bullet">

 Brand, Stewart, <it>The Media Lab, Inventing the Future at MIT</it> (New York: Penguin Books, 1989), 141.</entry>
<entry level="1" type="bullet">

 Brown, Eric, <it>Digital data bases on optical videodiscs</it>, Thesis E.E. 1981 B.S., Massachusetts Institute of Technology.</entry>
<entry level="1" type="bullet">

 Clay, Peter, <it>Surrogate travel via optical videodisc</it>, Thesis Urb.Stud 1978 B.S., Massachusetts Institute of Technology.</entry>
<entry level="1" type="bullet">

 Heckbert, Paul, "<weblink xlink:type="simple" xlink:href="http://www.soe.ucsc.edu/classes/cmps160/Fall05/papers/heckbert_texsurv.pdf">
Survey of Texture Mapping</weblink>," <it>IEEE Computer Graphics and Applications</it>, Nov. 1986, pp. 56&ndash;67.</entry>
<entry level="1" type="bullet">

 Lippman, Andrew,  "Movie-maps: An application of the optical videodisc to computer graphics," <it>Proceedings of the 7th annual conference on Computer graphics and interactive techniques</it>, Seattle, Washington, United States, 1980, pp. 32&ndash;42.</entry>
<entry level="1" type="bullet">

 Mohl, Robert, <it>Cognitive space in the interactive movie map : an investigation of spatial learning in virtual environments</it>, Thesis Arch 1982 Ph.D., Massachusetts Institute of Technology.</entry>
<entry level="1" type="bullet">

 Yelick, Steven, <it>Anamorphic image processing</it>, Thesis E.E. 1980 B.S., Massachusetts Institute of Technology.</entry>
</list>
</p>

</sec>
<sec>
<st>
External links</st>
<p>

<list>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.everyscape.com/aspen-co.us.aspx">
EveryScape: Aspen, Colorado</weblink></entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.naimark.net/projects/aspen.html">
Aspen Movie Map</weblink> on Michael Naimark’s website (includes video demo).</entry>
</list>




</p>
</sec>
</bdy>
</article>
