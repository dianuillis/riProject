<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 20:05:00[mciao0827] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>History of artificial intelligence</title>
<id>2894560</id>
<revision>
<id>244292666</id>
<timestamp>2008-10-10T03:34:15Z</timestamp>
<contributor>
<username>CharlesGillingham</username>
<id>4604963</id>
</contributor>
</revision>
<categories>
<category>History of artificial intelligence</category>
</categories>
</header>
<bdy>

<indent level="1">

<it>See also: <link xlink:type="simple" xlink:href="../470/12413470.xml">
timeline of artificial intelligence</link></it>
</indent>

The <b>history of artificial intelligence</b> begins in <link xlink:type="simple" xlink:href="../475/286475.xml">
antiquity</link> with myths, stories and rumors of artificial beings endowed with intelligence and consciousness by master craftsmen. In the middle of the 20th century, a handful of scientists began to explore a new approach to this ancient idea based on their discoveries in <link xlink:type="simple" xlink:href="../226/21226.xml">
neurology</link>, a new mathematical theory of <link xlink:type="simple" xlink:href="../062/18985062.xml">
information</link>, an understanding of control and stability called <link xlink:type="simple" xlink:href="../904/5904.xml">
cybernetic</link>s and, above all, by the invention of the <link xlink:type="simple" xlink:href="../457/7878457.xml">
digital computer</link>, a machine based on the abstract essence of mathematical reasoning.<p>

The field of <link xlink:type="simple" xlink:href="../164/1164.xml">
artificial intelligence</link> research was born at a conference on the campus of <university wordnetid="108286163" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../418/8418.xml">
Dartmouth College</link></university>
 in the summer of 1956. Those who attended would become the leaders of AI research for many decades. Many of them predicted that a machine as intelligent as a human being would exist in no more than a generation and they were given millions of dollars to make this vision come true. Eventually it became obvious that they had grossly underestimated the difficulty of the project. In 1973, in response to the criticism of <link xlink:type="simple" xlink:href="../659/946659.xml">
Sir James Lighthill</link> and ongoing pressure from congress, the <agency wordnetid="108337324" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../957/8957.xml">
U.S.</link></agency>
 and <link xlink:type="simple" xlink:href="../930/334930.xml">
British Government</link>s stopped funding undirected research into artificial intelligence. Seven years later, the <link xlink:type="simple" xlink:href="../925/2172925.xml">
Japanese Government</link> and American industry would provide AI with billions of dollars, but again the investors would be disappointed and by the late 80s the funding would dry up again. The cycle of boom and bust, of <bubble wordnetid="109229709" confidence="0.8">
<ball wordnetid="113899404" confidence="0.8">
<globule wordnetid="109289709" confidence="0.8">
<sphere wordnetid="113899200" confidence="0.8">
<round_shape wordnetid="113865483" confidence="0.8">
<shape wordnetid="100027807" confidence="0.8">
<link xlink:type="simple" xlink:href="../574/3548574.xml">
AI winter</link></shape>
</round_shape>
</sphere>
</globule>
</ball>
</bubble>
s and summers, continues to the present day. Undaunted, there are those that make extraordinary predictions even now.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref></p>
<p>

Despite the rise and fall of AI in the perceptions of venture capitalists and government bureaucrats, AI has made continuous advances in all areas regardless of the climate, overcoming unexpected obstacles, reorienting itself to the light of new discoveries and riding the crest of the wave of <link xlink:type="simple" xlink:href="../418/39418.xml">
increasing computer power</link>. Progress has been slower than predicted but progress has continued nonetheless. Artificial intelligence problems that had begun to seem impossible in 1970 have been solved and the solutions are now used in successful commercial products.</p>
<p>

It remains to be seen when or if an AI system will be built with a <link xlink:type="simple" xlink:href="../357/586357.xml">
human level of intelligence</link>. <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../208/1208.xml">
Alan Turing</link></scientist>
</person>
, in a famous 1950 paper, asked the question "can machines think?" and concluded: "We can only see a short distance ahead, but we can see plenty there that needs to be done."<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref></p>
<p>

<table style="background:#f9f9f9; font-size:85%; line-height:110%; ">
<row>
<col>
 <image width="32x28px" src="Portal.svg">
</image>
</col>
<col style="padding:0 0.2em;">
 <b><it>
artificial intelligence&#32;portal</it></b></col>
</row>
</table>
</p>

<p>

<table class="infobox">
<row>
<col style="background: #ccf; text-align:center;">
 <b><link xlink:type="simple" xlink:href="../519/386519.xml">
History of computing</link></b></col>
</row>
<row>
<col>
<link xlink:type="simple" xlink:href="../636/13636.xml">
Hardware before 1960</link></col>
</row>
<row>
<col>
<link>
Hardware 1960s to present</link></col>
</row>
<row>
<col>
<link xlink:type="simple" xlink:href="../959/397959.xml">
Hardware in Soviet Bloc countries</link></col>
</row>
<row>
<col style="border-bottom: 1px solid #ccc"></col>
</row>
<row>
<col>
<link xlink:type="simple" xlink:href="../413/3271413.xml">
Computer science</link></col>
</row>
<row>
<col>
<link xlink:type="simple" xlink:href="../395/55395.xml">
Operating systems</link></col>
</row>
<row>
<col>
<link xlink:type="simple" xlink:href="../167/16142167.xml">
Personal computers</link></col>
</row>
<row>
<col>
<link xlink:type="simple" xlink:href="../037/16785037.xml">
Laptops</link></col>
</row>
<row>
<col>
<link xlink:type="simple" xlink:href="../895/758895.xml">
Software engineering</link></col>
</row>
<row>
<col>
<link xlink:type="simple" xlink:href="../120/896120.xml">
Programming languages</link></col>
</row>
<row>
<col style="border-bottom: 1px solid #ccc"></col>
</row>
<row>
<col>
<link xlink:type="simple" xlink:href="../560/2894560.xml">
Artificial intelligence</link></col>
</row>
<row>
<col>
<link xlink:type="simple" xlink:href="../914/13914.xml">
Graphical user interface</link></col>
</row>
<row>
<col>
<link xlink:type="simple" xlink:href="../692/13692.xml">
Internet</link></col>
</row>
<row>
<col>
<link xlink:type="simple" xlink:href="../777/4192777.xml">
World Wide Web</link></col>
</row>
<row>
<col>
<link xlink:type="simple" xlink:href="../401/32401.xml">
Computer and video games</link></col>
</row>
<row>
<col style="border-bottom: 1px solid #ccc"></col>
</row>
<row>
<col>
<record wordnetid="106647206" confidence="0.8">
<chronology wordnetid="106503224" confidence="0.8">
<indication wordnetid="106797169" confidence="0.8">
<evidence wordnetid="106643408" confidence="0.8">
<timeline wordnetid="106504965" confidence="0.8">
<written_record wordnetid="106502378" confidence="0.8">
<link xlink:type="simple" xlink:href="../249/6249.xml">
Timeline of computing</link></written_record>
</timeline>
</evidence>
</indication>
</chronology>
</record>
 <p>

<list>
<entry level="1" type="bullet">

<link>
Timeline of computing 2400 BC–1949</link></entry>
<entry level="1" type="bullet">

<link>
1950–1979</link></entry>
<entry level="1" type="bullet">

<link>
1980–1989</link></entry>
<entry level="1" type="bullet">

<link>
1990&mdash;</link></entry>
<entry level="1" type="bullet">


Computing timelines|More timelines...</entry>
</list>
</p>
</col>
</row>
<row>
<col style="border-bottom: 1px solid #ccc"></col>
</row>
<row>
<col align="center">

History of computing|More...</col>
</row>
</table>
</p>

<sec>
<st>
 Precursors </st>
<p>

<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck (2004)</link> writes "<link xlink:type="simple" xlink:href="../164/1164.xml">
artificial intelligence</link> in one form or another is an idea that has pervaded Western intellectual history, a dream in urgent need of being realized," expressed in humanity's myths, legends, stories, speculation and clockwork <link xlink:type="simple" xlink:href="../749/189749.xml">
automaton</link>s.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%223%22])">3</ref> 
</p>
<ss1>
<st>
 AI in myth, fiction and speculation </st>

<p>

<indent level="1">

<it>Main article: <link xlink:type="simple" xlink:href="../227/11746227.xml">
artificial intelligence in fiction</link></it>
</indent>
Mechanical men and artificial beings appear in <link xlink:type="simple" xlink:href="../961/11961.xml">
Greek myth</link>s, such as the golden robots of <deity wordnetid="109505418" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../388/14388.xml">
Hephaestus</link></deity>
 and <link xlink:type="simple" xlink:href="../085/1869085.xml">
Pygmalion's</link> <link xlink:type="simple" xlink:href="../817/839817.xml">
Galatea</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%224%22])">4</ref>
In the Middle Ages, there were rumors of secret mystical or <link xlink:type="simple" xlink:href="../573/573.xml">
alchemical</link> means of placing mind into matter, such as <scholar wordnetid="110557854" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../140/63140.xml">
Geber</link></scholar>
's <it><link xlink:type="simple" xlink:href="../652/1158652.xml">
Takwin</link></it>, <person wordnetid="100007846" confidence="0.9508927676800064">
<occultist wordnetid="110370381" confidence="0.9173553029164789">
<astrologer wordnetid="109817816" confidence="0.9173553029164789">
<doctor wordnetid="110020890" confidence="0.9173553029164789">
<link xlink:type="simple" xlink:href="../487/152487.xml">
Paracelsus</link></doctor>
</astrologer>
</occultist>
</person>
' <link xlink:type="simple" xlink:href="../467/317467.xml">
homunculus</link> and <link xlink:type="simple" xlink:href="../031/176031.xml">
Rabbi Judah Loew</link>'s <link xlink:type="simple" xlink:href="../888/11888.xml">
Golem</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%225%22])">5</ref> 
By the 19th century, ideas about artificial men and thinking machines were developed in fiction, as in <person wordnetid="100007846" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../832/19832.xml">
Mary Shelley</link></person>
's <it><literary_composition wordnetid="106364329" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<fiction wordnetid="106367107" confidence="0.8">
<novel wordnetid="106367879" confidence="0.8">
<link xlink:type="simple" xlink:href="../673/18580673.xml">
Frankenstein</link></novel>
</fiction>
</writing>
</written_communication>
</literary_composition>
</it>  or  <link>
Karel Čapek</link>'s <it><dramatic_composition wordnetid="107007684" confidence="0.8">
<play wordnetid="107007945" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../386/37386.xml">
R.U.R. (Rossum's Universal Robots)</link></writing>
</written_communication>
</play>
</dramatic_composition>
</it>,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref>
and speculation, such as <link xlink:type="simple" xlink:href="../515/937515.xml">
Samuel Butler</link>'s <it><link xlink:type="simple" xlink:href="../221/15938221.xml">
Darwin Among the Machines</link></it>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%227%22])">7</ref></p>
<p>

<image location="left" width="250px" src="Al-jazari_robots.jpg" type="thumb">
</image>
</p>

</ss1>
<ss1>
<st>
 Automatons </st>

<p>

<indent level="1">

<it>Main article: <link xlink:type="simple" xlink:href="../749/189749.xml">
automaton</link></it>
</indent>
Realistic humanoid <link xlink:type="simple" xlink:href="../749/189749.xml">
automaton</link>s were built by craftsman from every civilization,  including <sovereign wordnetid="110628644" confidence="0.8">
<physical_entity wordnetid="100001930" confidence="0.8">
<representative wordnetid="110522035" confidence="0.8">
<communicator wordnetid="109610660" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<king wordnetid="110231515" confidence="0.8">
<head_of_state wordnetid="110164747" confidence="0.8">
<ruler wordnetid="110541229" confidence="0.8">
<negotiator wordnetid="110351874" confidence="0.8">
<link xlink:type="simple" xlink:href="../839/326839.xml#xpointer(//*[./st=%22Robotics%22])">
Yan Shi</link></negotiator>
</ruler>
</head_of_state>
</king>
</causal_agent>
</person>
</communicator>
</representative>
</physical_entity>
</sovereign>
,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%228%22])">8</ref>
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../274/68274.xml">
Hero of Alexandria</link></scientist>
,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%229%22])">9</ref>
<link xlink:type="simple" xlink:href="../981/271981.xml">
Al-Jazari</link><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2210%22])">10</ref>
and <physical_entity wordnetid="100001930" confidence="0.8">
<automaton wordnetid="109825519" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<inventor wordnetid="110214637" confidence="0.8">
<anomaly wordnetid="109606527" confidence="0.8">
<creator wordnetid="109614315" confidence="0.8">
<link xlink:type="simple" xlink:href="../100/1144100.xml">
Wolfgang von Kempelen</link></creator>
</anomaly>
</inventor>
</scientist>
</causal_agent>
</person>
</automaton>
</physical_entity>
.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2211%22])">11</ref>
The oldest known <link xlink:type="simple" xlink:href="../749/189749.xml">
automaton</link>s were the <link xlink:type="simple" xlink:href="../174/3731174.xml">
sacred statues</link> of <link xlink:type="simple" xlink:href="../874/874.xml">
ancient Egypt</link> and <link xlink:type="simple" xlink:href="../540/66540.xml">
Greece</link>. The faithful believed that craftsman had imbued these figures with very real minds, capable of wisdom and emotion—<belief wordnetid="105941423" confidence="0.8">
<deity wordnetid="109505418" confidence="0.8">
<spiritual_being wordnetid="109504135" confidence="0.8">
<link xlink:type="simple" xlink:href="../928/68928.xml">
Hermes Trismegistus</link></spiritual_being>
</deity>
</belief>
 wrote that "by discovering the true nature of the gods, man has been able to reproduce it."<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2212%22])">12</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2213%22])">13</ref></p>
<p>

<image location="right" width="150px" src="Gottfried_Wilhelm_von_Leibniz.jpg" type="thumb">

</image>
</p>

</ss1>
<ss1>
<st>
Formal reasoning</st>

<p>

<indent level="1">

<it>Main article: <link xlink:type="simple" xlink:href="../760/748760.xml">
history of philosophy</link></it>
</indent>

In the 17th century, <person wordnetid="100007846" confidence="0.9508927676800064">
<philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../823/29823.xml">
Thomas Hobbes</link></philosopher>
</person>
, <link>
René Descartes</link> and <person wordnetid="100007846" confidence="0.9508927676800064">
<philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../281/12281.xml">
Gottfried Leibniz</link></philosopher>
</person>
 explored the possibility that all rational thought could be made as systematic as algebra or geometry.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2214%22])">14</ref>
<link xlink:type="simple" xlink:href="../823/29823.xml">
Hobbes</link> famously wrote in <work wordnetid="104599396" confidence="0.8">
<product wordnetid="104007894" confidence="0.8">
<creation wordnetid="103129123" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<book wordnetid="106410904" confidence="0.8">
<publication wordnetid="106589574" confidence="0.8">
<link xlink:type="simple" xlink:href="../192/190192.xml">
<it>Leviathan''</it></link></publication>
</book>
</artifact>
</creation>
</product>
</work>
: "reason is nothing but reckoning".<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2215%22])">15</ref>
<person wordnetid="100007846" confidence="0.9508927676800064">
<philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../281/12281.xml">
Leibniz</link></philosopher>
</person>
 envisioned a universal language of reasoning (his <it><link xlink:type="simple" xlink:href="../705/3230705.xml">
characteristica universalis</link></it>) which would reduce argumentation to calculation, so that "there would be no more need of disputation between two philosophers than between two accountants. For it would suffice to take their pencils in hand, down to their slates, and to say each other (with a friend as witness, if they liked): <it>Let us calculate</it>."<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2216%22])">16</ref>
These philosophers had begun to articulate the <link xlink:type="simple" xlink:href="../999/2685999.xml">
physical symbol system</link> hypothesis that would become the guiding faith of AI research.</p>
<p>

<image location="left" width="250px" src="Classic_shot_of_the_ENIAC.jpg" type="thumb">
<caption>

The ENIAC, at the Moore School of Electrical Engineering.
</caption>
</image>
</p>

</ss1>
<ss1>
<st>
Computer science</st>
<p>

<indent level="1">

</indent>
:<it>Main articles: <link xlink:type="simple" xlink:href="../636/13636.xml">
history of computer hardware</link>&#32;and&#32;<link xlink:type="simple" xlink:href="../413/3271413.xml">
history of computer science</link></it></p>
<p>

Calculating machines were built in antiquity and improved throughout history by many mathematicians, including (once again) philosopher <person wordnetid="100007846" confidence="0.9508927676800064">
<philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../281/12281.xml#xpointer(//*[./st=%22Information+Technology%22])">
Gottfried Leibniz</link></philosopher>
</person>
. The first modern computers were the massive code breaking machines of the <link xlink:type="simple" xlink:href="../927/32927.xml">
Second World War</link> (such as <computer wordnetid="103082979" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<device wordnetid="103183080" confidence="0.8">
<machine wordnetid="103699975" confidence="0.8">
<link xlink:type="simple" xlink:href="../671/152671.xml">
Z3</link></machine>
</device>
</instrumentality>
</artifact>
</computer>
, <computer wordnetid="103082979" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<device wordnetid="103183080" confidence="0.8">
<machine wordnetid="103699975" confidence="0.8">
<link xlink:type="simple" xlink:href="../572/66572.xml">
ENIAC</link></machine>
</device>
</instrumentality>
</artifact>
</computer>
 and <computer wordnetid="103082979" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<device wordnetid="103183080" confidence="0.8">
<machine wordnetid="103699975" confidence="0.8">
<link xlink:type="simple" xlink:href="../229/6229.xml">
Colossus</link></machine>
</device>
</instrumentality>
</artifact>
</computer>
).<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2217%22])">17</ref></p>
<p>

A key insight was the <invention wordnetid="105633385" confidence="0.8">
<know-how wordnetid="105616786" confidence="0.8">
<method wordnetid="105660268" confidence="0.8">
<link xlink:type="simple" xlink:href="../403/30403.xml">
Turing machine</link></method>
</know-how>
</invention>
, a simple theoretical construct that captured the essence of abstract symbol manipulation. The <link xlink:type="simple" xlink:href="../854/6854.xml">
Church-Turing thesis</link> implied that a mechanical device, shuffling symbols as simple as 0 and 1, could imitate any conceivable process of mathematical deduction. This would inspire a handful of scientists to begin discussing the possibility of thinking machines.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2218%22])">18</ref></p>

</ss1>
</sec>
<sec>
<st>
The birth of artificial intelligence 1943−1956</st>
<p>

<image width="420px" src="BRL61-IBM_702.jpg" type="thumb">
<caption>

The IBM 702: a computer used by the first generation of AI researchers.
</caption>
</image>

<it>A note on the sections in this article</it>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2219%22])">19</ref></p>
<p>

In the 1940s and 50s, a handful of scientists from a variety fields (mathematics, psychology, engineering, economics and political science) began to discuss the possibility of creating an artificial brain. The field of <link xlink:type="simple" xlink:href="../164/1164.xml">
artificial intelligence</link> research was founded as an academic discipline in 1956.</p>

<ss1>
<st>
Cybernetics and early neural networks</st>
<p>

The earliest research into thinking machines was inspired by a confluence of ideas that became prevalent in the late 30s, 40s and early 50s: the realization that the brain was an electrical network of neurons that fired in all-or-nothing pulses; <link xlink:type="simple" xlink:href="../185/63185.xml">
Norbert Weiner</link>'s <link xlink:type="simple" xlink:href="../904/5904.xml">
cybernetic</link>s, which described electrical networks; <scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../693/5693.xml">
Claude Shannon</link></scientist>
's <link xlink:type="simple" xlink:href="../773/14773.xml">
information theory</link> which described all-or-nothing signals; and <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../208/1208.xml">
Alan Turing</link></scientist>
</person>
's <link xlink:type="simple" xlink:href="../402/30402.xml">
theory of computation</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2220%22])">20</ref></p>
<p>

Robots built at this time, such as <link xlink:type="simple" xlink:href="../410/310410.xml">
W. Grey Walter</link>'s <automaton wordnetid="102761392" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<device wordnetid="103183080" confidence="0.8">
<mechanism wordnetid="103738472" confidence="0.8">
<link xlink:type="simple" xlink:href="../198/9022198.xml">
turtles</link></mechanism>
</device>
</instrumentality>
</artifact>
</automaton>
 and the <link xlink:type="simple" xlink:href="../552/13882552.xml">
Johns Hopkins Beast</link>, did not use computers, digital electronics or symbolic reasoning; they were controlled entirely by analog circuitry.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2221%22])">21</ref>
<link xlink:type="simple" xlink:href="../949/302949.xml">
Walter Pitts</link> and <link xlink:type="simple" xlink:href="../508/44508.xml">
Warren McCulloch</link> analyzed networks of idealized artificial <link xlink:type="simple" xlink:href="../120/21120.xml">
neurons</link> and showed how they might perform simple logical functions. They were the first to describe what later researchers would call a <link xlink:type="simple" xlink:href="../542/1729542.xml">
neural network</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2222%22])">22</ref></p>
<p>

One of the students inspired by <link xlink:type="simple" xlink:href="../949/302949.xml">
Pitts</link> and <link xlink:type="simple" xlink:href="../508/44508.xml">
McCulloch</link> was a young <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../639/19639.xml">
Marvin Minsky</link></scientist>
</person>
, then a 24 year old graduate student. In 1951 (with Dean Edmonds) he built the first neural net machine, the <link xlink:type="simple" xlink:href="../554/12322554.xml">
SNARC</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2223%22])">23</ref>
<person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../639/19639.xml">
Minsky</link></scientist>
</person>
 was to become one of the most important leaders and innovators in AI for the next 50 years.</p>

</ss1>
<ss1>
<st>
Turing's test</st>
<p>

In 1950 <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../208/1208.xml">
Alan Turing</link></scientist>
</person>
 published a <link xlink:type="simple" xlink:href="../048/404048.xml">
landmark paper</link> in which he speculated about the possibility of creating machines with true intelligence.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2224%22])">24</ref>
He noted that "intelligence" is difficult to define and devised his famous <link xlink:type="simple" xlink:href="../840/43840.xml">
Turing Test</link>. If a machine could carry on a conversation (over a <link xlink:type="simple" xlink:href="../247/31247.xml">
teletype</link>) that was indistinguishable from a conversation with a human being, then the machine could be called "intelligent." This simplified version of the problem allowed Turing to argue convincingly that a "thinking machine" was at least <it>plausible</it> and the paper answered all the most common objections to the proposition.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2225%22])">25</ref> The <link xlink:type="simple" xlink:href="../840/43840.xml">
Turing Test</link> was the first serious proposal in the <link xlink:type="simple" xlink:href="../015/2958015.xml">
philosophy of artificial intelligence</link>.</p>

</ss1>
<ss1>
<st>
Symbolic reasoning and the Logic Theorist</st>
<p>

When access to digital computers became possible in the middle fifties, a few scientists instinctively recognized that a machine that could manipulate numbers could also manipulate symbols and that the manipulation of symbols could well be the essence of human thought. This was a new approach to creating thinking machines.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2226%22])">26</ref></p>
<p>

In 1955, <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../300/287300.xml">
Allen Newell</link></scientist>
</person>
 and (future Nobel Laureate) <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../205/14205.xml">
Herbert Simon</link></scientist>
</person>
 created the "<link xlink:type="simple" xlink:href="../265/13685265.xml">
Logic Theorist</link>" (with help from <link xlink:type="simple" xlink:href="../092/317092.xml">
J. C. Shaw</link>). The program would eventually prove 38 of the first 52 theorems in <person wordnetid="100007846" confidence="0.9508927676800064">
<philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../163/4163.xml">
Russell</link></philosopher>
</person>
 and <person wordnetid="100007846" confidence="0.9508927676800064">
<philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../395/43395.xml">
Whitehead's</link></philosopher>
</person>
 <it><work wordnetid="104599396" confidence="0.8">
<product wordnetid="104007894" confidence="0.8">
<creation wordnetid="103129123" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<book wordnetid="106410904" confidence="0.8">
<publication wordnetid="106589574" confidence="0.8">
<link xlink:type="simple" xlink:href="../133/24133.xml">
Principia Mathematica</link></publication>
</book>
</artifact>
</creation>
</product>
</work>
</it>, and find new and more elegant proofs for some.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2227%22])">27</ref> 
Simon said that they had "solved the venerable <link xlink:type="simple" xlink:href="../483/6880483.xml">
mind/body problem</link>, explaining how a system composed of matter can have the properties of mind."<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2228%22])">28</ref>
(This was an early statement of the philosophical position <philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../079/147079.xml">
John Searle</link></philosopher>
 would later call "<link>
Strong AI</link>": that machines can contain minds just as human bodies do.)<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2229%22])">29</ref></p>

</ss1>
<ss1>
<st>
Dartmouth Conference 1956: the birth of AI</st>
<p>

The <link xlink:type="simple" xlink:href="../646/1124646.xml">
Dartmouth Conference</link> of 1956<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2230%22])">30</ref>
was organized by <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../639/19639.xml">
Marvin Minsky</link></scientist>
</person>
, <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../362/308362.xml">
John McCarthy</link></scientist>
</person>
 and two senior scientists: <scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../693/5693.xml">
Claude Shannon</link></scientist>
 and <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<link xlink:type="simple" xlink:href="../794/13884794.xml">
Nathan Rochester</link></scientist>
</causal_agent>
</person>
</physical_entity>
 of <company wordnetid="108058098" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../259/18622259.xml">
IBM</link></company>
. The proposal for the conference included this assertion: "every aspect of learning or any other feature of intelligence can be so precisely described that a machine can be made to simulate it" — a clear statement of the <link xlink:type="simple" xlink:href="../015/2958015.xml">
philosophical position</link> of AI research.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2231%22])">31</ref>
The participants included <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<theorist wordnetid="110706812" confidence="0.8">
<intellectual wordnetid="109621545" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../673/402673.xml">
Ray Solomonoff</link></causal_agent>
</intellectual>
</theorist>
</person>
</physical_entity>
, <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<research_worker wordnetid="110523076" confidence="0.8">
<link xlink:type="simple" xlink:href="../706/1631706.xml">
Oliver Selfridge</link></research_worker>
</scientist>
</causal_agent>
</person>
</physical_entity>
, <link>
Trenchard More</link>, <scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../677/10809677.xml">
Arthur Samuel</link></scientist>
, <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../300/287300.xml">
Allen Newell</link></scientist>
</person>
 and <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../205/14205.xml">
Herbert Simon</link></scientist>
</person>
, all of whom would create important programs during the first decades of AI research.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2232%22])">32</ref>
At the conference Newell and Simon debuted the "<link xlink:type="simple" xlink:href="../265/13685265.xml">
Logic Theorist</link>" and McCarthy persuaded the attendees to accept "Artificial Intelligence" as the name of the field.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2233%22])">33</ref>
The 1956 Dartmouth conference was the moment that AI gained its name, its mission, its first success and its major players, and is widely considered the birth of AI.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2234%22])">34</ref></p>

</ss1>
</sec>
<sec>
<st>
The golden years 1956−1974</st>
<p>

The years after the Dartmouth conference were an era of discovery, of sprinting across new ground. The programs that were developed during this time were, to most people, simply "astonishing":<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2235%22])">35</ref> computers were solving algebra word problems, proving theorems in geometry and learning to speak English. Few at the time would have believed that such "intelligent" behavior by machines was possible at all.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2236%22])">36</ref> Researchers expressed an intense optimism in private and in print, predicting that a fully intelligent machine would be built in less than 20 years.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2237%22])">37</ref> Government agencies like <agency wordnetid="108337324" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../957/8957.xml">
ARPA</link></agency>
 poured money into the new field.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2238%22])">38</ref></p>

<ss1>
<st>
The work</st>
<p>

There were many successful programs and new directions in the late 50s and 1960s. Among the most influential were these:</p>
<p>

<list>
<entry level="1" type="definition">

 Reasoning as search</entry>
</list>

Many AI programs used the same basic <link xlink:type="simple" xlink:href="../775/775.xml">
algorithm</link> in the early years of AI research: to achieve some goal (like winning a game or proving a theorem) and they proceeded step by step towards it (by making a move or a deduction) as if searching through a maze, <link xlink:type="simple" xlink:href="../867/238867.xml">
backtracking</link> whenever they reached a dead end. This paradigm was called "<link xlink:type="simple" xlink:href="../094/6278094.xml">
reasoning as search</link>".<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2239%22])">39</ref></p>
<p>

The principal difficulty was that, for many problems, the number of possible paths through the "maze" was simply astronomical (this is called a "<link xlink:type="simple" xlink:href="../738/7835738.xml">
combinatorial explosion</link>"). Researchers would reduce the search space by using <link xlink:type="simple" xlink:href="../452/63452.xml">
heuristics</link> or "rules of thumb" that would eliminate those paths that were unlikely to lead to a solution.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2240%22])">40</ref></p>
<p>

<link xlink:type="simple" xlink:href="../304/287304.xml">
Newell</link> and <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../205/14205.xml">
Simon</link></scientist>
</person>
 tried to capture a general version of this algorithm in a program called the "<link xlink:type="simple" xlink:href="../658/1234658.xml">
General Problem Solver</link>".<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2241%22])">41</ref> Other "searching" programs were able to accomplish impressive tasks like solving problems in geometry and algebra: <link>
Herbert Gelernter</link>'s <link>
Geometry Theorem Prover</link> (1958) and <link>
SAINT</link>, written by <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../639/19639.xml">
Minsky's</link></scientist>
</person>
 student <link>
James Slagle</link> (1961).<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2242%22])">42</ref> Other programs searched through goals and subgoals to plan actions, like the <link xlink:type="simple" xlink:href="../958/1953958.xml">
STRIPS</link> system developed at <link>
Stanford</link> to control the behavior of their robot <automaton wordnetid="102761392" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<device wordnetid="103183080" confidence="0.8">
<mechanism wordnetid="103738472" confidence="0.8">
<link xlink:type="simple" xlink:href="../688/2288688.xml">
Shakey</link></mechanism>
</device>
</instrumentality>
</artifact>
</automaton>
.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2243%22])">43</ref></p>
<p>

<image width="250px" src="Semantic_Net.svg" type="thumb">
<caption>

An example of a semantic network
</caption>
</image>
</p>
<p>

<list>
<entry level="1" type="definition">

 Natural language</entry>
</list>

An important goal of AI research is to allow computers to communicate in <link xlink:type="simple" xlink:href="../652/21652.xml">
natural languages</link> like English. An early success was <link xlink:type="simple" xlink:href="../635/8383635.xml">
Daniel Bobrow</link>'s program <link xlink:type="simple" xlink:href="../997/8511997.xml">
STUDENT</link>, which could solve high school algebra word problems.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2244%22])">44</ref></p>
<p>

A <link xlink:type="simple" xlink:href="../109/29109.xml">
semantic net</link> represents concepts (e.g. "house","door") as nodes and relations among concepts (e.g. "has-a") as links between the nodes. The first AI program to use a semantic net was written by <link>
Ross Quillian</link><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2245%22])">45</ref> and the most successful (and controversial) version was <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<research_worker wordnetid="110523076" confidence="0.8">
<link xlink:type="simple" xlink:href="../541/1076541.xml">
Roger Schank</link></research_worker>
</scientist>
</causal_agent>
</person>
</physical_entity>
's <link>
Conceptual Dependency</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2246%22])">46</ref></p>
<p>

Perhaps the most interesting English speaking computer program was <link xlink:type="simple" xlink:href="../003/16003.xml">
Joseph Weizenbaum</link>'s <link xlink:type="simple" xlink:href="../235/10235.xml">
ELIZA</link>, the first <link xlink:type="simple" xlink:href="../349/148349.xml">
chatterbot</link>. ELIZA could carry out conversations that were so realistic that users occasionally were fooled into thinking they were communicating with a human being and not a program. But in fact, ELIZA had no idea what she was talking about. She simply gave a <link xlink:type="simple" xlink:href="../998/1647998.xml">
canned response</link> or repeated back what was said to her, rephrasing her response with a few grammar rules.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2247%22])">47</ref></p>
<p>

<list>
<entry level="1" type="definition">

 Micro-worlds</entry>
</list>

In the late 60s, <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../639/19639.xml">
Marvin Minsky</link></scientist>
</person>
 and <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../802/27802.xml">
Seymour Papert</link></scientist>
</person>
 of the <link xlink:type="simple" xlink:href="../061/19061.xml">
MIT</link> AI Laboratory proposed that AI research should focus on artificially simple situations known as <link>
Micro-Worlds</link>. They pointed out that in successful sciences like physics, basic principles were often best understood using simplified models like frictionless planes or perfectly rigid bodies. Much of the research focused on the so-called "blocks world," which consists of colored blocks of various shapes and sizes arrayed on a flat surface.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2248%22])">48</ref></p>
<p>

This paradigm led to innovative work in <link xlink:type="simple" xlink:href="../088/172088.xml">
machine vision</link> by <link xlink:type="simple" xlink:href="../431/96431.xml">
Gerald Sussman</link> (who led the team), <link>
Adolfo Guzman</link>, <link>
David Waltz</link> (who invented "<link xlink:type="simple" xlink:href="../747/3923747.xml">
constraint propagation</link>"), and especially <link xlink:type="simple" xlink:href="../242/5843242.xml">
Patrick Winston</link>. At the same time, <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../639/19639.xml">
Minsky</link></scientist>
</person>
 and <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../802/27802.xml">
Papert</link></scientist>
</person>
 built a robot arm that could stack blocks, bringing the blocks world to life. The crowning achievement of the micro-world program was <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<employee wordnetid="110053808" confidence="0.8">
<research_worker wordnetid="110523076" confidence="0.8">
<link xlink:type="simple" xlink:href="../786/192786.xml">
Terry Winograd</link></research_worker>
</employee>
</scientist>
</causal_agent>
</worker>
</person>
</physical_entity>
's <software wordnetid="106566077" confidence="0.8">
<application wordnetid="106570110" confidence="0.8">
<program wordnetid="106568978" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106359877" confidence="0.8">
<code wordnetid="106355894" confidence="0.8">
<coding_system wordnetid="106353757" confidence="0.8">
<link xlink:type="simple" xlink:href="../791/98791.xml">
SHRDLU</link></coding_system>
</code>
</writing>
</written_communication>
</program>
</application>
</software>
. It could communicate in ordinary English sentences, plan operations and execute them.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2249%22])">49</ref></p>

</ss1>
<ss1>
<st>
The optimism</st>
<p>

The first generation of AI researchers made these predictions about their work:
<list>
<entry level="1" type="bullet">

 1958, <link xlink:type="simple" xlink:href="../205/14205.xml">
H. A. Simon</link> and <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../300/287300.xml">
Allen Newell</link></scientist>
</person>
: "within ten years a digital computer will be the world's chess champion" and "within ten years a digital computer will discover and prove an important new mathematical theorem."<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2250%22])">50</ref></entry>
<entry level="1" type="bullet">

 1965, <link xlink:type="simple" xlink:href="../205/14205.xml">
H. A. Simon</link>: "machines will be capable, within twenty years, of doing any work a man can do."<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2251%22])">51</ref></entry>
<entry level="1" type="bullet">

 1967, <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../639/19639.xml">
Marvin Minsky</link></scientist>
</person>
: "Within a generation ... the problem of creating 'artificial intelligence' will substantially be solved."<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2252%22])">52</ref></entry>
<entry level="1" type="bullet">

 1970, <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../639/19639.xml">
Marvin Minsky</link></scientist>
</person>
 (in <link xlink:type="simple" xlink:href="../479/187479.xml">
<it>Life</it> Magazine</link>): "In from three to eight years we will have a machine with the general intelligence of an average human being."<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2253%22])">53</ref></entry>
</list>
</p>

</ss1>
<ss1>
<st>
The money</st>
<p>

In June 1963 <link xlink:type="simple" xlink:href="../061/19061.xml">
MIT</link> received a $2.2 million grant from the newly created Advanced Research Projects Agency (later known as <agency wordnetid="108337324" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../957/8957.xml">
DARPA</link></agency>
). The money was used to fund <link xlink:type="simple" xlink:href="../147/254147.xml">
project MAC</link> which subsumed the "AI Group" founded by <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../639/19639.xml">
Minsky</link></scientist>
</person>
 and <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../362/308362.xml">
McCarthy</link></scientist>
</person>
 five years earlier. <agency wordnetid="108337324" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../957/8957.xml">
ARPA</link></agency>
 continued to provide three million dollars a year until the 70s.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2254%22])">54</ref>
<agency wordnetid="108337324" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../957/8957.xml">
ARPA</link></agency>
 made similar grants to <link xlink:type="simple" xlink:href="../304/287304.xml">
Newell</link> and <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../205/14205.xml">
Simon's</link></scientist>
</person>
 program at <university wordnetid="108286163" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../093/48093.xml">
CMU</link></university>
 and to the <point wordnetid="108620061" confidence="0.8">
<institute wordnetid="108407330" confidence="0.8">
<geographic_point wordnetid="108578706" confidence="0.8">
<location wordnetid="100027167" confidence="0.8">
<association wordnetid="108049401" confidence="0.8">
<workplace wordnetid="104602044" confidence="0.8">
<lab wordnetid="103629986" confidence="0.8">
<link xlink:type="simple" xlink:href="../358/310358.xml">
Stanford AI Project</link></lab>
</workplace>
</association>
</location>
</geographic_point>
</institute>
</point>
 (founded by <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../362/308362.xml">
John McCarthy</link></scientist>
</person>
 in 1963).<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2255%22])">55</ref> Another important AI laboratory was established at <link xlink:type="simple" xlink:href="../395/64395.xml">
Edinburgh University</link> by <scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../921/5842921.xml">
Donald Michie</link></scientist>
 in 1965.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2256%22])">56</ref>
These four institutions would continue to be the main centers of AI research (and funding) in academia for many years.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2257%22])">57</ref></p>
<p>

The money was proffered with few strings attached: <person wordnetid="100007846" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../150/254150.xml">
J. C. R. Licklider</link></person>
, then the director of <agency wordnetid="108337324" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../957/8957.xml">
ARPA</link></agency>
, believed that his organization should "fund people, not projects!" and allowed researchers to pursue whatever directions might interest them.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2258%22])">58</ref> This created a freewheeling atmosphere at <link xlink:type="simple" xlink:href="../061/19061.xml">
MIT</link> that gave birth to the <controversy wordnetid="107183151" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<dispute wordnetid="107181935" confidence="0.8">
<disagreement wordnetid="107180787" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<speech_act wordnetid="107160883" confidence="0.8">
<link xlink:type="simple" xlink:href="../533/13533.xml">
hacker</link></speech_act>
</psychological_feature>
</act>
</disagreement>
</dispute>
</event>
</controversy>
 culture,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2259%22])">59</ref> but this "hands off" approach would not last.</p>

</ss1>
</sec>
<sec>
<st>
The first AI winter 1974−1980</st>
<p>

In the 70s, AI was subject to critiques and financial setbacks. AI researchers had failed to appreciate the difficulty of the problems they face. Their tremendous optimism had raised expectations impossibly high, and when the results they had promised failed to materialize, funding for AI disappeared.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2260%22])">60</ref> At the same time, the field of <link xlink:type="simple" xlink:href="../636/263636.xml">
connectionism</link> (or <link xlink:type="simple" xlink:href="../542/1729542.xml">
neural nets</link>) was shut down almost completely for 10 years by <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../639/19639.xml">
Marvin Minsky</link></scientist>
</person>
's devastating criticism of <link xlink:type="simple" xlink:href="../777/172777.xml">
perceptrons</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2261%22])">61</ref>
Despite the difficulties with public perception of AI in the late 70s, new ideas were explored in <link xlink:type="simple" xlink:href="../de)/17927_(Z$I$P$_code).xml">
logic programming</link>, <link xlink:type="simple" xlink:href="../026/996026.xml">
commonsense reasoning</link> and many other areas.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2262%22])">62</ref>
</p>
<ss1>
<st>
The problems</st>
<p>

In the early seventies, the capabilities of AI programs were disturbingly limited. Even the most impressive could only handle trivial versions of the problems they were supposed to solve; all the programs were, in some sense, "toys".<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2263%22])">63</ref> AI researchers had begun to run into several fundamental limits that could not be overcome in the 1970s. Although some of these limits would be conquered in later decades, others still stymie the field to this day.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2264%22])">64</ref>
<list>
<entry level="1" type="number">

 <b>Limited computer power</b>: There was not enough memory or processing speed to accomplish anything truly useful. For example, <link>
Ross Quillian</link>'s successful work on natural language was demonstrated with a vocabulary of only <it>twenty</it> words, because that was all that would fit in memory.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2265%22])">65</ref> <link xlink:type="simple" xlink:href="../556/298556.xml">
Hans Moravec</link> argued in 1976 that computers were still millions of times too weak to exhibit intelligence. He suggested an analogy: artificial intelligence requires computer power in the same way that aircraft require horsepower. Below a certain threshold, it's impossible, but, as power <link xlink:type="simple" xlink:href="../418/39418.xml">
increases</link>, eventually it could become easy.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2266%22])">66</ref></entry>
<entry level="1" type="number">

 <b><link>
Intractability</link> and the <link xlink:type="simple" xlink:href="../738/7835738.xml">
combinatorial explosion</link></b>. In 1972 <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../763/298763.xml">
Richard Karp</link></scientist>
</person>
 (building on <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../432/39432.xml">
Stephen Cook</link></scientist>
</person>
's 1971 <link xlink:type="simple" xlink:href="../047/663047.xml">
theorem</link>) showed there are <condition wordnetid="113920835" confidence="0.8">
<state wordnetid="100024720" confidence="0.8">
<problem wordnetid="114410605" confidence="0.8">
<difficulty wordnetid="114408086" confidence="0.8">
<link xlink:type="simple" xlink:href="../564/2012564.xml">
many problems</link></difficulty>
</problem>
</state>
</condition>
 that can probably only be solved in <link xlink:type="simple" xlink:href="../581/44581.xml">
exponential time</link> (in the size of the inputs). To find optimal solutions to these problems required unimaginable amounts of computer time except when the problems were trivial. This almost certainly meant that many of the "toy" solutions used by AI would probably never scale up into useful systems.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2267%22])">67</ref></entry>
<entry level="1" type="number">

 <b><link xlink:type="simple" xlink:href="../339/2239339.xml">
Commonsense knowledge</link> and <link xlink:type="simple" xlink:href="../026/996026.xml">
reasoning</link></b>. Many important artificial intelligence applications like <link xlink:type="simple" xlink:href="../596/6596.xml">
vision</link> or <link xlink:type="simple" xlink:href="../173/21173.xml">
natural language</link> required simply enormous amounts of information about the world: the program needed to have some idea of what it might be looking at or what it was talking about. This required that the program know most of the same things about the world that a child does. Researchers soon discovered that this was a truly <it>vast</it> amount of information. No one in 1970 could build a database so large and no one knew how a program might learn so much information.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2268%22])">68</ref></entry>
<entry level="1" type="number">

 <b><link xlink:type="simple" xlink:href="../035/12476035.xml">
Moravec's paradox</link></b>: It would eventually dawn on many AI researchers working with <link xlink:type="simple" xlink:href="../596/6596.xml">
vision</link> and <link xlink:type="simple" xlink:href="../673/46673.xml">
robotics</link> that tasks like proving theorems or solving geometry problems were easy for computers to carry out, but supposedly "simple" tasks like recognizing a face or crossing a room without bumping into anything were extremely difficult. This helped explain why research in these areas had made so little progress by the middle 1970s.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2269%22])">69</ref></entry>
<entry level="1" type="number">

 <b>The <link xlink:type="simple" xlink:href="../306/11306.xml">
frame</link> and <link xlink:type="simple" xlink:href="../287/731287.xml">
qualification</link> problems</b>. AI researchers (like <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../362/308362.xml">
John McCarthy</link></scientist>
</person>
) who used <link xlink:type="simple" xlink:href="../225/3729225.xml">
logic</link> discovered that they could not represent ordinary deductions that involved <link xlink:type="simple" xlink:href="../641/1505641.xml">
planning</link> or default reasoning without making changes to the structure of logic itself. They developed new logics (like <link xlink:type="simple" xlink:href="../086/341086.xml">
non-monotonic logic</link>s and <link xlink:type="simple" xlink:href="../365/333365.xml">
modal logic</link>s) to try to solve the problems.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2270%22])">70</ref></entry>
</list>
</p>

</ss1>
<ss1>
<st>
The end of funding</st>

<p>

<indent level="1">

<it>See also: <link xlink:type="simple" xlink:href="../574/3548574.xml">
AI Winter</link></it>
</indent>

The agencies that funded AI research (such as the <link xlink:type="simple" xlink:href="../930/334930.xml">
British government</link>, <agency wordnetid="108337324" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../957/8957.xml">
DARPA</link></agency>
 and <link xlink:type="simple" xlink:href="../638/37638.xml">
NRC</link>) became frustrated with the lack of progress and eventually cut off almost all funding for undirected research into AI. The pattern began as early as 1966 when the <link xlink:type="simple" xlink:href="../712/3993712.xml">
ALPAC</link> report appeared criticizing machine translation efforts. After spending 20 million dollars, the <link xlink:type="simple" xlink:href="../638/37638.xml">
NRC</link> ended all support.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2271%22])">71</ref>
In 1973, the <link xlink:type="simple" xlink:href="../377/1940377.xml">
Lighthill report</link> on the state of AI research in England criticized the utter failure of AI to achieve its "grandiose objectives" and led to the dismantling of AI research in that country.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2272%22])">72</ref> 
(The report specifically mentioned the <link xlink:type="simple" xlink:href="../738/7835738.xml">
combinatorial explosion</link> problem as a reason for AI's failings.)<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2273%22])">73</ref>
<agency wordnetid="108337324" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../957/8957.xml">
DARPA</link></agency>
 was deeply disappointed with researchers working on the <link xlink:type="simple" xlink:href="../468/29468.xml">
Speech Understanding Research</link> program at <link xlink:type="simple" xlink:href="../137/61137.xml">
CMU</link> and canceled an annual grant of three million dollars.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2274%22])">74</ref>
By 1974, funding for AI projects was hard to find.</p>
<p>

<link xlink:type="simple" xlink:href="../556/298556.xml">
Hans Moravec</link> blamed the crisis on the unrealistic predictions of his colleagues. "Many researchers were caught up in a web of increasing exaggeration."<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2275%22])">75</ref>
However, there was another issue: since the passage of <link xlink:type="simple" xlink:href="../183/80183.xml">
Mansfield Amendment</link> in 1969, <agency wordnetid="108337324" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../957/8957.xml">
DARPA</link></agency>
 had been under increasing pressure to fund "mission-oriented direct research, rather than basic undirected research." The creative, freewheeling exploration that had gone on in the 60s would not be funded by <agency wordnetid="108337324" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../957/8957.xml">
DARPA</link></agency>
. The money was directed to specific projects with clear objectives, like autonomous tanks and battle management systems.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2276%22])">76</ref></p>

</ss1>
<ss1>
<st>
Critiques from across campus</st>

<p>

<indent level="1">

<it>See also: <link xlink:type="simple" xlink:href="../015/2958015.xml">
Philosophy of artificial intelligence</link></it>
</indent>

Several philosophers had strong objections to the claims being made by AI researchers. One of the earliest was <physical_entity wordnetid="100001930" confidence="0.8">
<peer wordnetid="109626238" confidence="0.8">
<philosopher wordnetid="110423589" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<intellectual wordnetid="109621545" confidence="0.8">
<colleague wordnetid="109935990" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scholar wordnetid="110557854" confidence="0.8">
<associate wordnetid="109816771" confidence="0.8">
<link xlink:type="simple" xlink:href="../188/311188.xml">
John Lucas</link></associate>
</scholar>
</causal_agent>
</colleague>
</intellectual>
</person>
</philosopher>
</peer>
</physical_entity>
, who argued that <link xlink:type="simple" xlink:href="../736/16736.xml">
Gödel's</link> <link xlink:type="simple" xlink:href="../863/58863.xml">
incompleteness theorem</link> showed that a <link xlink:type="simple" xlink:href="../102/396102.xml">
formal system</link> (such as a computer program) could never see the truth of certain statements, while a human being could.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2277%22])">77</ref> <philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../926/952926.xml">
Hubert Dreyfus</link></philosopher>
 ridiculed the broken promises of the 60s and critiqued the assumptions of AI, arguing that human reasoning actually involved very little "symbol processing" and a great deal of <link xlink:type="simple" xlink:href="../169/179169.xml">
embodied</link>, <link xlink:type="simple" xlink:href="../316/288316.xml">
instinct</link>ive, <link xlink:type="simple" xlink:href="../599/47599.xml">
unconscious</link> "<link>
know how</link>".<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2278%22])">78</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2279%22])">79</ref> <philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../079/147079.xml">
John Searle</link></philosopher>
's <link>
Chinese Room</link> argument, presented in 1980, attempted to show that a program could not be said to "understand" the symbols that it uses (a quality called "<link xlink:type="simple" xlink:href="../483/184483.xml">
intentionality</link>"). If the symbols have no meaning for the machine, Searle argued, then the machine can never be truly intelligent.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2280%22])">80</ref></p>
<p>

These critiques were not taken seriously by AI researchers, often because they seemed so far off the point. Problems like <link xlink:type="simple" xlink:href="../543/7543.xml#xpointer(//*[./st=%22Intractability%22])">
intractability</link> and <link xlink:type="simple" xlink:href="../026/996026.xml">
commonsense knowledge</link> seemed much more immediate and serious. It wasn't clear what difference "<link>
know how</link>" or "<link xlink:type="simple" xlink:href="../570/14570.xml">
intensionality</link>" made to an actual program. <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../639/19639.xml">
Minsky</link></scientist>
</person>
 said of Dreyfus and Searle "they misunderstand, and should be ignored."<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2281%22])">81</ref> Dreyfus, who taught at <link xlink:type="simple" xlink:href="../061/19061.xml">
MIT</link>, was given a cold shoulder: he later said that AI researchers "dared not be seen having lunch with me."<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2282%22])">82</ref> <link xlink:type="simple" xlink:href="../003/16003.xml">
Joseph Weizenbaum</link>, the author of <link xlink:type="simple" xlink:href="../235/10235.xml">
ELIZA</link>, felt his colleagues' treatment of <philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../926/952926.xml">
Dreyfus</link></philosopher>
 was unprofessional and childish. Although he was an outspoken critic of Dreyfus' positions, he "deliberately made it plain that theirs was not the way to treat a human being."<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2283%22])">83</ref></p>
<p>

Weizenbaum began to have serious ethical doubts about AI when <link xlink:type="simple" xlink:href="../196/18306196.xml">
Kenneth Colby</link> wrote <link xlink:type="simple" xlink:href="../235/10235.xml">
DOCTOR</link>, a <link xlink:type="simple" xlink:href="../349/148349.xml">
chatterbot</link> therapist. Weizenbaum was disturbed that Colby saw his mindless program as a serious therapeutic tool. A feud began, and the situation was not helped when Colby did not credit Weizenbaum for his contribution to the program. Eventually <link xlink:type="simple" xlink:href="../003/16003.xml">
Weizenbaum</link> would publish a thoughtful moral critique of AI.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2284%22])">84</ref></p>

</ss1>
<ss1>
<st>
Perceptrons and the dark age of connectionism</st>
<p>

A <link xlink:type="simple" xlink:href="../777/172777.xml">
perceptron</link> was a form of <link xlink:type="simple" xlink:href="../542/1729542.xml">
neural network</link> introduced in 1958 by <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<psychologist wordnetid="110488865" confidence="0.8">
<link xlink:type="simple" xlink:href="../462/1945462.xml">
Frank Rosenblatt</link></psychologist>
</scientist>
</causal_agent>
</person>
</physical_entity>
, who had been a schoolmate of <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../639/19639.xml">
Marvin Minsky</link></scientist>
</person>
 at the <school wordnetid="108276720" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../637/367637.xml">
Bronx High School of Science</link></school>
. Like most AI researchers, he was optimistic about their power, predicting that "perceptron may eventually be able to learn, make decisions, and translate languages." An active research program into the paradigm was carried out throughout the 60s but came to a sudden halt with the publication of <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../639/19639.xml">
Minsky</link></scientist>
</person>
 and <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../802/27802.xml">
Papert's</link></scientist>
</person>
 1969 book <it><link xlink:type="simple" xlink:href="../777/172777.xml">
Perceptrons</link></it>. They showed that there were severe limitations to what perceptrons could do and that <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<psychologist wordnetid="110488865" confidence="0.8">
<link xlink:type="simple" xlink:href="../462/1945462.xml">
Frank Rosenblatt</link></psychologist>
</scientist>
</causal_agent>
</person>
</physical_entity>
's predictions had been grossly exaggerated. The effect of the book was devastating: virtually no research at all was done in <link xlink:type="simple" xlink:href="../636/263636.xml">
connectionism</link> for 10 years. Eventually, a new generation of researchers would revive the field and thereafter it would become a vital and useful part of artificial intelligence. <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<psychologist wordnetid="110488865" confidence="0.8">
<link xlink:type="simple" xlink:href="../462/1945462.xml">
Rosenblatt</link></psychologist>
</scientist>
</causal_agent>
</person>
</physical_entity>
 would not live to see this, as he died in a boating accident shortly after the book was published.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2261%22])">61</ref></p>

</ss1>
<ss1>
<st>
The neats: logic, Prolog and expert systems</st>
<p>

Logic was introduced into AI research as early as 1958, by <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../362/308362.xml">
John McCarthy</link></scientist>
</person>
 in his <link xlink:type="simple" xlink:href="../008/8992008.xml">
Advice Taker</link> proposal.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2285%22])">85</ref> 
In 1963, <skilled_worker wordnetid="110605985" confidence="0.8">
<peer wordnetid="109626238" confidence="0.8">
<physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<intellectual wordnetid="109621545" confidence="0.8">
<traveler wordnetid="109629752" confidence="0.8">
<colleague wordnetid="109935990" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<exile wordnetid="110071332" confidence="0.8">
<absentee wordnetid="109757653" confidence="0.8">
<associate wordnetid="109816771" confidence="0.8">
<editor wordnetid="110044879" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<alumnus wordnetid="109786338" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<mathematician wordnetid="110301261" confidence="0.8">
<scholar wordnetid="110557854" confidence="0.8">
<link xlink:type="simple" xlink:href="../114/8895114.xml">
J. Alan Robinson</link></scholar>
</mathematician>
</causal_agent>
</alumnus>
</worker>
</editor>
</associate>
</absentee>
</exile>
</scientist>
</colleague>
</traveler>
</intellectual>
</person>
</physical_entity>
</peer>
</skilled_worker>
 had discovered a simple method to implement deduction on computers, the <link xlink:type="simple" xlink:href="../082/2724082.xml">
resolution</link> and <link xlink:type="simple" xlink:href="../432/54432.xml">
unification</link> algorithm. However, straightforward implementations, like those attempted by McCarthy and his students in the late 60s, were especially intractable: the programs required astronomical numbers of steps to prove simple theorems.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2286%22])">86</ref> A more fruitful approach to logic was developed in the 70s by <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../364/1621364.xml">
Robert Kowalski</link></scientist>
</person>
 at the <university wordnetid="108286163" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../395/64395.xml">
University of Edinburgh</link></university>
, and soon this led to the collaboration with French researchers <physical_entity wordnetid="100001930" confidence="0.8">
<expert wordnetid="109617867" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<interior_designer wordnetid="110210648" confidence="0.8">
<specialist wordnetid="110631941" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<link xlink:type="simple" xlink:href="../762/371762.xml">
Alain Colmerauer</link></scientist>
</causal_agent>
</specialist>
</interior_designer>
</person>
</expert>
</physical_entity>
 and <link>
Phillipe Roussel</link> who created the successful logic programming language <link xlink:type="simple" xlink:href="../485/23485.xml">
Prolog</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2287%22])">87</ref>
Prolog uses a subset of logic (<link xlink:type="simple" xlink:href="../824/333824.xml">
Horn clause</link>s, closely related to "rules" and "<link xlink:type="simple" xlink:href="../457/3157457.xml">
production rules</link>") that permit tractable computation. Rules would continue to be influential, providing a foundation for <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../517/307517.xml">
Edward Feigenbaum</link></scientist>
</person>
's <link xlink:type="simple" xlink:href="../136/10136.xml">
expert systems</link> and the continuing work by <link xlink:type="simple" xlink:href="../304/287304.xml">
Alan Newell</link> and <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../205/14205.xml">
Herbert Simon</link></scientist>
</person>
 that would lead to <link xlink:type="simple" xlink:href="../751/729751.xml">
Soar</link> and their <link xlink:type="simple" xlink:href="../053/1804053.xml">
unified theories of cognition</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2288%22])">88</ref></p>
<p>

Critics of the logical approach noted, as <philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../926/952926.xml">
Dreyfus</link></philosopher>
 had, that human beings rarely used logic when they solved problems. Experiments by psychologists like <link xlink:type="simple" xlink:href="../729/4850729.xml">
Peter Wason</link>, <person wordnetid="100007846" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../366/1047366.xml">
Eleanor Rosch</link></person>
, <economist wordnetid="110043643" confidence="0.9173553029164789">
<person wordnetid="100007846" confidence="0.9508927676800064">
<psychologist wordnetid="110488865" confidence="0.9173553029164789">
<link xlink:type="simple" xlink:href="../494/165494.xml">
Amos Tversky</link></psychologist>
</person>
</economist>
, <scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../492/165492.xml">
Daniel Kahneman</link></scientist>
 and others provided proof.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2289%22])">89</ref>
McCarthy responded that what people do is irrelevant and pointed out that we don't need machines that think as people do, we need machines that can solve problems that people normally solve by thinking.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2290%22])">90</ref></p>

</ss1>
<ss1>
<st>
The scruffies: frames and scripts</st>
<p>

Among the critics of <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../362/308362.xml">
McCarthy's</link></scientist>
</person>
 approach were his colleagues across the country at <link xlink:type="simple" xlink:href="../061/19061.xml">
MIT</link>. <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../639/19639.xml">
Marvin Minsky</link></scientist>
</person>
, <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../802/27802.xml">
Seymour Papert</link></scientist>
</person>
 and <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<research_worker wordnetid="110523076" confidence="0.8">
<link xlink:type="simple" xlink:href="../541/1076541.xml">
Roger Schank</link></research_worker>
</scientist>
</causal_agent>
</person>
</physical_entity>
 were trying to solve problems like "story understanding" and "object recognition" that <it>required</it> a machine to think like a person. In order to use ordinary concepts like "chair" or "restaurant" they had to make all the same illogical assumptions that people normally made. Unfortunately, imprecise concepts like these are hard to represent in logic. <link xlink:type="simple" xlink:href="../431/96431.xml">
Gerald Sussman</link> observed that "using precise language to describe essentially imprecise concepts doesn't make them any more precise."<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2291%22])">91</ref> <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<research_worker wordnetid="110523076" confidence="0.8">
<link xlink:type="simple" xlink:href="../541/1076541.xml">
Schank</link></research_worker>
</scientist>
</causal_agent>
</person>
</physical_entity>
 described their "anti-logic" approaches as "<link xlink:type="simple" xlink:href="../037/404037.xml">
scruffy</link>", as opposed to the "<link xlink:type="simple" xlink:href="../037/404037.xml">
neat</link>" paradigms used by <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../362/308362.xml">
McCarthy</link></scientist>
</person>
, <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../364/1621364.xml">
Kowalski</link></scientist>
</person>
, <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../517/307517.xml">
Feigenbaum</link></scientist>
</person>
, <link xlink:type="simple" xlink:href="../304/287304.xml">
Newell</link> and <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../205/14205.xml">
Simon</link></scientist>
</person>
.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2292%22])">92</ref></p>
<p>

In 1975, in a seminal paper, <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../639/19639.xml">
Minsky</link></scientist>
</person>
 noted that many of his fellow "scruffy" researchers were using the same kind of tool: a framework that captures all our <link xlink:type="simple" xlink:href="../339/2239339.xml">
common sense assumptions</link> about something. For example, if we use the concept of a bird, there is a constellation of facts that immediately come to mind: we might assume that it flies, eats worms and so on. We know these facts are not always true and that deductions using these facts will not be "logical," but these structured sets of assumptions are part of the <it>context</it> of everything we say and think. He called these structures "<link xlink:type="simple" xlink:href="../067/9924067.xml">
frames</link>". <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<research_worker wordnetid="110523076" confidence="0.8">
<link xlink:type="simple" xlink:href="../541/1076541.xml">
Schank</link></research_worker>
</scientist>
</causal_agent>
</person>
</physical_entity>
 used a version of frames he called "<link xlink:type="simple" xlink:href="../688/6132688.xml">
scripts</link>" to successfully answer questions about short stories in English.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2293%22])">93</ref> Many years later <link xlink:type="simple" xlink:href="../757/22757.xml">
object-oriented programming</link> would adopt the essential idea of "<link xlink:type="simple" xlink:href="../746/2617746.xml">
inheritance</link>" from AI research on frames.</p>

</ss1>
</sec>
<sec>
<st>
Boom 1980&ndash;1987</st>
<p>

In the 1980s a form of AI program called "<link xlink:type="simple" xlink:href="../136/10136.xml">
expert system</link>s" was adopted by corporations around the world and <link xlink:type="simple" xlink:href="../920/16920.xml">
knowledge</link> became the focus of mainstream AI research. In those same years, the Japanese government aggressively funded AI with its <link xlink:type="simple" xlink:href="../832/347832.xml">
fifth generation computer</link> project. Another encouraging event in the early 1980s was the revival of <link xlink:type="simple" xlink:href="../636/263636.xml">
connectionism</link> in the work of <link xlink:type="simple" xlink:href="../572/649572.xml">
John Hopfield</link> and <link xlink:type="simple" xlink:href="../113/2823113.xml">
David Rumelhart</link>. Once again, AI had achieved success.</p>

<ss1>
<st>
The rise of expert systems</st>
<p>

An <link xlink:type="simple" xlink:href="../136/10136.xml">
expert system</link> is a program that answers questions or solves problems about a specific domain of knowledge, using logical <link xlink:type="simple" xlink:href="../457/3157457.xml">
rules</link> that are derived from the knowledge of experts. The earliest examples were developed by <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../517/307517.xml">
Edward Feigenbaum</link></scientist>
</person>
 and his students. <system wordnetid="104377057" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<link xlink:type="simple" xlink:href="../912/557912.xml">
Dendral</link></instrumentality>
</artifact>
</system>
, begun in 1965, identified compounds from spectrometer readings. <link xlink:type="simple" xlink:href="../929/649929.xml">
MYCIN</link>, developed in 1972, diagnosed infectious blood diseases. They demonstrated the feasibility of the approach.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2294%22])">94</ref></p>
<p>

Expert systems restricted themselves to a small domain of specific knowledge (thus avoiding the <link xlink:type="simple" xlink:href="../339/2239339.xml">
commonsense knowledge</link> problem) and their simple design made it relatively easy for programs to be built and then modified once they were in place. All in all, the programs proved to be <it>useful</it>: something that AI had not been able to achieve up to this point.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2295%22])">95</ref></p>
<p>

In 1980, an expert system called <link xlink:type="simple" xlink:href="../557/3234557.xml">
XCON</link> was completed at <link xlink:type="simple" xlink:href="../137/61137.xml">
CMU</link> for the <company wordnetid="108058098" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../952/7952.xml">
Digital Equipment Corporation</link></company>
. It was an enormous success: it was saving the company 40 million dollars annually by 1986.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2296%22])">96</ref> Corporations around the world began to develop and deploy expert systems and by 1985 they were spending over a billion dollars on AI, most of it to in-house AI departments. An industry grew up to support them, including hardware companies like <computer wordnetid="103082979" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<company wordnetid="108058098" confidence="0.8">
<device wordnetid="103183080" confidence="0.8">
<machine wordnetid="103699975" confidence="0.8">
<digital_computer wordnetid="103196324" confidence="0.8">
<workstation wordnetid="104603399" confidence="0.8">
<institution wordnetid="108053576" confidence="0.8">
<link xlink:type="simple" xlink:href="../195/28195.xml">
Symbolics</link></institution>
</workstation>
</digital_computer>
</machine>
</device>
</company>
</instrumentality>
</artifact>
</computer>
 and <company wordnetid="108058098" confidence="0.8">
<institution wordnetid="108053576" confidence="0.8">
<link xlink:type="simple" xlink:href="../355/1084355.xml">
Lisp Machines</link></institution>
</company>
 and software companies such as <link xlink:type="simple" xlink:href="../386/4510386.xml">
IntelliCorp</link> and <system wordnetid="104377057" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<link xlink:type="simple" xlink:href="../570/2052570.xml">
Aion</link></instrumentality>
</artifact>
</system>
.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2297%22])">97</ref></p>

</ss1>
<ss1>
<st>
The knowledge revolution</st>
<p>

The power of expert systems came from the expert knowledge they contained. They were part of a new direction in AI research that had been gaining ground throughout the 70s. "AI researchers were beginning to suspect—reluctantly, for it violated the scientific canon of parsimony—that intelligence might very well be based on the ability to use large amounts of diverse knowledge in different ways,"<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2298%22])">98</ref> writes Pamela McCorduck. "[T]he great lesson from the 1970s was that intelligent behavior depended very much on dealing with knowledge, sometimes quite detailed knowledge, of a domain where a given task lay".<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2299%22])">99</ref> <link xlink:type="simple" xlink:href="../136/10136.xml">
Knowledge based system</link>s and <link xlink:type="simple" xlink:href="../499/458499.xml">
knowledge engineering</link> became a major focus of AI research in the 1980s.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22100%22])">100</ref></p>
<p>

The 1980s also saw the birth of <link xlink:type="simple" xlink:href="../874/6874.xml">
Cyc</link>, the first attempt to attack the <link xlink:type="simple" xlink:href="../026/996026.xml">
commonsense knowledge problem</link> directly, by creating a massive database that would contain all the mundane facts that the average person knows. <physical_entity wordnetid="100001930" confidence="0.8">
<peer wordnetid="109626238" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<colleague wordnetid="109935990" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<research_worker wordnetid="110523076" confidence="0.8">
<associate wordnetid="109816771" confidence="0.8">
<link xlink:type="simple" xlink:href="../991/99991.xml">
Douglas Lenat</link></associate>
</research_worker>
</scientist>
</causal_agent>
</colleague>
</person>
</peer>
</physical_entity>
, who started and led the project, argued that there is no shortcut ― the only way for machines to know the meaning of human concepts is to teach them, one concept at a time, by hand. The project was not expected to be completed for many decades.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22101%22])">101</ref></p>

</ss1>
<ss1>
<st>
The money returns: the fifth generation project</st>
<p>

In 1981, the <link xlink:type="simple" xlink:href="../853/376853.xml">
Japanese Ministry of International Trade and Industry</link> set aside $850 million dollars for the <link xlink:type="simple" xlink:href="../832/347832.xml">
Fifth generation computer</link> project. Their objectives were to write programs and build machines that could carry on conversations, translate languages, interpret pictures, and reason like human beings.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22102%22])">102</ref> Much to the chagrin of <link xlink:type="simple" xlink:href="../037/404037.xml">
scruffies</link>, they chose <link xlink:type="simple" xlink:href="../485/23485.xml">
Prolog</link> as the primary computer language for the project.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22103%22])">103</ref></p>
<p>

Other countries responded with new programs of their own: England began the ₤350 million <link xlink:type="simple" xlink:href="../479/6487479.xml">
Alvey</link> project and a consortium of American companies formed the <link xlink:type="simple" xlink:href="../100/3185100.xml">
Microelectronics and Computer Technology Corporation</link> (or "MCC") to fund large scale projects in AI and information technology.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22104%22])">104</ref> <agency wordnetid="108337324" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../957/8957.xml">
DARPA</link></agency>
 responded as well, founding the <link>
Strategic Computing Initiative</link> and tripling its investment in AI between 1984 and 1988.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22105%22])">105</ref>
<image location="left" width="150px" src="Hopfield-net.png" type="thumb">
<caption>

A Hopfield net with four nodes.
</caption>
</image>
</p>

</ss1>
<ss1>
<st>
The revival of connectionism</st>
<p>

In 1982, physicist <link xlink:type="simple" xlink:href="../572/649572.xml">
John Hopfield</link> was able to prove that a form of neural network (now called a "<link xlink:type="simple" xlink:href="../097/1170097.xml">
Hopfield net</link>") could learn and process information in a completely new way. Around the same time, <link xlink:type="simple" xlink:href="../113/2823113.xml">
David Rumelhart</link> popularized a new method for training neural networks called "<link xlink:type="simple" xlink:href="../091/1360091.xml">
backpropagation</link>" (discovered years earlier by <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<link xlink:type="simple" xlink:href="../764/5693764.xml">
Paul Werbos</link></scientist>
</causal_agent>
</person>
</physical_entity>
). These two discoveries revived the field of <link xlink:type="simple" xlink:href="../636/263636.xml">
connectionism</link> which had been largely abandoned since 1970.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22106%22])">106</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22107%22])">107</ref></p>
<p>

The new field was unified and inspired by the appearance of <it>Parallel Distributed Processing</it> in 1986—a two volume collection of papers edited by <link xlink:type="simple" xlink:href="../113/2823113.xml">
Rumelhart</link> and psychologist <link xlink:type="simple" xlink:href="../308/1540308.xml">
James McClelland</link>. Neural networks would become commercially successful in the 1990s, when they began to be used as the engines driving programs like <link xlink:type="simple" xlink:href="../091/49091.xml">
optical character recognition</link> and <link xlink:type="simple" xlink:href="../468/29468.xml">
speech recognition</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22108%22])">108</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22107%22])">107</ref></p>

</ss1>
</sec>
<sec>
<st>
Bust: the second AI winter 1987−1993</st>
<p>

The business community's fascination with AI rose and fell in the 80s in the classic pattern of an <link xlink:type="simple" xlink:href="../993/139993.xml">
economic bubble</link>. The collapse was in the <it>perception</it> of AI by government agencies and investors — the field continued to make advances despite the criticism. <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../498/632498.xml">
Rodney Brooks</link></scientist>
</person>
 and <link xlink:type="simple" xlink:href="../556/298556.xml">
Hans Moravec</link>, researchers from the related field of <link xlink:type="simple" xlink:href="../673/46673.xml">
robotics</link>, argued for an entirely new approach to artificial intelligence.</p>

<ss1>
<st>
AI winter</st>
<p>

The term "<bubble wordnetid="109229709" confidence="0.8">
<ball wordnetid="113899404" confidence="0.8">
<globule wordnetid="109289709" confidence="0.8">
<sphere wordnetid="113899200" confidence="0.8">
<round_shape wordnetid="113865483" confidence="0.8">
<shape wordnetid="100027807" confidence="0.8">
<link xlink:type="simple" xlink:href="../574/3548574.xml">
AI winter</link></shape>
</round_shape>
</sphere>
</globule>
</ball>
</bubble>
" was coined by researchers who had survived the funding cuts of 1974 when they  became concerned that enthusiasm for expert systems had spiraled out of control and that disappointment would certainly follow.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22109%22])">109</ref></p>
<p>

The first indication of a change in weather was the sudden collapse of the market for specialized AI hardware in 1987. Desktop computers from <link xlink:type="simple" xlink:href="../856/856.xml">
Apple</link> and <company wordnetid="108058098" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../259/18622259.xml">
IBM</link></company>
 had been steadily gaining speed and power and in 1987 they became more powerful than the more expensive <link xlink:type="simple" xlink:href="../123/18123.xml">
Lisp machines</link> made by <computer wordnetid="103082979" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<company wordnetid="108058098" confidence="0.8">
<device wordnetid="103183080" confidence="0.8">
<machine wordnetid="103699975" confidence="0.8">
<digital_computer wordnetid="103196324" confidence="0.8">
<workstation wordnetid="104603399" confidence="0.8">
<institution wordnetid="108053576" confidence="0.8">
<link xlink:type="simple" xlink:href="../195/28195.xml">
Symbolics</link></institution>
</workstation>
</digital_computer>
</machine>
</device>
</company>
</instrumentality>
</artifact>
</computer>
 and others. There was no longer a good reason to buy them. An entire industry worth half a billion dollars was demolished overnight.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22110%22])">110</ref></p>
<p>

Eventually the earliest successful expert systems, such as <link xlink:type="simple" xlink:href="../557/3234557.xml">
XCON</link>, proved too expensive to maintain. They were difficult to update, they could not learn, they were "<link xlink:type="simple" xlink:href="../449/1805449.xml">
brittle</link>" (i.e., they could make grotesque mistakes when given unusual inputs), and they fell prey to problems (such as the <link xlink:type="simple" xlink:href="../287/731287.xml">
qualification problem</link>) that had been identified years earlier. Expert systems proved useful, but only in a few special contexts.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22111%22])">111</ref></p>
<p>

In the late 80s, the new management of the <link>
Strategic Computing Initiative</link> cut funding to AI "deeply and brutally"<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22112%22])">112</ref> in favor of other projects that seemed more likely to produce immediate results.</p>
<p>

By 1991, the impressive list of goals penned in 1981 for Japan's <link xlink:type="simple" xlink:href="../832/347832.xml">
Fifth Generation Project</link> had not been met. Indeed, some of them, like "carry on a casual conversation" had not been met by 2008.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22113%22])">113</ref> As with other AI projects, expectations had run much higher than what was actually possible.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22113%22])">113</ref></p>

</ss1>
<ss1>
<st>
The importance of having a body: Nouvelle AI and embodied reason</st>

<p>

<indent level="1">

<it>Main articles: <link xlink:type="simple" xlink:href="../926/11298926.xml">
Nouvelle AI</link>,&#32;<link xlink:type="simple" xlink:href="../919/3918919.xml">
behavior-based AI</link>,&#32;<link xlink:type="simple" xlink:href="../720/3479720.xml">
situated</link>,&#32;and&#32;<link xlink:type="simple" xlink:href="../699/6338699.xml">
embodied cognitive science</link></it>
</indent>

In the late 80s, several researchers advocated a completely new approach to artificial intelligence, based on robotics.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22114%22])">114</ref> They believed that, to show real intelligence, a machine needs to have a <it>body</it> — it needs to perceive, move, survive and deal with the world. They argued that these <link xlink:type="simple" xlink:href="../599/1058599.xml">
sensorimotor</link> skills are essential to higher level skills like <link xlink:type="simple" xlink:href="../026/996026.xml">
commonsense reasoning</link> and that abstract reasoning was actually the <it>least</it> interesting or important human skill (see <link xlink:type="simple" xlink:href="../035/12476035.xml">
Moravec's paradox</link>). They advocated building intelligence "from the bottom up."<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22115%22])">115</ref></p>
<p>

The approach revived ideas from <link xlink:type="simple" xlink:href="../904/5904.xml">
cybernetic</link>s and <link xlink:type="simple" xlink:href="../039/7039.xml">
control theory</link> that had been unpopular since the sixties. Another precursor was <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<biologist wordnetid="109855630" confidence="0.8">
<neurobiologist wordnetid="110353928" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<neuroscientist wordnetid="110354580" confidence="0.8">
<research_worker wordnetid="110523076" confidence="0.8">
<link xlink:type="simple" xlink:href="../031/417031.xml">
David Marr</link></research_worker>
</neuroscientist>
</scientist>
</causal_agent>
</neurobiologist>
</biologist>
</person>
</physical_entity>
, who had come to <link xlink:type="simple" xlink:href="../061/19061.xml">
MIT</link> in the late 70s from a successful background in neurology to lead the group studying <link xlink:type="simple" xlink:href="../596/6596.xml">
vision</link>. He rejected all symbolic approaches (<it>both</it> <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../362/308362.xml">
McCarthy's</link></scientist>
</person>
 logic and <link xlink:type="simple" xlink:href="../450/7158450.xml">
Minsky</link>'s frames), arguing that AI needed to understand the physical machinery of vision from the bottom up before any symbolic processing took place. Marr's work would be cut short by leukemia in 1980.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22116%22])">116</ref></p>
<p>

In a 1990 paper <weblink xlink:type="simple" xlink:href="http://people.csail.mit.edu/brooks/papers/elephants.pdf">
Elephants Don't Play Chess</weblink>, robotics researcher <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../498/632498.xml">
Rodney Brooks</link></scientist>
</person>
 took direct aim at the <link xlink:type="simple" xlink:href="../999/2685999.xml">
physical symbol system hypothesis</link>, arguing that symbols are not always necessary since "the world is its own best model. It is always exactly up to date. It always has every detail there is to be known. The trick is to sense it appropriately and often enough."<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22117%22])">117</ref> In the 80s and 90s, many <link xlink:type="simple" xlink:href="../626/5626.xml">
cognitive scientists</link> also rejected the symbol processing model of the mind and argued that the body was essential for reasoning, a theory called the <link xlink:type="simple" xlink:href="../895/48895.xml">
embodied mind</link> thesis.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22118%22])">118</ref></p>

</ss1>
</sec>
<sec>
<st>
AI 1993−present</st>
<p>

The field of AI, now more than a half a century old, finally achieved some of its oldest goals. It began to be used successfully throughout the technology industry, although somewhat behind the scenes. Some of the success was due to increasing computer power and some was achieved by focusing on specific isolated problems and pursuing them with the highest standards of scientific accountability. Still, the reputation of AI, in the business world at least, was less than pristine. Inside the field there was little agreement on the reasons for AI's failure to fulfill the dream of human level intelligence that had captured the imagination of the world in the 1960s. Together, all these factors helped to fragment AI into competing subfields focussed on particular problems or approaches, sometimes even under new names that disguised the tarnished pedigree of "artificial intelligence."<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22119%22])">119</ref> AI was both more cautious and more successful than it had ever been.</p>


<ss1>
<st>
Milestones and Moore's Law</st>
<p>

On 11 May 1997, <link xlink:type="simple" xlink:href="../387/49387.xml">
Deep Blue</link> became the first computer Chess-playing system to beat a reigning world Chess champion, <link xlink:type="simple" xlink:href="../810/12810.xml">
Gary Kasparov</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22120%22])">120</ref> In 2005, a Stanford robot won the <event wordnetid="100029378" confidence="0.8">
<social_event wordnetid="107288639" confidence="0.8">
<contest wordnetid="107456188" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<link xlink:type="simple" xlink:href="../702/289702.xml">
DARPA Grand Challenge</link></psychological_feature>
</contest>
</social_event>
</event>
 by driving autonomously for 131 miles along an unrehearsed desert trail. After many years of effort, such milestones were finally achieved. These successes were not due to some revolutionary new paradigm, but mostly on the tedious application of engineering skill and on the tremendous power of computers today.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22121%22])">121</ref> In fact, <link xlink:type="simple" xlink:href="../387/49387.xml">
Deep Blue's</link> computer was 10 million times faster than the <computer wordnetid="103082979" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<device wordnetid="103183080" confidence="0.8">
<machine wordnetid="103699975" confidence="0.8">
<link xlink:type="simple" xlink:href="../886/571886.xml">
Ferranti Mark I</link></machine>
</device>
</instrumentality>
</artifact>
</computer>
 that <scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../784/932784.xml">
Christopher Strachey</link></scientist>
 taught to play chess in 1951.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22122%22])">122</ref> Thanks to <link xlink:type="simple" xlink:href="../418/39418.xml">
Moore's law</link>, the fundamental problem of "raw computer power" was slowly being overcome.</p>

</ss1>
<ss1>
<st>
Intelligent agents</st>
<p>

A new paradigm called "<link xlink:type="simple" xlink:href="../317/2711317.xml">
intelligent agent</link>s" became widely accepted during the 90s.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22123%22])">123</ref> Although earlier researchers had proposed modular "divide and conquer" approaches to AI,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22124%22])">124</ref> the <link xlink:type="simple" xlink:href="../317/2711317.xml">
intelligent agent</link> did not reach its modern form until <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../964/699964.xml">
Judea Pearl</link></scientist>
</person>
, <link xlink:type="simple" xlink:href="../304/287304.xml">
Alan Newell</link> and others brought concepts from <link xlink:type="simple" xlink:href="../216/446216.xml">
decision theory</link> and <link xlink:type="simple" xlink:href="../223/9223.xml">
economics</link> into the study of AI.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22125%22])">125</ref> When the <link xlink:type="simple" xlink:href="../223/9223.xml">
economist's</link> definition of a <link xlink:type="simple" xlink:href="../752/3736752.xml">
rational agent</link> was married to <link xlink:type="simple" xlink:href="../323/5323.xml">
computer science</link>'s definition of an <link xlink:type="simple" xlink:href="../757/22757.xml">
object</link> or <link xlink:type="simple" xlink:href="../133/939133.xml">
module</link>, the <link xlink:type="simple" xlink:href="../317/2711317.xml">
intelligent agent</link> paradigm was complete.</p>
<p>

An <link xlink:type="simple" xlink:href="../317/2711317.xml">
intelligent agent</link> is a system that perceives its environment and takes actions which maximize its chances of success. The simplest intelligent agents are programs that solve specific problems. The most complicated intelligent agents would be rational, thinking human beings. The <link xlink:type="simple" xlink:href="../317/2711317.xml">
intelligent agent paradigm</link> defines AI research "the study of intelligent agents". This is a generalization of some earlier definitions of AI: it goes beyond studying human intelligence; it studies all kinds of intelligence.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22126%22])">126</ref></p>
<p>

The paradigm gave researchers license to study isolated problems and find solutions that were both verifiable and useful. It provided a common language to describe problems and share their solutions with each other, and with other fields that also used concepts of abstract agents, like <link xlink:type="simple" xlink:href="../223/9223.xml">
economics</link> and <link xlink:type="simple" xlink:href="../039/7039.xml">
control theory</link>. It was hoped that a complete <link xlink:type="simple" xlink:href="../677/4510677.xml">
agent architecture</link> (like <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../300/287300.xml">
Newell's</link></scientist>
</person>
 <link xlink:type="simple" xlink:href="../751/729751.xml">
SOAR</link>) would one day allow researchers to build more versatile and intelligent systems out of interacting <link xlink:type="simple" xlink:href="../317/2711317.xml">
intelligent agents</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22125%22])">125</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22127%22])">127</ref></p>

</ss1>
<ss1>
<st>
Victory of the neats</st>
<p>

AI researchers began to develop and use sophisticated mathematical tools more than they ever had in the past.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22128%22])">128</ref> There was a widespread realization that many of the problems that AI needed to solve were already being worked on by researchers in fields like <link xlink:type="simple" xlink:href="../831/18831.xml">
mathematics</link>, <link xlink:type="simple" xlink:href="../223/9223.xml">
economics</link> or <link xlink:type="simple" xlink:href="../476/43476.xml">
operations research</link>. The shared mathematical language allowed both a higher level of collaboration with more established and successful fields and the achievement of results which were measurable and provable; AI had become a more rigorous "scientific" discipline. <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig (2003)</link> describe this as nothing less than a "revolution" and "the victory of the <link xlink:type="simple" xlink:href="../037/404037.xml">
neats</link>."<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22129%22])">129</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22130%22])">130</ref></p>
<p>

<person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../964/699964.xml">
Judea Pearl</link></scientist>
</person>
's highly influential 1988 book<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22131%22])">131</ref> brought <link xlink:type="simple" xlink:href="../934/22934.xml">
probability</link> and <link xlink:type="simple" xlink:href="../216/446216.xml">
decision theory</link> into AI. Among the many new tools in use were <link xlink:type="simple" xlink:href="../996/203996.xml">
Bayesian networks</link>, <link xlink:type="simple" xlink:href="../770/98770.xml">
hidden Markov models</link>, <link xlink:type="simple" xlink:href="../773/14773.xml">
information theory</link>, <link xlink:type="simple" xlink:href="../422/4074422.xml">
stochastic modeling</link> and classical <link xlink:type="simple" xlink:href="../402/22402.xml">
optimization</link>. Precise mathematical descriptions were also developed for "<link xlink:type="simple" xlink:href="../306/1563306.xml">
computational intelligence</link>" paradigms like <link>
neural networks</link> and <link xlink:type="simple" xlink:href="../837/190837.xml">
evolutionary algorithm</link>s.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22129%22])">129</ref></p>

</ss1>
<ss1>
<st>
 AI behind the scenes </st>

<p>

Algorithms originally developed by AI researchers began to appear as parts of larger systems. AI had solved a lot of very difficult problems and their solutions proved to be useful throughout the technology industry,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22132%22])">132</ref> such as
<link xlink:type="simple" xlink:href="../253/42253.xml">
data mining</link>,
<link>
industrial robotics</link>,
<link xlink:type="simple" xlink:href="../547/77547.xml">
logistics</link>,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22133%22])">133</ref>
<link xlink:type="simple" xlink:href="../468/29468.xml">
speech recognition</link>,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22134%22])">134</ref>
banking software,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22135%22])">135</ref>
medical diagnosis<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22135%22])">135</ref>
and <company wordnetid="108058098" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../923/1092923.xml">
Google</link></company>
's search engine.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22136%22])">136</ref></p>
<p>

The field of AI receives little or no credit for these successes. Many of AI's greatest innovations have been reduced to the status of just another item in the tool chest of computer science.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22137%22])">137</ref>
<physical_entity wordnetid="100001930" confidence="0.8">
<philosopher wordnetid="110423589" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<intellectual wordnetid="109621545" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scholar wordnetid="110557854" confidence="0.8">
<link xlink:type="simple" xlink:href="../292/408292.xml">
Nick Bostrom</link></scholar>
</causal_agent>
</intellectual>
</person>
</philosopher>
</physical_entity>
 explains "A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore."<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22138%22])">138</ref></p>
<p>

Many researchers in AI today deliberately call their work by other names, such as <link xlink:type="simple" xlink:href="../625/4964625.xml">
informatics</link>, <link xlink:type="simple" xlink:href="../612/1377612.xml">
knowledge-based systems</link>, <link>
cognitive system</link>s or <link xlink:type="simple" xlink:href="../306/1563306.xml">
computational intelligence</link>. In part, this may be because they considered their field to be fundamentally different from AI, but also the new names help to procure funding. In the commercial world at least, the failed promises of the <link xlink:type="simple" xlink:href="../574/3548574.xml">
AI Winter</link> continue to haunt AI research, as the New York Times reported in 2005: "Computer scientists and software engineers avoided the term artificial intelligence for fear of being viewed as wild-eyed dreamers."<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22139%22])">139</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22140%22])">140</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22141%22])">141</ref></p>

</ss1>
<ss1>
<st>
Where is HAL 9000?</st>
<p>

In 1968, <link xlink:type="simple" xlink:href="../148/18598148.xml">
Arthur C. Clark</link> and <cameraman wordnetid="109889539" confidence="0.9173553029164789">
<film_director wordnetid="110088200" confidence="0.9173553029164789">
<person wordnetid="100007846" confidence="0.9508927676800064">
<editor wordnetid="110044879" confidence="0.9173553029164789">
<screenwriter wordnetid="110564400" confidence="0.9173553029164789">
<film_maker wordnetid="110088390" confidence="0.9173553029164789">
<actor wordnetid="109765278" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../683/26683.xml">
Stanley Kubrick</link></actor>
</film_maker>
</screenwriter>
</editor>
</person>
</film_director>
</cameraman>
 had imagined that by the year , a machine would exist with an intelligence that matched or exceeded the capability of human beings. The character they created, <link xlink:type="simple" xlink:href="../384/14384.xml">
HAL-9000</link>, was based on hard science: many leading AI researchers also believed that such a machine would exist by the year 2001.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22142%22])">142</ref></p>
<p>

<person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../639/19639.xml">
Marvin Minsky</link></scientist>
</person>
 asks "So the question is why didn't we get HAL in 2001?"<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22143%22])">143</ref> Minsky believes that the answer is that the central problems, like <link xlink:type="simple" xlink:href="../026/996026.xml">
commonsense reasoning</link>, were being neglected, while most researchers pursued things like commercial applications of <link xlink:type="simple" xlink:href="../542/1729542.xml">
neural nets</link> or <link xlink:type="simple" xlink:href="../254/40254.xml">
genetic algorithms</link>. <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../362/308362.xml">
John McCarthy</link></scientist>
</person>
, on the other hand, still blames the <link xlink:type="simple" xlink:href="../287/731287.xml">
qualification problem</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22144%22])">144</ref> For <link xlink:type="simple" xlink:href="../984/25984.xml">
Ray Kurzweil</link>, the issue is computer power and, using <link xlink:type="simple" xlink:href="../418/39418.xml">
Moore's Law</link>, he predicts that machines with human-level intelligence will appear by 2029.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22145%22])">145</ref> <person wordnetid="100007846" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../957/399957.xml">
Jeff Hawkins</link></person>
 argues that <link xlink:type="simple" xlink:href="../542/1729542.xml">
neural net</link> research ignores the essential properties of the human <link xlink:type="simple" xlink:href="../686/58686.xml">
cortex</link>, preferring simple models that have been successful at solving simple problems.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%22146%22])">146</ref> There are many other explanations and for each there is a corresponding research program underway. </p>
<p>

<person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../208/1208.xml">
Alan Turing</link></scientist>
</person>
's quote from 1950 still applies in the 21st century: "We can only see a short distance ahead, but we can see that there is much to be done.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref></p>

</ss1>
</sec>
<sec>
<st>
Notes</st>

<p>

<reflist>
<entry id="1">
For example <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFKurzweil2005%22])">
Kurzweil (2005)</link> argues that machines with <link xlink:type="simple" xlink:href="../357/586357.xml">
human level intelligence</link> will exist by 2029.</entry>
<entry id="2">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFTuring1950%22])">
Turing 1950</link>, p.&nbsp;460</entry>
<entry id="3">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;5-35</entry>
<entry id="4">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;5,
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;939
</entry>
<entry id="5">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;15-16,
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFBuchanan2005%22])">
Buchanan 2005</link>, p.&nbsp;50 (<link xlink:type="simple" xlink:href="../031/176031.xml">
Judah Loew</link>'s <link xlink:type="simple" xlink:href="../888/11888.xml">
Golem</link>),
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;13-14 (Paracelsus),
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFO'Connor1994%22])">
O'Connor 1994</link> (Geber's <it>Takwin</it>)
</entry>
<entry id="6">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;17-25
</entry>
<entry id="7">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFButler1863%22])">
Butler 1863</link>
</entry>
<entry id="8">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNeedham1986%22])">
Needham 1986</link>, p.&nbsp;53
</entry>
<entry id="9">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;6
</entry>
<entry id="10">
<weblink xlink:type="simple" xlink:href="http://www.shef.ac.uk/marcoms/eview/articles58/robot.html">
A Thirteenth Century Programmable Robot</weblink>
</entry>
<entry id="11">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;17 and see also <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLevitt2000%22])">
Levitt 2000</link>
</entry>
<entry id="12">
Quoted in <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;8. <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, p.&nbsp;1 and <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;6-9 discusses sacred statues.
</entry>
<entry id="13">
Other important <link xlink:type="simple" xlink:href="../749/189749.xml">
automaton</link>s were built by <link xlink:type="simple" xlink:href="../388/78388.xml">
Haroun al-Rashid</link>  <cite class="inline">(<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;10)</cite>, <link xlink:type="simple" xlink:href="../045/431045.xml">
Jacques de Vaucanson</link>  <cite class="inline">(<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;16)</cite> and <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<engineer wordnetid="109615807" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<inventor wordnetid="110214637" confidence="0.8">
<creator wordnetid="109614315" confidence="0.8">
<link xlink:type="simple" xlink:href="../044/182044.xml">
Leonardo Torres y Quevedo</link></creator>
</inventor>
</causal_agent>
</engineer>
</person>
</physical_entity>
  <cite class="inline">(<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;59-62)</cite></entry>
<entry id="14">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;37-46, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;6, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFHaugeland1986%22])">
Haugeland 1986</link>, chpt. 2, and <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFBuchanan2005%22])">
Buchanan 2005</link>, p.&nbsp;53
</entry>
<entry id="15">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;42, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFHobbes1651%22])">
Hobbes 1651</link>, chapter 5
</entry>
<entry id="17">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;61-62, 64-66, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;14-15</entry>
<entry id="16">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;41, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;6, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFBerlinski2000%22])">
Berlinski 2000</link>, p.&nbsp;12, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFBuchanan2005%22])">
Buchanan 2005</link>, p.&nbsp;53
</entry>
<entry id="19">
The starting and ending dates of the sections in this article are adopted from <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link> and <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;16−27. Themes, trends and projects are treated in the period that the most important work was done.</entry>
<entry id="18">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;63-64,
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;22-24,
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;8 and see
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFTuring1936%22])">
Turing 1936</link>. Other important contributors to the <link xlink:type="simple" xlink:href="../402/30402.xml">
theory of computation</link> include <link xlink:type="simple" xlink:href="../942/15942.xml">
John Von Neumann</link>  <cite class="inline">(<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;76-80)</cite></entry>
<entry id="21">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;98, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;27−28, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;15, 940 and <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMoravec1988%22])">
Moravec 1988</link>, p.&nbsp;3</entry>
<entry id="20">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;51-57, 80-107,
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;27-32,
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;15, 940,
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMoravec1988%22])">
Moravec 1988</link>, p.&nbsp;3.
</entry>
<entry id="23">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;102, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;34−35 and <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;17</entry>
<entry id="22">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;51-57, 88-94, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, p.&nbsp;30, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;15−16 and see also <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPittsMcCullough1943%22])">
Pitts &amp; McCullough 1943</link></entry>
<entry id="25">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNorvigRussell2003%22])">
Norvig &amp; Russell (2003</link>, p.&nbsp;948) claim that Turing answered all the major objections to AI that have been offered in the years since the paper appeared.</entry>
<entry id="24">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;70−72,
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, p.&nbsp;22−25,
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;2−3 and 948,
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFHaugeland1985%22])">
Haugeland 1985</link>, pp.&nbsp;6−9.
See also 
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFTuring1950%22])">
Turing 1950</link>
</entry>
<entry id="27">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;123-125, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;44−46 and <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;17</entry>
<entry id="26">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;137-170, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier%22])">
Crevier</link>, pp.&nbsp;44-47</entry>
<entry id="29">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;947,952</entry>
<entry id="28">
Quoted in <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, p.&nbsp;46 and <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;17</entry>
<entry id="31">
See <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCarthyMinskyRochesterShannon1955%22])">
McCarthy et al. 1955</link>. Also see <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, p.&nbsp;48 where <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<academician wordnetid="109759069" confidence="0.8">
<adult wordnetid="109605289" confidence="0.8">
<professional wordnetid="110480253" confidence="0.8">
<educator wordnetid="110045713" confidence="0.8">
<link xlink:type="simple" xlink:href="../005/11702005.xml">
Crevier</link></educator>
</professional>
</adult>
</academician>
</causal_agent>
</person>
</physical_entity>
 states "[the proposal] later became known as the 'physical symbol systems hypothesis'". The <link xlink:type="simple" xlink:href="../999/2685999.xml">
physical symbol system</link> hypothesis was articulated and named by <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../300/287300.xml">
Newell</link></scientist>
</person>
 and <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../205/14205.xml">
Simon</link></scientist>
</person>
 in their paper on <link xlink:type="simple" xlink:href="../658/1234658.xml">
GPS</link>.  <cite class="inline">(<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNewellSimon1963%22])">
Newell &amp; Simon 1963</link>)</cite> It includes a more specific definition of a "machine" as an agent that manipulates symbols. See the <link xlink:type="simple" xlink:href="../015/2958015.xml">
philosophy of artificial intelligence</link>.</entry>
<entry id="30">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;111-136,
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;49-51 and
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig%22])">
Russell Norvig</link>, p.&nbsp;17
</entry>
<entry id="34">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier (1993</link>, pp.&nbsp;49)  writes "the conference is generally recognized as the official birthdate of the new science."</entry>
<entry id="35">
Russell and Norvig write "it was astonishing whenever a computer did anything remotely clever." <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;18</entry>
<entry id="32">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck (2004</link>, p.&nbsp;129-130) discusses how the Dartmouth conference alumni dominated the first two decades of AI research, calling them the "invisible college".</entry>
<entry id="33">
"I won't swear and I hadn't seen it before," McCarthy told Pamela McCorduck in 1979.  <cite class="inline">(<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;114)</cite> However, <link xlink:type="simple" xlink:href="../841/58841.xml">
McCarthy</link> also stated unequivocally "I came up with the term" in a <link xlink:type="simple" xlink:href="../836/385836.xml">
CNET</link> interview.  <cite class="inline">(<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFSkilling2006%22])">
Skilling 2006</link>)</cite></entry>
<entry id="38">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;52−107, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMoravec1988%22])">
Moravec 1988</link>, p.&nbsp;9</entry>
<entry id="39">
Means-ends analysis, reasoning as search: <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;247-248. <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;59−61</entry>
<entry id="36">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;52−107, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMoravec1988%22])">
Moravec 1988</link>, p.&nbsp;9 and <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;18−21</entry>
<entry id="37">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;218, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;108−109 and <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;21</entry>
<entry id="42">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;51−58,65−66 and <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;18−19</entry>
<entry id="43">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;268-271, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;95−96, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMoravec1988%22])">
Moravec 1988</link>, pp.&nbsp;14−15</entry>
<entry id="40">
Heuristic: <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;246, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;21−22</entry>
<entry id="41">
GPS: <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;245-250, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, p.&nbsp;GPS?, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;GPS?</entry>
<entry id="46">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;164−172</entry>
<entry id="47">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;291-296, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;134−139</entry>
<entry id="44">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;286, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;76−79, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;19</entry>
<entry id="45">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;79−83</entry>
<entry id="51">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFSimon1965%22])">
Simon 1965</link>, p.&nbsp;96 quoted in <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, p.&nbsp;109</entry>
<entry id="50">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFSimonNewell1958%22])">
Simon &amp; Newell 1958</link>, p.&nbsp;7−8 quoted in <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, p.&nbsp;108. See also <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;21</entry>
<entry id="49">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;300-305, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;84−102, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;19</entry>
<entry id="48">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;299-305, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;83−102, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;19 and see also <weblink xlink:type="simple" xlink:href="http://www.alanturing.net/turing_archive/pages/Reference%20Articles/what_is_AI/What%20is%20AI06.html">
Micro-World AI</weblink></entry>
<entry id="55">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, p.&nbsp;94</entry>
<entry id="54">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;64−65</entry>
<entry id="53">
Minsky strongly believes he was misquoted. See <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;272-274, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, p.&nbsp;96 and <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFDarrach1970%22])">
Darrach 1970</link>.</entry>
<entry id="52">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMinsky1967%22])">
Minsky 1967</link>, p.&nbsp;2 quoted in <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, p.&nbsp;109</entry>
<entry id="59">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;68−71 and <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFTurkle1984%22])">
Turkle 1984</link></entry>
<entry id="58">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, p.&nbsp;65</entry>
<entry id="57">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;131, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, p.&nbsp;51. McCorduck also notes that funding was mostly under the direction of alumni of the <link xlink:type="simple" xlink:href="../646/1124646.xml">
Dartmouth conference</link> of 1956.</entry>
<entry id="56">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFHowe1994%22])">
Howe 1994</link></entry>
<entry id="63">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, p.&nbsp;146</entry>
<entry id="62">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier_1993%22])">
Crevier  1993</link>, pp.&nbsp;163−196</entry>
<entry id="61">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;104−107,
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;102−105,
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;22</entry>
<entry id="60">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;100−144 and <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;21−22</entry>
<entry id="68">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;300 &amp; 421, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;113−114, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMoravec1988%22])">
Moravec 1988</link>, p.&nbsp;13, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLenat1989%22])">
Lenat 1989</link> (Introduction) and <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;21</entry>
<entry id="69">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;456, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMoravec1988%22])">
Moravec 1988</link>, pp.&nbsp;15−16</entry>
<entry id="70">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCarthyHayes1969%22])">
McCarthy &amp; Hayes 1969</link>, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;117−119</entry>
<entry id="71">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;280-281, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, p.&nbsp;110, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;21 and <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNRC1999%22])">
NRC 1999</link> under "Success in Speech Recognition".
</entry>
<entry id="64">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;20−21</entry>
<entry id="65">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;146−148, see also <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFBuchanan2005%22])">
Buchanan 2005</link>, p.&nbsp;56: "Early programs were necessarily limited in scope by the size and speed of memory"</entry>
<entry id="66">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMoravec1976%22])">
Moravec 1976</link>. <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../362/308362.xml">
McCarthy</link></scientist>
</person>
 has always disagreed with Moravec, back to their early days together at <link xlink:type="simple" xlink:href="../328/310328.xml">
SAIL</link>. He states "I would say that 50 years ago, the machine capability was much too small, but by 30 years ago, machine capability wasn't the real problem." in a <link xlink:type="simple" xlink:href="../836/385836.xml">
CNET</link> interview.  <cite class="inline">(<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFSkillings2006%22])">
Skillings 2006</link>)</cite></entry>
<entry id="67">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;9,21−22 and <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLighthill1973%22])">
Lighthill 1973</link></entry>
<entry id="76">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNRC1999%22])">
NRC 1999</link> under "Shift to Applied Research Increases Investment." While the autonomous tank was a failure, the battle management system proved to be enormously successful, saving billions in the first <conflict wordnetid="100958896" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../000/182000.xml">
Gulf War</link></conflict>
, repaying the investment and justifying the <agency wordnetid="108337324" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../957/8957.xml">
DARPA</link></agency>
's pragmatic policy, at least as far as <agency wordnetid="108337324" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../957/8957.xml">
DARPA</link></agency>
 was concerned.
</entry>
<entry id="77">
 <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier_1993%22])">
Crevier 1993</link>, p.&nbsp;22, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;949−950, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFHofstadter1980%22])">
Hofstadter 1980</link>, pp.&nbsp;471−477 and see <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLucas1961%22])">
Lucas 1961</link></entry>
<entry id="78">
"Know-how" is Dreyfus' term. (Dreyfus makes a distinction between "knowing how" and "knowing that", a modern version of <link xlink:type="simple" xlink:href="../304/37304.xml">
Heidegger</link>'s distinction of <link>
ready-to-hand</link> and <link xlink:type="simple" xlink:href="../014/6299014.xml">
present-at-hand</link>.)  <cite class="inline">(<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFDreyfusDreyfus1986%22])">
Dreyfus &amp; Dreyfus 1986</link>)</cite></entry>
<entry id="79">
Dreyfus' critique of AI: <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;211−239, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;120−132, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;950−952 and see <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFDreyfus1972%22])">
Dreyfus 1972</link></entry>
<entry id="72">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, p.&nbsp;117, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;22, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFHowe1994%22])">
Howe 1994</link> and see also <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLighthill1973%22])">
Lighthill 1973</link>.
</entry>
<entry id="73">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;22, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLighthill1973%22])">
Lighthill 1973</link>,  <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../362/308362.xml">
John McCarthy</link></scientist>
</person>
 wrote in response that "the combinatorial explosion problem has been recognized in AI from the beginning" in <weblink xlink:type="simple" xlink:href="http://www-formal.stanford.edu/jmc/reviews/lighthill/lighthill.html">
Review of Lighthill report</weblink>
</entry>
<entry id="74">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;115−116 (on whom this account is based). Other views include <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;306-313 and <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNRC1999%22])">
NRC 1999</link> under "Success in Speech Recognition".
</entry>
<entry id="75">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, p.&nbsp;115. Moravec explains, "Their initial promises to DARPA had been much too optimistic. Of course, what they delivered stopped considerably short of that. But they felt they couldn't in their next proposal promise less than in the first one, so they promised more."
</entry>
<entry id="85">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;51, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;19, 23
</entry>
<entry id="84">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;356−373, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;132−144, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;961 and see <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFWeizenbaum1976%22])">
Weizenbaum 1976</link></entry>
<entry id="87">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;193−196</entry>
<entry id="86">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;51, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;190−192</entry>
<entry id="81">
Quoted in <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, p.&nbsp;143</entry>
<entry id="80">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;443−445, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;269−271, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2004%22])">
Russell &amp; Norvig 2004</link>, pp.&nbsp;958−960 and see <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFSearle1980%22])">
Searle 1980</link></entry>
<entry id="83">
"I became the only member of the AI community to be seen eating lunch with Dreyfus. And I deliberately made it plain that theirs was not the way to treat a human being." <link xlink:type="simple" xlink:href="../003/16003.xml">
Joseph Weizenbaum</link>, quoted in <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, p.&nbsp;123.</entry>
<entry id="82">
Quoted in <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, p.&nbsp;122</entry>
<entry id="93">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;305-306, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;170−173, 246 and <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;24. Minsky's frame paper: <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMinsky1974%22])">
Minsky 1974</link>.</entry>
<entry id="92">
Neat vs. scruffy: <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;421-424 (who picks up the state of the debate in 1984). <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;168 (who documents Schank's original use of the term). Another aspect of the conflict was called "the procedural/declarative distinction" but did not prove to be influential in later AI research.</entry>
<entry id="95">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;158−159 and <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;23−24</entry>
<entry id="94">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;327-335 (<system wordnetid="104377057" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<link xlink:type="simple" xlink:href="../912/557912.xml">
Dendral</link></instrumentality>
</artifact>
</system>
), <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;148−159, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;22−23</entry>
<entry id="89">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFWason1966%22])">
Wason (1966)</link> showed that people do poorly on completely abstract problems, but if the problem is restated to allowed the use of intuitive <link xlink:type="simple" xlink:href="../799/5197799.xml">
social intelligence</link>, performance dramatically improves. (See <puzzle wordnetid="106784639" confidence="0.8">
<message wordnetid="106598915" confidence="0.8">
<subject wordnetid="106599788" confidence="0.8">
<problem wordnetid="106784003" confidence="0.8">
<question wordnetid="106783768" confidence="0.8">
<link xlink:type="simple" xlink:href="../236/823236.xml">
Wason selection task</link></question>
</problem>
</subject>
</message>
</puzzle>
) <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFTverskySlovicKahnemann1982%22])">
Tversky, Slovic &amp; Kahnemann (1982)</link> have shown that people are terrible at elementary problems that involve uncertain reasoning. (See <link xlink:type="simple" xlink:href="../791/510791.xml">
list of cognitive biases</link> for several examples). <person wordnetid="100007846" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../366/1047366.xml">
Eleanor Rosch</link></person>
's work is described in <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLakoff1987%22])">
Lakoff 1987</link>
</entry>
<entry id="88">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;145−149,258−63</entry>
<entry id="91">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;175</entry>
<entry id="90">
An early example of <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../362/308362.xml">
McCathy's</link></scientist>
</person>
 position was in the journal <periodical wordnetid="106593296" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../513/193513.xml">
Science</link></periodical>
 where he said "This is AI, so we don't care if it's psychologically real" (see <weblink xlink:type="simple" xlink:href="http://books.google.com/books?id=PEkqAAAAMAAJ&amp;q=%22we+don't+care+if+it's+psychologically+real%22&amp;dq=%22we+don't+care+if+it's+psychologically+real%22&amp;output=html&amp;pgis=1">
see Science at Google Books</weblink>), and he recently reiterated his position at the <social_group wordnetid="107950920" confidence="0.8">
<meeting wordnetid="108307589" confidence="0.8">
<gathering wordnetid="107975026" confidence="0.8">
<group wordnetid="100031264" confidence="0.8">
<conference wordnetid="108308497" confidence="0.8">
<link xlink:type="simple" xlink:href="../535/5992535.xml">
AI@50</link></conference>
</group>
</gathering>
</meeting>
</social_group>
 conference where he said "Artificial intelligence is not, by definition, simulation of human intelligence" (see <weblink xlink:type="simple" xlink:href="http://www.engagingexperience.com/2006/07/ai50_ai_past_pr.html">
McCarthy's presentation at AI@50</weblink>)</entry>
<entry id="102">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;436-441, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;211, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;24 and see also <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFFeigenbaumMcCorduck1983%22])">
Feigenbaum &amp; McCorduck 1983</link></entry>
<entry id="103">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;195</entry>
<entry id="100">
Knowledge revolution: <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;266-276, 298-300, 314, 421, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig%22])">
Russell Norvig</link>, pp.&nbsp;22-23</entry>
<entry id="101">
Cyc: <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;489, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;239−243, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;363−365 and <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLenatGuha1989%22])">
Lenat &amp; Guha 1989</link></entry>
<entry id="98">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;299</entry>
<entry id="99">
{<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;421</entry>
<entry id="96">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, p.&nbsp;198</entry>
<entry id="97">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;434-435, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;161−162,197−203 and <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;24</entry>
<entry id="110">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;435, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;209−210</entry>
<entry id="111">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;435 (who cites institutional reasons for their ultimate failure), <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;204−208 (who cites the difficulty of truth maintenance, i.e., learning and updating), <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLenatGuha1989%22])">
Lenat &amp; Guha 1989</link>, Introduction (who emphasizes the brittleness and the inability to handle excessive qualification.)</entry>
<entry id="108">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;215−216.</entry>
<entry id="109">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;203. <bubble wordnetid="109229709" confidence="0.8">
<ball wordnetid="113899404" confidence="0.8">
<globule wordnetid="109289709" confidence="0.8">
<sphere wordnetid="113899200" confidence="0.8">
<round_shape wordnetid="113865483" confidence="0.8">
<shape wordnetid="100027807" confidence="0.8">
<link xlink:type="simple" xlink:href="../574/3548574.xml">
AI winter</link></shape>
</round_shape>
</sphere>
</globule>
</ball>
</bubble>
 was first used as the title of a seminar on the subject for the <association wordnetid="108049401" confidence="0.8">
<link xlink:type="simple" xlink:href="../794/534794.xml">
Association for the Advancement of Artificial Intelligence</link></association>
.</entry>
<entry id="106">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;214−215.</entry>
<entry id="107">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;25</entry>
<entry id="104">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;240.</entry>
<entry id="105">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;426-432, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNRC1999%22])">
NRC 1999</link> under "Shift to Applied Research Increases Investment"</entry>
<entry id="119">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck (2004</link>, p.&nbsp;424) discusses the fragmentation and the abandonment of AI's original goals.</entry>
<entry id="118">
See, for example, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLakoffTurner1999%22])">
Lakoff &amp; Turner 1999</link></entry>
<entry id="117">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFBrooks_1990%22])">
Brooks 1990</link>, p.&nbsp;3</entry>
<entry id="116">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;183−190.</entry>
<entry id="115">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMoravec1988%22])">
Moravec (1988</link>, p.&nbsp;20) writes: "I am confident that this bottom-up route to artificial intelligence will one date meet the traditional top-down route more than half way, ready to provide the real world competence and the commonsense knowledge that has been so frustratingly elusive in reasoning programs. Fully intelligent machines will result when the metaphorical <link xlink:type="simple" xlink:href="../929/373929.xml">
golden spike</link> is driven uniting the two efforts."
</entry>
<entry id="114">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;454-462</entry>
<entry id="113">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;441, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, p.&nbsp;212. McCorduck writes "Two and a half decades later, we can see that the Japanese didn't quite meet all of those ambitious goals."</entry>
<entry id="112">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;430-431</entry>
<entry id="127">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;478</entry>
<entry id="126">
This is how the most widely accepted textbooks of the 21st century define artificial intelligence. See <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;32 and <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998%22])">
Poole, Mackworth &amp; Goebel 1998</link>, p.&nbsp;1</entry>
<entry id="125">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;27, 55</entry>
<entry id="124">
For example, both <link xlink:type="simple" xlink:href="../236/815236.xml">
John Doyle</link>  <cite class="inline">(<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFDoyle1983%22])">
Doyle 1983</link>)</cite> and <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../639/19639.xml">
Marvin Minsky</link></scientist>
</person>
's popular classic <it><link xlink:type="simple" xlink:href="../320/295320.xml">
The Society of Mind</link></it>  <cite class="inline">(<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMinsky1986%22])">
Minsky 1986</link>)</cite> used the word "agent". Other "modular" proposals included <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../498/632498.xml">
Rodney Brook's</link></scientist>
</person>
 <link xlink:type="simple" xlink:href="../552/83552.xml">
subsumption architecture</link>, <link xlink:type="simple" xlink:href="../757/22757.xml">
object-oriented programming</link> and others.</entry>
<entry id="123">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;471-478, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;55, where they write: "The whole-agent view is now widely accepted in the field". The <link xlink:type="simple" xlink:href="../317/2711317.xml">
intelligent agent</link> paradigm is discussed in major AI textbooks, such as: <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, pp.&nbsp;32−58, 968−972, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPooleMackworthGoebel1998%22])">
Poole, Mackworth &amp; Goebel 1998</link>, pp.&nbsp;7−21, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFLugerStubblefield2004%22])">
Luger &amp; Stubblefield 2004</link>, pp.&nbsp;235−240</entry>
<entry id="122">
Cycle time of <computer wordnetid="103082979" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<device wordnetid="103183080" confidence="0.8">
<machine wordnetid="103699975" confidence="0.8">
<link xlink:type="simple" xlink:href="../886/571886.xml">
Ferranti Mark I</link></machine>
</device>
</instrumentality>
</artifact>
</computer>
 was 1.2&nbsp;milliseconds, which is arguably equivalent to about 833&nbsp;<link xlink:type="simple" xlink:href="../930/82930.xml">
flops</link>. <link xlink:type="simple" xlink:href="../387/49387.xml">
Deep Blue</link> ran at 11.38&nbsp;<link xlink:type="simple" xlink:href="../930/82930.xml">
gigaflops</link> (and this does not even take into account Deep Blue's special-purpose hardware for chess). <it>Very</it> approximately, these differ by a factor of 10^7.</entry>
<entry id="121">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFKurzweil2005%22])">
Kurzweil 2005</link>, p.&nbsp;274 writes that the improvement in computer chess, "according to common wisdom, is governed only by the brute force expansion of computer hardware."</entry>
<entry id="120">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, pp.&nbsp;480-483</entry>
<entry id="137">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;423, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFKurzweil2005%22])">
Kurzweil 2005</link>, p.&nbsp;265, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFHofstadter1979%22])">
Hofstadter 1979</link>, p.&nbsp;601</entry>
<entry id="136">
For the use of AI at Google, see <weblink xlink:type="simple" xlink:href="http://news.com.com/Googles+man+behind+the+curtain/2008-1024_3-5208228.html">
Google's man behind the curtain</weblink>, <weblink xlink:type="simple" xlink:href="http://news.com.com/Google+backs+character-recognition+research/2100-1032_3-6175136.html">
Google backs character recognition</weblink> and <weblink xlink:type="simple" xlink:href="http://news.com.com/Spying+an+intelligent+search+engine/2100-1032_3-6107048.html">
Spying an intelligent search engine</weblink>.</entry>
<entry id="139">
 Markoff, John&#32;(2005-10-14).&#32;"<weblink xlink:type="simple" xlink:href="http://www.nytimes.com/2005/10/14/technology/14artificial.html?ei=5070&amp;en=11ab55edb7cead5e&amp;ex=1185940800&amp;adxnnl=1&amp;adxnnlx=1185805173-o7WsfW7qaP0x5/NUs1cQCQ">
Behind Artificial Intelligence, a Squadron of Bright Real People</weblink>", The New York Times.&#32;Retrieved on <link>
2007-07-30</link>.&nbsp;</entry>
<entry id="138">
<weblink xlink:type="simple" xlink:href="http://www.cnn.com/2006/TECH/science/07/24/ai.bostrom/">
AI set to exceed human brain power</weblink> CNN.com (July 26, 2006)</entry>
<entry id="141">
Patty Tascarella, <weblink xlink:type="simple" xlink:href="http://www.bizjournals.com/pittsburgh/stories/2006/08/14/focus3.html?b=1155528000%5E1329573">
Robotics firms find fundraising struggle, with venture capital shy</weblink>. Pittsburgh Business Times (August 11, 2006)</entry>
<entry id="140">
Alex Castro (2007) <weblink xlink:type="simple" xlink:href="http://www.economist.com/science/tq/displaystory.cfm?story_id=9249338">
Are you talking to me?</weblink> The Economist Technology Quarterly (June 7, 2007)</entry>
<entry id="143">
He goes on to say: "The answer is, I believe we could have ... I once went to an international conference on neural net[s]. There were 40 thousand registrants ... but ... if you had an international conference, for example, on using multiple representations for common sense reasoning, I've only been able to find 6 or 7 people in the whole world." <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../639/19639.xml">
Marvin Minsky</link></scientist>
</person>
, in <weblink xlink:type="simple" xlink:href="http://technetcast.ddj.com/tnc_play_stream.html?stream_id=526">
It's 2001</weblink></entry>
<entry id="142">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCrevier1993%22])">
Crevier 1993</link>, pp.&nbsp;108−109</entry>
<entry id="129">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;25−26</entry>
<entry id="128">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck 2004</link>, p.&nbsp;486-487, <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;25-26</entry>
<entry id="131">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFPearl1988%22])">
Pearl 1988</link></entry>
<entry id="130">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMcCorduck2004%22])">
McCorduck (2004</link>, p.&nbsp;487): "As I write, AI enjoys a Neat hegemony."</entry>
<entry id="133">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRussellNorvig2003%22])">
Russell &amp; Norvig 2003</link>, p.&nbsp;28</entry>
<entry id="132">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFNRC1999%22])">
NRC 1999</link> under "Artificial Intelligence in the 90s", and <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFKurzweil2005%22])">
Kurzweil 2005</link>, p.&nbsp;264</entry>
<entry id="135">
"AI-inspired systems were already integral to many everyday technologies such as internet search engines, bank software for processing transactions and in medical diagnosis." <physical_entity wordnetid="100001930" confidence="0.8">
<philosopher wordnetid="110423589" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<intellectual wordnetid="109621545" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scholar wordnetid="110557854" confidence="0.8">
<link xlink:type="simple" xlink:href="../292/408292.xml">
Nick Bostrom</link></scholar>
</causal_agent>
</intellectual>
</person>
</philosopher>
</physical_entity>
, <weblink xlink:type="simple" xlink:href="http://www.cnn.com/2006/TECH/science/07/24/ai.bostrom/">
AI set to exceed human brain power</weblink> CNN.com (July 26, 2006)</entry>
<entry id="134">
For the new state of the art in AI based speech recognition, see <weblink xlink:type="simple" xlink:href="http://www.economist.com/science/tq/displaystory.cfm?story_id=9249338">
Are You Talking to Me?</weblink></entry>
<entry id="144">
See <weblink xlink:type="simple" xlink:href="http://www.engagingexperience.com/2006/07/ai50_ai_past_pr.html">
McCarthy's presentation at AI@50</weblink></entry>
<entry id="145">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFKurzweil2005%22])">
Kurzweil 2005</link></entry>
<entry id="146">
<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFHawkinsBlakeslee2004%22])">
Hawkins &amp; Blakeslee 2004</link></entry>
</reflist>
</p>

</sec>
<sec>
<st>
References</st>

<p>

<list>
<entry level="1" type="bullet">

  <cite id="CITEREFBerlinski2000" style="font-style:normal"><link>
Berlinski, David</link>&#32;(2000),&#32;<it>The Advent of the Algorithm</it>, Harcourt Books</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFBuchanan2005" style="font-style:normal"><link>
Buchanan, Bruce G.</link>&#32;(2005),&#32;"<weblink xlink:type="simple" xlink:href="http://www.aaai.org/AITopics/assets/PDF/AIMag26-04-016.pdf">
A (Very) Brief History of Artificial Intelligence</weblink>",&#32;<it>AI Magazine</it>:  53−60, .&#32;Retrieved on 29 August 2007</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFBrooks1990" style="font-style:normal"><link>
Brooks, Rodney</link>&#32;(1990),&#32;"<weblink xlink:type="simple" xlink:href="http://people.csail.mit.edu/brooks/papers/elephants.pdf">
Elephants Don't Play Chess</weblink>",&#32;<it>Robotics and Autonomous Systems</it>&#32;<b>6</b>:  3−15, <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1016%2FS0921-8890%2805%2980025-9">
10.1016/S0921-8890(05)80025-9</weblink>, .&#32;Retrieved on 29 August 2007</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFButler1863" style="font-style:normal"><link>
Butler, Samuel</link>&#32;(13 June 1863),&#32;"<weblink xlink:type="simple" xlink:href="http://www.nzetc.org/tm/scholarly/tei-ButFir-t1-g1-t1-g1-t4-body.html">
Darwin Among the Machines</weblink>",&#32;<it>the Press, Christchurch, New Zealand</it>, .&#32;Retrieved on 9 October 2008</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFCrevier1993" style="font-style:normal"><link>
Crevier, Daniel</link>&#32;(1993),&#32;<it>AI: The Tumultuous Search for Artificial Intelligence</it>, New York, NY: BasicBooks, ISBN 0-465-02997-3</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFDarrach1970" style="font-style:normal">Darrach, Brad&#32;(20 November 1970),&#32;"Meet Shakey, the First Electronic Person",&#32;<it>Life Magazine</it>:  58−68</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFDoyle1983" style="font-style:normal">Doyle, J.&#32;(1983),&#32;"What is rational psychology? Toward a modern mental philosophy",&#32;<it>AI Magazine</it>&#32;<b>4</b>(3):  50−53</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFDreyfus1972" style="font-style:normal"><link>
Dreyfus, Hubert</link>&#32;(1972),&#32;<it><work wordnetid="104599396" confidence="0.8">
<product wordnetid="104007894" confidence="0.8">
<creation wordnetid="103129123" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<book wordnetid="106410904" confidence="0.8">
<publication wordnetid="106589574" confidence="0.8">
<link xlink:type="simple" xlink:href="../856/8919856.xml">
What Computers Can't Do</link></publication>
</book>
</artifact>
</creation>
</product>
</work>
</it>, MIT Press</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFFeigenbaumMcCorduck1983" style="font-style:normal"><link>
Feigenbaum, Edward A.</link>&#32;&amp;&#32;McCorduck, Pamela&#32;(1983),&#32;<it>The Fifth Generation: Artificial Intelligence and Japan's Computer Challenge to the World</it>, Michael Joseph, ISBN 0-7181-2401-4</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFHawkinsBlakeslee2004" style="font-style:normal"><link>
Hawkins, Jeff</link>&#32;&amp;&#32;Blakeslee, Sandra&#32;(2004),&#32;<it>On Intelligence</it>, New York, NY: Owl Books, ISBN 0-8050-7853-3, <link xlink:type="simple" xlink:href="../885/883885.xml">
OCLC</link> <weblink xlink:type="simple" xlink:href="http://worldcat.org/oclc/61273290">
61273290</weblink></cite>&nbsp;.</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFHebb1949" style="font-style:normal"><link>
Hebb, D.O.</link>&#32;(1949),&#32;<it>The organization of behavior</it>, New York: Wiley</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFHobbes1651" style="font-style:normal"><link>
Hobbes</link>&#32;(1651),&#32;<it><link xlink:type="simple" xlink:href="../359/143359.xml">
Leviathan</link></it></cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFHofstadter1980" style="font-style:normal"><link>
Hofstadter, Douglas</link>&#32;(1980),&#32;</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFHowe1994" style="font-style:normal">Howe, J.&#32;(November 1994),&#32;<it><weblink xlink:type="simple" xlink:href="http://www.inf.ed.ac.uk/about/AIhistory.html">
Artificial Intelligence at Edinburgh University: a Perspective</weblink></it>, </cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFKurzweil2005" style="font-style:normal"><link>
Kurzweil, Ray</link>&#32;(2005),&#32;<it><link xlink:type="simple" xlink:href="../123/767123.xml">
The Singularity is Near</link></it>, Viking Press</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFLakoff1987" style="font-style:normal"><link>
Lakoff, George</link>&#32;(1987),&#32;<it>Women, Fire, and Dangerous Things: What Categories Reveal About the Mind</it>, University of Chicago Press., ISBN 0-226-46804-6</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFLenatGuha1989" style="font-style:normal"><link>
Lenat, Douglas</link>&#32;&amp;&#32;Guha, R. V.&#32;(1989),&#32;<it>Building Large Knowledge-Based Systems</it>, Addison-Wesley</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFLevitt2000" style="font-style:normal">Levitt, Gerald M.&#32;(2000),&#32;<it>The Turk, Chess Automaton</it>, McFarland, ISBN 0786407786</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFLighthill1973" style="font-style:normal"><link>
Lighthill, Professor Sir James</link>&#32;(1973),&#32;"Artificial Intelligence: A General Survey",&#32;<it>Artificial Intelligence: a paper symposium</it>, Science Research Council</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFLucas1961" style="font-style:normal"><link>
Lucas, John</link>&#32;(1961),&#32;<it><weblink xlink:type="simple" xlink:href="http://users.ox.ac.uk/~jrlucas/Godel/mmg.html">
Minds, Machines and Gödel</weblink></it>, </cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFMcCarthyMinskyRochesterShannon1955" style="font-style:normal"><link>
McCarthy, John</link>; <link>
Minsky, Marvin</link>; <link>
Rochester, Nathan</link>&#32;&amp;&#32;<link>
Shannon, Claude</link>&#32;(1955),&#32;<it><weblink xlink:type="simple" xlink:href="http://www-formal.stanford.edu/jmc/history/dartmouth/dartmouth.html">
A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence</weblink></it>, </cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFMcCarthyHayes1969" style="font-style:normal"><link>
McCarthy, John</link>&#32;&amp;&#32;Hayes, P. J.&#32;(1969),&#32;"<weblink xlink:type="simple" xlink:href="http://www-formal.stanford.edu/jmc/mcchay69.html">
Some philosophical problems from the standpoint of artificial intelligence</weblink>",&#32;<it>Machine Intelligence</it>&#32;<b>4</b>:  463−502, </cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFMcCorduck2004" style="font-style:normal">McCorduck, Pamela&#32;(2004),&#32;<it>Machines Who Think</it>&#32;(2nd ed.), Natick, MA: A. K. Peters, Ltd., ISBN 1-56881-205-1, <link xlink:type="simple" xlink:href="../885/883885.xml">
OCLC</link> <weblink xlink:type="simple" xlink:href="http://worldcat.org/oclc/52197627">
52197627</weblink></cite>&nbsp;.</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFMcCulloughPitts1943" style="font-style:normal"><link>
McCullough, W. S.</link>&#32;&amp;&#32;Pitts, W.&#32;(1943),&#32;"A logical calculus of the ideas immanent in nervous activity",&#32;<it>Bulletin of Mathematical Biophysics</it>&#32;<b>5</b>:  115−127, <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1007%2FBF02478259">
10.1007/BF02478259</weblink></cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFMinsky1967" style="font-style:normal"><link>
Minsky, Marvin</link>&#32;(1967),&#32;<it>Computation: Finite and Infinite Machines</it>, Englewood Cliffs, N.J.: Prentice-Hall</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFMinsky1969" style="font-style:normal"><link>
Minsky, Marvin</link>&#32;(1969),&#32;<it>Perceptrons: An Introduction to Computational Geometry</it>, The MIT Press</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFMinsky1974" style="font-style:normal"><link>
Minsky, Marvin</link>&#32;(1974),&#32;<it><weblink xlink:type="simple" xlink:href="http://web.media.mit.edu/~minsky/papers/Frames/frames.html">
A Framework for Representing Knowledge</weblink></it>, </cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFMinsky1986" style="font-style:normal"><link>
Minsky, Marvin</link>&#32;(1986),&#32;<it><link xlink:type="simple" xlink:href="../320/295320.xml">
The Society of Mind</link></it>, Simon and Schuster</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFMoravec1976" style="font-style:normal"><link>
Moravec, Hans</link>&#32;(1976),&#32;<it><weblink xlink:type="simple" xlink:href="http://www.frc.ri.cmu.edu/users/hpm/project.archive/general.articles/1975/Raw.Power.html">
The Role of Raw Power in Intelligence</weblink></it>, </cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFMoravec1988" style="font-style:normal"><link>
Moravec, Hans</link>&#32;(1988),&#32;<it>Mind Children</it>, Harvard University Press</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFNRC1999" style="font-style:normal"><link>
NRC</link>&#32;(1999),&#32;<weblink xlink:type="simple" xlink:href="http://www.nap.edu/readingroom/books/far/ch9.html">
"Developments in Artificial Intelligence"</weblink>,&#32;<it>Funding a Revolution: Government Support for Computing Research</it>, National Academy Press</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFNewellSimon1963" style="font-style:normal"><link>
Newell, Allen</link>&#32;&amp;&#32;Simon, H. A.&#32;(1963),&#32;"GPS: A Program that Simulates Human Thought", in&#32;Feigenbaum, E.A.&#32;&amp;&#32;Feldman, J.,&#32;<it>Computers and Thought</it>, McGraw-Hill</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFO.27Connor1994" style="font-style:normal">O'Connor, Kathleen Malone&#32;(1994),&#32;<it><weblink xlink:type="simple" xlink:href="http://repository.upenn.edu/dissertations/AAI9503804">
The alchemical creation of life (takwin) and other concepts of Genesis in medieval Islam</weblink></it>, University of Pennsylvania, .&#32;Retrieved on 9 January 2007</cite>&nbsp; </entry>
<entry level="1" type="bullet">

  <cite id="CITEREFPearl1988" style="font-style:normal"><link>
Pearl, J.</link>&#32;(1988),&#32;<it>Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference</it>, Morgan Kaufmann</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFRussellNorvig2003" style="font-style:normal"><link>
Russell, Stuart J.</link>&#32;&amp;&#32;<link>
Norvig, Peter</link>&#32;(2003),&#32;<it><weblink xlink:type="simple" xlink:href="http://aima.cs.berkeley.edu/">
</weblink></it>&#32;(2nd ed.), Upper Saddle River, NJ: Prentice Hall, ISBN 0-13-790395-2, </cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFPooleMackworthGoebel1998" style="font-style:normal">Poole, David; Mackworth, Alan&#32;&amp;&#32;Goebel, Randy&#32;(1998),&#32;<it><weblink xlink:type="simple" xlink:href="http://www.cs.ubc.ca/~poole/ci.html">
Computational Intelligence: A Logical Approach</weblink></it>, Oxford University Press., ISBN 0-19-510270-3, </cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFSamuel1959" style="font-style:normal"><link>
Samuel, Arthur L.</link>&#32;(1959),&#32;"<weblink xlink:type="simple" xlink:href="http://domino.research.ibm.com/tchjr/journalindex.nsf/600cc5649e2871db852568150060213c/39a870213169f45685256bfa00683d74?OpenDocument">
Some studies in machine learning using the game of checkers</weblink>",&#32;<it>IBM Journal of Research and Development</it>&#32;<b>3</b>(3):  210−219, .&#32;Retrieved on 19 August 2007</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFSearle1980" style="font-style:normal"><link>
Searle, John</link>&#32;(1980),&#32;"<weblink xlink:type="simple" xlink:href="http://members.aol.com/NeoNoetics/MindsBrainsPrograms.html">
Minds, Brains and Programs</weblink>",&#32;<it><link xlink:type="simple" xlink:href="../246/3477246.xml">
Behavioral and Brain Sciences</link></it>&#32;<b>3</b>(3):  417–457, .&#32;Retrieved on 7 October 2008</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFSimonNewell1958" style="font-style:normal"><link>
Simon, H. A.</link>&#32;&amp;&#32;<link>
Newell, Allen</link>&#32;(1958),&#32;"Heuristic Problem Solving: The Next Advance in Operations Research",&#32;<it>Operations Research</it>&#32;<b>6</b></cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFSimon1965" style="font-style:normal"><link>
Simon, H. A.</link>&#32;(1965),&#32;<it>The Shape of Automation for Men and Management</it>, New York: Harper &amp; Row</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFSkillings2006" style="font-style:normal">Skillings, Jonathan&#32;(2006),&#32;<it><weblink xlink:type="simple" xlink:href="http://news.cnet.com/Getting-machines-to-think-like-us---page-2/2008-11394_3-6090207-2.html?tag=st.next">
Newsmaker: Getting machines to think like us</weblink></it>, .&#32;Retrieved on 7 October 2008</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFAlan1936" style="font-style:normal"><link>
Alan, Turing</link>&#32;(1936-37),&#32;"<weblink xlink:type="simple" xlink:href="http://www.abelard.org/turpap2/tp2-ie.asp">
On Computable Numbers, with an Application to the Entscheidungsproblem</weblink>",&#32;<it>Proceedings of the London Mathematical Society</it>, 2&#32;(42):  230–265, .&#32;Retrieved on 7 October 2008</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFTuring1950" style="font-style:normal"><link>
Turing, Alan</link>&#32;(October 1950),&#32;"<weblink xlink:type="simple" xlink:href="http://loebner.net/Prizef/TuringArticle.html">
Computing Machinery and Intelligence</weblink>",&#32;<it><periodical wordnetid="106593296" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../598/3995598.xml">
Mind</link></periodical>
</it>&#32;<b>LIX</b>(236):  433–460, <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1093%2Fmind%2FLIX.236.433">
10.1093/mind/LIX.236.433</weblink>, <symbol wordnetid="106806469" confidence="0.8">
<standard wordnetid="107260623" confidence="0.8">
<signal wordnetid="106791372" confidence="0.8">
<identifier wordnetid="107270601" confidence="0.8">
<system_of_measurement wordnetid="113577171" confidence="0.8">
<link xlink:type="simple" xlink:href="../930/234930.xml">
ISSN</link></system_of_measurement>
</identifier>
</signal>
</standard>
</symbol>
 <weblink xlink:type="simple" xlink:href="http://worldcat.org/issn/0026-4423">
0026-4423</weblink>, .&#32;Retrieved on 17 August 2008</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite id="CITEREFWeizenbaum1976" style="font-style:normal"><link>
Weizenbaum, Joseph</link>&#32;(1976),&#32;<it>Computer Power and Human Reason</it>, W.H. Freeman &amp; Company</cite>&nbsp;</entry>
</list>
</p>





</sec>
</bdy>
</article>
