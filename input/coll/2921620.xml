<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 20:05:22[mciao0827] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Sipser-Lautemann theorem</title>
<id>2921620</id>
<revision>
<id>225462358</id>
<timestamp>2008-07-13T20:40:52Z</timestamp>
<contributor>
<username>Ibanix</username>
<id>1283376</id>
</contributor>
</revision>
<categories>
<category>Computational complexity theory</category>
</categories>
</header>
<bdy>

In <link xlink:type="simple" xlink:href="../543/7543.xml">
computational complexity theory</link>, the <b>Sipser-Lautemann theorem</b> or <b>Sipser-Gács-Lautemann theorem</b> states that <class wordnetid="107997703" confidence="0.8">
<collection wordnetid="107951464" confidence="0.8">
<group wordnetid="100031264" confidence="0.8">
<link xlink:type="simple" xlink:href="../079/4079.xml">
BPP</link></group>
</collection>
</class>
 (Bounded-error Probablistic Polynomial) time, is contained in the <link xlink:type="simple" xlink:href="../651/658651.xml">
polynomial time hierarchy</link>, and more specifically &amp;Sigma;2 &amp;cap; &amp;Pi;2.<p>

In 1983, <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<mathematician wordnetid="110301261" confidence="0.8">
<link xlink:type="simple" xlink:href="../015/3644015.xml">
Michael Sipser</link></mathematician>
</scientist>
</causal_agent>
</person>
</physical_entity>
 showed that <class wordnetid="107997703" confidence="0.8">
<collection wordnetid="107951464" confidence="0.8">
<group wordnetid="100031264" confidence="0.8">
<link xlink:type="simple" xlink:href="../079/4079.xml">
BPP</link></group>
</collection>
</class>
 is contained in the <link xlink:type="simple" xlink:href="../651/658651.xml">
polynomial time hierarchy</link>. <link>
Péter Gács</link> showed that BPP is actually contained in &amp;Sigma;2 &amp;cap; &amp;Pi;2. <link>
Clemens Lautemann</link> contributed by giving a simple proof of <class wordnetid="107997703" confidence="0.8">
<collection wordnetid="107951464" confidence="0.8">
<group wordnetid="100031264" confidence="0.8">
<link xlink:type="simple" xlink:href="../079/4079.xml">
BPP</link></group>
</collection>
</class>
’s membership in &amp;Sigma;2 &amp;cap; &amp;Pi;2 , also in 1983.</p>

<sec>
<st>
 Proof </st>

<p>

<physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<mathematician wordnetid="110301261" confidence="0.8">
<link xlink:type="simple" xlink:href="../015/3644015.xml">
Michael Sipser's</link></mathematician>
</scientist>
</causal_agent>
</person>
</physical_entity>
 version of the proof works as follows.  Without loss of generality, a machine <it>M</it> &amp;sube; <class wordnetid="107997703" confidence="0.8">
<collection wordnetid="107951464" confidence="0.8">
<group wordnetid="100031264" confidence="0.8">
<link xlink:type="simple" xlink:href="../079/4079.xml">
BPP</link></group>
</collection>
</class>
 with error &amp;le; 2-|<it>x</it>| can be chosen.  (All <class wordnetid="107997703" confidence="0.8">
<collection wordnetid="107951464" confidence="0.8">
<group wordnetid="100031264" confidence="0.8">
<link xlink:type="simple" xlink:href="../079/4079.xml">
BPP</link></group>
</collection>
</class>
 problems can be amplified to reduce the error probability exponentially.)  The basic idea of the proof is to define a &amp;Sigma;2 &amp;cap; &amp;Pi;2 sentence that is equivalent to stating that <it>x</it> is in the language, <it>L</it>, defined by <it>M</it> by using a set of transforms of the random variable inputs.</p>
<p>

Since the output of <it>M</it> depends on random input, as well as the input <it>x</it>, it is useful to define which random strings produce the correct output as <it>A(x)</it> = {<it>r</it> | <it>M</it>(<it>x</it>,<it>r</it>) accepts}.  The key to the proof is to note that when <it>x</it> &amp;isin; <it>L</it>, <it>A(x)</it> is very large and when <it>x</it> &amp;notin; <it>L</it>, <it>A(x)</it> is very small.  By using <link xlink:type="simple" xlink:href="../979/105979.xml">
bitwise parity</link>, &amp;oplus;, a set of transforms can be defined as <it>A(x)</it> &amp;oplus; <it>t</it>={<it>r</it> &amp;oplus; <it>t</it> | <it>r</it> &amp;isin; <it>A(x)</it>}.  The first main lemma of the proof shows that the union of a small finite number of these transforms will contain the entire space of random input strings.  Using this fact, a &amp;Sigma;2 sentence and a &amp;Pi;2 sentence can be generated that is true if and only if <it>x</it>&amp;isin;<it>L</it> (see corollary).</p>

<ss1>
<st>
 Lemma 1 </st>
<p>

The general idea of lemma one is to prove that if <it>A(x)</it> covers a large part of the random space <math>R= \{ 1,0 \} ^ {|r|} </math> then there exists a small set of translations that will cover the entire random space.  In more mathematical language:</p>
<p>

<it>If</it> <math>\frac{|A(x)|}{|R|} &amp;gt; 1 - \frac{1}{2^{|x|}}</math>, <it>then</it> <math>\exists  t_1,t_2,\ldots,t_{|r|}</math>, <it>where</it> <math>t_i \in \{ 1,0 \} ^{|r|} \ </math> <it>such that</it> <math> \cup_i A(x) \oplus t_i = R \ </math></p>
<p>

<b>Proof.</b> Randomly pick <it>t1,t2,...,t|r|</it>. Let <it>S</it>= &amp;cup;<it>i</it> <it>A(x)</it> &amp;oplus; <it>ti</it> (the union of all transforms of <it>A(x)</it>).</p>
<p>

So, <math>\forall r \in R</math>:
<indent level="1">

<math>\Pr [r \notin S] = \Pr [r \notin A(x) \oplus t_1] \cdot \Pr [r \notin A(x) \oplus t_2] \cdots \Pr [r \notin A(x) \oplus t_{|r|}] \le { \frac{1}{2^{|x| \cdot |r|}} } </math>
</indent>

The probability that there will exist at least one element in <it>R</it> not in <it>S</it> is:</p>
<p>

<indent level="1">

<math>\Pr [ \bigvee_i (r_i \notin S)] \le \sum_r \frac{1}{2^{|x| \cdot |r|}} = \frac{1}{2^{|x|}} &amp;lt; 1</math>
</indent>
</p>
<p>

Therefore </p>
<p>

<indent level="1">

<math>\Pr [S = R] \ge 1 - \frac{1}{2^{|x|}}</math>. 
</indent>

Thus there is a selection for each <math>t_1,t_2,\ldots,t_{|r|}</math> such that </p>
<p>

<indent level="1">

<math> \cup_i A(x) \oplus t_i = R \ </math>.
</indent>

</p>
</ss1>
<ss1>
<st>
 Lemma 2 </st>

<p>

The previous lemma shows that <it>A(x)</it> can cover every possible point in the space using a small set of translations.  Complementary to this, for <it>x</it> &amp;notin; <it>L</it> only a small fraction of the space is covered by <it>A(x)</it>.  Therefore the set of random strings causing M(x,r) to accept cannot be generated by a small set of vectors ti.</p>
<p>

<math>R = \cup_i A(x) \oplus t_i</math></p>
<p>

<it>R</it> is the set of all accepting random strings, exclusive-or'd with vectors ti.</p>
<p>

<math>\frac{|A(x)|}{|R|} \le  \frac{1}{2^{|k|}} \implies \neg \exists t_1,t_2,...,t_{r}</math></p>

</ss1>
<ss1>
<st>
 Corollary </st>

<p>

An important corollary of the lemmas shows that the result of the proof can be expressed as a &amp;Sigma;2 expression, as follows.</p>
<p>

<math>x \in L \iff \exists t_1,t_2,...,t_{|r|} \forall r \in R. \bigvee_{ 1 \le i \le |r|} (M(r \oplus t_i) accepts).</math></p>
<p>

That is, <it>x</it> is in language <it>L</it> if and only if there exist |<it>r</it>| binary vectors, where for all random bit vectors r, TM <it>M</it> accepts at least one random vector &amp;oplus; ti.</p>
<p>

The above expression is in <link xlink:type="simple" xlink:href="../651/658651.xml">
&amp;Sigma;2</link> in that it is first existentially then universally quantified.  Therefore BPP &amp;isin; &amp;Sigma;2.  Because <class wordnetid="107997703" confidence="0.8">
<collection wordnetid="107951464" confidence="0.8">
<group wordnetid="100031264" confidence="0.8">
<link xlink:type="simple" xlink:href="../079/4079.xml">
BPP</link></group>
</collection>
</class>
 is closed under <link xlink:type="simple" xlink:href="../955/1929955.xml">
complement</link>, this proves BPP &amp;isin; &amp;Sigma;2&amp;cap;&amp;Pi;2</p>

</ss1>
</sec>
<sec>
<st>
 Lautemann's Proof </st>

<p>

Here we present the proof (due to Lautemann) that BPP &amp;isin; &amp;Sigma;2.  See Trevisan's notes for more information.</p>

<ss1>
<st>
 Lemma 3 </st>

<p>

Based on the definition of BPP we define the following:</p>
<p>

If L is in <class wordnetid="107997703" confidence="0.8">
<collection wordnetid="107951464" confidence="0.8">
<group wordnetid="100031264" confidence="0.8">
<link xlink:type="simple" xlink:href="../079/4079.xml">
BPP</link></group>
</collection>
</class>
 then there is an algorithm A such that for every x, 
<math>Pr_r(A(x,r) = \mbox{right answer}) \ge 1 - \frac{1}{3m}</math></p>
<p>

where m is the number of random bits <math>|r| = m = |x|^{O(1)}</math> and A runs in time <math>|x|^{O(1)}</math></p>
<p>

<b>Proof:</b> Let A' be a <class wordnetid="107997703" confidence="0.8">
<collection wordnetid="107951464" confidence="0.8">
<group wordnetid="100031264" confidence="0.8">
<link xlink:type="simple" xlink:href="../079/4079.xml">
BPP</link></group>
</collection>
</class>
 algorithm for L.  For every x, <math>Pr_r(A'(x,r) = \mbox{wrong answer}) \le 1/3</math>.  A' uses m'(n) random bits where n = |x|.</p>
<p>

Do k(n) repetitions of A' and accept if and only if at least <math>\frac{k(n)}{2}</math> executions of A' accept.  Define this new algorithm as A.  So A uses k(n)m'(n) random bits and <math>Pr_r(A(x,r) = \mbox{wrong answer}) \le 2^{-ck(n)}</math>.  We can then find k(n) with k(n) = <math>\theta (log m'(n))</math> such that <math>\frac{1}{2^{ck(n)}} \le \frac{1}{3k(n)m'(n)}</math></p>

</ss1>
<ss1>
<st>
 Theorem 1 </st>

<p>

<b>Proof:</b> Let L be in <class wordnetid="107997703" confidence="0.8">
<collection wordnetid="107951464" confidence="0.8">
<group wordnetid="100031264" confidence="0.8">
<link xlink:type="simple" xlink:href="../079/4079.xml">
BPP</link></group>
</collection>
</class>
 and A as in Lemma 3.  We want to show
<math>x \in L \iff \exists y_1,...,y_m \in \{0,1\}^m \forall z \in \{0,1\}^m \bigvee_{i=1}^mA(x,y_i \oplus z)=1</math></p>
<p>

where m is the number of random bits used by A on input x.
Given <math>x \in L</math>, then
<math>Pr_{y_1,...,y_m}(\exists z A(x,y_1 \oplus z)=...=A(x,y_m \oplus z)=0)</math>
<math>\le \sum_{z \in \{0,1\}^m} Pr_{y1,...,y_m}(A(x,y_1 \oplus z) = ... = A( x, y_m \oplus z) = 0)</math>
<math>\le 2^m \frac{1}{(3m)^m}</math>
<math>&amp;lt; 1.</math></p>
<p>

So
<math>Pr_{y_1,...,y_m}( \forall z \bigvee_i A(x,y_i \oplus z))=1 - Pr_{y_1,...,y_m}(\exists z A(x,y_1 \oplus z)=...=A(x,y_m \oplus z)=0)</math>
So <math>(y_1,...,y_m)</math> exists.</p>
<p>

Conversely, suppose <math>x \notin L</math>. Then</p>
<p>

<math>Pr_z \left( \bigvee_i A(x,y_i \oplus z) \right) \le \sum_i Pr_z (A(x,y_i \oplus z)=1)</math>
<math>\le m \frac{1}{3m}</math>
<math>= \frac{1}{3}</math>.
So 
<math>Pr_z(A(x,y_1 \oplus z)=...=A(x,y_m \oplus z)=0)= 1 - Pr_z \left( \bigvee_i A(x,y_i \oplus z) \right)</math>
<math>\ge \frac{2}{3} &amp;gt; 0.</math>
So there is a z such that <math> \bigvee_i A(x,y_i \oplus z)=0</math> for all <math>y_1,...,y_m \in \{0,1\}^m.</math></p>

</ss1>
</sec>
<sec>
<st>
 References </st>
<p>

<list>
<entry level="1" type="bullet">

 M. Sipser. <it>A complexity theoretic approach to randomness</it> In Proceedings of the 15th ACM Symposium on Theory of Computing, 330--335. ACM Press, 1983</entry>
<entry level="1" type="bullet">

 C. Lautemann, <it>BPP and the polynomial hierarchy</it> Inf. Proc. Lett. 14 215-217, 1983</entry>
<entry level="1" type="bullet">

 Luca Trevisan's Lecture Notes, University of California, Berkeley, http://www.cs.berkeley.edu/~luca/notes/</entry>
</list>
</p>

</sec>
</bdy>
</article>
