<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 20:10:37[mciao0827] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Gibbs algorithm</title>
<id>3046323</id>
<revision>
<id>235252867</id>
<timestamp>2008-08-30T21:19:52Z</timestamp>
<contributor>
<username>Linas</username>
<id>159886</id>
</contributor>
</revision>
<categories>
<category>Particle statistics</category>
<category>Statistical mechanics</category>
<category>Articles with invalid date parameter in template</category>
<category>Accuracy disputes from March 2008</category>
<category>Entropy and information</category>
</categories>
</header>
<bdy>

<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-content" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="40x40px" src="Ambox_content.png">
</image>
</p>
</col>
<col style="" class="mbox-text">
 <b>The factual accuracy of this article is .</b></col>
</row>
</table>

<p>

In <link xlink:type="simple" xlink:href="../481/28481.xml">
statistical mechanics</link>, the <b>Gibbs algorithm</b>, first introduced by <link xlink:type="simple" xlink:href="../332/37332.xml">
J. Willard Gibbs</link> in <link xlink:type="simple" xlink:href="../938/34938.xml">
1878</link>, is the injunction to choose a <link xlink:type="simple" xlink:href="../052/59052.xml">
statistical ensemble</link> (probability distribution) for the unknown <link xlink:type="simple" xlink:href="../350/3066350.xml">
microscopic state</link> of a <link xlink:type="simple" xlink:href="../190/466190.xml">
thermodynamic system</link> by minimising the average log probability</p>
<p>

<indent level="1">

<math> H = \sum_i p_i \ln p_i \, </math>
</indent>

subject to the probability distribution satisfying a set of constraints (usually expectation values) corresponding to the known <link xlink:type="simple" xlink:href="../187/382187.xml">
macroscopic</link> quantities.  Physicists call the result of applying the Gibbs algorithm the <link xlink:type="simple" xlink:href="../914/3085914.xml">
Gibbs distribution</link> for the given constraints, most notably Gibbs's <link xlink:type="simple" xlink:href="../074/1129074.xml">
grand canonical ensemble</link> for open systems when the average energy and the average number of particles are given. (See also <it><link xlink:type="simple" xlink:href="../849/16846849.xml">
partition function</link></it>).</p>
<p>

In the light of <link xlink:type="simple" xlink:href="../693/5693.xml">
Claude Shannon</link>'s <link xlink:type="simple" xlink:href="../773/14773.xml">
information theory</link>,  in <link xlink:type="simple" xlink:href="../606/34606.xml">
1957</link> <link xlink:type="simple" xlink:href="../971/166971.xml">
E.T. Jaynes</link> re-interpreted the Gibbs algorithm as a much more general, more widely applicable inference technique, leading to the <link xlink:type="simple" xlink:href="../718/201718.xml">
principle of maximum entropy</link>, and the <link xlink:type="simple" xlink:href="../758/3015758.xml">
MaxEnt view of thermodynamics</link>.  </p>
<p>

This general result of the Gibbs algorithm is then a <link xlink:type="simple" xlink:href="../193/1813193.xml">
maximum entropy probability distribution</link>.  Statisticians identify such distributions as belonging to <link xlink:type="simple" xlink:href="../174/339174.xml">
exponential families</link>.</p>

<sec>
<st>
 Not to be confused with </st>

<p>

The <link xlink:type="simple" xlink:href="../709/509709.xml">
Gibbs sampler</link>, an update algorithm used in <know-how wordnetid="105616786" confidence="0.8">
<method wordnetid="105660268" confidence="0.8">
<link xlink:type="simple" xlink:href="../801/236801.xml">
Markov chain Monte Carlo</link></method>
</know-how>
 iterations, a special case of the <link xlink:type="simple" xlink:href="../107/56107.xml">
Metropolis-Hastings algorithm</link>.</p>


</sec>
</bdy>
</article>
