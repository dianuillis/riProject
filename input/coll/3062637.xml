<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 20:03:15[mciao0828] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Estimation of distribution algorithm</title>
<id>3062637</id>
<revision>
<id>242212856</id>
<timestamp>2008-10-01T10:19:30Z</timestamp>
<contributor>
<username>Coffee2theorems</username>
<id>1847344</id>
</contributor>
</revision>
<categories>
<category>All articles with unsourced statements</category>
<category>Wikipedia references cleanup</category>
<category>Wikipedia articles needing context</category>
<category> Evolutionary computation</category>
<category>Wikipedia introduction cleanup</category>
<category>Articles with unsourced statements since January 2008</category>
</categories>
</header>
<bdy>

<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-style" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="40x40px" src="Ambox_style.png">
</image>
</p>
</col>
<col style="" class="mbox-text">
 The introduction to this article provides <b>insufficient context</b> for those unfamiliar with the subject.
Please help <weblink xlink:type="simple" xlink:href="http://localhost:18088/wiki/index.php?title=Estimation_of_distribution_algorithm&amp;action=edit">
improve the article</weblink> with a .</col>
</row>
</table>

<p>

<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-content" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="40x40px" src="Ambox_content.png">
</image>
</p>
</col>
<col style="" class="mbox-text">
 <b>This article or section is missing  or needs .</b>
Using helps guard against copyright violations and factual inaccuracies. <it>(January 2008)''</it></col>
</row>
</table>

</p>

<p>

This article is about <link xlink:type="simple" xlink:href="../020/268020.xml">
evolutionary computation</link>.&#32;&#32;For methods on estimating <link xlink:type="simple" xlink:href="../543/23543.xml">
probability distribution</link>s, see <link xlink:type="simple" xlink:href="../671/554671.xml">
density estimation</link>.&#32;&#32;</p>
<p>

<b>Estimation of Distribution Algorithms</b> (EDA), sometimes called <b>Probabilistic Model-Building Genetic Algorithms</b> (PMBGA), are an outgrowth of <link xlink:type="simple" xlink:href="../254/40254.xml">
genetic algorithms</link>. In a genetic algorithm, a population of candidate solutions to a problem is maintained as part of the search for an optimum solution. This population is typically represented explicitly as an array of objects. Depending on the specifics of the GA, the objects might be bit strings, vectors of real numbers, <link xlink:type="simple" xlink:href="../016/18016.xml">
LISP</link> style S expressions or some custom representation. In an EDA, this explicit representation of the population is replaced with a probability distribution over the choices available at each position in the vector that represents a population member.</p>
<p>

For example, if the population is represented by bit strings of length 4, the EDA for the populations would be a single vector of four probablities (p1, p2, p3, p4) where each p is the probability of that position being a 1. Using this probability vector it is possible to create an arbitrary number of candidate solutions.</p>
<p>

In <link xlink:type="simple" xlink:href="../020/268020.xml">
evolutionary computation</link> new candidate solutions are often generated by combining and modifying existing solutions in a stochastic way. The underlying probability distribution of new solutions over the space of possible solutions is usually not explicitly specified. In EDAs a population may be approximated with a probability distribution and new candidate solutions can be obtained by sampling this distribution. This may have several advantages, including avoiding premature convergence and being a more compact representation.</p>
<p>

Better-known EDAs include the <link>
Compact Genetic Algorithm</link>, <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../122/12698122.xml">
Population-based incremental learning</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
, the <link>
Univariate Marginal Distribution Algorithm</link>, and the <link>
Estimation of Multivariate Normal Algorithm</link>.</p>
<p>

The model may be found to fit an existing population or take on the role of the population entirely.  Once the model is obtained, it can be sampled to produce more candidate solutions which are then used to adapt or regenerate the model. EDAs are typically classified according to the level of variable interaction that their probabilistic model includes - they can be classed as <link xlink:type="simple" xlink:href="../982/2398982.xml">
univariate</link> (no interactions), <link xlink:type="simple" xlink:href="../763/8285763.xml">
bivariate</link> (interactions between pairs of variables) or <link xlink:type="simple" xlink:href="../384/19384.xml">
multivariate</link> (interactions between more than two variables) (Pelikan, 1999).</p>

<sec>
<st>
References</st>

<p>

<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-style" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="40x40px" src="Ambox_style.png">
</image>
</p>
</col>
<col style="" class="mbox-text">
 The references used in this article may be clearer with a different or consistent style of <b>, , or </b>.</col>
</row>
</table>


<list>
<entry level="1" type="bullet">

Larrañga, Pedro; &amp; Lozano, Jose A. (Eds.). Estimation of distribution algorithms: A new tool for evolutionary computation. Kluwer Academic Publishers, Boston, 2002.</entry>
<entry level="1" type="bullet">

Lozano, J. A.; Larrañga, P.; Inza, I.; &amp; Bengoetxea, E. (Eds.). Towards a new evolutionary computation. Advances in estimation of distribution algorithms. Springer, 2006.</entry>
<entry level="1" type="bullet">

 <cite id="CITEREFPelikanGoldbergLobo1999" style="font-style:normal">Pelikan, Martin; Goldberg, David&#32;&amp;&#32;Lobo, Fernando&#32;(1999),&#32;<it>A Survey of Optimization by Building and Using Probabilistic Models</it>, Illinois: Illinois Genetic Algorithms Laboratory (IlliGAL), University of Illinois at Urbana-Champaign</cite>&nbsp;.</entry>
<entry level="1" type="bullet">

Pelikan, Martin. Hierarchical Bayesian optimization algorithm: Toward a new generation of evolutionary algorithms. Springer, 2005.</entry>
<entry level="1" type="bullet">

Pelikan, Martin; Sastry, Kumara; &amp; Cantu-Paz, Erick (Eds.). Scalable optimization via probabilistic modeling: From algorithms to applications. Springer, 2006.</entry>
</list>
</p>




</sec>
</bdy>
</article>
