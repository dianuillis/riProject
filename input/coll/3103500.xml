<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 20:08:15[mciao0825] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Deviance information criterion</title>
<id>3103500</id>
<revision>
<id>231109991</id>
<timestamp>2008-08-10T22:48:47Z</timestamp>
<contributor>
<username>SpBot</username>
<id>7016748</id>
</contributor>
</revision>
<categories>
<category>Statistical deviation and dispersion</category>
<category>Bayesian statistics</category>
</categories>
</header>
<bdy>

The <b>deviance information criterion</b> (<b>DIC</b>) is a hierarchical modeling generalization of the AIC (<link xlink:type="simple" xlink:href="../512/690512.xml">
Akaike information criterion</link>) and BIC (<link xlink:type="simple" xlink:href="../272/2473272.xml">
Bayesian information criterion</link>, also known as the Schwarz criterion). It is particularly useful in <link xlink:type="simple" xlink:href="../526/38526.xml">
Bayesian</link> <link xlink:type="simple" xlink:href="../073/3664073.xml">
model selection</link> problems where the <link xlink:type="simple" xlink:href="../672/357672.xml">
posterior distribution</link>s of the <link xlink:type="simple" xlink:href="../576/27576.xml">
model</link>s have been obtained by <know-how wordnetid="105616786" confidence="0.8">
<method wordnetid="105660268" confidence="0.8">
<link xlink:type="simple" xlink:href="../801/236801.xml">
Markov chain Monte Carlo</link></method>
</know-how>
 (MCMC) simulation. Like AIC and BIC it is an asymptotic approximation as the sample size becomes large. It is only valid when the posterior distribution is approximately <link xlink:type="simple" xlink:href="../347/50347.xml">
multivariate normal</link>.<p>

Define the <link xlink:type="simple" xlink:href="../609/432609.xml">
deviance</link> as <math>D(\theta)=-2 \log(p(y|\theta))+C\,</math>, where <math>y\,</math> are the data, <math>\theta\,</math> are the unknown parameters of the model and <math>p(y|\theta)\,</math> is the <link xlink:type="simple" xlink:href="../968/44968.xml">
likelihood function</link>. <math>C\,</math> is a constant that cancels out in all calculations that compare different models, and which therefore does not need to be known.</p>
<p>

The <link xlink:type="simple" xlink:href="../653/9653.xml">
expectation</link> <math>\bar{D}=\mathbf{E}^\theta[D(\theta)]</math> is a measure of how well the model fits the data; the larger this is, the worse the fit.</p>
<p>

The effective number of parameters of the model is computed as <math>p_D=\bar{D}-D(\bar{\theta})</math>, where <math>\bar{\theta}</math> is the expectation of <math>\theta\,</math>. The larger this is, the <it>easier</it> it is for the model to fit the data. </p>
<p>

The deviance information criterion is calculated as</p>
<p>

<indent level="1">

<math>\mathit{DIC} = p_D+\bar{D}.</math>
</indent>

The idea is that models with smaller DIC should be preferred to models with larger DIC. Models are penalized both by the value of <math>\bar{D}</math>, which favors a good fit, but also (in common with AIC and BIC) by the effective number of parameters <math>p_D\,</math>. Since <math>\bar{D}</math> will decrease as the number of parameters in a model increases, the <math>p_D\,</math> term compensates for this effect by favoring models with a smaller number of parameters.</p>
<p>

The advantage of DIC over other criteria, for Bayesian model selection, is that the DIC is easily calculated from the samples generated by a Markov chain Monte Carlo simulation. AIC and BIC require calculating the likelihood at its maximum over <math>\theta\,</math>, which is not readily available from the MCMC simulation. But to calculate DIC, simply compute <math>\bar{D}</math> as the average of <math>D(\theta)\,</math> over the samples of <math>\theta\,</math>, and <math>D(\bar{\theta})</math> as the value of <math>D\,</math> evaluated at the average of the samples of <math>\theta\,</math>. Then the DIC follows directly from these approximations.</p>

<sec>
<st>
See also</st>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../512/690512.xml">
Akaike information criterion</link></entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../272/2473272.xml">
Bayesian information criterion</link></entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../527/467527.xml">
Kullback-Leibler divergence</link></entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../573/4019573.xml">
Jensen-Shannon divergence</link></entry>
</list>
</p>

</sec>
<sec>
<st>
References</st>
<p>

<list>
<entry level="1" type="bullet">

 <cite id="Reference-Gelman-2004" style="font-style:normal" class="book">Gelman, Andrew;&#32;John B. Carlin, Hal. S. Stern, and Donald B. Rubin&#32;(2004). <weblink xlink:type="simple" xlink:href="http://books.google.com/books?id=TNYhnkXQSjAC">
Bayesian Data Analysis</weblink>, 2nd edition,&#32;<village wordnetid="108672738" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../745/44745.xml">
Boca Raton, Florida</link></village>
:&#32;Chapman &amp; Hall/CRC,&#32;pp. 182&ndash;184. ISBN 1-58488-388-X, <link xlink:type="simple" xlink:href="../327/18327.xml">
LCC</link> <weblink xlink:type="simple" xlink:href="http://catalog.loc.gov/cgi-bin/Pwebrecon.cgi?Search_Arg=QA279.5.B386+2004&amp;Search_Code=CALL_&amp;CNT=5">
QA279.5.B386&nbsp;2004</weblink>.</cite>&nbsp;</entry>
<entry level="1" type="bullet">

 <cite style="font-style:normal">Spiegelhalter, David J.; Nicola G. Best, Bradley P. Carlin, and Angelika van der Linde&#32;(October 2002).&#32;"Bayesian measures of model complexity and fit (with discussion)". <it><periodical wordnetid="106593296" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../143/13327143.xml">
Journal of the Royal Statistical Society</link></periodical>
, Series B (Statistical Methodology)</it>&#32;<b>64</b>&#32;(4): 583&ndash;639. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1111%2F1467-9868.00353">
10.1111/1467-9868.00353</weblink>.</cite>&nbsp;</entry>
</list>
</p>


</sec>
</bdy>
</article>
