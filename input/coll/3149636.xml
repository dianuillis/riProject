<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 20:12:40[mciao0826] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Pseudo-polynomial time</title>
<id>3149636</id>
<revision>
<id>212054218</id>
<timestamp>2008-05-13T06:40:58Z</timestamp>
<contributor>
<username>Sardanaphalus</username>
<id>427947</id>
</contributor>
</revision>
<categories>
<category>Computational complexity theory</category>
</categories>
</header>
<bdy>

In <link xlink:type="simple" xlink:href="../543/7543.xml">
computational complexity theory</link>, a numeric algorithm runs in <b>pseudo-polynomial time</b> if its <link>
running time</link> is <link xlink:type="simple" xlink:href="../000/23000.xml">
polynomial</link> in the <it>numeric value</it> of the input (which is exponential in the <it>length</it> of the input -- its number of digits).
<sec>
<st>
An Example</st>
<p>

Consider the problem of <link>
testing whether a number <it>n</it> is prime</link>, by naively checking whether no number in {2,3,..., <it>n</it>/2} divides <it>n</it> evenly.  This approach can take up to <it>n</it>/2-1 divisions, which is indeed linear in <it>n</it> but not in the <it>size of n</it>.  For example, the number <it>n</it> = 2,000,000,000 would require approximately 1 billion divisions, even though the length of <it>n</it> is only 10 digits. Moreover one can easily write down an input (say, a 300-digit number) for which this algorithm is impractical. Since computational complexity measures difficulty with respect to the <it>length</it> of the (encoded) input, this naive algorithm is actually exponential. It <it>is</it>, however, pseudo-polynomial time.</p>
<p>

Contrast this algorithm with a true polynomial numeric algorithm -- say, the straightforward algorithm for addition:  Adding two 9-digit numbers takes around 9 simple steps, and in general the algorithm is truly linear in the length of the input.  Compared with the actual numbers being added (in the billions), the algorithm could be called "pseudo-logarithmic time", though such a term is not standard.  Thus, adding 300-digit numbers is not impractical.  Similarly, long division is quadratic: an <it>m</it>-digit number can be divided by a <it>n</it>-digit number in <math>O(mn)</math> steps (see <link xlink:type="simple" xlink:href="../578/44578.xml">
Big O notation</link>.)</p>
<p>

In the case of primality, it turns out there is a different algorithm for <process wordnetid="105701363" confidence="0.8">
<institute wordnetid="108407330" confidence="0.8">
<inquiry wordnetid="105797597" confidence="0.8">
<thinking wordnetid="105770926" confidence="0.8">
<association wordnetid="108049401" confidence="0.8">
<problem_solving wordnetid="105796750" confidence="0.8">
<experiment wordnetid="105798043" confidence="0.8">
<trial wordnetid="105799212" confidence="0.8">
<higher_cognitive_process wordnetid="105770664" confidence="0.8">
<link xlink:type="simple" xlink:href="../847/405847.xml">
testing whether <it>n</it> is prime</link></higher_cognitive_process>
</trial>
</experiment>
</problem_solving>
</association>
</thinking>
</inquiry>
</institute>
</process>
 (discovered in 2002) which runs in time <math>O(\log^6{n})</math>.</p>

</sec>
<sec>
<st>
Ramifications</st>
<p>

If a problem is in <link xlink:type="simple" xlink:href="../550/658550.xml">
P</link>, then it perforce has a pseudo-polynomial time algorithm.  But <link xlink:type="simple" xlink:href="../466/39466.xml">
NP-Complete</link> problems may also have pseudo-polynomial time algorithms (for example, the <condition wordnetid="113920835" confidence="0.8">
<state wordnetid="100024720" confidence="0.8">
<problem wordnetid="114410605" confidence="0.8">
<difficulty wordnetid="114408086" confidence="0.8">
<link xlink:type="simple" xlink:href="../974/16974.xml">
Knapsack problem</link></difficulty>
</problem>
</state>
</condition>
).
Garey and Johnson write:
A pseudo-polynomial-time algorithm â€¦ will display 'exponential behavior' only when confronted with instances containing 'exponentially large' numbers, [which] might be rare for the application we are interested in. If so, this type of algorithm might serve our purposes almost as well as a polynomial time algorithm.
(where by "exponentially large numbers", they mean "numbers with many digits").
On the other hand, some NP-complete problems remain NP-complete even when their numeric parameters are polynomially bounded in their size. Such problems are called <class wordnetid="107997703" confidence="0.8">
<collection wordnetid="107951464" confidence="0.8">
<group wordnetid="100031264" confidence="0.8">
<link xlink:type="simple" xlink:href="../351/6319351.xml">
Strongly NP-complete</link></group>
</collection>
</class>
.</p>

</sec>
<sec>
<st>
Generalizing to non-numeric problems</st>
<p>

Although the notion of pseudo-polynomial time is used almost exclusively for numeric problems, the concept can be generalized:
The function <it>m</it> is pseudo-polynomial if
<it>m</it>(<it>n</it>) is no greater than a <link>
polynomial function</link> of the <link xlink:type="simple" xlink:href="../299/89299.xml">
problem size</link> <it>n</it> and an additional property of the input, <it>k</it>(<it>n</it>).  (Presumably, <it>k</it> is chosen to be something relevant to the problem.)
This makes numeric problems a special case by taking <it>k</it> to be the number of (binary) digits of the input.</p>
<p>

The distinction between the value of a number and its length is one of encoding: if numeric inputs are always encoded in <system wordnetid="104377057" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<link>
unary</link></instrumentality>
</artifact>
</system>
, then <it>pseudo-polynomial</it> would coincide with <it>polynomial</it>.</p>

</sec>
<sec>
<st>
References</st>
<p>

<list>
<entry level="1" type="bullet">

 M. R. Garey and D. S. Johnson. Computers and Intractability: A Guide to the Theory of NP-Completeness. W.H. Freeman and Company, 1979.</entry>
</list>


</p>

</sec>
</bdy>
</article>
