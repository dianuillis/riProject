<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 20:16:06[mciao0827] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<algorithm  confidence="0.9511911446218017" wordnetid="105847438">
<header>
<title>Frank–Wolfe algorithm</title>
<id>3152055</id>
<revision>
<id>235931011</id>
<timestamp>2008-09-03T00:37:59Z</timestamp>
<contributor>
<username>Thijs!bot</username>
<id>1392310</id>
</contributor>
</revision>
<categories>
<category>Optimization algorithms</category>
</categories>
</header>
<bdy>

The <b>Frank–Wolfe algorithm</b>, also known as the <it>convex combination algorithm</it>, is a classic algorithm in <link xlink:type="simple" xlink:href="../476/43476.xml">
operations research</link> (OR).  It was originally proposed by Marguerite Frank and Phil Wolfe in 1956 as a procedure for solving <link xlink:type="simple" xlink:href="../324/40324.xml">
quadratic programming</link> problems with linear constraints. At each  step the objective function is linearized and then a step is taken in a direction that reduces the objective while maintaining feasibility.  The algorithm can be seen as a generalization of the primal <link xlink:type="simple" xlink:href="../458/349458.xml">
simplex algorithm</link> for <link xlink:type="simple" xlink:href="../730/43730.xml">
linear programming</link>.  In recent years it has been widely used for determining the equilibrium flows in transportation networks.
<ss1>
<st>
Problem statement</st>
<p>

<indent level="1">

Minimize <math> f(\mathbf{x}) = \frac{1}{2} \mathbf{x}^{\mathrm{T}} E\mathbf{x} +  \mathbf{h}^{\mathrm{T}} \mathbf{x} </math>
</indent>
:subject to <math> \mathbf{x} \epsilon \mathbf{P}</math>.
Where the n×n matrix E is <link>
positive semidefinite</link>, h is an n×1 vector, and <math>\mathbf{P}</math> represents a feasible region defined by a mix of linear inequality and equality constraints (for example Ax ≤ b, Cx = d).</p>

</ss1>
<ss1>
<st>
Algorithm</st>

<p>

<b>Step 1.</b> Initialization. Let <math>k \leftarrow 0</math> and let <math>x_0 \!</math> be any point in <math>\mathbf{P}</math>.</p>
<p>

<b>Step 2.</b>  Convergence test.  If <math> \nabla f(x_k)=0</math> then Stop, we have found the minimum.</p>
<p>

<b>Step 3.</b>  Direction-finding subproblem. The approximation of the problem that is obtained by replacing the function f with its first-order <mathematical_relation wordnetid="113783581" confidence="0.8">
<function wordnetid="113783816" confidence="0.8">
<link xlink:type="simple" xlink:href="../448/30448.xml">
Taylor expansion</link></function>
</mathematical_relation>
 around <math>x_k \!</math> is found. Solve for <math>\bar{x}_k</math>:
<indent level="1">

Minimize <math>f(x_k) + \nabla^T f(x_k) \bar{x}_k</math>
</indent>
:Subject to <math>\bar{x}_k \epsilon \mathbf{P}</math>
<indent level="1">

(note that this is a Linear Program.  <math>x_k \!</math> is fixed during Step 3, while the minimization takes place by varying <math>\bar{x}_k</math> and is equivalent to minimization of <math>\nabla^T f(x_k) \bar{x}_k</math>).
</indent>

<b>Step 4.</b>  Step size determination. Find <math>\lambda \!</math> that minimizes <math> f(x_k+\lambda(\bar{x}_k-x_k))</math> subject to <math>0 \le \lambda \le 1</math> .  If <math>\lambda = 0 \!</math> then Stop, we have found the minimum.</p>
<p>

<b>Step 5.</b>  Update.  Let <math>x_{k+1}\leftarrow x_k+\lambda(\bar{x}_k-x_k)</math>, let <math>k \leftarrow k+1</math> and go back to Step 2.</p>

</ss1>
<ss1>
<st>
Comments</st>

<p>

The algorithm generally makes good progress towards the optimum during the first few iterations, but convergence often slows down substantially when close to the minimum point.  For this reason the algorithm is perhaps best used to find an approximate solution.  It can be shown that the worst case convergence rate is <link xlink:type="simple" xlink:href="../541/1750541.xml">
sublinear</link>; however, in practice the convergence rate has been observed to improve in case of many constraints.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref></p>

</ss1>
<sec>
<st>
References</st>

<p>

<list>
<entry level="1" type="bullet">

M. Frank and P. Wolfe, <it>An algorithm for quadratic programming</it>, Naval Research Logistics Quarterly, 3 (1956), pp. 95--110.</entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.math.chalmers.se/Math/Grundutb/CTH/tma946/0203/fw_eng.pdf">
The Frank-Wolfe algorithm</weblink> description</entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://swutc.tamu.edu/publications/technicalreports/472840-00074-1.pdf">
Combined Traffic Signal Control and Traffic Assignment: Algorithms, Implementation and Numerical Results</weblink>, Chungwon Lee and <link>
Randy B. Machemehl</link>, University of Texas at Austin, March 2005</entry>
</list>
</p>

</sec>
<sec>
<st>
 Notes </st>
<p>

<reflist>
<entry id="1">
"Nonlinear Programming", Dimitri Bertsekas, 2003, page 222.  Athena Scientific, ISBN 1-886529-00-0.</entry>
</reflist>
</p>


</sec>
</bdy>
</algorithm>
</article>
