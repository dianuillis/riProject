<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 20:21:44[mciao0827] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<kind  confidence="0.9511911446218017" wordnetid="105839024">
<algorithm  confidence="0.9508927676800064" wordnetid="105847438">
<header>
<title>Quicksort</title>
<id>3268249</id>
<revision>
<id>243122390</id>
<timestamp>2008-10-05T07:06:41Z</timestamp>
<contributor>
<username>Inge</username>
<id>149397</id>
</contributor>
</revision>
<categories>
<category>Articles with example pseudocode</category>
<category>Comparison sorts</category>
<category>Sorting algorithms</category>
</categories>
</header>
<bdy>
<template>
<name>Infobox Algorithm</name>
<parameters>

<image width="150px" src="Sorting_quicksort_anim.gif">
<caption>

Quicksort in action on a list of numbers. The horizontal lines are pivot values.
</caption>
</image>
Quicksort in action on a list of numbers. The horizontal lines are pivot values.<time>
<math>O(n\log n)</math> on average</time>
<data>
Varies</data>
<class>
<link xlink:type="simple" xlink:href="../442/28442.xml">
Sorting algorithm</link></class>
<optimal>
Sometimes</optimal>
<Stability>
[Sorting_algorithm#Classification|Not Stable]</Stability>
<space>
Varies by implementation</space>
</parameters>
</template>


"Q sort" redirects here. For the psychological research method, see <link xlink:type="simple" xlink:href="../449/5442449.xml">
Q methodology</link>.
<p>

<b>Quicksort</b> is a well-known <link xlink:type="simple" xlink:href="../442/28442.xml">
sorting algorithm</link> developed by <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../434/39434.xml">
C. A. R. Hoare</link></scientist>
</person>
 that, <link xlink:type="simple" xlink:href="../956/37956.xml">
on average</link>, makes <math>O(n\log n)</math> (<link xlink:type="simple" xlink:href="../578/44578.xml">
big O notation</link>) comparisons to sort <it>n</it> items. However, in the <link xlink:type="simple" xlink:href="../956/37956.xml">
worst case</link>, it makes <math>O(n^2)</math> comparisons. Typically, quicksort is significantly faster in practice than other <math>O(n \log n)</math> algorithms, because its inner loop can be efficiently implemented on most architectures, and in most real-world data it is possible to make design choices which minimize the probability of requiring quadratic time.</p>
<p>

Quicksort is a <link xlink:type="simple" xlink:href="../304/3189304.xml">
comparison sort</link> and, in efficient implementations, is not a <link xlink:type="simple" xlink:href="../442/28442.xml#xpointer(//*[./st=%22Classification%22])">
stable sort</link>.</p>

<sec>
<st>
 History </st>
<p>

The quicksort algorithm was developed by <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../434/39434.xml">
C. A. R. Hoare</link></scientist>
</person>
 in 1962 while working for the small British scientific computer manufacturer <company wordnetid="108058098" confidence="0.8">
<electronics_company wordnetid="108003035" confidence="0.8">
<institution wordnetid="108053576" confidence="0.8">
<link>
Elliott Brothers</link></institution>
</electronics_company>
</company>
.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref></p>

</sec>
<sec>
<st>
 Algorithm </st>

<p>

Quicksort sorts by employing a <link xlink:type="simple" xlink:href="../154/201154.xml">
divide and conquer</link> strategy to divide a <link xlink:type="simple" xlink:href="../382/208382.xml">
list</link> into two sub-lists.</p>
<p>

The steps are:
<list>
<entry level="1" type="number">

 Pick an element, called a <link xlink:type="simple" xlink:href="../503/9811503.xml">
<it>pivot''</it></link>, from the list.</entry>
<entry level="1" type="number">

 Reorder the list so that all elements which are less than the pivot come before the pivot and so that all elements greater than the pivot come after it (equal values can go either way). After this partitioning, the pivot is in its final position. This is called the <b>partition</b> operation.</entry>
<entry level="1" type="number">

 <parlance wordnetid="107081177" confidence="0.8">
<formulation wordnetid="107069948" confidence="0.8">
<expressive_style wordnetid="107066659" confidence="0.8">
<link xlink:type="simple" xlink:href="../867/4044867.xml">
Recursively</link></expressive_style>
</formulation>
</parlance>
 sort the sub-list of lesser elements and the sub-list of greater elements.  </entry>
</list>
</p>
<p>

The <link xlink:type="simple" xlink:href="../867/4044867.xml#xpointer(//*[./st=%22Recursive+programming%22])">
base case</link> of the recursion are lists of size zero or one, which are always sorted. </p>
<p>

In simple <link xlink:type="simple" xlink:href="../185/24185.xml">
pseudocode</link>, the algorithm might be expressed as this:</p>
<p>

<b>function</b> quicksort(array)
<b>var</b> <it>list</it> less, greater
<b>if</b> length(array) ≤ 1  
<b>return</b> array  
select and remove a pivot value <it>pivot</it> from array
<b>for each</b> x <b>in</b> array
<b>if</b> x ≤ pivot <b>then</b> append x to less
<b>else</b> append x to greater
<b>return</b> concatenate(quicksort(less), pivot, quicksort(greater))</p>
<p>

Notice that we only examine elements by comparing them to other elements. This makes quicksort a <link xlink:type="simple" xlink:href="../304/3189304.xml">
comparison sort</link>. This version is also a stable sort (considering that the "for each" method retrieves elements in original order, and the pivot selected is the last among those of equal value).</p>
<p>

The correctness of the partition algorithm is based on the following two arguments:
<list>
<entry level="1" type="bullet">

At each iteration, all the elements processed so far are in the desired position: before the pivot if less than or equal to the pivot's value, after the pivot otherwise (loop invariant).</entry>
<entry level="1" type="bullet">

Each iteration leaves one fewer element to be processed (loop variant).</entry>
</list>
</p>
<p>

The correctness of the overall algorithm follows from inductive reasoning: for zero or one element, the algorithm leaves the data unchanged; for a larger data set it produces the concatenation of two parts, elements less than or equal to the pivot and elements greater than it, themselves sorted by the recursive hypothesis.</p>
<p>

<image location="right" width="200px" src="Partition_example.svg" type="thumb">
<caption>

In-place partition in action on a small list. The boxed element is the pivot element, blue elements are less or equal, and red elements are larger.
</caption>
</image>

The disadvantage of the simple version above is that it requires <math>\Omega(n)</math> extra storage space, which is as bad as <link xlink:type="simple" xlink:href="../039/20039.xml">
mergesort</link>. The additional memory allocations required can also drastically impact speed and cache performance in practical implementations. There is a more complex version which uses an <link xlink:type="simple" xlink:href="../861/219861.xml">
in-place</link> partition algorithm and can achieve the complete sort using <math>O(n\log n)</math> space use on average (for the <link xlink:type="simple" xlink:href="../105/1718105.xml">
call stack</link>):</p>
<p>

<b>function</b> partition(array, left, right, pivotIndex)
pivotValue := array[pivotIndex]
swap array[pivotIndex] and array[right] <it>// Move pivot to end</it>
storeIndex := left
<b>for</b> i <b> from </b> left <b>to</b> right &amp;minus; 1
<b>if</b> array[i] &amp;le; pivotValue 
swap array[i] and array[storeIndex]
storeIndex := storeIndex + 1
swap array[storeIndex] and array[right] <it>// Move pivot to its final place</it>
<b>return</b> storeIndex</p>
<p>

This is the in-place partition algorithm. It partitions the portion of the array between indexes <it>left</it> and <it>right</it>, inclusively, by moving all elements less than or equal to a[pivotIndex] to the beginning of the subarray, leaving all the greater elements following them. In the process it also finds the final position for the pivot element, which it returns. It temporarily moves the pivot element to the end of the subarray, so that it doesn't get in the way. Because it only uses exchanges, the final list has the same elements as the original list. Notice that an element may be exchanged multiple times before reaching its final place.</p>
<p>

This form of the partition algorithm is not the original form; multiple variations can be found in various textbooks, such as versions not having the storeIndex. However, this form is probably the easiest to understand.</p>
<p>

Once we have this, writing quicksort itself is easy:</p>
<p>

<b>procedure</b> quicksort(array, left, right)
<b>if</b> right &amp;gt; left
select a pivot index (e.g. pivotIndex := left)
pivotNewIndex := partition(array, left, right, pivotIndex)
quicksort(array, left, pivotNewIndex - 1)
quicksort(array, pivotNewIndex + 1, right)</p>
<p>

However, since <it>partition</it> reorders elements within a partition, this version of quicksort is not a stable sort.</p>

<ss1>
<st>
 Parallelizations </st>

<p>

Like <link xlink:type="simple" xlink:href="../039/20039.xml">
mergesort</link>, quicksort can also be easily <link xlink:type="simple" xlink:href="../840/148840.xml">
parallelized</link> due to its divide-and-conquer nature. Individual in-place partition operations are difficult to parallelize, but once divided, different sections of the list can be sorted in parallel. If we have <math>p</math> processors, we can divide a list of <math>n</math> elements into <math>p</math> sublists in <math>\Theta(n)</math> average time, then sort each of these in <math>\Theta\left(\frac{n}{p} \log\frac{n}{p}\right)</math>
average time. Ignoring the <math>\Theta(n)</math> preprocessing, this is <link xlink:type="simple" xlink:href="../612/1448612.xml">
linear speedup</link>. Given <math>n</math> processors, only <math>\Theta(n)</math> time is required overall.</p>
<p>

One advantage of parallel quicksort over other parallel sort algorithms is that no synchronization is required. A new thread is started as soon as a sublist is available for it to work on and it does not communicate with other threads. When all threads complete, the sort is done.</p>
<p>

Other more sophisticated parallel sorting algorithms can achieve even better time bounds<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref>. For example, in 1991 David Powers described a parallelized quicksort that can operate in <math>O(\log n)</math> time given enough processors by performing partitioning implicitly<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%223%22])">3</ref>.</p>

</ss1>
</sec>
<sec>
<st>
 Formal analysis </st>

<p>

From the initial description it's not obvious that quicksort takes <math>\Theta(n \log n)</math> time on average. It's not hard to see that the partition operation, which simply loops over the elements of the array once, uses <math>\Theta(n)</math> time. In versions that perform concatenation, this operation is also <math>\Theta(n)</math>.</p>
<p>

In the best case, each time we perform a partition we divide the list into two nearly equal pieces. This means each recursive call processes a list of half the size. Consequently, we can make only <math>\log n</math> nested calls before we reach a list of size 1. This means that the depth of the <link xlink:type="simple" xlink:href="../105/1718105.xml">
call tree</link> is <math>\Theta(\log n)</math>. But no two calls at the same level of the call tree process the same part of the original list; thus, each level of calls needs only <math>\Theta(n)</math> time all together (each call has some constant overhead, but since there are only <math>\Theta(n)</math> calls at each level, this is subsumed in the <math>\Theta(n)</math> factor). The result is that the algorithm uses only <math>\Theta(n \log n)</math> time.</p>
<p>

An alternate approach is to set up a <link xlink:type="simple" xlink:href="../806/146806.xml">
recurrence relation</link> for the <math>T(n)</math> factor, the time needed to sort a list of size <math>n</math>. Because a single quicksort call involves <math>\Theta(n)</math> factor work plus two recursive calls on lists of size <math>n/2</math> in the best case, the relation would be:</p>
<p>

<indent level="1">

<math>T(n) = \Theta(n) + 2T\left(\frac{n}{2}\right).</math>
</indent>

The <link xlink:type="simple" xlink:href="../585/561585.xml">
master theorem</link> tells us that <math>T(n) = \Theta(n \log n)</math>.</p>
<p>

In fact, it's not necessary to divide the list this precisely; even if each pivot splits the elements with 99% on one side and 1% on the other (or any other fixed fraction), the call depth is still limited to <math>100 log n</math>, so the total running time is still <math>\Theta(n \log n)</math>.</p>
<p>

In the worst case, however, the two sublists have size 1 and <math>n-1</math> (for example, if the array consists of the same element by value), and the call tree becomes a linear chain of <math>n</math> nested calls. The <math>i</math>th call does <math>\Theta(n-i)</math> work, and <math>\sum_{i=0}^n (n-i) = \Theta(n^2)</math>. The recurrence relation is:</p>
<p>

<indent level="1">

<math>T(n) = \Theta(n) + T(1) + T(n-1) = O(n) + T(n-1)</math>
</indent>

This is the same relation as for <link xlink:type="simple" xlink:href="../205/15205.xml">
insertion sort</link> and <link xlink:type="simple" xlink:href="../352/29352.xml">
selection sort</link>, and it solves to <math>T(n) = \Theta(n^2)</math>.
Given knowledge of which comparisons are performed by the sort, there are adaptive algorithms that are effective at generating worst-case input for quicksort on-the-fly, regardless of the pivot selection strategy.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%224%22])">4</ref></p>

<ss1>
<st>
 Randomized quicksort expected complexity </st>

<p>

Randomized quicksort has the desirable property that it requires only <math>\Theta(n \log n)</math> <link xlink:type="simple" xlink:href="../653/9653.xml">
expected</link> time, regardless of the input. But what makes random pivots a good choice?</p>
<p>

Suppose we sort the list and then divide it into four parts. The two parts in the middle will contain the best pivots; each of them is larger than at least 25% of the elements and  smaller than at least 25% of the elements. If we could consistently choose an element from these two middle parts, we would only have to split the list at most <math>2 \log_2 n</math> times before reaching lists of size 1, yielding an <math>\Theta(n \log n)</math> algorithm.</p>
<p>

A random choice will only choose from these middle parts half the time. However, this is good enough. Imagine that you are flipping a coin over and over until you get <math>k</math> heads. Although this could take a long time, on average only <math>2k</math> flips are required, and the chance that you won't get <math>k</math> heads after <math>100k</math> flips is highly improbable. By the same argument, quicksort's recursion will terminate on average at a call depth of only <math>2(2\log_2 n)</math>. But if its average call depth is <math>\Theta(\log n)</math>, and each level of the call tree processes at most <math>n</math> elements, the total amount of work done on average is the product, <math>\Theta(n \log n)</math>. Note that the algorithm does not have to verify that the pivot is in the middle half - if we hit it any constant fraction of the times, that's enough for the desired complexity.</p>
<p>

The outline of a formal proof of the <math>O(n \log n)</math> expected time complexity follows. Assume that there are no duplicates as duplicates could be handled with linear time pre- and post-processing, or considered cases easier than the analyzed. Choosing a pivot, uniformly at random from <math>0</math> to <math>n-1</math>, is then equivalent to choosing the size of one particular partition, uniformly at random from <math>0</math> to <math>n-1</math>. With this observation, the continuation of the proof is analogous to the one given in the <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Average+complexity%22])">
 average complexity section</link>.</p>

</ss1>
<ss1>
<st>
 Average complexity </st>

<p>

Even if pivots aren't chosen randomly, quicksort still requires only <math>\Theta(n \log n)</math> time over all possible permutations of its input. Because this average is simply the sum of the times over all permutations of the input divided by <math>n</math> factorial, it's equivalent to choosing a random permutation of the input. When we do this, the pivot choices are essentially random, leading to an algorithm with the same running time as randomized quicksort.</p>
<p>

More precisely, the average number of comparisons over all permutations of the input sequence can be estimated accurately by solving the recurrence relation:</p>
<p>

<indent level="1">

<math>C(n) = n - 1 + \frac{1}{n} \sum_{i=0}^{n-1} (C(i)+C(n-i-1)) = 2n \ln n = 1.39n \log_2 n.</math> 
</indent>

Here, <math>n-1</math> is the number of comparisons the partition uses. Since the pivot is equally likely to fall anywhere in the sorted list order, the sum is averaging over all possible splits.</p>
<p>

This means that, on average, quicksort performs only about 39% worse than the ideal number of comparisons, which is its best case. In this sense it is closer to the best case than the worst case. This fast average runtime is another reason for quicksort's practical dominance over other sorting algorithms.</p>
<p>

<math>
\begin{align}
 C(n) &amp;= (n-1) + C \cdot \frac{n}{2} + C \cdot \frac{n}{2}\\
      &amp;= (n-1) + 2C \cdot \frac{n}{2}\\
      &amp;= (n-1) + 2\left(\frac{n}{2} - 1 + 2C \cdot \frac{n}{4} \right)\\
      &amp;= n + n + 4C \cdot \frac{n}{4} - 1 - 2\\
      &amp;= n + n + n + 8C \cdot \frac{n}{8} - 1 - 2 - 4\\
      &amp;= \cdots\\
      &amp;= kn + 2^kC \cdot \frac{n}{2^k} - (1 + 2 + 4 + \cdots + 2^{k-1}), \mbox{ where } \log_2 n &amp;gt; k &amp;gt; 0\\
      &amp;= kn + 2^kC \cdot \frac{n}{2^k} - 2^k + 1,
      \rightarrow n \log_2 n + nC(1) - n + 1.
\end{align}
</math></p>

</ss1>
<ss1>
<st>
 Space complexity </st>

<p>

The space used by quicksort depends on the version used.</p>
<p>

Quicksort has a space complexity of <math>\Theta(\log n)</math>, even in the worst case, when it is carefully implemented such that
<list>
<entry level="1" type="bullet">

 in-place partitioning is used. This requires <math>\Theta(1)</math>.</entry>
<entry level="1" type="bullet">

 After partitioning, the partition with the fewest elements is (recursively) sorted first, requiring at most <math>\Theta(\log n)</math> space. Then the other partition is sorted using tail-recursion or iteration. (This idea is commonly attributed to R.Sedgewick <weblink xlink:type="simple" xlink:href="http://www.cs.columbia.edu/~hgs/teaching/isp/hw/qsort.c"></weblink><weblink xlink:type="simple" xlink:href="http://www.ugrad.cs.ubc.ca/~cs260/chnotes/ch6/Ch6CovCompiled.html"></weblink><weblink xlink:type="simple" xlink:href="http://home.tiscalinet.ch/t_wolf/tw/ada95/sorting/index.html"></weblink>)</entry>
</list>
</p>

<p>

The version of quicksort with in-place partitioning uses only constant additional space before making any recursive call. However, if it has made <math>\Theta(\log n)</math> nested recursive calls, it needs to store a constant amount of information from each of them. Since the best case makes at most <math>\Theta(\log n)</math> nested recursive calls, it uses <math>\Theta(\log n)</math> space. The worst case makes <math>\Theta(n)</math> nested recursive calls, and so needs <math>\Theta(n)</math> space.</p>
<p>

We are eliding a small detail here, however. If we consider sorting arbitrarily large lists, we have to keep in mind that our variables like <it>left</it> and <it>right</it> can no longer be considered to occupy constant space; it takes <math>\Theta(\log n)</math> bits to index into a list of <math>n</math> items. Because we have variables like this in every stack frame, in reality quicksort requires <math>\Theta(\log^2n)</math> bits of space in the best and average case and <math>\Theta(n \log n)</math> space in the worst case. This isn't too terrible, though, since if the list contains mostly distinct elements, the list itself will also occupy <math>\Theta(n \log n)</math> bits of space.</p>
<p>

The not-in-place version of quicksort uses <math>\Theta(n)</math> space before it even makes any recursive calls. In the best case its space is still limited to <math>\Theta(n)</math>, because each level of the recursion uses half as much space as the last, and</p>
<p>

<indent level="1">

<math>\sum_{i=0}^{\infty} \frac{n}{2^i} = 2n.</math>
</indent>

Its worst case is dismal, requiring</p>
<p>

<indent level="1">

<math>\sum_{i=0}^n (n-i+1) = O(n^2)</math>
</indent>

space, far more than the list itself. If the list elements are not themselves constant size, the problem grows even larger; for example, if most of the list elements are distinct, each would require about <math>\Theta{O}(\log n)</math> bits, leading to a best-case <math>\Theta(n \log n)</math> and worst-case <math>\Theta(n^2 \log n)</math> space requirement.</p>

</ss1>
</sec>
<sec>
<st>
 Selection-based pivoting </st>
<p>

A <link xlink:type="simple" xlink:href="../786/552786.xml">
selection algorithm</link> chooses the <it>k</it>th smallest of a list of numbers; this is an easier problem in general than sorting. One simple but effective selection algorithm works nearly in the same manner as quicksort, except that instead of making recursive calls on both sublists, it only makes a single tail-recursive call on the sublist which contains the desired element. This small change lowers the average complexity to linear or <math>\Theta(n)</math> time, and makes it an <link xlink:type="simple" xlink:href="../861/219861.xml">
in-place algorithm</link>. A variation on this algorithm brings the worst-case time down to <math>\Theta(n)</math> (see <link xlink:type="simple" xlink:href="../786/552786.xml">
selection algorithm</link> for more information).</p>
<p>

Conversely, once we know a worst-case <math>\Theta(n)</math> selection algorithm is available, we can use it to find the ideal pivot (the median) at every step of quicksort, producing a variant with worst-case <math>\Theta(n \log n)</math> running time. In practical implementations, however, this variant is considerably slower on average.</p>
<p>

Another variant is to choose the Median of Medians as the pivot element instead of the median itself for partitioning the elements. While maintaining the asymptotically optimal run time complexity of <math>\Theta(n \log n)</math> (by preventing worst case partitions), it is also considerably faster than the variant that chooses the median as pivot.</p>
<p>

The C implementation of the above algorithm:</p>

<p>

//Quicksort the array
void quicksort(int* array, int left, int right)
{
if(left &amp;gt;= right)
return;</p>
<p>

int index = partition(array, left, right);
quicksort(array, left, index - 1);
quicksort(array, index + 1, right);
}</p>
<p>

//Partition the array into two halves and return the
//index about which the array is partitioned
int partition(int* array, int left, int right)
{
//Makes the leftmost element a good pivot,
//specifically the median of medians
findMedianOfMedians(array, left, right);
int pivotIndex = left, pivotValue = array[pivotIndex], index = left, i;</p>
<p>

swap(&amp;array[pivotIndex], &amp;array[right]);
for(i = left; i  right; i++)
{
if(array[i]  pivotValue)
{
swap(&amp;array[i], &amp;array[index]);
index += 1;
}
}
swap(&amp;array[right], &amp;array[index]);</p>
<p>

return index;
}</p>
<p>

//Computes the median of each group of 5 elements and stores
//it as the first element of the group. Recursively does this
//till there is only one group and hence only one Median
int findMedianOfMedians(int* array, int left, int right)
{
if(left == right)
return array[left];</p>
<p>

int i, shift = 1;
while(shift = (right - left))
{
for(i = left; i = right; i+=shift*5)
{
int endIndex = (i + shift*5 - 1  right) ? i + shift*5 - 1 : right;
int medianIndex = findMedianIndex(array, i, endIndex, shift);</p>
<p>

swap(&amp;array[i], &amp;array[medianIndex]);
}
shift *= 5;
}</p>
<p>

return array[left];
}</p>
<p>

//Find the index of the Median of the elements
//of array that occur at every "shift" positions.
int findMedianIndex(int* array, int left, int right, int shift)
{
int i, groups = (right - left)/shift + 1, k = left + groups/2*shift;
for(i = left; i = k; i+= shift)
{
int minIndex = i, minValue = array[minIndex], j;
for(j = i; j = right; j+=shift)
if(array[j]  minValue)
{
minIndex = j;
minValue = array[minIndex];
}
swap(&amp;array[i], &amp;array[minIndex]);
}</p>
<p>

return k;
}</p>
<p>

//Swap two integers
void swap(int* a, int* b)
{
int temp;
temp = *a;
<list>
<entry level="1" type="bullet">

a = *b;</entry>
<entry level="1" type="bullet">

b = temp;</entry>
</list>

}</p>


</sec>
<sec>
<st>
 Comparison with other sorting algorithms </st>
<p>

Quicksort is a space-optimized version of the <link xlink:type="simple" xlink:href="../027/6508027.xml">
binary tree sort</link>. Instead of inserting items sequentially into an explicit tree, quicksort organizes them concurrently into a tree that is implied by the recursive calls. The algorithms make exactly the same comparisons, but in a different order.</p>
<p>

The most direct competitor of quicksort is <link xlink:type="simple" xlink:href="../995/13995.xml">
heapsort</link>. Heapsort is typically somewhat slower than quicksort, but the worst-case running time is always <math>\Theta(n \log n)</math>. Quicksort is usually faster, though there remains the chance of worst case performance except in the <link xlink:type="simple" xlink:href="../477/363477.xml">
introsort</link> variant. If it's known in advance that heapsort is going to be necessary, using it directly will be faster than waiting for introsort to switch to it. Heapsort also has the important advantage of using only constant additional space (heapsort is in-place), whereas even the best variant of quicksort uses <math>\Theta(\log n)</math> space. However, heapsort requires efficient random access to be practical.</p>
<p>

Quicksort also competes with <link xlink:type="simple" xlink:href="../039/20039.xml">
mergesort</link>, another recursive sort algorithm but with the benefit of worst-case <math>\Theta(n \log n)</math> running time. Mergesort is a <link>
stable sort</link>, unlike quicksort and heapsort, and can be easily adapted to operate on <link xlink:type="simple" xlink:href="../167/18167.xml">
linked list</link>s and very large lists stored on slow-to-access media such as <link xlink:type="simple" xlink:href="../472/Species_8472.xml">
disk storage</link> or <link xlink:type="simple" xlink:href="../995/451995.xml">
network attached storage</link>. Although quicksort can be written to operate on linked lists, it will often suffer from poor pivot choices without random access. The main disadvantage of mergesort is that, when operating on arrays, it requires <math>\Theta(n)</math> auxiliary space in the best case, whereas the variant of quicksort with in-place partitioning and tail recursion uses only <math>\Theta(\log n)</math> space.  (Note that when operating on linked lists, mergesort only requires a small, constant amount of auxiliary storage.)</p>
<p>

<message wordnetid="106598915" confidence="0.8">
<information wordnetid="106634376" confidence="0.8">
<idea wordnetid="105833840" confidence="0.8">
<electronic_database wordnetid="106588511" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<category wordnetid="105838765" confidence="0.8">
<lexical_database wordnetid="106638868" confidence="0.8">
<wordnet wordnetid="106639428" confidence="0.8">
<kind wordnetid="105839024" confidence="0.8">
<database wordnetid="106637824" confidence="0.8">
<link xlink:type="simple" xlink:href="../592/97592.xml">
Bucket sort</link></database>
</kind>
</wordnet>
</lexical_database>
</category>
</concept>
</electronic_database>
</idea>
</information>
</message>
 with two buckets is very similar to quicksort; the pivot in this case is effectively the value in the middle of the value range, which does well on average for uniformly distributed inputs.</p>

</sec>
<sec>
<st>
Notes </st>
<p>

<reflist>
<entry id="1">
"<weblink xlink:type="simple" xlink:href="http://www.computerhistory.org/timeline/?year=1960">
Timeline of Computer History: 1960</weblink>".&#32;  Computer History Museum.</entry>
<entry id="2">
R.Miller, L.Boxer, Algorithms Sequential &amp; Parallel, A Unified Approach, Prentice Hall, NJ, 2006</entry>
<entry id="3">
David M. W. Powers, <weblink xlink:type="simple" xlink:href="http://citeseer.ist.psu.edu/327487.html">
Parallelized Quicksort with Optimal Speedup</weblink>, <it>Proceedings of International Conference on Parallel Computing Technologies</it>. <city wordnetid="108524735" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../065/63065.xml">
Novosibirsk</link></city>
. 1991.</entry>
<entry id="4">
M. D. McIlroy. A Killer Adversary for Quicksort. Software Practice and Experience: vol.29, no.4, 341&ndash;344. 1999. <weblink xlink:type="simple" xlink:href="http://citeseer.ist.psu.edu/212772.html">
At Citeseer</weblink></entry>
</reflist>
</p>

</sec>
<sec>
<st>
References</st>
<p>

<list>
<entry level="1" type="bullet">

Brian C. Dean, "A Simple Expected Running Time Analysis for Randomized 'Divide and Conquer' Algorithms." <it>Discrete Applied Mathematics</it> 154(1): 1-5.  2006. </entry>
<entry level="1" type="bullet">

Hoare, C. A. R. "Partition: Algorithm 63," "Quicksort: Algorithm 64," and "Find: Algorithm 65." <link xlink:type="simple" xlink:href="../161/291161.xml">
Comm. ACM</link> 4(7), 321-322, 1961</entry>
<entry level="1" type="bullet">

Hoare, C. A. R. <weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1093/comjnl/5.1.10">
"Quicksort."</weblink> Computer Journal 5 (1): 10-15. (1962). (Reprinted in Hoare and Jones: <weblink xlink:type="simple" xlink:href="http://portal.acm.org/citation.cfm?id=SERIES11430.63445">
<it>Essays in computing science''</it></weblink>, 1989.)</entry>
<entry level="1" type="bullet">

R. Sedgewick. Implementing quicksort programs, Comm. ACM, 21(10):847-857, 1978.</entry>
<entry level="1" type="bullet">

David Musser. Introspective Sorting and Selection Algorithms, Software Practice and Experience vol 27, number 8, pages 983-993, 1997</entry>
<entry level="1" type="bullet">

<person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../095/8095.xml">
Donald Knuth</link></scientist>
</person>
. <it>The Art of Computer Programming</it>, Volume 3: <it>Sorting and Searching</it>, Third Edition. Addison-Wesley, 1997. ISBN 0-201-89685-0. Pages 113&ndash;122 of section 5.2.2: Sorting by Exchanging.</entry>
<entry level="1" type="bullet">

 <scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../475/4108475.xml">
Thomas H. Cormen</link></scientist>
, <scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../884/1400884.xml">
Charles E. Leiserson</link></scientist>
, <link xlink:type="simple" xlink:href="../057/68057.xml">
Ronald L. Rivest</link>, and <scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../993/3489993.xml">
Clifford Stein</link></scientist>
. <it><work wordnetid="104599396" confidence="0.8">
<product wordnetid="104007894" confidence="0.8">
<creation wordnetid="103129123" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<book wordnetid="106410904" confidence="0.8">
<publication wordnetid="106589574" confidence="0.8">
<link xlink:type="simple" xlink:href="../226/3499226.xml">
Introduction to Algorithms</link></publication>
</book>
</artifact>
</creation>
</product>
</work>
</it>, Second Edition. <company wordnetid="108058098" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../601/719601.xml">
MIT Press</link></company>
 and <company wordnetid="108058098" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../269/651269.xml">
McGraw-Hill</link></company>
, 2001. ISBN 0-262-03293-7. Chapter 7: Quicksort, pp.145&ndash;164.</entry>
<entry level="1" type="bullet">

A. LaMarca and R. E. Ladner. "The Influence of Caches on the Performance of Sorting." Proceedings of the Eighth Annual ACM-SIAM Symposium on Discrete Algorithms, 1997. pp. 370-379.</entry>
<entry level="1" type="bullet">

<physical_entity wordnetid="100001930" confidence="0.8">
<peer wordnetid="109626238" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<colleague wordnetid="109935990" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<academician wordnetid="109759069" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<adult wordnetid="109605289" confidence="0.8">
<professional wordnetid="110480253" confidence="0.8">
<educator wordnetid="110045713" confidence="0.8">
<associate wordnetid="109816771" confidence="0.8">
<link xlink:type="simple" xlink:href="../726/7615726.xml">
Faron Moller</link></associate>
</educator>
</professional>
</adult>
</scientist>
</academician>
</causal_agent>
</colleague>
</person>
</peer>
</physical_entity>
. <weblink xlink:type="simple" xlink:href="http://www.cs.swan.ac.uk/~csfm/Courses/CS_332/quicksort.pdf">
Analysis of Quicksort</weblink>. CS 332: Designing Algorithms. Department of Computer Science, University of Wales Swansea.</entry>
<entry level="1" type="bullet">

 Steven Skiena. <weblink xlink:type="simple" xlink:href="http://www.cs.sunysb.edu/~algorith/lectures-good/node5.html">
Lecture 5 - quicksort</weblink>. CSE 373/548 - Analysis of Algorithms. Department of Computer Science. <link xlink:type="simple" xlink:href="../208/251208.xml">
State University of New York at Stony Brook</link>.</entry>
<entry level="1" type="bullet">

 Conrado Martínez and Salvador Roura, <it>Optimal sampling strategies in quicksort and quickselect.</it> SIAM J. Computing 31(3):683-705, 2001.</entry>
<entry level="1" type="bullet">

 Jon L. Bentley and M. Douglas McIlroy, <weblink xlink:type="simple" xlink:href="http://citeseer.ist.psu.edu/bentley93engineering.html">
Engineering a Sort Function</weblink>,  <it>Software&mdash;Practice and Experience</it>, Vol. 23(11), 1249&ndash;1265, 1993</entry>
</list>
</p>

</sec>
<sec>
<st>
 See also </st>
<p>

<list>
<entry level="1" type="bullet">

 <message wordnetid="106598915" confidence="0.8">
<information wordnetid="106634376" confidence="0.8">
<idea wordnetid="105833840" confidence="0.8">
<electronic_database wordnetid="106588511" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<category wordnetid="105838765" confidence="0.8">
<lexical_database wordnetid="106638868" confidence="0.8">
<wordnet wordnetid="106639428" confidence="0.8">
<kind wordnetid="105839024" confidence="0.8">
<database wordnetid="106637824" confidence="0.8">
<link xlink:type="simple" xlink:href="../477/363477.xml">
Introsort</link></database>
</kind>
</wordnet>
</lexical_database>
</category>
</concept>
</electronic_database>
</idea>
</information>
</message>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../464/14097464.xml">
Flashsort</link></entry>
</list>
</p>

</sec>
<sec>
<st>
External links</st>

<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://tide4javascript.com/?s=Quicksort">
Analyze Quicksort in an online Javascript IDE</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://thomasgilray.com/classes/quicksort.php">
Javascript Quicksort and Bubblesort</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.atkinson.yorku.ca/~sychen/research/sorting/sortingHome.html">
Quicksort applet</weblink> with "level-order" recursive calls to help improve algorithm analysis</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.wanginator.de/studium/applets/quicksort_en.html">
Quicksort Java Applet</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://fiehnlab.ucdavis.edu/staff/wohlgemuth/java/quicksort">
Multidimensional quicksort in Java</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://en.literateprograms.org/Category:Quicksort">
Literate implementations of Quicksort in various languages</weblink> on LiteratePrograms</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.mycsresource.net/articles/programming/sorting_algos/quicksort/">
Quicksort tutorial with illustrated examples</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://vision.bc.edu/~dmartin/teaching/sorting/anim-html/quick.html">
A graphical demonstration and discussion of 2-way partition quick sort</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://vision.bc.edu/~dmartin/teaching/sorting/anim-html/quick3.html">
A graphical demonstration and discussion of 3-way partition quick sort</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://coderaptors.com/?QuickSort">
A colored graphical Java applet</weblink> which allows experimentation with initial state and shows statistics</entry>
</list>
</p>

<p>

<table style=";" class="navbox" cellspacing="0">
<row>
<col style="padding:2px;">
<table style="width:100%;background:transparent;color:inherit;;" class="nowraplinks collapsible autocollapse " cellspacing="0">
<row>
<header colspan="3" style=";" class="navbox-title">
<link xlink:type="simple" xlink:href="../442/28442.xml">
Sorting algorithm</link>s</header>
</row>
<row style="height:2px;">

</row>
<row>
<col style=";;" class="navbox-group">
Theory</col>
<col style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<link xlink:type="simple" xlink:href="../543/7543.xml">
Computational complexity theory</link> | <link xlink:type="simple" xlink:href="../578/44578.xml">
Big O notation</link> | <link xlink:type="simple" xlink:href="../330/30330.xml">
Total order</link> | <link xlink:type="simple" xlink:href="../382/208382.xml">
Lists</link> | <link xlink:type="simple" xlink:href="../442/28442.xml#xpointer(//*[./st=%22Stability%22])">
Stability</link> | <message wordnetid="106598915" confidence="0.8">
<information wordnetid="106634376" confidence="0.8">
<electronic_database wordnetid="106588511" confidence="0.8">
<lexical_database wordnetid="106638868" confidence="0.8">
<wordnet wordnetid="106639428" confidence="0.8">
<database wordnetid="106637824" confidence="0.8">
<link xlink:type="simple" xlink:href="../304/3189304.xml">
Comparison sort</link></database>
</wordnet>
</lexical_database>
</electronic_database>
</information>
</message>
</col>
<col style="width:0%;padding:0px 0px 0px 2px;" rowspan="15">
<image width="200px" src="SimpleSortingNetwork.svg">
</image>
</col>
</row>
<row style="height:2px">

</row>
<row>
<col style=";;" class="navbox-group">
Exchange sorts</col>
<col style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<algorithm wordnetid="105847438" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../255/4255.xml">
Bubble sort</link></algorithm>
 | <algorithm wordnetid="105847438" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../482/159482.xml">
Cocktail sort</link></algorithm>
 | <message wordnetid="106598915" confidence="0.8">
<information wordnetid="106634376" confidence="0.8">
<idea wordnetid="105833840" confidence="0.8">
<electronic_database wordnetid="106588511" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<category wordnetid="105838765" confidence="0.8">
<lexical_database wordnetid="106638868" confidence="0.8">
<wordnet wordnetid="106639428" confidence="0.8">
<kind wordnetid="105839024" confidence="0.8">
<database wordnetid="106637824" confidence="0.8">
<link xlink:type="simple" xlink:href="../945/10807945.xml">
Odd-even sort</link></database>
</kind>
</wordnet>
</lexical_database>
</category>
</concept>
</electronic_database>
</idea>
</information>
</message>
 | <message wordnetid="106598915" confidence="0.8">
<information wordnetid="106634376" confidence="0.8">
<idea wordnetid="105833840" confidence="0.8">
<electronic_database wordnetid="106588511" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<category wordnetid="105838765" confidence="0.8">
<lexical_database wordnetid="106638868" confidence="0.8">
<wordnet wordnetid="106639428" confidence="0.8">
<kind wordnetid="105839024" confidence="0.8">
<database wordnetid="106637824" confidence="0.8">
<link xlink:type="simple" xlink:href="../439/159439.xml">
Comb sort</link></database>
</kind>
</wordnet>
</lexical_database>
</category>
</concept>
</electronic_database>
</idea>
</information>
</message>
 | <message wordnetid="106598915" confidence="0.8">
<information wordnetid="106634376" confidence="0.8">
<idea wordnetid="105833840" confidence="0.8">
<electronic_database wordnetid="106588511" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<category wordnetid="105838765" confidence="0.8">
<lexical_database wordnetid="106638868" confidence="0.8">
<wordnet wordnetid="106639428" confidence="0.8">
<kind wordnetid="105839024" confidence="0.8">
<database wordnetid="106637824" confidence="0.8">
<link xlink:type="simple" xlink:href="../127/522127.xml">
Gnome sort</link></database>
</kind>
</wordnet>
</lexical_database>
</category>
</concept>
</electronic_database>
</idea>
</information>
</message>
 | <algorithm wordnetid="105847438" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../249/3268249.xml">
Quicksort</link></algorithm>
</col>
</row>
<row style="height:2px">

</row>
<row>
<col style=";;" class="navbox-group">
Selection sorts</col>
<col style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<algorithm wordnetid="105847438" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../352/29352.xml">
Selection sort</link></algorithm>
 | <algorithm wordnetid="105847438" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../995/13995.xml">
Heapsort</link></algorithm>
 | <link xlink:type="simple" xlink:href="../450/100450.xml">
Smoothsort</link></col>
</row>
<row style="height:2px">

</row>
<row>
<col style=";;" class="navbox-group">
Insertion sorts</col>
<col style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<algorithm wordnetid="105847438" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../205/15205.xml">
Insertion sort</link></algorithm>
 | <message wordnetid="106598915" confidence="0.8">
<information wordnetid="106634376" confidence="0.8">
<idea wordnetid="105833840" confidence="0.8">
<electronic_database wordnetid="106588511" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<category wordnetid="105838765" confidence="0.8">
<lexical_database wordnetid="106638868" confidence="0.8">
<wordnet wordnetid="106639428" confidence="0.8">
<kind wordnetid="105839024" confidence="0.8">
<database wordnetid="106637824" confidence="0.8">
<link xlink:type="simple" xlink:href="../355/77355.xml">
Shell sort</link></database>
</kind>
</wordnet>
</lexical_database>
</category>
</concept>
</electronic_database>
</idea>
</information>
</message>
 | <message wordnetid="106598915" confidence="0.8">
<information wordnetid="106634376" confidence="0.8">
<electronic_database wordnetid="106588511" confidence="0.8">
<lexical_database wordnetid="106638868" confidence="0.8">
<wordnet wordnetid="106639428" confidence="0.8">
<database wordnetid="106637824" confidence="0.8">
<link xlink:type="simple" xlink:href="../027/6508027.xml">
Tree sort</link></database>
</wordnet>
</lexical_database>
</electronic_database>
</information>
</message>
 | <message wordnetid="106598915" confidence="0.8">
<information wordnetid="106634376" confidence="0.8">
<idea wordnetid="105833840" confidence="0.8">
<electronic_database wordnetid="106588511" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<category wordnetid="105838765" confidence="0.8">
<lexical_database wordnetid="106638868" confidence="0.8">
<wordnet wordnetid="106639428" confidence="0.8">
<kind wordnetid="105839024" confidence="0.8">
<database wordnetid="106637824" confidence="0.8">
<link xlink:type="simple" xlink:href="../633/2448633.xml">
Library sort</link></database>
</kind>
</wordnet>
</lexical_database>
</category>
</concept>
</electronic_database>
</idea>
</information>
</message>
 | <idea wordnetid="105833840" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<category wordnetid="105838765" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<social_event wordnetid="107288639" confidence="0.8">
<contest wordnetid="107456188" confidence="0.8">
<game wordnetid="100456199" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<kind wordnetid="105839024" confidence="0.8">
<link xlink:type="simple" xlink:href="../256/1184256.xml">
Patience sorting</link></kind>
</psychological_feature>
</game>
</contest>
</social_event>
</event>
</category>
</concept>
</idea>
</col>
</row>
<row style="height:2px">

</row>
<row>
<col style=";;" class="navbox-group">
Merge sorts</col>
<col style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<algorithm wordnetid="105847438" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../039/20039.xml">
Merge sort</link></algorithm>
 | <message wordnetid="106598915" confidence="0.8">
<information wordnetid="106634376" confidence="0.8">
<idea wordnetid="105833840" confidence="0.8">
<electronic_database wordnetid="106588511" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<category wordnetid="105838765" confidence="0.8">
<lexical_database wordnetid="106638868" confidence="0.8">
<wordnet wordnetid="106639428" confidence="0.8">
<kind wordnetid="105839024" confidence="0.8">
<database wordnetid="106637824" confidence="0.8">
<link xlink:type="simple" xlink:href="../351/14083351.xml">
Strand sort</link></database>
</kind>
</wordnet>
</lexical_database>
</category>
</concept>
</electronic_database>
</idea>
</information>
</message>
</col>
</row>
<row style="height:2px">

</row>
<row>
<col style=";;" class="navbox-group">
Non-comparison sorts</col>
<col style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<message wordnetid="106598915" confidence="0.8">
<information wordnetid="106634376" confidence="0.8">
<idea wordnetid="105833840" confidence="0.8">
<electronic_database wordnetid="106588511" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<category wordnetid="105838765" confidence="0.8">
<lexical_database wordnetid="106638868" confidence="0.8">
<wordnet wordnetid="106639428" confidence="0.8">
<kind wordnetid="105839024" confidence="0.8">
<database wordnetid="106637824" confidence="0.8">
<link xlink:type="simple" xlink:href="../980/25980.xml">
Radix sort</link></database>
</kind>
</wordnet>
</lexical_database>
</category>
</concept>
</electronic_database>
</idea>
</information>
</message>
 | <message wordnetid="106598915" confidence="0.8">
<information wordnetid="106634376" confidence="0.8">
<idea wordnetid="105833840" confidence="0.8">
<electronic_database wordnetid="106588511" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<category wordnetid="105838765" confidence="0.8">
<lexical_database wordnetid="106638868" confidence="0.8">
<wordnet wordnetid="106639428" confidence="0.8">
<kind wordnetid="105839024" confidence="0.8">
<database wordnetid="106637824" confidence="0.8">
<link xlink:type="simple" xlink:href="../592/97592.xml">
Bucket sort</link></database>
</kind>
</wordnet>
</lexical_database>
</category>
</concept>
</electronic_database>
</idea>
</information>
</message>
 | <message wordnetid="106598915" confidence="0.8">
<information wordnetid="106634376" confidence="0.8">
<idea wordnetid="105833840" confidence="0.8">
<electronic_database wordnetid="106588511" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<category wordnetid="105838765" confidence="0.8">
<lexical_database wordnetid="106638868" confidence="0.8">
<wordnet wordnetid="106639428" confidence="0.8">
<kind wordnetid="105839024" confidence="0.8">
<database wordnetid="106637824" confidence="0.8">
<link xlink:type="simple" xlink:href="../864/99864.xml">
Counting sort</link></database>
</kind>
</wordnet>
</lexical_database>
</category>
</concept>
</electronic_database>
</idea>
</information>
</message>
 | <message wordnetid="106598915" confidence="0.8">
<information wordnetid="106634376" confidence="0.8">
<idea wordnetid="105833840" confidence="0.8">
<electronic_database wordnetid="106588511" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<category wordnetid="105838765" confidence="0.8">
<lexical_database wordnetid="106638868" confidence="0.8">
<wordnet wordnetid="106639428" confidence="0.8">
<kind wordnetid="105839024" confidence="0.8">
<database wordnetid="106637824" confidence="0.8">
<link xlink:type="simple" xlink:href="../681/24681.xml">
Pigeonhole sort</link></database>
</kind>
</wordnet>
</lexical_database>
</category>
</concept>
</electronic_database>
</idea>
</information>
</message>
 | <message wordnetid="106598915" confidence="0.8">
<information wordnetid="106634376" confidence="0.8">
<electronic_database wordnetid="106588511" confidence="0.8">
<lexical_database wordnetid="106638868" confidence="0.8">
<wordnet wordnetid="106639428" confidence="0.8">
<database wordnetid="106637824" confidence="0.8">
<link xlink:type="simple" xlink:href="../302/11517302.xml">
Burstsort</link></database>
</wordnet>
</lexical_database>
</electronic_database>
</information>
</message>
</col>
</row>
<row style="height:2px">

</row>
<row>
<col style=";;" class="navbox-group">
Others</col>
<col style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<information wordnetid="106634376" confidence="0.8">
<electronic_database wordnetid="106588511" confidence="0.8">
<lexical_database wordnetid="106638868" confidence="0.8">
<database wordnetid="106637824" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<message wordnetid="106598915" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<wordnet wordnetid="106639428" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<link xlink:type="simple" xlink:href="../064/897064.xml">
Topological sorting</link></procedure>
</activity>
</psychological_feature>
</wordnet>
</act>
</rule>
</event>
</message>
</algorithm>
</database>
</lexical_database>
</electronic_database>
</information>
 | <message wordnetid="106598915" confidence="0.8">
<information wordnetid="106634376" confidence="0.8">
<electronic_database wordnetid="106588511" confidence="0.8">
<lexical_database wordnetid="106638868" confidence="0.8">
<wordnet wordnetid="106639428" confidence="0.8">
<database wordnetid="106637824" confidence="0.8">
<link xlink:type="simple" xlink:href="../061/562061.xml">
Sorting network</link></database>
</wordnet>
</lexical_database>
</electronic_database>
</information>
</message>
 | <message wordnetid="106598915" confidence="0.8">
<information wordnetid="106634376" confidence="0.8">
<electronic_database wordnetid="106588511" confidence="0.8">
<lexical_database wordnetid="106638868" confidence="0.8">
<wordnet wordnetid="106639428" confidence="0.8">
<database wordnetid="106637824" confidence="0.8">
<link xlink:type="simple" xlink:href="../090/2713090.xml">
Bitonic sorter</link></database>
</wordnet>
</lexical_database>
</electronic_database>
</information>
</message>
</col>
</row>
<row style="height:2px">

</row>
<row>
<col style=";;" class="navbox-group">
Ineffective/jokeful sorts</col>
<col style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<algorithm wordnetid="105847438" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../870/99870.xml">
Bogosort</link></algorithm>
 | <message wordnetid="106598915" confidence="0.8">
<information wordnetid="106634376" confidence="0.8">
<idea wordnetid="105833840" confidence="0.8">
<electronic_database wordnetid="106588511" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<category wordnetid="105838765" confidence="0.8">
<lexical_database wordnetid="106638868" confidence="0.8">
<wordnet wordnetid="106639428" confidence="0.8">
<kind wordnetid="105839024" confidence="0.8">
<database wordnetid="106637824" confidence="0.8">
<link xlink:type="simple" xlink:href="../662/563662.xml">
Stooge sort</link></database>
</kind>
</wordnet>
</lexical_database>
</category>
</concept>
</electronic_database>
</idea>
</information>
</message>
</col>
</row>
</table>
</col>
</row>
</table>
</p>


</sec>
</bdy>
</algorithm>
</kind>
</article>
