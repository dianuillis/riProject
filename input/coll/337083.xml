<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 16:52:07[mciao0828] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<event  confidence="0.8" wordnetid="100029378">
<rule  confidence="0.8" wordnetid="105846932">
<act  confidence="0.8" wordnetid="100030358">
<psychological_feature  confidence="0.8" wordnetid="100023100">
<procedure  confidence="0.8" wordnetid="101023820">
<activity  confidence="0.8" wordnetid="100407535">
<algorithm  confidence="0.8" wordnetid="105847438">
<header>
<title>Particle swarm optimization</title>
<id>337083</id>
<revision>
<id>237500397</id>
<timestamp>2008-09-10T14:11:40Z</timestamp>
<contributor>
<username>Allstar86</username>
<id>49760</id>
</contributor>
</revision>
<categories>
<category>Evolutionary algorithms</category>
<category>Optimization algorithms</category>
<category>Articles with example pseudocode</category>
</categories>
</header>
<bdy>

<b>Particle swarm optimization (PSO)</b> is a <link xlink:type="simple" xlink:href="../988/762988.xml">
swarm intelligence</link> based <link xlink:type="simple" xlink:href="../775/775.xml">
algorithm</link> to find a solution to an optimization problem in a <link xlink:type="simple" xlink:href="../707/389707.xml">
search space</link>, or model and predict social behavior in the presence of objectives.
<sec>
<st>
Overview</st>
<p>

Particle swarm optimization is a <link xlink:type="simple" xlink:href="../222/292222.xml">
stochastic</link>, population-based evolutionary computer algorithm for problem solving. It is a kind of <link xlink:type="simple" xlink:href="../988/762988.xml">
swarm intelligence</link> that is based on <link xlink:type="simple" xlink:href="../990/26990.xml">
social-psychological</link> principles and provides insights into <link xlink:type="simple" xlink:href="../733/1967733.xml">
social behavior</link>, as well as contributing to engineering applications.  The particle swarm optimization algorithm was first described in 1995 by <physical_entity wordnetid="100001930" confidence="0.8">
<communicator wordnetid="109610660" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<writer wordnetid="110794014" confidence="0.8">
<psychologist wordnetid="110488865" confidence="0.8">
<link xlink:type="simple" xlink:href="../912/11558912.xml">
James Kennedy</link></psychologist>
</writer>
</scientist>
</causal_agent>
</person>
</communicator>
</physical_entity>
 and <link xlink:type="simple" xlink:href="../284/19241284.xml">
Russell C. Eberhart</link>.  The techniques have evolved greatly since then, and the original version of the algorithm is barely recognizable in the current ones.</p>
<p>

<link xlink:type="simple" xlink:href="../500/509500.xml">
Social influence</link> and <link xlink:type="simple" xlink:href="../176/330176.xml">
social learning</link> enable a person to maintain <link xlink:type="simple" xlink:href="../305/169305.xml">
cognitive consistency</link>.  People solve problems by talking with other people about them, and as they interact their beliefs, attitudes, and behaviors change; the changes could typically be depicted as the individuals moving toward one another in a sociocognitive space.</p>
<p>

The particle swarm simulates this kind of social optimization.  A problem is given, and some way to evaluate a proposed solution to it exists in the form of a <link xlink:type="simple" xlink:href="../285/412285.xml">
fitness function</link>. A communication structure or <link xlink:type="simple" xlink:href="../726/325726.xml">
social network</link> is also defined, assigning neighbors for each individual to interact with.  Then a population of individuals defined as random guesses at the problem solutions is initialized. These individuals are candidate solutions. They are also known as the particles, hence the name particle swarm. An iterative process to improve these candidate solutions is set in motion.  The particles iteratively evaluate the fitness of the candidate solutions and remember the location where they had their best success. The individual's best solution is called the particle best or the local best. Each particle makes this information available to their neighbors. They are also able to see where their neighbors have had success.  Movements through the search space are guided by these successes, with the population usually converging, by the end of a trial, on a problem solution better than that of non-swarm approach using the same methods.</p>
<p>

The swarm is typically <link xlink:type="simple" xlink:href="../590/20590.xml">
modelled</link> by particles in <link xlink:type="simple" xlink:href="../697/9697.xml">
multidimensional space</link> that have a position and a <link xlink:type="simple" xlink:href="../357/32357.xml">
velocity</link>. These particles fly through hyperspace (i.e., <math>\mathbb{R}^n</math>) and have two essential reasoning capabilities: their memory of their own best position and knowledge of the global or their neighborhood's best. In a minimization optimization problem, "best" simply meaning the position with the smallest objective value. Members of a swarm communicate good positions to each other and adjust their own position and velocity based on these good positions. So a particle has the following information to make a suitable change in its position and velocity:
<list>
<entry level="1" type="bullet">

 A global best that is known to all and immediately updated when a new best position is found by any particle in the swarm.</entry>
<entry level="1" type="bullet">

 Neighborhood best that the particle obtains by communicating with a subset of the swarm.</entry>
<entry level="1" type="bullet">

 The local best, which is the best solution that the particle has seen. </entry>
</list>
</p>
<p>

The particle position and velocity update equations in the simplest form that govern the PSO are given by
<list>
<entry level="1" type="bullet">

 <math> v_{i,j} \leftarrow c_0 v_{i} + c_1 r_1 ( global best_j - x_{i,j} ) + c_2 r_2 ( local best_{i,j} - x_{i,j} ) + c_3 r_3 ( neighborhood best_j - x_{i,j} )</math></entry>
<entry level="1" type="bullet">

 <math> x_{i,j} \leftarrow x_{i,j} + v_{i,j}</math></entry>
</list>
</p>
<p>

As the swarm iterates, the fitness of the global best solution improves (decreases for minimization problem). It could happen that all particles being influenced by the global best eventually approach the global best, and there on the fitness never improves despite however many runs the PSO is iterated thereafter. The particles also move about in the search space in close proximity to the global best and not exploring the rest of search space. This phenomenon is called 'convergence'. If the inertial coefficient of the velocity is small, all particles could slow down until they approach zero velocity at the global best. The selection of coefficients in the velocity update equations affects the convergence and the ability of the swarm to find the optimum. One way to come out of the situation is to reinitialize the particles positions at intervals or when convergence is detected.</p>
<p>

Some research approaches investigated the application of constriction coefficients and inertia weights. Numerous techniques for preventing premature convergence. The introduction of the fully informed particle swarm. Many variations on the social network topology, parameter-free, fully adaptive swarms, and some highly simplified models have been created.  The algorithm has been analyzed as a <link xlink:type="simple" xlink:href="../087/9087.xml">
dynamical system</link>, and has been used in hundreds of engineering applications; it is used to compose music, to model markets and organizations, and in art installations.</p>

</sec>
<sec>
<st>
 A basic, canonical PSO algorithm </st>

<p>

The algorithm presented below uses the global best and local bests but no neighborhood bests. Neighborhood bests allow parallel exploration of the search space and reduce the susceptibility of PSO to falling into local minima, but slow down convergence speed. Note that neighborhoods merely slow down the proliferation of new bests, rather than creating isolated subswarms because of the overlapping of neighborhoods: to make neighborhoods of size 3, say, particle 1 would only communicate with particles 2 through 5, particle 2 with 3 through 6, and so on. But then a new best position discovered by particle 2's neighborhood would be communicated to particle 1's neighborhood at the next iteration of the PSO algorithm presented below. Smaller neighborhoods lead to slower convergence, while larger neighborhoods to faster convergence, with a global best representing a neighborhood consisting of the entire swarm. The tendency is now to use partly random neighborhoods (see Standard PSO on the Particle Swarm Central).</p>
<p>

A single particle by itself is unable to accomplish anything.  The power is in interactive collaboration.</p>
<p>

Let <math>f : \mathbb{R}^m \rightarrow \mathbb{R}</math> be the fitness function that takes a particle's solution with several components in higher dimensional space and maps it to a single dimension metric. Let there be <math>n</math> particles, each with associated positions <math>\mathbf{x}_i \in \mathbb{R}^m</math> and velocities <math>\mathbf{v}_i \in \mathbb{R}^m</math>, <math>i = 1, \ldots, n</math>. Let <math>\hat{\mathbf{x}}_i</math> be the current best position of each particle and let <math>\hat{\mathbf{g}}</math> be the global best.</p>
<p>

<list>
<entry level="1" type="bullet">

 Initialize <math>\mathbf{x}_i</math> and <math>\mathbf{v}_i</math> for all <math>i</math>. One common choice is to take <math>\mathbf{x}_{ij} \in U[a_j, b_j]</math> and <math>\mathbf{v}_i = \mathbf{0}</math> for all <math>i</math> and <math>j = 1, \ldots, m</math>, where <math>a_j, b_j</math> are the limits of the search domain in each dimension, and <math>U</math> represents the <structure wordnetid="105726345" confidence="0.8">
<arrangement wordnetid="105726596" confidence="0.8">
<distribution wordnetid="105729036" confidence="0.8">
<link xlink:type="simple" xlink:href="../223/1699223.xml">
Uniform distribution (continuous)</link></distribution>
</arrangement>
</structure>
.</entry>
<entry level="1" type="bullet">

 <math>\hat{\mathbf{x}}_i \leftarrow \mathbf{x}_i</math> and <math>\hat{\mathbf{g}} \leftarrow \arg\min_{\mathbf{x}_i} f(\mathbf{x}_i), i = 1, \ldots, n</math>.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 While not converged:</entry>
<entry level="2" type="bullet">

 For each particle <math>1 \leq i \leq n</math>:</entry>
<entry level="3" type="bullet">

 Create random vectors <math>\mathbf{r}_{1}</math>, <math>\mathbf{r}_{2}</math>: <math>\mathbf{r}_{1 j}</math> and <math>\mathbf{r}_{2 j}</math> for all <math>j</math>,by taking <math>\mathbf{r}_{1 j},\mathbf{r}_{2 j} \in U[0, 1]</math> for <math>j = 1, \ldots, m</math></entry>
<entry level="3" type="bullet">

 Update the particle positions: <math>\mathbf{x}_i \leftarrow \mathbf{x}_i+\mathbf{v}_i</math>.</entry>
<entry level="3" type="bullet">

 Update the particle velocities: <math>\mathbf{v}_i \leftarrow {\omega}\mathbf{v}_i+c_1\mathbf{r}_1\circ(\hat{\mathbf{x}}_i-\mathbf{x}_i)+c_2\mathbf{r}_2\circ(\hat{\mathbf{g}}-\mathbf{x}_i)</math>.</entry>
<entry level="3" type="bullet">

 Update the local bests: If <math>f(\mathbf{x}_i) &amp;lt; f(\hat{\mathbf{x}}_i)</math>, <math>\hat{\mathbf{x}}_i \leftarrow \mathbf{x}_i</math>.</entry>
<entry level="3" type="bullet">

 Update the global best If <math>f(\mathbf{x}_i) &amp;lt; f(\hat{\mathbf{g}})</math>, <math>\hat{\mathbf{g}} \leftarrow \mathbf{x}_i</math>.</entry>
<entry level="1" type="bullet">

 <math>\hat{\mathbf{g}}</math> is the optimal solution with fitness <math>f(\hat{\mathbf{g}})</math>.</entry>
</list>
</p>
<p>

Note the following about the above algorithm:
<list>
<entry level="1" type="bullet">

 <math>\omega</math> is an inertial constant. Good values are usually slightly less than 1.</entry>
<entry level="1" type="bullet">

 <math>c_1</math> and <math>c_2</math> are constants that say how much the particle is directed towards good positions. They represent a "cognitive" and a "social" component, respectively, in that they affect how much the particle's personal best and the global best (respectively) influence its movement. Usually we take <math>c_1, c_2 \approx 2</math>.</entry>
<entry level="1" type="bullet">

 <math>\mathbf{r}_1, \mathbf{r}_2</math> are two random vectors with each component generally a uniform random number between 0 and 1.</entry>
<entry level="1" type="bullet">

 <math>\circ</math> operator indicates element-by-element multiplication i.e. the Hadamard <link xlink:type="simple" xlink:href="../280/125280.xml">
matrix multiplication</link> operator.</entry>
</list>
</p>
<p>

<list>
<entry level="3" type="bullet">

 Note that there is a misconception arising from the tendency to write the velocity formula in a "vector notation" (see for example D.N. Wilke's papers). The original intent (see M.C.'s "Particle Swarm Optimization, 2006") was to multiply a NEW random component per dimension, rather than multiplying the same component with each dimension per particle. Moreover, r1 and r2 are supposed to consist of a single number, defined as Cmax, which normally has a relationship with omega (defined as C1 in the literature) through a transcendental function, given the value 'phi': C1 = 1.0 / (phi - 1.0 + (v_phi * v_phi) - (2.0 * v_phi))   - and -   Cmax = C1 * phi.   Optimal "confidence coefficients" are therefore approximately in the ratio scale of C1=0.7 and Cmax=1.43.   The Pseudo code shown below however, describes the intent correctly - mishka</entry>
</list>
</p>

<ss1>
<st>
 Pseudo code </st>
<p>

Here follows a pseudo code example of the basic PSO.
Note that the random vectors <math>\mathbf{r}_1, \mathbf{r}_2</math>
are implemented as scalars inside the dimension loop which is equivalent
to the mathematical description given above.</p>
<p>

// Initialize the particle positions and their velocities
for I = 1 to number of particles n do
for J = 1 to number of dimensions m do
X[I][J] = lower limit + (upper limit - lower limit) * uniform random number 
V[I][J] = 0
enddo
enddo</p>
<p>

// Initialize the global and local fitness to the worst possible
fitness_gbest = inf;
for I = 1 to number of particles n do
fitness_lbest[I] = inf
enddo</p>
<p>

// Loop until convergence, in this example a finite number of iterations chosen
for k = 1 to number of iterations t do</p>
<p>

// evaluate the fitness of each particle
fitness_X = evaluate_fitness(X)</p>
<p>

// Update the local bests and their fitness 
for I = 1 to number of particles n do
if (fitness_X(I)  fitness_lbest(I))
fitness_lbest[I] = fitness_X(I)
for J = 1 to number of dimensions m do
X_lbest[I,J] = X(I,J)
enddo
endif
enddo</p>
<p>

// Update the global best and its fitness 
[min_fitness, min_fitness_index] = min(fitness_X(I))
if (min_fitness  fitness_gbest)
fitness_gbest = min_fitness
for J = 1 to number of dimensions m do
X_gbest[J] = X(min_fitness_index,J)
enddo
endif</p>
<p>

// Update the particle velocity and position
for I = 1 to number of particles n do
for J = 1 to number of dimensions m do
R1 = uniform random number
R2 = uniform random number
V[I][J] = w*V[I][J]
+ C1*R1*(X_lbest[I][J] - X[I][J])
+ C2*R2*(X_gbest[J] - X[I][J])
X[I][J] = X[I][J] + V[I][J]
enddo
enddo</p>
<p>

enddo</p>

</ss1>
<ss1>
<st>
 Discussion </st>
<p>

By studying this algorithm, we see that we are essentially carrying out something like a discrete-time simulation where each iteration of it represents a "tick" of time. The particles "communicate" information they find about each other by updating their velocities in terms of local and global bests. When a new best is found, the particles will change their positions accordingly so that the new information is "broadcast" to the swarm. The particles are always drawn back both to their own personal best positions and also to the best position of the entire swarm. They also have stochastic exploration capability via the use of the random multipliers <math>r_1, r_2</math>. The vector, floating-point nature of the algorithm suggests that high-performance implementations could be created that take advantage of modern hardware extensions pertaining to vectorization, such as <message wordnetid="106598915" confidence="0.8">
<direction wordnetid="106786629" confidence="0.8">
<link xlink:type="simple" xlink:href="../365/55365.xml">
Streaming SIMD Extensions</link></direction>
</message>
 and <link xlink:type="simple" xlink:href="../360/55360.xml">
Altivec</link>.</p>
<p>

Typical convergence conditions include reaching a certain number of iterations, reaching a certain fitness value, and so on.</p>

</ss1>
</sec>
<sec>
<st>
 Variations and practicalities </st>
<p>

There are a number of considerations in using PSO in practice; one might wish to clamp the velocities to a certain maximum amount, for instance. The considerable adaptability of PSO to variations and hybrids is seen as a strength over other robust evolutionary optimization mechanisms, such as <link xlink:type="simple" xlink:href="../254/40254.xml">
genetic algorithms</link>. For example, one common, reasonable modification is to add a probabilistic bit-flipping local search heuristic to the loop. Normally, a stochastic hill-climber risks getting stuck at local maxima, but the stochastic exploration and communication of the swarm overcomes this. Thus, PSO can be seen as a basic search "workbench" that can be adapted as needed for the problem at hand.</p>
<p>

Note that the research literature has uncovered many heuristics and variants determined to be better with respect to convergence speed and robustness, such as clever choices of <math>\omega</math>, <math>c_i</math>, and <math>r_i</math>. There are also other variants of the algorithm, such as discretized versions for searching over subsets of <math>\mathbb{Z}^n</math> rather than <math>\mathbb{R}^n</math>. There has also been experimentation with coevolutionary versions of the PSO algorithm with good results reported. Very frequently the value of <math>\omega</math> is taken to decrease over time; e.g., one might have the PSO run for a certain number of iterations and DECREASE linearly from a starting value (0.9, say) to a final value (0.4, say) in order to facilitate exploitation over exploration in later states of the search. The literature is full of such heuristics. In other words, the canonical PSO algorithm is not as strong as various improvements which have been developed on several common function optimization benchmarks and consulting the literature for ideas on parameter choices and variants for particular problems is likely to be helpful.</p>
<p>

Significant, non-trivial modifications have been developed for multi-objective optimization, versions designed to find solutions satisfying linear or non-linear constraints, as well as "niching" versions designed to find multiple solutions to problems where it is believed or known that there are multiple global minima which ought to be located.</p>
<p>

There is also a modified version of the algorithm called <link xlink:type="simple" xlink:href="../217/936217.xml">
repulsive particle swarm optimization</link>, in which a new factor, called repulsion, is added to the basic algorithm step.</p>

</sec>
<sec>
<st>
 Applications </st>

<p>

Although a relatively new paradigm, PSO has been applied to a variety of tasks, such as the training of <link xlink:type="simple" xlink:href="../523/21523.xml">
artificial neural networks</link> and for <link xlink:type="simple" xlink:href="../942/13697942.xml">
finite element updating</link>. Very recently, PSO has been applied in combination with <link xlink:type="simple" xlink:href="../640/5609640.xml">
grammatical evolution</link> to create a hybrid optimization paradigm called "grammatical swarms".</p>

</sec>
<sec>
<st>
 See also </st>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../217/936217.xml">
Repulsive particle swarm optimization</link></entry>
<entry level="1" type="bullet">

 <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../615/588615.xml">
Ant colony optimization</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../033/52033.xml">
Optimization (mathematics)</link></entry>
<entry level="1" type="bullet">

 <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../241/3132241.xml">
Differential evolution</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</entry>
</list>
</p>

</sec>
<sec>
<st>
References</st>
<p>

<list>
<entry level="1" type="bullet">

 J. Kennedy and R. C. Eberhart. <it>Swarm Intelligence.</it> Morgan Kaufmann. 2001</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 M. Clerc. <it>Particle Swarm Optimization.</it> ISTE, 2006.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 D. N. Wilke, S. Kok, and A. A. Groenwold, <it>Comparison of linear and classical velocity update rules in particle swarm optimization: notes on diversity</it>, International Journal for Numerical Methods in Engineering, Vol. 70, No. 8, pp. 962&ndash;984, 2007. </entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 A. Chatterjee, P. Siarry, <it>Nonlinear inertia variation for dynamic adaptation in particle swarm optimization</it>, Computers and Operations Research, Vol. 33, No. 3, pp. 859&ndash;871, 2006.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 A. P. Engelbrecht. <it>Fundamentals of Computational Swarm Intelligence.</it> Wiley, 2005. <weblink xlink:type="simple" xlink:href="http://si.cs.up.ac.za/">
http://si.cs.up.ac.za/</weblink></entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 D. N. Wilke. <it>Analysis of the particle swarm optimization algorithm</it>, Master's Dissertation, University of Pretoria, 2005. <weblink xlink:type="simple" xlink:href="http://upetd.up.ac.za/thesis/available/etd-01312006-125743/">
http://upetd.up.ac.za/thesis/available/etd-01312006-125743/</weblink></entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 T. Marwala. Finite element model updating using particle swarm optimization. International Journal of Engineering Simulation, 2005, 6(2), pp. 25-30. ISSN: 1468-1137.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 M. Clerc, and J. Kennedy,  <it>The Particle Swarm-Explosion, Stability, and Convergence in a Multidimensional Complex Space</it>, IEEE Transactions on Evolutionary Computation, 2002, 6, 58-73</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 J. Kennedy, and R. Eberhart, <it>Particle swarm optimization</it>, in Proc. of the IEEE Int. Conf. on Neural Networks, Piscataway, NJ, pp. 1942&ndash;1948, 1995.</entry>
</list>
</p>

</sec>
<sec>
<st>
External links</st>
<p>

<list>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.particleswarm.info">
Particle Swarm Central</weblink>. News, people, places, programs, papers, etc. See in particular the current Standard PSO.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://paradiseo.gforge.inria.fr/">
ParadisEO is a powerful C++ framework dedicated to the reusable design of metaheuristics including PSO algorithms</weblink>. Ready-to-use algorithms, many tutorials to easily implement your PSO. </entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www1.webng.com/economics">
FORTRAN Codes Particle Swarm Optimization</weblink> Performance on Benchmark functions</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://jswarm-pso.sourceforge.net">
JSwarm-PSO Particle swarm optimization package</weblink></entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://search.cpan.org/~kylesch/AI-PSO-0.86/lib/AI/PSO.pm">
Perl PSO Module</weblink>  </entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://gecco.org.chemie.uni-frankfurt.de/PsoVis/index.html">
Java Applet for 3D-visualisation of PSO</weblink></entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.projectcomputing.com/resources/psovis/index.html">
Java Applet 3D-visualisation of PSO with source code</weblink></entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.adaptivebox.net/research/bookmark/psocodes_link.html">
Links to PSO source codes</weblink></entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://cilib.sourceforge.net">
CILib</weblink> - GPLed computational intelligence simulation and research environment written in Java, includes various PSO implementations</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.cs.up.ac.za/cs/fvdbergh/publications/phd_thesis.ps.gz">
An Analysis of Particle Swarm Optimizers</weblink> - F. van den Bergh 2002 </entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://biomath.ugent.be/~brecht/downloads.html">
An implementation of PSO in MATLAB</weblink></entry>
</list>
</p>



</sec>
</bdy>
</algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</article>
