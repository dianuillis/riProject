<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 16:53:12[mciao0828] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<event  confidence="0.8" wordnetid="100029378">
<rule  confidence="0.8" wordnetid="105846932">
<act  confidence="0.8" wordnetid="100030358">
<psychological_feature  confidence="0.8" wordnetid="100023100">
<procedure  confidence="0.8" wordnetid="101023820">
<activity  confidence="0.8" wordnetid="100407535">
<algorithm  confidence="0.8" wordnetid="105847438">
<header>
<title>Neuroevolution of augmenting topologies</title>
<id>344922</id>
<revision>
<id>243776379</id>
<timestamp>2008-10-08T00:07:53Z</timestamp>
<contributor>
<username>Onkelringelhuth</username>
<id>2921997</id>
</contributor>
</revision>
<categories>
<category>Evolutionary algorithms</category>
<category>Neural networks</category>
<category>Genetic algorithms</category>
<category>Evolutionary computation</category>
</categories>
</header>
<bdy>

<b>NeuroEvolution of Augmenting Topologies</b> (<b>NEAT</b>) is a <link xlink:type="simple" xlink:href="../706/440706.xml">
neuroevolution</link> technique&mdash;a <link xlink:type="simple" xlink:href="../254/40254.xml">
genetic algorithm</link> for evolving <link xlink:type="simple" xlink:href="../523/21523.xml">
artificial neural networks</link>&mdash;developed by Ken Stanley while at <link xlink:type="simple" xlink:href="../031/32031.xml">
The University of Texas at Austin</link>. It notably evolves both network weights and structure, attempting to balance between the fitness and diversity of evolved solutions. It is based on three key ideas: tracking genes with historical markings to allow crossover between different topologies, protecting innovation via speciation, and building topology incrementally from an initial, minimal structure ("complexifying"). 
<sec>
<st>
 Performance </st>
<p>

On simple control tasks, the NEAT algorithm often converges to effective networks more quickly than a variety of other contemporary neuro-evolutionary techniques and <link xlink:type="simple" xlink:href="../294/66294.xml">
reinforcement learning</link> methods.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref> <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref></p>

</sec>
<sec>
<st>
 Complexification </st>
<p>

Conventionally, neural <link xlink:type="simple" xlink:href="../413/41413.xml">
network topology</link> is chosen by a human experimenter, and a genetic algorithm is used to select effective connection weights. The topology of such a network stays constant throughout this weight selection process.</p>
<p>

The NEAT approach begins with a <link xlink:type="simple" xlink:href="../777/172777.xml">
perceptron</link>-like feed-forward network of only input and output neurons. As evolution progresses, the topology of the network may be augmented by either adding a neuron along an existing connection, or by adding a new connection between previously unconnected neurons.</p>

</sec>
<sec>
<st>
 Implementation </st>
<p>

The original implementation by Ken Stanley is published under the <link xlink:type="simple" xlink:href="../683/18938683.xml">
GPL</link>. It integrates with <software wordnetid="106566077" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../948/1436948.xml">
Guile</link></software>
, a GNU <programming_language wordnetid="106898352" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../119/28119.xml">
scheme</link></programming_language>
 interpreter. This implementation of NEAT is considered the base reference for implementations of the NEAT algorithm. </p>

</sec>
<sec>
<st>
 Extensions to NEAT </st>

<ss1>
<st>
 rtNEAT </st>
<p>

In 2003 Stanley devised an extension to NEAT that allows evolution to occur in real time rather than through an iteration of generations as used by most genetic algorithms. The basic idea is to put the population under constant evaluation with a "lifetime" timer on each individual in the population. When a network's timer expires its current fitness measure is examined to see whether it falls near the bottom of the population, and if so it is discarded and replaced by a new network bred from two high-fitness parents. A timer is set for the new network and it is placed in the population to participate in the ongoing evaluations. </p>
<p>

The first application of rtNEAT is a video game called Neuro-Evolving Robotic Operatives, or NERO. In the first phase of the game, individual players deploy robots in a 'sandbox' and train them to some desired tactical doctrine. Once a collection of robots has been trained, a second phase of play allows players to pit their robots in a battle against robots trained by some other player, to see how well their training regimens prepared their robots for battle.</p>

</ss1>
<ss1>
<st>
 Phased Pruning </st>
<p>

An extension of Ken Stanley's NEAT, developed by Colin Green, adds periodic pruning of the network topologies of candidate solutions during the evolution process. This addition addressed concern that unbounded automated growth would generate unnecessary structure.</p>

</ss1>
<ss1>
<st>
 HyperNEAT </st>

<p>

A novel technique for evolving large-scale neural networks utilizing the geometric regularities of the task domain was recently developed and called Hypercube-based NEAT. It is originally based on the CPPN theory and is an active field of research.</p>

</ss1>
</sec>
<sec>
<st>
References</st>
<p>

<reflist>
<entry id="1">
Kenneth O. Stanley and Risto Miikkulainen (2002). "Evolving Neural Networks Through Augmenting Topologies". Evolutionary Computation 10 (2): 99-127</entry>
<entry id="2">
Matthew E. Taylor, Shimon Whiteson, and Peter Stone (2006). "Comparing Evolutionary and Temporal Difference Methods in a Reinforcement Learning Domain". GECCO 2006: Proceedings of the Genetic and Evolutionary Computation Conference.</entry>
</reflist>
</p>

</sec>
<sec>
<st>
Bibliography</st>

<p>

<list>
<entry level="1" type="bullet">

 <cite style="font-style:normal">Kenneth O. Stanley and Risto Miikkulainen&#32;(2002).&#32;"<weblink xlink:type="simple" xlink:href="http://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf">
Evolving Neural Networks Through Augmenting Topologies</weblink>". <it>Evolutionary Computation</it>&#32;<b>10</b>&#32;(2): 99–127. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1162%2F106365602320169811">
10.1162/106365602320169811</weblink>.</cite>&nbsp;</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <cite style="font-style:normal">Kenneth O. Stanley and Risto Miikkulainen&#32;(2002).&#32;"<weblink xlink:type="simple" xlink:href="http://nn.cs.utexas.edu/downloads/papers/stanley.gecco02_1.pdf">
Efficient Reinforcement Learning Through Evolving Neural Network Topologies</weblink>". <it>Proceedings of the Genetic and Evolutionary Computation Conference (GECCO-2002)</it>.</cite>&nbsp;</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <cite style="font-style:normal">Kenneth O. Stanley, Bobby D. Bryant, and Risto Miikkulainen&#32;(2003).&#32;"<weblink xlink:type="simple" xlink:href="http://nn.cs.utexas.edu/downloads/papers/stanley.cec03.pdf">
Evolving Adaptive Neural Networks with and without Adaptive Synapses</weblink>". <it>Proceedings of the 2003 IEEE Congress on Evolutionary Computation (CEC-2003)</it>.</cite>&nbsp;</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <cite style="font-style:normal">Colin Green&#32;(2004).&#32;"<weblink xlink:type="simple" xlink:href="http://sharpneat.sourceforge.net/phasedsearch.html">
Phased Searching with NEAT: Alternating Between Complexification And Simplification</weblink>".</cite>&nbsp;</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <cite style="font-style:normal">Kenneth O. Stanley, Ryan Cornelius, Risto Miikkulainen, Thomas D’Silva, and Aliza Gold&#32;(2005).&#32;"<weblink xlink:type="simple" xlink:href="http://www.cs.utexas.edu/users/nn/downloads/papers/stanley.aiide05demo.pdf">
Real-Time Learning in the NERO Video Game</weblink>". <it>Proceedings of the Artificial Intelligence and Interactive Digital Entertainment Conference (AIIDE 2005) Demo Papers</it>.</cite>&nbsp;</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <cite style="font-style:normal">Matthew E. Taylor, Shimon Whiteson, and Peter Stone&#32;(2006).&#32;"<weblink xlink:type="simple" xlink:href="http://www.cs.utexas.edu/~shimon/pubs/taylorgecco06.pdf">
Comparing Evolutionary and Temporal Difference Methods in a Reinforcement Learning Domain</weblink>". <it>GECCO 2006: Proceedings of the Genetic and Evolutionary Computation Conference</it>.</cite>&nbsp;</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <cite style="font-style:normal">Shimon Whiteson and Daniel Whiteson&#32;(2007).&#32;"<weblink xlink:type="simple" xlink:href="http://www.cs.utexas.edu/~shimon/pubs/whitesoniaai07.pdf">
Stochastic Optimization for Collision Selection in High Energy Physics</weblink>". <it>IAAI 2007: Proceedings of the Nineteenth Annual Innovative Applications of Artificial Intelligence Conference</it>.</cite>&nbsp;</entry>
</list>
</p>


</sec>
<sec>
<st>
External links</st>
<p>

<list>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.cs.ucf.edu/~kstanley/">
Ken Stanley's website</weblink></entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://eplex.cs.ucf.edu">
"Evolutionary Complexity Research Group at UCF"</weblink> - Ken Stanley's current research group</entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.cs.ucf.edu/~kstanley/neat.html">
NEAT Homepage</weblink> - NEAT Project homepage</entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://nerogame.org/">
Project NERO Website</weblink> - an example application of rtNEAT (a realtime version of NEAT)</entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://code.google.com/p/neat-python/">
NEAT-Python</weblink> - a NEAT implementation in Python</entry>
</list>
</p>

</sec>
</bdy>
</algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</article>
