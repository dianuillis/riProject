<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 15:38:30[mciao0825] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Raven paradox</title>
<id>37391</id>
<revision>
<id>228455857</id>
<timestamp>2008-07-28T19:43:18Z</timestamp>
<contributor>
<username>Gwern</username>
<id>2164608</id>
</contributor>
</revision>
<categories>
<category>Paradoxes</category>
</categories>
</header>
<bdy>

The <b>Raven paradox</b>, also known as <b>Hempel's paradox</b> or <b>Hempel's ravens</b> is a <link xlink:type="simple" xlink:href="../390/24390.xml">
paradox</link> proposed by the <country wordnetid="108544813" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../867/11867.xml">
German</link></country>
 logician <philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../238/1380238.xml">
Carl Gustav Hempel</link></philosopher>
 in the 1940s to illustrate a problem where <link xlink:type="simple" xlink:href="../736/393736.xml">
inductive logic</link> violates <link xlink:type="simple" xlink:href="../170/154170.xml">
intuition</link>. It reveals the <link xlink:type="simple" xlink:href="../456/177456.xml">
problem of induction</link>.
<sec>
<st>
The paradox</st>
<p>

<image location="right" width="100px" src="Corvus_corax_(FWS).jpg" type="thumb">
<caption>

A black raven
</caption>
</image>

<image width="100px" src="Apples.jpg" type="thumb">
<caption>

Non-black non-ravens
</caption>
</image>

Hempel describes the paradox in terms of the <link xlink:type="simple" xlink:href="../281/14281.xml">
hypothesis</link><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref>: 
<indent level="1">

 (1) <it>All <link xlink:type="simple" xlink:href="../151/26151.xml">
raven</link>s are <link xlink:type="simple" xlink:href="../035/4035.xml">
black</link></it>. 
</indent>

In strict <link xlink:type="simple" xlink:href="../225/3729225.xml">
logic</link>al terms, via the Law of Implication, this statement is equivalent to:
<indent level="1">

 (2) <it>Everything that is not black is not a raven.</it>
</indent>

It should be clear that in all circumstances where (2) is true, (1) is also true; and likewise, in all circumstances where (2) is false (i.e. if we imagine a world in which something that was not black, yet was a raven, existed), (1) is also false.  This establishes logical equivalence.</p>
<p>

Given a general statement such as <it>all ravens are black</it>, we would generally consider a form of the same statement that refers to a specific observable instance of the general class to constitute evidence for that general statement.  For example,
<indent level="1">

 (3) <it>Nevermore, my pet raven, is black.</it>
</indent>
is clearly evidence supporting the hypothesis that <it>all ravens are black</it>.</p>
<p>

The paradox arises when this same process is applied to statement (2).  On sighting a green apple, we can observe:
<indent level="1">

 (4) <it>This green (and thus not black) thing is an apple (and thus not a raven).</it>
</indent>
By the same reasoning, this statement is evidence that (2) <it>everything that is not black is not a raven.</it>  But since (as above) this statement is logically equivalent to (1) <it>all ravens are black</it>, it follows that the sight of a green apple offers evidence that all ravens are black.</p>

</sec>
<sec>
<st>
Proposed Resolutions</st>

<p>

Two apparently reasonable premises:</p>
<p>

<indent level="1">

 The Equivalence Condition (EC): If a proposition, X, provides evidence in favor of another proposition Y, then X also provides evidence in favor of any proposition which is logically equivalent to Y.
</indent>

and</p>
<p>

<indent level="1">

 <link xlink:type="simple" xlink:href="../853/2078853.xml">
Nicod</link>'s Criterion (NC): A proposition of the form "All P are Q" is supported by the observation of a particular P which is Q.
</indent>

can be combined to reach the paradoxical conclusion:</p>
<p>

<indent level="1">

 (PC): The observation of a green apple provides evidence that all ravens are black.
</indent>

A resolution to the paradox must therefore either accept (PC) or reject
(EC) or reject (NC). A satisfactory resolution should also explain
<it>why</it> there naively appears to be a paradox. Solutions which
accept the paradoxical conclusion can do this by presenting a
proposition which we intuitively know to be false but which
is easily confused with (PC), while solutions which reject (EC)
or (NC) should present a proposition which we intuitively know
to be true but which is easily confused with (EC) or (NC)<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%223%22])">3</ref>.</p>

<ss1>
<st>
Approaches which Accept the Paradoxical Conclusion</st>

<ss2>
<st>
Hempel's Resolution</st>

<p>

Hempel himself accepted the paradoxical conclusion, arguing that
the reason the result appears paradoxical is because we possess
prior information without which the observation of a non-black
non-raven would indeed provide evidence that all ravens are black.</p>
<p>

He illustrates this with the example of the generalization "All sodium
salts burn yellow", and asks us to consider the observation which occurs
when somebody holds a piece of pure ice in a colorless flame which does
not turn yellow.</p>
<p>

<indent level="1">

This result would confirm the assertion, "Whatever does not burn yellow is no sodium salt", and consequently, by virtue of the equivalence condition, it would confirm the original formulation. Why does this impress us as paradoxical? The reason becomes clear when we compare the previous situation with the case of an experiment where an object whose chemical constitution is as yet unknown to us is held into a flame and fails to turn it yellow, and where subsequent analysis reveals it to contain no sodium salt. This outcome, we should no doubt agree, is what was to be expected on the basis of the hypothesis ... thus the data here obtained constitute confirming evidence for the hypothesis. 
</indent>

<indent level="1">

 In the seemingly paradoxical cases of confirmation, we are often not actually judging the relation of the given evidence, E alone to the hypothesis H ... we tacitly introduce a comparison of H with a body of evidence which consists of E in conjunction with an additional amount of information which we happen to have at our disposal; in our illustration, this information includes the knowledge (1) that the substance used in the experiment is ice, and (2) that ice contains no sodium salt. If we assume this additional information as given, then, of course, the outcome of the experiment can add no strength to the hypothesis under consideration. But if we are careful to avoid this tacit reference to additional knowledge ... the paradoxes vanish.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%224%22])">4</ref>
</indent>

</p>
</ss2>
<ss2>
<st>
The Standard Bayesian Solution</st>

<p>

One of the most popular proposed resolutions is to accept the
conclusion that the observation of a green apple provides
evidence that all ravens are black but to argue that the
amount of confirmation provided is very small, due to
the large discrepancy between the number of ravens and
the number of non-black objects. According to this resolution,
the conclusion appears paradoxical because we intuitively estimate the
amount of evidence provided by the observation of a green apple
to be zero, when it is in fact non-zero but very small.</p>
<p>

<link xlink:type="simple" xlink:href="../404/404404.xml">
I J Good</link>'s presentation of this
argument in 1960<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%225%22])">5</ref> is perhaps the best known, and variations of the argument have been popular ever
since <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref>
although it had been presented in 1958<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%227%22])">7</ref> and
early forms of the argument appeared as early as 1940<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%228%22])">8</ref>.</p>
<p>

Good's argument involves calculating the <link xlink:type="simple" xlink:href="../552/824552.xml">
weight of evidence</link> provided by the observation of a black raven or a white shoe in favor of the hypothesis that all the ravens in a collection of objects are black. The weight of evidence is the logarithm of the <link xlink:type="simple" xlink:href="../552/824552.xml">
Bayes factor</link>, which in this case is simply the factor by which the <link xlink:type="simple" xlink:href="../069/172069.xml">
odds</link> of the hypothesis changes when the observation is made. The argument goes as follows:</p>

<p>

... suppose that there are <math>N</math> objects that might be seen at any moment, of which <math>r</math> are ravens and <math>b</math> are black, and that the <math>N</math> objects each have probability 1/<math>N</math> of being seen. Let <math>H_i</math> be the hypothesis that there are <math>i</math> non-black ravens, and suppose that the hypotheses <math>H_1, H_2, ... ,H_r</math> are initially equiprobable. Then, if we happen to see a black raven, the Bayes factor in favour of <math>H_0</math> is</p>
<p>

<indent level="1">

<math>\frac{r}{N} \Bigg / </math>average<math> \Bigg ( \frac{r-1}{N},\frac{r-2}{N}, ...\ ,\frac{1}{N}\Bigg ) \ = \ \frac{2r}{r-1}</math>
</indent>

i.e. about 2 if the number of ravens in existence is known to be large. But the factor if we see a white shoe is only</p>
<p>

<indent level="1">

<math>\frac{N-b}{N} \Bigg / </math>average<math> \Bigg ( \frac{N-b-1}{N},\frac{N-b-2}{N}, ...\ ,\max(0,\frac{N-b-r}{N})\Bigg )</math>
</indent>

<indent level="1">

<math> \ = \ \frac{N-b}{\max(N-b-r/2 -1/2\ , \ (N-b-1)/2)}</math>
</indent>
</p>
<p>

<indent level="1">

and this exceeds unity by only about r/(2N-2b) if N-b is large compared to r. Thus the weight of evidence provided by the sight of a white shoe is positive, but is small if the number of ravens is known to be small compared to the number of non-black objects.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%229%22])">9</ref>
</indent>

Many of the proponents of this resolution and variants of it have 
been advocates of Bayesian probability, and it is now commonly called 
the Bayesian Solution, although, as Chihara<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2210%22])">10</ref> 
observes, "there is no such thing as <it>the</it> Bayesian solution. There
are many different `solutions' that Bayesians have put forward
using Bayesian techniques." Noteworthy approaches using Bayesian
techniques include Earman,
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2211%22])">11</ref>, Eells
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2212%22])">12</ref>, Gibson
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2213%22])">13</ref>, Hosaisson-Lindenbaum
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2214%22])">14</ref>, Howson and Urbach 
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2215%22])">15</ref>, Mackie
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2216%22])">16</ref> and
Hintikka<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2217%22])">17</ref>, who claims that his approach 
is "more Bayesian than the so-called `Bayesian solution' of the same
paradox." Bayesian approaches which make use of Carnap's theory of inductive inference include
Humburg<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2218%22])">18</ref>, Maher,
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2219%22])">19</ref>
and Fitelson et al.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2220%22])">20</ref>. Vranas<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2221%22])">21</ref> introduced
the term "Standard Bayesian Solution" to avoid confusion.</p>

</ss2>
</ss1>
<ss1>
<st>
The Carnapian Approach</st>

<p>

Maher<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2222%22])">22</ref> accepts the paradoxical conclusion, and refines it:</p>

<p>

A non-raven (of whatever color) confirms that all ravens are black because </p>
<p>

<indent level="1">

(i) the information that this object is not a raven removes the possibility that this object is a counterexample to the generalization, and 
</indent>

<indent level="1">

(ii) it reduces the probability that unobserved objects are ravens, thereby reducing the probability that they are counterexamples to the generalization.
</indent>
</p>
<p>

In order to reach (ii), he appeals to Carnap's theory of inductive
probability, which is (from the Bayesian point of view) a way of assigning
prior probabilities which naturally implements induction. According to
Carnap's theory, the posterior probability, <math>P(Fa|E)</math>, that an object, 
<math>a</math>, will have a predicate, <math>F</math>, after the evidence 
<math>E</math> has been observed, is:</p>
<p>

<indent level="1">

<math>P(Fa|E) \ = \ \frac{n_F+\lambda P(Fa)}{n+\lambda}</math>
</indent>

where <math>P(Fa)</math> is the initial probability that <math>a</math> has
the predicate <math>F</math>; <math>n</math> is the number of objects which 
have been examined (according to the available evidence <math>E</math>); 
<math>n_F</math> is the number of examined objects which turned out to have the predicate <math>F</math>, and <math>\lambda</math> is a constant which measures resistance to generalization.</p>
<p>

If <math>\lambda</math> is close to zero, <math>P(Fa|E)</math> will be very
close to one after a single observation of an object which turned out to have the predicate <math>F</math>,
while if <math>\lambda</math> is much larger than <math>n</math>, <math>P(Fa|E)</math> will 
be very close to <math>P(Fa)</math> regardless of the fraction of observed
objects which had the predicate <math>F</math>.</p>
<p>

Using this Carnapian approach, Maher identifies a proposition which we intuitively 
(and correctly) know to be false, but which we easily confuse with the paradoxical conclusion. The proposition in question
is the proposition that observing non-ravens tells us about the color of ravens.
While this is intuitively false and is also false according to Carnap's theory
of induction, observing non-ravens (according to that same theory) causes us
to reduce our estimate of the total number of ravens, and thereby reduces
the estimated number of possible counterexamples to the rule that all ravens
are black. </p>
<p>

Hence, from the Bayesian-Carnapian point of view, the observation of a non-raven
does not tell us anything about the color of ravens, but it tells us about
the prevalence of ravens, and supports "All ravens are black" by reducing
our estimate of the number of ravens which might not be black.</p>

</ss1>
</sec>
<sec>
<st>
The Role of Background Knowledge</st>

<p>

Much of the discussion of the paradox in general and the Bayesian approach
in particular has centred on the relevance of background knowledge.
Surprisingly, Maher<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2223%22])">23</ref> shows that, for a large class of possible configurations of background knowledge, the observation of a non-black non-raven provides <it>exactly the same</it> amount of confirmation as the observation of a black raven. The configurations of background knowledge which he considers are those which are provided by a <it>sample proposition</it>, namely a proposition which is a <link xlink:type="simple" xlink:href="../959/74959.xml">
conjunction</link> of atomic propositions, each of which ascribes a single predicate to a single individual, with no two atomic propositions involving the same individual. Thus, a proposition of the form "A is a black raven and B is a white shoe" can be considered a sample proposition by taking "black raven" and "white shoe" to be predicates.</p>
<p>

Maher's proof appears to contradict the result of the Bayesian argument, which was that the observation of a non-black non-raven provides much less evidence than the observation of a black raven. The reason is that the background knowledge which Good and others use can not be expressed in the form of a sample proposition - in particular, variants of the standard Bayesian approach often suppose (as Good did in the argument quoted above) that the total numbers of ravens, non-black objects and/or the total number of objects, are known quantities. Maher comments that, "The reason we think there are more non-black things than ravens is because that has been true of the things we have observed to date. Evidence of this kind can be represented by a sample proposition. But ... given any sample proposition as background evidence, a non-black non-raven confirms A just as strongly as a black raven does ... Thus my analysis suggests that this response to the paradox [i.e. the Standard Bayesian one] cannot be correct."</p>
<p>

Fitelson et al.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2224%22])">24</ref> examined the conditions under which the 
observation of a non-black non-raven provides less evidence than the observation
of a black raven. They show that, if <math>a</math> is an object selected at random, <math>Ba</math> is the proposition that the object is black, and <math>Ra</math> is the proposition that the object is a raven, then the condition:</p>
<p>

<indent level="1">

<math>\frac{P(\overline{Ba}|\overline{H})}{P(Ra|\overline{H})} \ - \ P(\overline{Ba}|Ra\overline{H}) \  \geq \ P(Ba|Ra\overline{H}) \frac{P(\overline{Ba}|H)}{P(Ra|H)}</math>
</indent>

is sufficient for the observation of a non-black non-raven to provide less
evidence than the observation of a black raven. Here, a line over a
proposition indicates the logical negation of that proposition.</p>
<p>

This condition does not tell us <it>how large</it> the difference
in the evidence provided is, but a later calculation in the same paper
shows that the weight of evidence provided by a black raven exceeds
that provided by a non-black non-raven by about 
<math>-\log P(Ba|Ra\overline{H})</math>. This is equal to the amount of
additional information (in bits, if the base of the logarithm is 2) which 
is provided when a raven of unknown color is discovered to be black, 
given the hypothesis that not all ravens are black.</p>
<p>

Fitelson et al.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2225%22])">25</ref> explain that:</p>
<p>

<indent level="1">

Under normal circumstances, <math>p=P(Ba|Ra\overline{H})</math> may be somewhere around 0.9 or 0.95; so <math>1/p</math> is somewhere around 1.11 or 1.05. Thus, it may appear that a single instance of a black raven does not yield much more support than would a non-black non-raven. However, under plausible conditions it can be shown that a sequence of <math>n</math> instances (i.e. of n black ravens, as compared to n non-black non-ravens) yields a ratio of likelihood ratios on the order of <math>(1/p)^n</math>, which blows up significantly for large <math>n</math>.
</indent>

The authors point out that their analysis is completely
consistent with the supposition that a non-black non-raven
provides an extremely small amount of evidence although
they do not attempt to prove it; they merely calculate the difference between
the amount of evidence that a black raven provides and the amount of evidence 
that a non-black non-raven provides.</p>

</sec>
<sec>
<st>
Rejecting Nicod's Criterion</st>

<ss1>
<st>
The Red Herring</st>

<p>

Good <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2226%22])">26</ref> gives an example
of background knowledge with respect to which the observation of a black raven
<it>decreases</it> the probability that all ravens are black:</p>
<p>

<indent level="1">

Suppose that we know we are in one or other of two worlds, and the hypothesis, H, under consideration is that all the ravens in our world are black. We know in advance that in one world there are a hundred black ravens, no non-black ravens, and a million other birds; and that in the other world there are a thousand black ravens, one white raven, and a million other birds. A bird is selected equiprobably at random from all the birds in our world. It turns out to be a black raven. This is strong evidence ... that we are in the second world, wherein not all ravens are black.
</indent>

Good concludes that the white shoe is a "red herring": Sometimes even a black raven
can constitute evidence <it>against</it> the hypothesis that all ravens are black, so
the fact that the observation of a white shoe can support it is not surprising and 
not worth attention. Nicod's criterion is false, according to Good, and so the
paradoxical conclusion does not follow.</p>
<p>

Hempel rejected this as a solution to the paradox, insisting that the proposition 'c is a raven and is black' must be considered "by itself and without reference to any other information", and pointing out that it "... was emphasized in section 5.2(b) of my article in Mind ... that the very appearance of paradoxicality in cases like that of the white shoe results in part from a failure to observe this maxim."<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2227%22])">27</ref></p>
<p>

The question which then arises is whether the paradox is to be understood in the context of absolutely no background information (as Hempel suggests), or in the context of the background information which we actually possess regarding ravens and black objects, or with regard to all possible configurations of background information.</p>
<p>

Good had shown that, for some configurations of background knowledge, Nicod's criterion
is false (provided that we are willing to equate "inductively support" with 
"increase the probability of" - see below). The possibility remained that, with
respect to our actual configuration of knowledge, which is very different from
Good's example, Nicod's criterion might still be true and so we could still
reach the paradoxical conclusion. Hempel, on the other hand, insists that
it is our background knowledge itself which is the red herring, and that
we should consider induction with respect to a condition of perfect ignorance.</p>

</ss1>
<ss1>
<st>
Good's Baby</st>

<p>

In his proposed resolution, Maher implicitly made use of the fact that the 
proposition "All ravens are black" is highly probable when it is highly 
probable that there are no ravens. Good had used this fact before to respond
to Hempel's insistence that Nicod's criterion was to be understood to hold
in the absence of background information<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2228%22])">28</ref>:</p>
<p>

<indent level="1">

...imagine an infinitely intelligent newborn baby having built-in neural circuits enabling him to deal with formal logic, English syntax, and subjective probability. He might now argue, after defining a raven in detail, that it is extremely unlikely that there are any ravens, and therefore it is extremely likely that all ravens are black, that is, that <math>H</math> is true. 'On the other hand', he goes on to argue, 'if there are ravens, then there is a reasonable chance that they are of a variety of colours. Therefore, if I were to discover that even a black raven exists I would consider <math>H</math> to be less probable than it was initially.'
</indent>

This, according to Good, is as close as one can reasonably expect to get to 
a condition of perfect ignorance, and it appears that Nicod's condition is still 
false. Maher made Good's argument more precise by using Carnap's theory of induction
to formalize the notion that if there is one raven, then it is likely
that there are many<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2229%22])">29</ref>.</p>
<p>

Maher's argument considers a universe of exactly two objects, each of which
is very unlikely to be a raven (a one in a thousand chance) and reasonably 
unlikely to be black (a one in ten chance). Using Carnap's formula for induction,
he finds that the probability that all ravens are black decreases from 0.9985
to 0.8995 when it is discovered that one of the two objects is a black raven.</p>
<p>

Maher concludes that not only is the paradoxical conclusion true, but
that Nicod's criterion is false in the absence of background knowledge
(except for the knowledge that the number of objects in the universe
is two and that ravens are less likely than black things).</p>

</ss1>
<ss1>
<st>
Distinguished Predicates</st>

<p>

Quine<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2230%22])">30</ref> argued that the solution to the paradox
lies in the recognition that certain predicates, which he
called <link xlink:type="simple" xlink:href="../435/1137435.xml">
natural kind</link>s, have a distinguished status with respect
to induction. This can be illustrated with <philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../596/1179596.xml">
Nelson Goodman</link></philosopher>
's
example of the predicate <link xlink:type="simple" xlink:href="../248/577248.xml">
grue</link>. An object is grue
if it is blue before (say) 2010 and green afterwards. Clearly, we
expect objects which were blue before 2010 to remain blue afterwards,
but we do not expect the objects which were found to be grue before 
2010 to be grue afterwards. Quine's explanation is that "blue" is
a natural kind; a privileged predicate which can be used for induction,
while "grue" is not a natural kind and using induction with it leads
to error.</p>
<p>

This suggests a resolution to the paradox - Nicod's criterion is
true for natural kinds, such as "blue" and "black", but is false
for artificially contrived predicates, such as "grue" or "non-raven".
The paradox arises, according to this resolution, because we implicitly
interpret Nicod's criterion as applying to all predicates when in fact
it only applies to natural kinds.</p>
<p>

Another approach which favours specific predicates over others 
was taken by Hintikka<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2231%22])">31</ref>. Hintikka was motivated
to find a Bayesian approach to the paradox which did not make use
of knowledge about the relative frequencies of ravens and black things.
Arguments concerning relative frequencies, he contends, cannot always 
account for the perceived irrelevance of evidence consisting of
observations of objects of type A for the purposes of learning
about objects of type not-A. </p>
<p>

His argument can be illustrated by rephrasing the paradox using
predicates other than "raven" and "black". For example, "All men
are tall" is equivalent to "All short people are women", and so
observing that a randomly selected person is a short woman should
provide evidence that all men are tall. Despite the fact that
we lack background knowledge to indicate that there are dramatically
fewer men than short people, we still find ourselves inclined to
reject the conclusion. Hintikka's example is: "... a generalization
like 'no material bodies are infinitely divisible' seems to be completely
unaffected by questions concerning immaterial entities, independently
of what one thinks of the relative frequencies of material and
immaterial entities in one's universe of discourse."</p>
<p>

His solution is to introduce an <it>order</it> into the 
set of predicates. When the logical system is equipped with this order,
it is possible to restrict the <it>scope</it> of a generalization such as 
"All ravens are black" so that it applies to ravens only and not to 
non-black things, since the order privileges ravens over non-black things. 
As he puts it:</p>
<p>

<indent level="1">

If we are justified in assuming that the scope of the generalization 'All ravens are black' can be restricted to ravens, then this means that we have some outside information which we can rely on concerning the factual situation. The paradox arises from the fact that this information, which colors our spontaneous view of the situation, is not incorporated in the usual treatments of the inductive situation. <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2232%22])">32</ref>
</indent>

</p>
</ss1>
</sec>
<sec>
<st>
Proposed Resolutions which Reject the Equivalence Condition</st>

<ss1>
<st>
Selective Confirmation</st>

<p>

Scheffler and <link xlink:type="simple" xlink:href="../957/513957.xml">
Goodman</link><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2233%22])">33</ref> took an approach to the paradox which incorporates
<person wordnetid="100007846" confidence="0.9508927676800064">
<philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../623/16623.xml">
Karl Popper</link></philosopher>
</person>
's view that scientific hypotheses are never really confirmed,
only falsified. </p>
<p>

The approach begins by noting that the observation of a black raven does not prove that "All ravens are black" but it falsifies the contrary hypothesis, "No ravens are black". A non-black non-raven, on the other hand, is consistent with both "All ravens are black" and with "No ravens are black". As the authors put it:</p>
<p>

<indent level="1">

... the statement that all ravens are black is not merely <it>satisfied</it> by evidence of a black raven but is <it>favored</it> by such evidence, since a black raven disconfirms the contrary statement that all ravens are not black, i.e. satisfies its denial. A black raven, in other words, satisfies the hypothesis <it>that all ravens are black rather than not:</it> it thus selectively confirms <it>that all ravens are black</it>.
</indent>

Selective confirmation violates the equivalence condition since
a black raven selectively confirms "All ravens are black" but
not "All non-black things are non-ravens". </p>

<ss2>
<st>
Probabilistic or Non-Probabilistic Induction</st>

<p>

Scheffler and Goodman's concept of selective confirmation is
an example of an interpretation of "provides evidence in favor of" 
which does not coincide with "increase the probability of". 
This must be a general feature of all resolutions which reject the
equivalence condition, since logically equivalent propositions must
always have the same probability. </p>
<p>

It is impossible for the observation 
of a black raven to increase the probability of the proposition
"All ravens are black" without causing exactly the same
change to the probability that "All non-black things are non-ravens".
If an observation inductively supports the former but not the
latter, then "inductively support" must refer to something other
than changes in the probabilities of propositions. A possible loophole
is to interpret "All" as "Nearly all" - "Nearly all ravens are black"
is not equivalent to "Nearly all non-black things are non-ravens", and
these propositions can have very different probabilities<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2234%22])">34</ref>.</p>
<p>

This raises the broader question of the relation of probability
theory to inductive reasoning. <person wordnetid="100007846" confidence="0.9508927676800064">
<philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../623/16623.xml">
Karl Popper</link></philosopher>
</person>
 argued that probability theory alone cannot 
account for induction. His argument involves splitting a hypothesis,
<math>H</math>, into a part which is deductively entailed by the
evidence, <math>E</math>, and another part. This can be done in two
ways.</p>
<p>

First, consider the splitting<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2235%22])">35</ref>:</p>
<p>

<indent level="1">

<math>H=A\ and\ B \ \ \ \ \ \ E=B\ and\ C</math>
</indent>

where <math>A</math>, <math>B</math> and <math>C</math> are
probabilistically independent: <math>P(A\ and\ B)=P(A)P(B)</math> and
so on. The condition which is necessary for such a splitting
of H and E to be possible is <math>P(H|E)&amp;gt;P(H)</math>, that is,
that <math>H</math> is probabilistically supported by <math>E</math>.</p>
<p>

Popper's observation is that the part, <math>B</math>, of <math>H</math>
which receives support from <math>E</math> actually follows deductively
from <math>E</math>, while the part of <math>H</math> which does not
follow deductively from <math>E</math> receives no support at all from
<math>E</math> - that is, <math>P(A|E)=P(A)</math>.  </p>
<p>

Second, the splitting<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2236%22])">36</ref>:</p>
<p>

<indent level="1">

<math>H=(H\ or\ E)\ and\ (H\ or\ \overline{E})</math> 
</indent>

separates <math>H</math> into <math>(H\ or\ E)</math>, which as
Popper says, "is the logically strongest part of <math>H</math>
(or of the content of <math>H</math>) that follows [deductively]
from <math>E</math>," and <math>(H\ or\ \overline{E})</math>, which, 
he says, "contains all of <math>H</math> that goes beyond <math>E</math>."
He continues:</p>
<p>

<indent level="1">

Does <math>E</math>, in this case, provide any support for the factor <math>(H\ or\ \overline{E})</math>, which in the presence of <math>E</math> is alone needed to obtain <math>H</math>? The answer is: No. It never does. Indeed, <math>E</math> countersupports <math>(H\ or\ \overline{E})</math> unless either <math>P(H|E)=1</math> or <math>P(E)=1</math> (which are possibilities of no interest). ...
</indent>

<indent level="1">

This result is completely devastating to the inductive interpretation of the calculus of probability. All probabilistic support is purely deductive: that part of a hypothesis that is not deductively entailed by the evidence is always strongly countersupported by the evidence ... There is such a thing as probabilistic support; there might even be such a thing as inductive support (though we hardly think so). But the calculus of probability reveals that probabilistic support cannot be inductive support.
</indent>

</p>
</ss2>
</ss1>
<ss1>
<st>
The Orthodox Approach</st>

<p>

The orthodox <link xlink:type="simple" xlink:href="../877/5657877.xml">
Neyman-Pearson</link> theory
of hypothesis testing considers how to decide whether to
<it>accept</it> or <it>reject</it> a hypothesis, rather than what
probability to assign to the hypothesis. From this point of view,
the hypothesis that "All ravens are black" is not accepted
<it>gradually</it>, as its probability increases towards one when more
and more observations are made, but is accepted in a single action as the result of evaluating the data which has already been collected. As Neyman and Pearson put it:</p>
<p>

<indent level="1">

Without hoping to know whether each separate hypothesis is true or false, we may search for rules to govern our behaviour with regard to them, in following which we insure that, in the long run of experience, we shall not be too often wrong.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2237%22])">37</ref>
</indent>

According to this approach, it is not necessary to assign any
value to the probability of a <it>hypothesis</it>, although one must
certainly take into account the probability of the <it>data</it>
given the hypothesis, or given a competing hypothesis, when deciding
whether to accept or to reject. The acceptance or rejection of a hypothesis
carries with it the risk of <link xlink:type="simple" xlink:href="../877/5657877.xml">
error</link>.</p>
<p>

This contrasts with the Bayesian approach, which requires that the
hypothesis be assigned a prior probability, which is revised in the 
light of the observed data to obtain the final probability of the
hypothesis. Within the Bayesian framework there is no risk of error
since hypotheses are not accepted or rejected; instead they are
assigned probabilities.</p>
<p>

An analysis of the paradox from the orthodox point of view has been
performed, and leads to, among other insights, a rejection of the 
equivalence condition:</p>
<p>

<indent level="1">

It seems obvious that one cannot both <it>accept</it> the hypothesis that all P's are Q and also reject the contrapositive, i.e. that all non-Q's are non-P. Yet it is easy to see that on the Neyman-Pearson theory of testing, a test of "All P's are Q" is <it>not</it> necessarily a test of "All non-Q's are non-P" or vice versa. A test of "All P's are Q" requires reference to some alternative statistical hypothesis of the form <math>r</math> of all P's are Q, <math>0&amp;lt;r&amp;lt;1</math>, whereas a test of "All non-Q's are non-P" requires reference to some statistical alternative of the form <math>r</math> of all non-Q's are non-P, <math>0&amp;lt;r&amp;lt;1</math>. But these two sets of possible alternatives are different ... Thus one could have a test of <math>H</math> without having a test of its contrapositive.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2238%22])">38</ref>
</indent>

</p>
</ss1>
<ss1>
<st>
Rejecting Material Implication</st>

<p>

The following propositions all imply one another: "Every object is either black or
not a raven", "Every Raven is black", and "Every non-black object is a non-raven."
They are therefore, by definition, logically equivalent. However, the three 
propositions have different domains: the first proposition says something about "Every 
object", while the second says something about "Every raven". </p>
<p>

The first proposition is the only one whose domain is unrestricted ("all objects"),
so this is the only one which can be expressed in <link xlink:type="simple" xlink:href="../983/10983.xml">
first order logic</link>. It is
logically equivalent to:</p>
<p>

<indent level="1">

<math>\forall\ x, Rx\ \rightarrow\ Bx</math>
</indent>

and also to</p>
<p>

<indent level="2">

<math>\forall\ x, \overline{Bx}\ \rightarrow\ \overline{Rx}</math>
</indent>

where <math>\rightarrow</math> indicates the <link xlink:type="simple" xlink:href="../808/658808.xml">
material conditional</link>, according
to which "If <math>A</math> then <math>B</math>" can be understood to mean "<math>B</math> or <math>\overline{A}</math>".</p>
<p>

It has been argued by several authors that material implication does not fully
capture the meaning of "If <math>A</math> then <math>B</math>" (see the <link xlink:type="simple" xlink:href="../474/12857474.xml">
paradoxes of material implication</link>). "For every object, <math>x</math>, <math>x</math> is either 
black or not a raven" is <it>true</it> when there are no ravens. It is because of this
that "All ravens are black" is regarded as true when there are no ravens. Furthermore, the
arguments which Good and Maher used to criticize Nicod's criterion (see Good's Baby, above)
relied on this fact - that "All ravens are black" is highly probable when it is
highly probable that there are no ravens.</p>
<p>

Some approaches to the paradox have sought to find other ways of interpreting "If <math>A</math> then <math>B</math>" and "All <math>A</math> are <math>B</math>" which would
eliminate the perceived equivalence between "All ravens are black" and "All non-black
things are non-ravens."</p>
<p>

One such approach involves introducing a <link xlink:type="simple" xlink:href="../024/38024.xml">
many-valued logic</link> according to which "If <math>A</math> then <math>B</math>" has the truth-value <math>I</math>, meaning "Indeterminate" or "Inappropriate" when <math>A</math> is false<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2239%22])">39</ref>. In such a system, <link xlink:type="simple" xlink:href="../497/8556497.xml">
contraposition</link> is not automatically allowed: "If <math>A</math> then <math>B</math>" is not equivalent to "If <math>\overline{B}</math> then <math>\overline{A}</math>". Consequently, "All ravens are black" is not equivalent to "All non-black things are non-ravens".</p>
<p>

In this system, when contraposition occurs, the <link xlink:type="simple" xlink:href="../495/84495.xml">
modality</link> of the conditional involved
changes from the <link xlink:type="simple" xlink:href="../701/1625701.xml">
indicative</link> ("If that piece of butter <it>has been</it> heated to 32 C then it <it>has</it> melted") to the <link xlink:type="simple" xlink:href="../697/658697.xml">
counterfactual</link> ("If that piece of butter <it>had been</it> heated to 32 C then it <it>would have</it> melted"). According to this argument,
this removes the alleged equivalence which is necessary to conclude that yellow cows can inform us about ravens:</p>
<p>

<indent level="1">

In proper grammatical usage, a contrapositive argument ought not to be stated entirely in the indicative. Thus:
</indent>

<indent level="2">

From the fact that if this match is scratched it will light, it follows that if it does not light it was not scratched.
</indent>

<indent level="1">

is awkward. We should say:
</indent>

<indent level="2">

From the fact that if this match is scratched it will light, it follows that if it <it>were</it> not to light it <it>would</it> not have been scratched. ...
</indent>

<indent level="1">

One might wonder what effect this interpretation of the Law of Contraposition has on Hempel's paradox of confirmation. "If <math>a</math> is a raven then <math>a</math> is black" is equivalent to "If <math>a</math> were not black then <math>a</math> would not be a raven". Therefore whatever confirms the latter should also, by the Equivalence Condition, confirm the former. True, but yellow cows still cannot figure into the confirmation of "All ravens are black" because, in science, confirmation is accomplished by prediction, and predictions are properly stated in the indicative mood. It is senseless to ask what confirms a counterfactual.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2240%22])">40</ref>
</indent>

</p>
</ss1>
<ss1>
<st>
Differing Results of Accepting the Hypotheses</st>

<p>

Several commentators have observed that the propositions "All ravens are black" and "All non-black things are non-ravens" suggest different procedures for testing the hypotheses. E.g. Good writes<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2241%22])">41</ref>:</p>
<p>

<indent level="1">

As propositions the two statements are logically equivalent. But they have a different psychological effect on the experimenter. If he is asked to test whether all ravens are black he will look for a raven and then decide whether it is black. But if he is asked to test whether all non-black things are non-ravens he may look for a non-black object and then decide whether it is a raven.
</indent>

More recently, it has been suggested that "All ravens are black" and "All non-black things are non-ravens" can have different effects when <it>accepted</it><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2242%22])">42</ref>. The argument considers situations in which the total numbers or prevalences of ravens and black objects are unknown, but estimated. When the hypothesis "All ravens are black" is accepted,
according to the argument, the estimated number of black objects increases, while the
estimated number of ravens does not change.</p>
<p>

It can be illustrated by considering the situation of two people who have identical information regarding ravens and black objects, and who have identical estimates of the
numbers of ravens and black objects. For concreteness, suppose that there are 100 objects
overall, and, according to the information available to the people involved, each object is just as likely to be a non-raven as it is to be a raven, and just as likely to be black as it is to be non-black:</p>
<p>

<indent level="1">

<math>P(Ra)=\frac{1}{2} \ \ \ \ \ \ \ \ P(Ba)=\frac{1}{2}</math>
</indent>

and the propositions <math>Ra,\ Rb</math> are independent for different
objects <math>a</math>, <math>b</math> and so on. Then the estimated number
of ravens is 50; the estimated number of black things is 50; the estimated
number of black ravens is 25, and the estimated number of non-black ravens
(counterexamples to the hypotheses) is 25.</p>
<p>

One of the people performs a statistical test (e.g. a <link xlink:type="simple" xlink:href="../877/5657877.xml">
Neyman-Pearson</link> test or the comparison of the accumulated <link xlink:type="simple" xlink:href="../552/824552.xml">
weight of evidence</link> to a threshold) of the hypothesis that "All ravens are black", while the other tests the hypothesis that "All non-black objects 
are non-ravens". For simplicity, suppose that the evidence used for the test has nothing to do with the collection of 100 objects dealt with here. If the first person accepts the hypothesis that "All ravens are black" then, according to the argument, about 50 objects whose colors were previously in doubt (the ravens) are now thought to be black, while nothing different is thought about the remaining objects (the non-ravens).  Consequently, he should estimate the number of black ravens at 50, the number of black non-ravens at 25 and the number of non-black non-ravens at 25. By specifying these changes, this argument <it>explicitly</it> restricts the domain of "All ravens are black" to ravens.</p>
<p>

On the other hand, if the second person accepts the hypothesis that "All non-black objects are non-ravens", then the approximately 50 non-black objects about which it was uncertain whether each was a raven, will be thought to be non-ravens. At the same time, nothing different will be thought about the approximately 50 remaining objects (the black objects). Consequently, he should estimate the number of black ravens at 25, the number of black non-ravens at 25 and the number of non-black non-ravens at 50. According to this argument, since the two people disagree about their estimates after they have accepted the different hypotheses, accepting "All ravens are black" is not equivalent to accepting "All non-black things are non-ravens"; accepting the former means estimating more things to be black, while accepting the latter involves estimating more things to be non-ravens. Correspondingly, the argument goes, the former requires as evidence ravens which turn out to be black and the latter requires non-black things which turn out to be non-ravens<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2243%22])">43</ref>.</p>

</ss1>
<ss1>
<st>
Existential Presuppositions</st>

<p>

A number of authors have argued that propositions of the form "All <math>A</math> are <math>B</math>" presuppose that there are objects which are <math>A</math><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2244%22])">44</ref>. This analysis has been applied to the raven paradox<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2245%22])">45</ref>:</p>
<p>

<indent level="1">

... <math>H_1</math>: "All ravens are black" and <math>H_2</math>: "All nonblack things are nonravens" are not <it>strictly equivalent</it> ... due to their different existential presuppositions. Moreover, although <math>H_1</math> and <math>H_2</math> describe the same regularity - the nonexistence of nonblack ravens - they have different logical forms. The two hypotheses have different senses and incorporate different procedures for testing the regularity they describe. 
</indent>

A modified logic can take account of existential presuppositions using the presuppositional operator, `*'. For example,</p>
<p>

<indent level="2">

<math>\forall\ x,\ *Rx\rightarrow Bx</math>
</indent>

can denote "All ravens are black" while indicating that it is ravens and not non-black objects which are presupposed to exist in this example. </p>
<p>

<indent level="1">

... the logical form of each hypothesis distinguishes it with respect to its recommended type of supporting evidence: the possibly true substitution instances of each hypothesis relate to different types of objects. The fact that the two hypotheses incorporate different kinds of testing procedures is expressed in the formal language by prefixing the operator `*' to a different predicate. The presuppositional operator thus serves as a relevance operator as well. It is prefixed to the predicate `<math>x</math> is a raven' in <math>H_1</math> because the objects relevant to the testing procedure incorporated in "All raven are black" include only ravens; it is prefixed to the predicate `<math>x</math> is nonblack', in <math>H_2</math>, because the objects relevant to the testing procedure incorporated in "All nonblack things are nonravens" include only nonblack things. ... Using <link xlink:type="simple" xlink:href="../416/48416.xml">
Fregean</link> terms: whenever their presuppositions hold, the two hypotheses have the same <link xlink:type="simple" xlink:href="../755/244755.xml">
referent</link> (truth-value), but different <link xlink:type="simple" xlink:href="../755/244755.xml">
senses</link>; that is, they express two different ways to determine that truth-value<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2246%22])">46</ref>
</indent>

=Notes=</p>
<p>

<reflist>
<entry id="1">
Hempel, CG (1945) Studies in the Logic of Confirmation I. Mind Vol 54, No. 213 p.1 <weblink xlink:type="simple" xlink:href="http://www.jstor.org/sici?sici=0026-4423(194501)2%3A54%3A213%3C1%3ASITLOC%3E2.0.CO%3B2-0">
JSTOR</weblink></entry>
<entry id="2">
Hempel, CG (1945) Studies in the Logic of Confirmation II. Mind Vol 54, No. 214 p.97 <weblink xlink:type="simple" xlink:href="http://www.jstor.org/sici?sici=0026-4423(194504)2%3A54%3A214%3C97%3ASITLOC%3E2.0.CO%3B2-M">
JSTOR</weblink></entry>
<entry id="3">
Maher, P
(1999) Inductive Logic and the Ravens Paradox, Philosphoy of Science,
66, p.50
<weblink xlink:type="simple" xlink:href="http://www.jstor.org/sici?sici=0031-8248(199903)66%3A1%3C50%3AILATRP%3E2.0.CO%3B2-9">
JSTOR</weblink></entry>
<entry id="4">
Hempel, CG (1945) Studies in the Logic of Confirmation I. Mind Vol 54, No. 213 p.1 <weblink xlink:type="simple" xlink:href="http://www.jstor.org/sici?sici=0026-4423(194501)2%3A54%3A213%3C1%3ASITLOC%3E2.0.CO%3B2-0">
JSTOR</weblink></entry>
<entry id="5">
 Good, IJ (1960) The Paradox of Confirmation, <it>The British Journal for the Philosophy of Science</it>, Vol. 11, No. 42, 145-149 <weblink xlink:type="simple" xlink:href="http://links.jstor.org/sici?sici=0007-0882%28196008%2911%3A42%3C145%3ATPOC%3E2.0.CO%3B2-5">
JSTOR</weblink></entry>
<entry id="6">
Fitelson, B and Hawthorne, J (2006) How Bayesian Confirmation Theory 
Handles the Paradox of the Ravens, in Probability in Science, Chicago: Open Court <weblink xlink:type="simple" xlink:href="http://fitelson.org/ravens.pdf">
Link</weblink></entry>
<entry id="7">
Alexander, HG (1958) The Paradoxes of Confirmation, The British Journal for the Philosophy of Science, Vol. 9, No. 35, P. 227 <weblink xlink:type="simple" xlink:href="http://www.jstor.org/stable/685654?origin=JSTOR-pdf">
JSTOR</weblink></entry>
<entry id="8">
Hosaisson-Lindenbaum, J (1940) On Confirmation, The Journal of Symbolic Logic, Vol. 5, No. 4, p. 133 <weblink xlink:type="simple" xlink:href="http://www.jstor.org/action/showArticle?doi=10.2307/2268173">
JSTOR</weblink></entry>
<entry id="9">
Note: Good used "crow" instead of "raven", but "raven" has been used here throughout for consistency.</entry>
<entry id="10">
Chihara, (1981) Some Problems for Bayesian Confirmation Theory, British Journal for the Philosophy of Science, Vol. 38, No. 4 <weblink xlink:type="simple" xlink:href="http://bjps.oxfordjournals.org/cgi/reprint/38/4/551">
LINK</weblink></entry>
<entry id="11">
Earman, 1992 Bayes or Bust? A Critical Examination of Bayesian Confirmation Theory, MIT Press, Cambridge, MA.</entry>
<entry id="12">
Eells, 1982 Rational Decision and Causality. New York: Cambridge University Press</entry>
<entry id="13">
Gibson, 1969 On Ravens and Relevance and a Likelihood Solution of the Paradox of Confirmation, <weblink xlink:type="simple" xlink:href="http://www.jstor.org/stable/686720">
LINK</weblink></entry>
<entry id="14">
Hosaisson-Lindenbaum 1940</entry>
<entry id="15">
Howson, Urbach, 1993 Scientific Reasoning: The Bayesian Approach, Open Court Publishing Company</entry>
<entry id="17">
Hintikka, 1969</entry>
<entry id="16">
Mackie, 1963 The Paradox of Confirmation, Brit. J. Phil. Sci. Vol. 13, No. 52, p. 265 <weblink xlink:type="simple" xlink:href="http://bjps.oxfordjournals.org/cgi/content/citation/XIII/52/265">
LINK</weblink></entry>
<entry id="19">
Maher 1999</entry>
<entry id="18">
Humburg 1986, The solution of Hempel's raven paradox in Rudolf Carnap's system of inductive logic, Erkenntnis, Vol. 24, No. 1, pp</entry>
<entry id="21">
Vranas (2002) Hempel`s Raven Paradox: A Lacuna in the Standard Bayesian Solution <weblink xlink:type="simple" xlink:href="http://philsci-archive.pitt.edu/archive/00000688/00/hempelacuna.doc">
LINK</weblink></entry>
<entry id="20">
Fitelson 2006</entry>
<entry id="23">
 Maher, 1999</entry>
<entry id="22">
Maher, 1999</entry>
<entry id="25">
 Fitelson, 2006</entry>
<entry id="24">
 Fitelson, 2006</entry>
<entry id="27">
Hempel 1967, The White Shoe - No Red Herring, The British Journal for the Philosophy of Science, Vol. 18, No. 3, p. 239 <weblink xlink:type="simple" xlink:href="http://www.jstor.org/stable/686596">
JSTOR</weblink></entry>
<entry id="26">
Good 1967, The White Shoe is a Red Herring, British Journal for the Philosophy of Science, Vol. 17, No. 4, p322 <weblink xlink:type="simple" xlink:href="http://www.jstor.org/stable/686774">
JSTOR</weblink></entry>
<entry id="29">
Maher 2004, Probability Captures the Logic of Scientific Confirmation <weblink xlink:type="simple" xlink:href="http://patrick.maher1.net/pctl.pdf">
LINK</weblink></entry>
<entry id="28">
Good 1968, The White Shoe qua Red Herring is Pink, The British Journal for the Philosophy of Science, Vol. 19, No. 2, p. 156 <weblink xlink:type="simple" xlink:href="http://www.jstor.org/stable/686795">
JSTOR</weblink></entry>
<entry id="31">
Hintikka, 1969</entry>
<entry id="30">
Quine, WV (1969) Natural Kinds, in Ontological Relativity and other Essays. New York:Columbia university Press, p.114</entry>
<entry id="34">
Gaifman, H (1979) Subjective Probability, Natural Predicates and Hempel's Ravens, Erkenntnis, Vol. 14, p. 105 <weblink xlink:type="simple" xlink:href="http://www.springerlink.com/content/vw370x1531q54422/">
Springer</weblink></entry>
<entry id="35">
Popper, K. Realism and the Aim of Science, Routlege, 1992, p. 325</entry>
<entry id="32">
Hintakka J. 1969, Inductive Independence and the Paradoxes of Confirmation <weblink xlink:type="simple" xlink:href="http://books.google.com/books?id=pWtPcRwuacAC&amp;pg=PA24&amp;lpg=PA24&amp;ots=-1PKZt0Jbz&amp;lr=&amp;sig=EK2qqOZ6-cZR1P1ZKIsndgxttMs">
LINK</weblink></entry>
<entry id="33">
Scheffler I, Goodman NJ, Selective Confirmation and the Ravens, Journal of Philosophy, Vol. 69, No. 3, 1972 <weblink xlink:type="simple" xlink:href="http://www.jstor.org/stable/2024647">
JSTOR</weblink></entry>
<entry id="38">
Giere, RN (1970) An Orthodox Statistical Resolution of the Paradox of Confirmation, Philosophy of Science, Vol. 37, No. 3, p.354 <weblink xlink:type="simple" xlink:href="http://www.jstor.org/stable/186464">
JSTOR</weblink></entry>
<entry id="39">
Farrell RJ (1979) Material Implication, Confirmation and Counterfactuals <weblink xlink:type="simple" xlink:href="http://projecteuclid.org/DPubS/Repository/1.0/Disseminate?view=body&amp;id=pdf_1&amp;handle=euclid.ndjfl/1093882546">
LINK</weblink></entry>
<entry id="36">
Popper K, Miller D, (1983) A Proof of the Impossibility of Inductive Probability, Nature, Vol. 302, p. 687 <weblink xlink:type="simple" xlink:href="http://www.nature.com/nature/journal/v302/n5910/abs/302687a0.html">
Link</weblink></entry>
<entry id="37">
Neyman J, Pearson ES (1933) On the Problem of the Most Efficient Tests of Statistical Hypotheses, Phil. Transactions of the Royal Society of London. Series A, Vol. 231, p289 <weblink xlink:type="simple" xlink:href="http://www.jstor.org/stable/91247">
JSTOR</weblink></entry>
<entry id="42">
O'Flanagan (2008) Judgment <weblink xlink:type="simple" xlink:href="http://philsci-archive.pitt.edu/archive/00003932/01/judgment6.pdf">
LINK</weblink></entry>
<entry id="43">
O'Flanagan (2008)</entry>
<entry id="40">
Farrell (1979)</entry>
<entry id="41">
Good (1960)</entry>
<entry id="46">
Cohen (1987)</entry>
<entry id="44">
Strawson PF (1952) Introduction to Logical Theory, methuan &amp; Co. London, John Wiley &amp; Sons, New York</entry>
<entry id="45">
Cohen Y (1987) Ravens and Relevance, Erkenntnis <weblink xlink:type="simple" xlink:href="http://www.springerlink.com/content/hnn2lutn1066xw47/fulltext.pdf">
LINK</weblink></entry>
</reflist>
</p>

</ss1>
</sec>
<sec>
<st>
References</st>
<p>

<list>
<entry level="1" type="bullet">

 Franceschi, P. <it><weblink xlink:type="simple" xlink:href="http://www.univ-corse.fr/~franceschi/HP(GB).html">
The Doomsday Argument and Hempel's Problem</weblink></it>, English translation of a paper initially published in French in the Canadian Journal of Philosophy 29, 139-156, 1999, under the title <it>Comment l'Urne de Carter et Leslie se Dverse dans celle de Hempel''</it></entry>
<entry level="1" type="bullet">

 Hempel, C. G. <it>A Purely Syntactical Definition of Confirmation.</it> J. Symb. Logic 8, 122-143, 1943. </entry>
<entry level="1" type="bullet">

 Hempel, C. G. <it>Studies in Logic and Confirmation.</it> Mind 54, 1-26, 1945. </entry>
<entry level="1" type="bullet">

 Hempel, C. G. <it>Studies in Logic and Confirmation. II.</it> Mind 54, 97-121, 1945. </entry>
<entry level="1" type="bullet">

 Hempel, C. G. <it>Studies in the Logic of Confirmation.</it>  In Marguerite H. Foster and <weblink xlink:type="simple" xlink:href="http://www.bu.edu/philo/faculty/martin.html">
Michael L. Martin</weblink>, eds. <it>Probability, Confirmation, and Simplicity</it>.  New York: Odyssey Press, 1966.  145-183.</entry>
<entry level="1" type="bullet">

 Whiteley, C. H. <it>Hempel's Paradoxes of Confirmation.</it> Mind 55, 156-158, 1945.</entry>
</list>
</p>

</sec>
<sec>
<st>
 External links </st>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.mathacademy.com/pr/prime/articles/paradox_raven/index.asp">
PRIME Encyclopedia</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.logicalparadoxes.info/hempelsravens.html">
Hempel's Ravens, at Logical Paradoxes.Info</weblink></entry>
</list>
</p>


</sec>
</bdy>
</article>
