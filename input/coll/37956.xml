<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 15:39:45[mciao0827] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Best, worst and average case</title>
<id>37956</id>
<revision>
<id>237657379</id>
<timestamp>2008-09-11T06:05:32Z</timestamp>
<contributor>
<username>JavierMC</username>
<id>2901134</id>
</contributor>
</revision>
<categories>
<category>Computational complexity theory</category>
<category>Analysis of algorithms</category>
</categories>
</header>
<bdy>

In <link xlink:type="simple" xlink:href="../323/5323.xml">
computer science</link>, <b>best</b>, <b>worst</b> and <b>average cases</b> of a given <link xlink:type="simple" xlink:href="../775/775.xml">
algorithm</link> express what the <link xlink:type="simple" xlink:href="../365/1728365.xml">
resource</link> usage is <it>at least</it>, <it>at most</it> and <it>on average</it>, respectively. Usually the resource being considered is running time, but it could also be memory or other resource. <p>

In <link xlink:type="simple" xlink:href="../767/25767.xml">
real-time computing</link>, the <link xlink:type="simple" xlink:href="../051/1029051.xml">
worst-case execution time</link> is often of particular concern since it is important to know how much time might be needed <it>in the worst case</it> to guarantee that the algorithm would always finish on time.</p>
<p>

Average performance and worst-case performance are the most used in algorithm analysis. Less widely found is <link xlink:type="simple" xlink:href="../956/37956.xml">
best-case performance</link>, but it does have uses, for example knowing the best cases of individual tasks can be used to improve accuracy of an overall worst-case analysis.  <link xlink:type="simple" xlink:href="../784/328784.xml">
Computer scientist</link>s use <link xlink:type="simple" xlink:href="../889/15383889.xml">
probabilistic analysis</link> techniques, especially <link xlink:type="simple" xlink:href="../653/9653.xml">
expected value</link>, to determine expected running times.</p>

<sec>
<st>
 Best-case performance </st>
<p>

The term <it>best-case performance</it> is used in computer science to describe the way an algorithm behaves under optimal conditions. For example, a simple linear search on an array has a worst-case performance O(n) (for the case where the desired element is the last, so the algorithm has to check every element; see <link xlink:type="simple" xlink:href="../578/44578.xml">
Big O notation</link>), and average running time is O(n) (the average position of an element is the middle of the array, ie. at position n/2, and O(n/2)=O(n)), but in the best case the desired element is the first element in the array and the run time is O(1).</p>
<p>

Development and choice of algorithms is rarely based on best-case performance: most academic and commercial enterprises are more interested in improving <link xlink:type="simple" xlink:href="../956/37956.xml">
average performance</link> and <link xlink:type="simple" xlink:href="../956/37956.xml">
worst-case performance</link>.</p>

</sec>
<sec>
<st>
 Worst case versus average case performance </st>

<p>

Worst-case performance analysis and average case performance analysis have similarities, but usually require different tools and approaches in practice.</p>
<p>

Determining what <it>average <link xlink:type="simple" xlink:href="../264/41264.xml">
input</link></it> means is difficult, and often that average input has properties which make it difficult to characterise mathematically (consider, for instance, algorithms that are designed to operate on <link xlink:type="simple" xlink:href="../701/27701.xml">
string</link>s of text). Similarly, even when a sensible description of a particular "average case" (which will probably only be applicable for some uses of the algorithm) is possible, they tend to result in more difficult to analyse equations. </p>
<p>

Worst-case analysis has similar problems, typically it is impossible to determine the exact worst-case scenario. Instead, a scenario is considered which is at least as bad as the worst case. For example, when analysing an algorithm, it may be possible to find the longest possible path through the algorithm (by considering maximum number of <link xlink:type="simple" xlink:href="../459/45459.xml#xpointer(//*[./st=%22Loops%22])">
loops</link>, for instance) even if it is not possible to determine the exact input that could generate this. Indeed, such an input may not exist. This leads to a <it>safe</it> analysis (the worst case is never underestimated), but which is <it>pessimistic</it>, since no input might require this path. </p>
<p>

Alternatively, a scenario which is thought to be close to (but not necessarily worse than) the real worst case may be considered. This may lead to an <it>optimistic</it> result, meaning that the analysis may actually underestimate the true worst case. </p>
<p>

In some situations it may be necessary to use a pessimistic analysis in order to guarantee safety. Often however, a pessimistic analysis may be too pessimistic, so an analysis that gets closer to the real value but may be optimistic (perhaps with some known low probability of failure) can be a much more practical approach.</p>
<p>

When analyzing algorithms which often take a small time to complete, but periodically require a much larger time, <link xlink:type="simple" xlink:href="../683/236683.xml">
amortized analysis</link> can be used to determine the worst-case running time over a (possibly infinite) series of <link xlink:type="simple" xlink:href="../245/4140245.xml">
operations</link>. This <b>amortized worst-case</b> cost can be much closer to the average case cost, while still providing a guaranteed upper limit on the running time.</p>

</sec>
<sec>
<st>
 Practical consequences </st>

<p>

Many problems with bad worst-case performance have good average-case performance.  For problems we want to solve, this is a good thing: we can hope that the particular instances we care about are average.  For <link xlink:type="simple" xlink:href="../432/18934432.xml">
cryptography</link>, this is very bad: we want typical instances of a cryptographic problem to be hard.  Here methods like <link xlink:type="simple" xlink:href="../266/3087266.xml">
random self-reducibility</link> can be used for some specific problems to show that the worst case is no harder than the average case, or, equivalently, that the average case is no easier than the worst case.</p>

</sec>
<sec>
<st>
 Examples </st>

<p>

<list>
<entry level="1" type="bullet">

 In the worst case, linear search on an array must visit every element once. It does this if either the element being sought is the last element in the list, or if the element being sought is not in the list. However, on average, assuming the input is in the list, it visits only <it>n</it>/2 elements.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 Applying <link xlink:type="simple" xlink:href="../205/15205.xml">
insertion sort</link> on <it>n</it> elements. On average, half the elements in an array <it>A</it>1 ... A<it>j</it>-1 are less than an element Aj, and half are greater. Therefore we check half the subarray so <it>tj</it> = <it>j</it>/2.  Working out the resulting average case running time yields a quadratic function of the input size, just like the worst-case running time.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 The popular <link xlink:type="simple" xlink:href="../442/28442.xml">
sorting algorithm</link> <algorithm wordnetid="105847438" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../249/3268249.xml">
Quicksort</link></algorithm>
 has an average case performance of O(n log n), which contributes to making it a very fast algorithm in practice. But given a worst-case input, its performance can degrade to O(<it>n</it>2).</entry>
</list>
</p>

</sec>
<sec>
<st>
See also </st>

<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../442/28442.xml">
Sorting algorithm</link> - an area where there is a great deal of performance analysis of various algorithms.</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../006/16011006.xml">
Worst case circuit analysis</link></entry>
</list>
</p>


</sec>
</bdy>
</article>
