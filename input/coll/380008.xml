<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 16:56:09[mciao0826] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Probably approximately correct learning</title>
<id>380008</id>
<revision>
<id>244652932</id>
<timestamp>2008-10-11T21:57:04Z</timestamp>
<contributor>
<username>JonathanWilliford</username>
<id>7799841</id>
</contributor>
</revision>
<categories>
<category>Machine learning</category>
</categories>
</header>
<bdy>

In <link xlink:type="simple" xlink:href="../537/387537.xml">
computational learning theory</link>, <b>probably approximately correct learning (PAC learning)</b> is a framework for mathematical analysis of <link xlink:type="simple" xlink:href="../488/233488.xml">
machine learning</link>. It was proposed in 1984 by <physical_entity wordnetid="100001930" confidence="0.8">
<peer wordnetid="109626238" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<honoree wordnetid="110183757" confidence="0.8">
<laureate wordnetid="110249011" confidence="0.8">
<colleague wordnetid="109935990" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<acquirer wordnetid="109764201" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<recipient wordnetid="109627906" confidence="0.8">
<associate wordnetid="109816771" confidence="0.8">
<link xlink:type="simple" xlink:href="../751/3006751.xml">
Leslie Valiant</link></associate>
</recipient>
</scientist>
</acquirer>
</causal_agent>
</colleague>
</laureate>
</honoree>
</person>
</peer>
</physical_entity>
.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref><p>

In this framework, the learner receives samples and must select a generalization function (called the <it>hypothesis</it>) from a certain class of possible functions. The goal is that, with high probability (the "probably" part), the selected function will have low <link xlink:type="simple" xlink:href="../249/2456249.xml">
generalization error</link> (the "approximately correct" part). The learner must be able to learn the concept given any arbitrary approximation ratio, probability of success, or <link xlink:type="simple" xlink:href="../455/2690455.xml">
distribution of the samples</link>. </p>
<p>

The model was later extended to treat noise (misclassified samples).</p>
<p>

An important innovation of the PAC framework is the introduction of <link xlink:type="simple" xlink:href="../132/6132.xml">
complexity theory</link> concepts to machine learning. In particular, the learner is expected to find efficient functions (time and space requirements bounded to a <link xlink:type="simple" xlink:href="../000/23000.xml">
polynomial</link> of the example size), and the learner itself must implement an efficient procedure (requiring an example count bounded to a polynomial of the concept size, modified by the approximation and <link xlink:type="simple" xlink:href="../968/44968.xml">
likelihood</link> bounds).  </p>

<sec>
<st>
 Definitions and Terminology </st>

<p>

In order to give the definition for something that is PAC-learnable, we first have to introduce some terminology.  For more exact definitions, see <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref>.</p>
<p>

For the following definitions, two examples will be used.  The first is the problem of character recognition given an array of <math>n</math> bits.  The other example is the problem of finding an interval that will correctly classify points within the interval as positive and the points outside of the range as negative.</p>
<p>

Let <math>X</math> be a set call the <b>instance space</b> or the encoding of all the samples.  In the character recognition problem, the instance space is <math>X=\{0,1\}^n</math>.  In the interval problem the instance space is <math>X=\mathbb{R}</math>, where <math>\mathbb{R}</math> denotes the set of all real numbers.</p>
<p>

A <b>concept</b> is a subset <math>c \subset X</math>.  One concept is the set of all of the bits that encode for the letter "P" in <math>X=\{0,1\}^n</math>.  An example concept from the second example is the set of all of the numbers between <math>\pi/2</math> and <math>\sqrt{10}</math>.  A <b>concept class</b> is a set of concepts over <math>X</math>.  This could be the set of all of the array of bits that are skeletonized 4-connected (width of the font is 1).</p>
<p>

Let <math>EX(c,D)</math> be a procedure draws an example, <math>x</math>, using a probability distribution <math>D</math> and gives the correct label <math>c(x)</math>.</p>
<p>

Say that there is an algorithm that given access to <math>EX(c,D)</math> and inputs <math>\epsilon</math> and <math>\delta</math> that, with probability at least <math>1-\delta</math>, <math>A</math> outputs a hypothesis <math>h \in C</math> that has error less than or equal to <math>\epsilon</math> with examples drawn from <math>X</math> with the distribution <math>D</math>.  If there is such an algorithm for
every concept <math>c \in C</math>, for every distribution <math>D</math> over <math>X</math>, and for all <math>0&amp;lt;\epsilon&amp;lt;1/2</math> and <math>0&amp;lt;\delta&amp;lt;1/2</math> then <math>C</math> is <b>PAC learnable</b>.</p>

</sec>
<sec>
<st>
 References </st>
<p>

<reflist>
<entry id="1">
L. Valiant. <it><weblink xlink:type="simple" xlink:href="http://web.mit.edu/6.435/www/Valiant84.pdf">
A theory of the learnable.</weblink></it> Communications of the ACM, 27, 1984.</entry>
<entry id="2">
Kearns, U. Vazirani. An Introduction to Computational Learning Theory. MIT Press, 1994. A textbook. pg. 1-12.</entry>
</reflist>
</p>

</sec>
<sec>
<st>
 Further reading </st>
<p>

<list>
<entry level="1" type="bullet">

 M. Kearns, U. Vazirani. <it>An Introduction to Computational Learning Theory.</it> MIT Press, 1994. A textbook.</entry>
<entry level="1" type="bullet">

 D. Haussler. <weblink xlink:type="simple" xlink:href="http://citeseer.ist.psu.edu/haussler92part.html">
Overview of the Probably Approximately Correct (PAC) Learning Framework</weblink>. An introduction to the topic.</entry>
</list>
</p>





</sec>
</bdy>
</article>
