<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 16:58:24[mciao0828] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Algorithmic learning theory</title>
<id>383480</id>
<revision>
<id>201610385</id>
<timestamp>2008-03-28T16:56:50Z</timestamp>
<contributor>
<username>Michael Hardy</username>
<id>4626</id>
</contributor>
</revision>
<categories>
<category>Articles lacking in-text citations</category>
<category>Articles with invalid date parameter in template</category>
<category>Learning theory (education) </category>
<category>Machine learning</category>
<category>Articles lacking reliable references from March 2008</category>
</categories>
</header>
<bdy>

<b>Algorithmic learning theory</b> (or <b>algorithmic inductive inference</b>) is a framework for <link xlink:type="simple" xlink:href="../488/233488.xml">
machine learning</link>.<p>

<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-style" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="50px" src="Text_document_with_red_question_mark.svg">
</image>
</p>
</col>
<col style="" class="mbox-text">
 This article or section includes a  or , but its sources remain unclear because it lacks <b>.</b>
You can  this article by introducing more precise citations . <it>(March 2008)''</it></col>
</row>
</table>


<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-content" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="50px" src="Question_book-new.svg">
</image>
</p>
</col>
<col style="" class="mbox-text">
 <b>This article or section relies largely or entirely upon a .</b>
Please help <weblink xlink:type="simple" xlink:href="http://localhost:18088/wiki/index.php?title=Algorithmic_learning_theory&amp;action=edit">
improve this article</weblink> by introducing appropriate of additional sources. <it>(March 2008)''</it></col>
</row>
</table>

</p>
<p>

The framework was introduced in <link>
E. Mark Gold</link>'s seminal paper "<language wordnetid="106282651" confidence="0.8">
<link xlink:type="simple" xlink:href="../933/1299933.xml">
Language identification in the limit</link></language>
". The objective of <link xlink:type="simple" xlink:href="../422/8642422.xml">
language identification</link> is for a machine running one program to be capable of developing another program by which any given sentence can be tested to determine whether it is "grammatical" or "ungrammatical". The language being learned need not be <link xlink:type="simple" xlink:href="../916/8569916.xml">
English</link> or any other <link xlink:type="simple" xlink:href="../173/21173.xml">
natural language</link> - in fact the definition of "grammatical" can be absolutely anything known to the tester.</p>
<p>

In the framework of algorithmic learning theory, the tester gives the learner an example sentence at each step, and the learner responds with a <link xlink:type="simple" xlink:href="../281/14281.xml">
hypothesis</link>, which is a suggested <link xlink:type="simple" xlink:href="../783/5783.xml">
program</link> to determine grammatical correctness. It is required of the tester that every possible sentence (grammatical or not) appears in the list eventually, but no particular order is required. It is required of the learner that at each step the hypothesis must be correct for all the sentences so far.</p>
<p>

A particular learner is said to be able to "learn a language in the limit" if there is a certain number of steps beyond which its hypothesis no longer changes. At this point it has indeed learned the language, because every possible sentence appears somewhere in the sequence of inputs (past or future), and the hypothesis is correct for all inputs (past or future), so the hypothesis is correct for every sentence. The learner is not required to be able to tell when it has reached a correct hypothesis, all that is required is that it be true.</p>
<p>

Gold showed that any language which is defined by a <invention wordnetid="105633385" confidence="0.8">
<know-how wordnetid="105616786" confidence="0.8">
<method wordnetid="105660268" confidence="0.8">
<link xlink:type="simple" xlink:href="../403/30403.xml">
Turing machine</link></method>
</know-how>
</invention>
 program can be learned in the limit by another <link xlink:type="simple" xlink:href="../621/30621.xml">
Turing-complete</link> machine using <link xlink:type="simple" xlink:href="../115/212115.xml">
enumeration</link>. This is done by the learner testing all possible Turing machine programs in turn until one is found which is correct so far - this forms the hypothesis for the current step. Eventually, the correct program will be reached, after which the hypothesis will never change again (but note that the learner does not know that it won't need to change).</p>
<p>

Gold also showed that if the learner is given only positive examples (that is, only grammatical sentences appear in the input, not ungrammatical sentences), then the language can only be guaranteed to be learned in the limit if there are only a <link xlink:type="simple" xlink:href="../742/11742.xml">
finite</link> number of possible sentences in the language (this is possible if, for example, sentences are known to be of limited length).</p>
<p>

Language identification in the limit is a very theoretical model. It does not allow for limits of <link xlink:type="simple" xlink:href="../263/192263.xml">
runtime</link> or <link xlink:type="simple" xlink:href="../847/25847.xml">
computer memory</link> which can occur in practice, and the enumeration method may fail if there are errors in the input. However the framework is very powerful, because if these strict conditions are maintained, it allows the learning of any program known to be computable. This is because a Turing machine program can be written to mimic any program in any conventional <link xlink:type="simple" xlink:href="../015/23015.xml">
programming language</link>. See <link xlink:type="simple" xlink:href="../854/6854.xml">
Church-Turing thesis</link>.</p>
<p>

Other frameworks of learning consider a much more restricted class of function than Turing machines, but complete the learning more quickly (in <link xlink:type="simple" xlink:href="../576/44576.xml">
polynomial time</link>).
An example of such a framework is <link xlink:type="simple" xlink:href="../008/380008.xml">
Probably approximately correct learning</link>.</p>

<sec>
<st>
External links</st>

<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.isrl.uiuc.edu/~amag/langev/paper/gold67limit.html">
Gold, E., "Language Identification in the Limit," Information and Control, 10, pp. 447-474, 1967.</weblink> (The original paper)</entry>
</list>
</p>

</sec>
</bdy>
</article>
