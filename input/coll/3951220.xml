<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 20:54:06[mciao0827] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Computational theory of mind</title>
<id>3951220</id>
<revision>
<id>243841445</id>
<timestamp>2008-10-08T07:58:46Z</timestamp>
<contributor>
<username>Taxa</username>
<id>5589890</id>
</contributor>
</revision>
<categories>
<category>All articles with unsourced statements</category>
<category>Articles lacking in-text citations</category>
<category>Philosophy of mind</category>
<category>Articles with unsourced statements since July 2008</category>
</categories>
</header>
<bdy>

<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-content" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="40x40px" src="Ambox_content.png">
</image>
</p>
</col>
<col style="" class="mbox-text">
 <b>This article or section is missing  or needs .</b>
Using helps guard against copyright violations and factual inaccuracies. <it>(July 2008)''</it></col>
</row>
</table>

<p>

<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-style" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="50px" src="Text_document_with_red_question_mark.svg">
</image>
</p>
</col>
<col style="" class="mbox-text">
 This article or section includes a  or , but its sources remain unclear because it lacks <b>.</b>
You can  this article by introducing more precise citations .</col>
</row>
</table>

</p>
<p>

In <link xlink:type="simple" xlink:href="../483/6880483.xml">
philosophy</link>, the <b>computational theory of mind</b> is the view that the human <link xlink:type="simple" xlink:href="../378/19378.xml">
mind</link> is best conceived as an <link xlink:type="simple" xlink:href="../456/465456.xml">
information processing system</link> and that <link xlink:type="simple" xlink:href="../080/37080.xml">
thought</link> is a form of <link xlink:type="simple" xlink:href="../926/5926.xml">
computation</link>. The theory was proposed in its modern form by <person wordnetid="100007846" confidence="0.9508927676800064">
<philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../233/75233.xml">
Hilary Putnam</link></philosopher>
</person>
 in 1961 and developed by <philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../994/427994.xml">
Jerry Fodor</link></philosopher>
 in the 60s and 70s.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref> This view is common in modern <link xlink:type="simple" xlink:href="../961/5961.xml">
cognitive psychology</link> and is presumed by theorists of <link xlink:type="simple" xlink:href="../703/9703.xml">
evolutionary psychology</link>.</p>
<p>

The computational theory of mind is a philosophical concept that the mind functions as a computer or symbol manipulator. The theory is that the mind computes input from the natural world to create outputs in the form of further mental or physical states. A <link xlink:type="simple" xlink:href="../926/5926.xml">
computation</link> is the process of taking input and following a step by step <link xlink:type="simple" xlink:href="../775/775.xml">
algorithm</link> to get a specific output. The computational theory of mind claims that there are certain aspects of the mind that follow step by step processes to compute representations of the world, however this theory does not claim that computation is sufficient for thought.</p>
<p>

The computational theory of mind requires <link xlink:type="simple" xlink:href="../211/348211.xml">
representation</link> because 'input' into a computation comes in the form of symbols or representations of other objects. A computer cannot compute an actual object, it must interpret and represent the object in some form and then compute the representation. The computational theory of mind is related to the representational theory of mind in that they both require that mental states are representations. However the two theories differ in that the represtenational theory claims that all mental states are representations while the computational theory leaves open that certain mental states, such as pain or 
depression, may not be representational and therefore may not be suitable for a computational treatment. These non-representational mental states are known as <link xlink:type="simple" xlink:href="../965/165965.xml">
qualia</link>. The computational theory of mind is also related to the <link xlink:type="simple" xlink:href="../038/652038.xml">
language of thought</link>. The language of thought theory allows the mind to process more complex representations with the help of semantics. (See below in semantics of mental states).</p>

<sec>
<st>
"Computer metaphor"</st>
<p>

Computational theory of mind is not the same as the computer metaphor, according to which the mind literally works like a computer.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref> Computational theory just uses some of the same principles as those found in digital computing.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref></p>
<p>

'Computer' is not meant to mean a modern day electronic computer. Rather a computer is a symbol manipulator that follows step by step functions to compute input and form output. <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../208/1208.xml">
Alan Turing</link></scientist>
</person>
 describes this type of computer in his concept of a <link xlink:type="simple" xlink:href="../403/30403.xml">
Turing Machine</link>.</p>

</sec>
<sec>
<st>
 Causal picture of thoughts </st>
<p>

At the heart of the Computational Theory of Mind is the idea that thoughts are a form of computation, and a computation is by definition a systematic set of laws for the relations among representations. Meaning that a mental state represents something if and only if there is some causal correlation between the mental state and that particular thing. An example would be seeing dark clouds and thinking “clouds mean rain”, there is a correlation between the thought of the clouds and rain, as the clouds causing rain.  This is known as Natural Meaning. Conversely, there is another side to the causality of thoughts and that is the non-natural representation of thoughts. An example would be seeing a red traffic light and thinking “red means stop”, there is nothing about the color red that indicates it represents stopping, and thus is just a convention that has been invented, similar to languages and their abilities to form representations.</p>

</sec>
<sec>
<st>
 Semantics of mental states </st>
<p>

The computational theory of mind states that the mind functions as a symbolic operator, and that mental representations are symbolic representations; just as the <link xlink:type="simple" xlink:href="../107/29107.xml">
semantics</link> of language are the features of words and sentences that relate to their meaning, the semantics of mental states are those meanings of representations, the definitions of the ‘words’ of the <link xlink:type="simple" xlink:href="../038/652038.xml">
language of thought</link>. If these basic mental states can have a particular meaning just as words in a language do, then this means that more complex mental states (thoughts) can be created, even if they have never been encountered before. Just as new sentences that are read can be understood even if they have never been encountered before, as long as the basic components are understood, and it is syntactically correct. For example: “I have eaten plum pudding every day of this fortnight.” While it's doubtful many have seen this particular configuration of words, nonetheless most readers should be able to glean an understanding of this sentence because it is syntactically correct and the constituent parts are understood.</p>

</sec>
<sec>
<st>
 Rejecting the Computational Theory of Mind </st>

<p>

There are arguments against the Computational Theory of Mind.  Some of the most compelling encompass the physical realm of a computational process.  Gallistel writes in Learning and Representation about some of the implications of a truly computational system of the mind.  Essentially Gallistel is concerned with the limits of thermodynamics within the circuits of the brain.  With the high volume of information, and the low level of lost material necessary, we have to ask where the energy comes from and how the heat would be dissipated.</p>
<p>

It can also be argued that not all thoughts are actually computable.  The idea that a thought (or thought process) can be broken down into a number-based system (such as would be used in a computer; a Turing Machine) is necessary to the computational theory of mind.  If it is not true that all thoughts can be reduced to numbers, then the computational theory of mind cannot be all true.  Herein lies another objection to the theory.  Is it even possible that the computational model constitutes learning?  </p>
<p>

John Searle has offered a thought experiment known as the Chinese Room that demonstrates this problem.  Imagine that there is a man in a room with no way of communicating to anyone or anything outside of the room except for a piece of paper that is passed under the door.  With the paper, he is to use a series of books provided to decode and “answer” what is on the paper.  The symbols are all in Chinese, and all the man knows is where to look in the books, which then tell him what to write in response.  It just so happens that this generates a conversation that the Chinese man outside of the room can actually understand, but can our man in the room really be said to understand it?  This is essentially what the CTM presents us with; a model in which the mind simply decodes symbols and outputs more symbols.  It is argued that perhaps this is not real learning or thinking at all.  </p>
<p>

Additionally, Penrose has noted the fact that the human mind seems to have a capacity to understand, use, and discover mathematical intricacies that computers have yet to accomplish, though one could argue that it is only a matter of time until computers too are at this level.</p>

</sec>
<sec>
<st>
Prominent scholars</st>
<p>

<list>
<entry level="1" type="bullet">

 <person wordnetid="100007846" confidence="0.9508927676800064">
<philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../756/8756.xml">
Daniel Dennett</link></philosopher>
</person>
 proposed the "Multiple Drafts" hypothesis, in which consciousness seems linear but is actually blurry and gappy, distributed over space and time in the brain. Consciousness is the computation, there is no extra step or "Cartesian Theater" in which you become conscious of the computation.</entry>
<entry level="1" type="bullet">

 <philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../994/427994.xml">
Jerry Fodor</link></philosopher>
 argues that mental states, such as beliefs and desires, are relations between individuals and mental representations. He maintains that these representations can only be correctly explained in terms of a language of thought (LOT) in the mind. Further, this language of thought itself is codified in the brain, not just a useful explanatory tool. Fodor adheres to a species of functionalism, maintaining that thinking and other mental processes consist primarily of computations operating on the syntax of the representations that make up the language of thought.</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../031/417031.xml">
David Marr</link> proposed that cognitive processes have three levels of description: the computational level (which describes that computational problem (i.e., input/output mapping) computed by the cognitive process); the algorithmic level (which presents the algorithm used for computing the problem postulated at the computational level); and the implementational level (which describes the physical implementation of the algorithm postulated at the algorithmic level in biological matter, e.g. the brain). (Marr 1981)</entry>
<entry level="1" type="bullet">

 <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<psychologist wordnetid="110488865" confidence="0.8">
<link xlink:type="simple" xlink:href="../481/2405481.xml">
Ulric Neisser</link></psychologist>
</scientist>
</causal_agent>
</person>
</physical_entity>
 coined the term 'cognitive psychology' in his book published in 1967 (Cognitive Psychology), wherein Neisser characterizes people as dynamic information-processing systems whose mental operations might be described in computational terms.</entry>
<entry level="1" type="bullet">

 <person wordnetid="100007846" confidence="0.9508927676800064">
<writer wordnetid="110794014" confidence="0.9173553029164789">
<link xlink:type="simple" xlink:href="../340/44340.xml">
Steven Pinker</link></writer>
</person>
 described a "language instinct," an evolved, built-in capacity to learn speech (if not writing). </entry>
<entry level="1" type="bullet">

 <person wordnetid="100007846" confidence="0.9508927676800064">
<philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../233/75233.xml">
Hilary Putnam</link></philosopher>
</person>
 proposed <link xlink:type="simple" xlink:href="../308/461308.xml">
functionalism</link> to describe consciousness, asserting that it is the computation that equates to consciousness, regardless of whether the computation is operating in a brain, in a computer, or in a "brain in a vat."</entry>
</list>
</p>

</sec>
<sec>
<st>
Alternative Theories</st>
<p>

<list>
<entry level="1" type="bullet">

 Classical <link xlink:type="simple" xlink:href="../047/317047.xml">
associationism</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../636/263636.xml">
Connectionism</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../997/988997.xml">
Situated cognition</link></entry>
<entry level="1" type="bullet">

 <event wordnetid="100029378" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<link xlink:type="simple" xlink:href="../714/1196714.xml">
Memory-prediction framework</link></activity>
</procedure>
</psychological_feature>
</act>
</event>
</entry>
</list>
</p>

</sec>
<sec>
<st>
See also</st>
<p>

<list>
<entry level="1" type="bullet">

 <process wordnetid="105701363" confidence="0.8">
<thinking wordnetid="105770926" confidence="0.8">
<explanation wordnetid="105793000" confidence="0.8">
<theory wordnetid="105989479" confidence="0.8">
<higher_cognitive_process wordnetid="105770664" confidence="0.8">
<link xlink:type="simple" xlink:href="../565/313565.xml">
Cognitivism</link></higher_cognitive_process>
</theory>
</explanation>
</thinking>
</process>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../483/6880483.xml">
Philosophy of mind</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../494/3129494.xml">
Functionalism</link></entry>
</list>
</p>

</sec>
<sec>
<st>
Notes</st>

<p>

<reflist>
<entry id="1">
<link>
Horst, Steven</link>, (2005) <weblink xlink:type="simple" xlink:href="http://plato.stanford.edu/entries/computational-mind/">
"The Computational Theory of Mind"</weblink> in <it>The Stanford Encyclopedia of Philosophy''</it></entry>
<entry id="2">
<person wordnetid="100007846" confidence="0.9508927676800064">
<writer wordnetid="110794014" confidence="0.9173553029164789">
<link xlink:type="simple" xlink:href="../340/44340.xml">
Pinker, Steven</link></writer>
</person>
. <work wordnetid="104599396" confidence="0.8">
<product wordnetid="104007894" confidence="0.8">
<creation wordnetid="103129123" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<book wordnetid="106410904" confidence="0.8">
<publication wordnetid="106589574" confidence="0.8">
<link xlink:type="simple" xlink:href="../363/1421363.xml">
The Blank Slate</link></publication>
</book>
</artifact>
</creation>
</product>
</work>
. New York: Penguin. 2002</entry>
</reflist>
</p>

</sec>
<sec>
<st>
References</st>
<p>

<list>
<entry level="1" type="bullet">

 <philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../994/427994.xml">
Jerry Fodor</link></philosopher>
 (1975) <it>The <unit_of_measurement wordnetid="113583724" confidence="0.8">
<definite_quantity wordnetid="113576101" confidence="0.8">
<link xlink:type="simple" xlink:href="../038/652038.xml">
Language of thought</link></definite_quantity>
</unit_of_measurement>
</it>.</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../031/417031.xml">
David Marr</link> (1981) <it>Vision</it>. </entry>
<entry level="1" type="bullet">

 <philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../182/7644182.xml">
Zenon Pylyshyn</link></philosopher>
 (1984) <weblink xlink:type="simple" xlink:href="http://mitpress.mit.edu/catalog/item/default.asp?ttype=2&amp;tid=5602">
<it>Computation and Cognition''</it></weblink></entry>
<entry level="1" type="bullet">

 <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<academician wordnetid="109759069" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<adult wordnetid="109605289" confidence="0.8">
<professional wordnetid="110480253" confidence="0.8">
<educator wordnetid="110045713" confidence="0.8">
<link xlink:type="simple" xlink:href="../426/179426.xml">
Stevan Harnad</link></educator>
</professional>
</adult>
</scientist>
</academician>
</causal_agent>
</person>
</physical_entity>
 (1994) <weblink xlink:type="simple" xlink:href="http://cogprints.org/1592/">
Computation Is Just Interpretable Symbol Manipulation: Cognition Isn't</weblink>. <it>Minds and Machines</it> 4: 379-390.</entry>
<entry level="1" type="bullet">

 <person wordnetid="100007846" confidence="0.9508927676800064">
<writer wordnetid="110794014" confidence="0.9173553029164789">
<link xlink:type="simple" xlink:href="../340/44340.xml">
Steven Pinker</link></writer>
</person>
 (1997) <weblink xlink:type="simple" xlink:href="http://pinker.wjh.harvard.edu/books/htmw/index.html">
<it>How the Mind Works''</it></weblink>.</entry>
<entry level="1" type="bullet">

   Tim Crane (2003). The Mechanical Mind: A philosophical introduction to minds, machines, and mental representation, New York, NY: Routledge</entry>
<entry level="1" type="bullet">

 <link>
C.R. Gallistel</link> <it>Learning and Representation</it>.</entry>
</list>
</p>

</sec>
<sec>
<st>
External links</st>


<p>

<list>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://consc.net/papers/computation.html">
A Computational Foundation for the Study of Cognition</weblink> by <philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../221/258221.xml">
David Chalmers</link></philosopher>
 </entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://209.85.165.104/search?q=cache:1ljcyvG8PTEJ:www.cs.bilkent.edu.tr/~david/papers/computationalism.doc+computationalism&amp;hl=en&amp;gl=us&amp;ct=clnk&amp;cd=3">
Computationalism: The Very Idea</weblink>, an overview of computationalism by David Davenport. </entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://plato.stanford.edu/entries/computational-mind/">
The Stanford Encyclopedia of Philosophy's entry on the computational theory</weblink></entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://homepage.mac.com/blinkcentral/">
The Cognitive Process Consciousness model of the Mind</weblink></entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://cogweb.ucla.edu/Abstracts/Fodor_00.html">
Fodor, The Mind Doesn't Work that Way</weblink></entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://consc.net/online2.html#comp">
Collection of links to online papers</weblink></entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://academia.wikia.com/wiki/A_Method_for_Simulating_the_Process_of_Logical_Human_Thought#Inspiration_and_Motivation_-_Why_simulate_logical_human_thought.3F">
Logical Human Thought</weblink></entry>
</list>

</p>

</sec>
</bdy>
</article>
