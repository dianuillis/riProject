<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 20:50:14[mciao0826] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<event  confidence="0.8" wordnetid="100029378">
<rule  confidence="0.8" wordnetid="105846932">
<act  confidence="0.8" wordnetid="100030358">
<psychological_feature  confidence="0.8" wordnetid="100023100">
<procedure  confidence="0.8" wordnetid="101023820">
<activity  confidence="0.8" wordnetid="100407535">
<algorithm  confidence="0.8" wordnetid="105847438">
<header>
<title>Memetic algorithm</title>
<id>3989208</id>
<revision>
<id>238454799</id>
<timestamp>2008-09-14T22:33:20Z</timestamp>
<contributor>
<username>SmackBot</username>
<id>433328</id>
</contributor>
</revision>
<categories>
<category>Evolutionary algorithms</category>
<category>Articles with invalid date parameter in template</category>
<category>Wikify from September 2008</category>
<category>All pages needing to be wikified</category>
</categories>
</header>
<bdy>

<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-style" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="50px" src="Wikitext.svg">
</image>
</p>
</col>
<col style="" class="mbox-text">
 <b>Please  this article or section.</b>
Help <weblink xlink:type="simple" xlink:href="http://localhost:18088/wiki/index.php?title=Memetic_algorithm&amp;action=edit">
improve this article</weblink> by adding  . <it>(September 2008)''</it></col>
</row>
</table>


<b>Memetic algorithms</b> (MA) represent one of the recent growing areas of research in evolutionary computation. The term MA is now widely used as a synergy of evolutionary or any population-based approach with separate individual learning or local improvement procedures for problem search. Quite often, MA are also referred to in the literature as Baldwinian EAs, Lamarckian EAs, cultural algorithms or genetic local search.
<sec>
<st>
Introduction</st>

<p>

The theory of “Universal Darwinism” was coined by Richard
Dawkins <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref> in 1983 to provide a unifying framework governing
the evolution of any complex systems. In particular, “Universal
Darwinism” suggests that evolution is not exclusive to biological
systems, i.e., it is not confined to the narrow context of the genes,
but applicable to any complex systems that exhibit the principles of
inheritance, variation and selection, thus fulfilling the traits of an evolving
system. For example, the new science of memetics represents
the mind-universe analogue to genetics in culture evolution that
stretches across the fields of biology, cognition and psychology,
which has attracted significant attention in the last decades. The
term “meme” was also introduced and defined by Dawkins <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref> in
1976 as “the basic unit of cultural transmission, or imitation”, and
in the English Oxford Dictionary as “an element of culture that
may be considered to be passed on by non-genetic means”.</p>
<p>

Inspired by both Darwinian principles of natural evolution and
Dawkins’ notion of a meme, the term “Memetic Algorithm” (MA)
was first introduced by Moscato in his technical report <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref> in 1989
where he viewed MA as being close to a form of population-based
hybrid genetic algorithm (GA) coupled with an individual learning
procedure capable of performing local refinements. The metaphorical
parallels, on the one hand, to Darwinian evolution and, on
the other hand, between memes and domain specific (local search)
heuristics are captured within memetic algorithms thus rendering a
methodology that balances well between generality and problem specificity.
In a more diverse context, memetic algorithms is now
used under various names including Hybrid Evolutionary Algorithm,
Baldwinian Evolutionary Algorithm, Lamarckian Evolutionary
Algorithms, Cultural Algorithm or Genetic Local Search. In
the context of complex optimization, many different instantiations
of memetic algorithms have been reported across a wide range of
<link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Applications%22])">
application domains</link>, in general, converging to high
quality solutions more efficiently than their conventional evolutionary
counterparts.</p>
<p>

Aspects of memetics when dealt within a computational framework is termed as "Memetic Computing" (MC).  With MC, the traits of Universal Darwinism are more appropriately captured. Viewed in this perspective, MA is a more constrained notion of MC. More specifically, MA covers one area of MC, in particular dealing with areas of evolutionary algorithms that marry other deterministic refinement techniques for solving optimization problems. Henceforth, the framework of MC extends the notion of memes to cover conceptual entities of knowledge-enhanced procedures or representations.</p>

</sec>
<sec>
<st>
The development of MAs</st>

<ss1>
<st>
1st generation:</st>
<p>

The first generation of MA refers to hybrid
algorithms, a marriage between a population-based global
search (often in the form of an evolutionary algorithm) coupled
with a cultural evolutionary stage. This first generation
of MA although encompasses characteristics of cultural
evolution (in the form of local refinement) in the search cycle,
it may not qualify as a true evolving system according
to Universal Darwinism, since all the core principles of inheritance/
memetic transmission, variation and selection are
missing. This suggests why the term MA stirred up criticisms
and controversies among researchers when first introduced in <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref>.</p>
<p>

Pseudo code:</p>
<p>

<b>Procedure</b> Memetic Algorithm
<b>Initialize:</b> Generate an initial population;
<b>while</b> Stopping conditions are not satisfied <b>do</b>
<it>Evaluate</it> all individuals in the population.
<it>Evolve</it> a new population using stochastic search operators.
<it>Select</it> the subset of individuals, <math>\Omega_{il}</math>, that should undergo the individual improvement procedure.
<b>for</b> each individual in ­<math>\Omega_{il}</math> <b>do</b>
<it>Perform</it> individual learning using meme(s) with frequency or probability of <math>f_{il}</math>, for a period of <math>t_{il}</math>.
<it>Proceed</it> with Lamarckian or Baldwinian learning.
<b>end for</b>
<b>end while</b>
----</p>

</ss1>
<ss1>
<st>
2nd generation:</st>
<p>

Multi-meme <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%223%22])">3</ref>, Hyper-heuristic <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%224%22])">4</ref>
and Meta-Lamarckian MA <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%225%22])">5</ref> are referred to as second generation
MA exhibiting the principles of memetic transmission
and selection in their design. In Multi-meme MA, the
memetic material is encoded as part of the genotype. Subsequently,
the decoded meme of each respective individual /
chromosome is then used to perform a local refinement. The
memetic material is then transmitted through a simple inheritance
mechanism from parent to offspring(s). On the other
hand, in hyper-heuristic and meta-Lamarckian MA, the pool
of candidate memes considered will compete, based on their
past merits in generating local improvements through a reward
mechanism, deciding on which meme to be selected to
proceed for future local refinements. Meme having higher rewards
will have greater chances of being replicated or copied
subsequently. For a review on second generation MA, i.e.,
MA considering multiple individual learning methods within
an evolutionary system, the reader is referred to <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref>.</p>

</ss1>
<ss1>
<st>
3rd generation:</st>
<p>

Co-evolution <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%227%22])">7</ref> and self-generation MAs <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%228%22])">8</ref> may be regarded as 3rd generation
MA where all three principles satisfying the definitions
of a basic evolving system has been considered. In contrast to
2nd generation MA which assumes the pool of memes to be
used being known a priori, a rule-based representation of local
search is co-adapted alongside candidate solutions within
the evolutionary system, thus capturing regular repeated features
or patterns in the problem space.</p>

</ss1>
</sec>
<sec>
<st>
Some design notes</st>

<p>

The frequency and intensity of individual learning directly define the degree of evolution (exploration) against
individual learning (exploitation) in the MA search, for a given fixed limited computational budget. Clearly, a more intense
individual learning provides greater chance of convergence to the local optima but limits the amount of evolution that
may be expended without incurring excessive computational resources. Therefore, care should be taken when setting
these two parameters to balance the computational budget available in achieving maximum search performance. When only a portion of the population individuals undergo learning, the issue on which subset of individuals to improve need to be considered to maximize the utility of MA search. Last but not least, the individual learning procedure/meme used also favors a different neighborhood structure, hence the need to decide which meme or memes to use for a given optimization problem at hand would be required.</p>

<ss1>
<st>
How often should individual learning be applied?</st>
<p>

One of the first issues pertinent to memetic algorithm design is to consider how often the individual learning should be applied, i.e., individual learning frequency. In <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%229%22])">9</ref>, the effect of individual learning frequency on MA search performance was considered where various configurations of the individual learning frequency at different stages of the MA search were investigated. Conversely, it was shown in <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2210%22])">10</ref> that it may be worthwhile to apply individual learning on every individual if the computational complexity of the individual learning is relatively low.</p>

</ss1>
<ss1>
<st>
On which solutions should individual learning be used?</st>
<p>

On the issue of selecting appropriate individuals among the EA population that should undergo individual learning, fitness-based and distribution-based strategies were studied for adapting the probability of applying individual learning on the population of chromosomes in continuous parametric search problems with Land <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2211%22])">11</ref> extending the work to combinatorial optimization problems. Bambha et al. <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2212%22])">12</ref> introduced a simulated heating technique for systematically integrating parameterized individual learning into evolutionary algorithms to achieve maximum solution quality.</p>

</ss1>
<ss1>
<st>
How long should individual learning be run?</st>

<p>

Individual learning intensity, <math>t_{il}</math>, is the amount of computational budget allocated to an iteration of individual learning, i.e., the maximum computational budget allowable for individual learning to expend on improving a single solution.</p>

</ss1>
<ss1>
<st>
What individual learning method or meme should be used for a particular problem or individual?</st>

<p>

In the context of continuous optimization, individual learning/individual learning exists in the form of local heuristics or conventional exact enumerative methods <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2213%22])">13</ref>. Examples of individual learning strategies include the hill climbing, Simplex method, Newton/Quasi-Newton method, interior point methods, conjugate gradient method, line search and other local heuristics. Note that most of common individual learninger are deterministic.</p>
<p>

In combinatorial optimization, on the other hand, individual learning methods commonly exists in the form of heuristics (which can be deterministic or stochastic), that are tailored to serve a problem of interest well. Typical heuristic procedures and schemes include the k-gene exchange, edge exchange, first-improvement, and many others.</p>

</ss1>
</sec>
<sec>
<st>
Applications</st>

<p>

Memetic algorithms are the subject of intense scientific research (a <link xlink:type="simple" xlink:href="../316/37316.xml">
scientific journal</link> devoted to <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22memeticcomputingjournal%22])">
their research</link> is going to be launched) and have been successfully applied to a multitude of real-world problems. Although many people employ techniques closely related to memetic algorithms, alternative names such as <it>hybrid genetic algorithms</it> are also employed. Furthermore, many people term their memetic techniques as <it>genetic algorithms</it>. The widespread use of this misnomer hampers the assessment of the total amount of applications.</p>
<p>

Researchers have used memetic algorithms to tackle many classical <class wordnetid="107997703" confidence="0.8">
<collection wordnetid="107951464" confidence="0.8">
<group wordnetid="100031264" confidence="0.8">
<link xlink:type="simple" xlink:href="../562/21562.xml">
NP</link></group>
</collection>
</class>
 problems. To cite some of them: <link xlink:type="simple" xlink:href="../947/11973947.xml">
graph partition</link>ing, <link xlink:type="simple" xlink:href="../974/16974.xml">
multidimensional knapsack</link>, <link xlink:type="simple" xlink:href="../248/31248.xml">
travelling salesman problem</link>, <link xlink:type="simple" xlink:href="../520/1636520.xml">
quadratic assignment problem</link>, <link xlink:type="simple" xlink:href="../399/870399.xml">
set cover problem</link>, <condition wordnetid="113920835" confidence="0.8">
<state wordnetid="100024720" confidence="0.8">
<problem wordnetid="114410605" confidence="0.8">
<difficulty wordnetid="114408086" confidence="0.8">
<link>
minimal graph colouring</link></difficulty>
</problem>
</state>
</condition>
, <condition wordnetid="113920835" confidence="0.8">
<state wordnetid="100024720" confidence="0.8">
<problem wordnetid="114410605" confidence="0.8">
<difficulty wordnetid="114408086" confidence="0.8">
<link xlink:type="simple" xlink:href="../375/394375.xml">
max independent set problem</link></difficulty>
</problem>
</state>
</condition>
, <link xlink:type="simple" xlink:href="../015/287015.xml">
bin packing problem</link> and  <link xlink:type="simple" xlink:href="../553/9124553.xml">
generalized assignment problem</link>.</p>
<p>

More recent applications include (but are not limited to): training of <link xlink:type="simple" xlink:href="../523/21523.xml">
artificial neural network</link>s<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2214%22])">14</ref>, <link xlink:type="simple" xlink:href="../706/126706.xml">
pattern recognition</link><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2215%22])">15</ref>, robotic <link xlink:type="simple" xlink:href="../875/4562875.xml">
motion planning</link><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2216%22])">16</ref>, <link xlink:type="simple" xlink:href="../727/758727.xml">
beam</link> orientation<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2217%22])">17</ref>, <link xlink:type="simple" xlink:href="../344/2848344.xml">
circuit design</link><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2218%22])">18</ref>, electric service restoration<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2219%22])">19</ref>, medical <link xlink:type="simple" xlink:href="../136/10136.xml">
expert system</link>s<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2220%22])">20</ref>, <link xlink:type="simple" xlink:href="../205/3650205.xml">
single machine scheduling</link><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2221%22])">21</ref>, automatic timetabling (notably, the timetable for the <link xlink:type="simple" xlink:href="../809/21809.xml">
NHL</link> <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2222%22])">22</ref>), <link xlink:type="simple" xlink:href="../968/1956968.xml">
manpower scheduling</link> <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2223%22])">23</ref>, <link>
nurse rostering and function optimisation</link><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2224%22])">24</ref>, <link>
processor allocation</link><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2225%22])">25</ref>, maintenance scheduling (for example, of an electric distribution network<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2226%22])">26</ref>),  <link xlink:type="simple" xlink:href="../823/32823.xml">
VLSI</link> design<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2227%22])">27</ref> and <link xlink:type="simple" xlink:href="../675/669675.xml">
clustering</link> of <link xlink:type="simple" xlink:href="../073/4007073.xml">
gene expression profiles</link><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2228%22])">28</ref>.</p>

</sec>
<sec>
<st>
Recent Activities in Memetic Algorithms</st>

<p>

<list>
<entry level="1" type="bullet">

 IEEE Workshop on Memetic Algorithms (WOMA 2009). Program Chairs: Jim Smith, University of the West of England, U.K.; Yew-Soon Ong, Nanyang Technological University, Singapore; Gustafson Steven, University of Nottingham; U.K.; Meng Hiot Lim, Nanyang Technological University, Singapore; Natalio Krasnogor, University of Nottingham, U.K.</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.springer.com/journal/12293">
Memetic Computing Journal</weblink>, first issue is scheduled for January 2009.</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.wcci2008.org/">
2008 IEEE World Congress on Computational Intelligence (WCCI 2008)</weblink>, Hong Kong, <weblink xlink:type="simple" xlink:href="http://users.jyu.fi/~neferran/MA2008/MA2008.htm">
Special Session on Memetic Algorithms</weblink>.</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.ntu.edu.sg/home/asysong/SC/Special-Issue-MA.htm">
Special Issue on 'Emerging Trends in Soft Computing - Memetic Algorithm'</weblink>, Soft Computing Journal, Completed &amp; In Press, 2008.</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.ntu.edu.sg/home/asysong/ETTC/ETTC%20Task%20Force%20-%20Memetic%20Computing.htm">
IEEE Computational Intelligence Society Emergent Technologies Task Force on Memetic Computing</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://cec2007.nus.edu.sg/">
IEEE Congress on Evolutionary Computation (CEC 2007)</weblink>, Singapore, <weblink xlink:type="simple" xlink:href="http://ntu-cg.ntu.edu.sg/ysong/MA-SS/MA.htm">
Special Session on Memetic Algorithms</weblink>.</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.esi-topics.com/erf/2007/august07-Ong_Keane.html">
'Memetic Computing'</weblink> by Thomson Scientific's Essential Science Indicators as an Emerging Front Research Area.</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://ieeexplore.ieee.org/Xplore/login.jsp?url=/iel5/3477/4067063/04067075.pdf?tp=&amp;isnumber=&amp;arnumber=4067075">
Special Issue on Memetic Algorithms</weblink>, IEEE Transactions on Systems, Man and Cybernetics - Part B, Vol. 37, No. 1, February 2007.</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.springeronline.com/sgw/cda/frontpage/0,11855,5-40356-72-34233226-0,00.html">
Recent Advances in Memetic Algorithms</weblink>, Series: Studies in Fuzziness and Soft Computing , Vol. 166, ISBN 978-3-540-22904-9, 2005.</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.mitpressjournals.org/doi/abs/10.1162/1063656041775009?prevSearch=allfield%3A%28memetic+algorithm%29">
Special Issue on Memetic Algorithms</weblink>, Evolutionary Computation Fall 2004, Vol. 12, No. 3: v-vi.</entry>
</list>
</p>

</sec>
<sec>
<st>
References</st>
<p>

<reflist>
<entry id="1">
 <cite style="font-style:normal">Dawkins R. and others&#32;(1989).&#32;"The Selfish Gene".&#32;Oxford University Press.</cite>&nbsp;</entry>
<entry id="2">
 <cite style="font-style:normal">Moscato, P.&#32;(1989).&#32;"On Evolution, Search, Optimization, Genetic Algorithms and Martial Arts: Towards Memetic Algorithms". <it>Caltech Concurrent Computation Program</it>&#32;(report 826).</cite>&nbsp;</entry>
<entry id="3">
 <cite style="font-style:normal">Krasnogor N.&#32;(1999).&#32;"Coevolution of genes and memes in memetic algorithms". <it>Graduate Student Workshop</it>: 371.</cite>&nbsp;</entry>
<entry id="4">
 <cite style="font-style:normal">Kendall G. and Soubeiga E. and Cowling P..&#32;"Choice function and random hyperheuristics". <it>4th Asia-Pacific Conference on Simulated Evolution And Learning
	SEAL 2002</it>: 667--671.</cite>&nbsp;</entry>
<entry id="5">
 <cite style="font-style:normal">Ong Y. S. and Keane A. J.&#32;(2004).&#32;"Meta-Lamarckian learning in memetic algorithms". <it>IEEE Transactions on Evolutionary Computation</it>&#32;<b>8</b>: 99--110. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1109%2FTEVC.2003.819944">
10.1109/TEVC.2003.819944</weblink>.</cite>&nbsp;</entry>
<entry id="6">
 <cite style="font-style:normal">Ong Y. S. and Lim M. H. and Zhu N. and Wong K. W.&#32;(2006).&#32;"Classification of Adaptive Memetic Algorithms: A Comparative Study". <it>IEEE Transactions on Systems Man and Cybernetics -- Part B.</it>&#32;<b>36</b>: 141.</cite>&nbsp;</entry>
<entry id="7">
 <cite style="font-style:normal">Smith J. E.&#32;(2007).&#32;"Coevolving Memetic Algorithms: A Review and Progress Report". <it>IEEE Transactions on Systems Man and Cybernetics - Part B</it>&#32;<b>37</b>: 6--17. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1109%2FTSMCB.2006.883273">
10.1109/TSMCB.2006.883273</weblink>.</cite>&nbsp;</entry>
<entry id="8">
 <cite style="font-style:normal">Krasnogor N. and Gustafson S.&#32;(2002).&#32;"Toward truly "memetic" memetic algorithms: discussion and proof
	of concepts". <it>Advances in Nature-Inspired Computation: The PPSN VII Workshops.
	PEDAL (Parallel Emergent and Distributed Architectures Lab). University
	of Reading</it>.</cite>&nbsp;</entry>
<entry id="9">
 <cite style="font-style:normal">Hart W. E.&#32;(1994).&#32;"Adaptive Global Optimization with Local Search".</cite>&nbsp;</entry>
<entry id="10">
 <cite style="font-style:normal">Ku K. W. C. and Mak M. W. and Siu W. C.&#32;(2000).&#32;"A study of the Lamarckian evolution of recurrent neural networks". <it>IEEE Transactions on Evolutionary Computation</it>&#32;<b>4</b>: 31--42. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1109%2F4235.843493">
10.1109/4235.843493</weblink>.</cite>&nbsp;</entry>
<entry id="11">
 <cite style="font-style:normal">Land M. W. S.&#32;(1998).&#32;"Evolutionary Algorithms with Local Search for Combinatorial Optimization".</cite>&nbsp;</entry>
<entry id="12">
 <cite style="font-style:normal">Bambha N. K. and Bhattacharyya S. S. and Teich J. and Zitzler
	E.&#32;(2004).&#32;"Systematic integration of parameterized local search into evolutionary
	algorithms". <it>IEEE Transactions on Evolutionary Computation</it>&#32;<b>8</b>: 137--155. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1109%2FTEVC.2004.823471">
10.1109/TEVC.2004.823471</weblink>.</cite>&nbsp;</entry>
<entry id="13">
 <cite style="font-style:normal" class="book">Schwefel H. P.&#32;(1995). Evolution and optimum seeking.&#32;Wiley New York.</cite>&nbsp;</entry>
<entry id="14">
 <cite style="font-style:normal">Ichimura, T.; Kuriyama, Y.&#32;(1998). "Learning of neural networks with parallel hybrid GA using a royal road function".&#32;<it>IEEE International Joint Conference on Neural Networks</it>&#32;<b>2</b>: 1131-1136.</cite>&nbsp;</entry>
<entry id="15">
 <cite style="font-style:normal">Aguilar, J.; Colmenares, A.&#32;(1998).&#32;"Resolution of pattern recognition problems using a hybrid genetic/random neural network learning algorithm". <it>Pattern Analysis and Applications</it>&#32;<b>1</b>&#32;(1): 52–61. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1007%2FBF01238026">
10.1007/BF01238026</weblink>.</cite>&nbsp;</entry>
<entry id="17">
 <cite style="font-style:normal">Haas, O.; Burnham, K.; Mills, J.&#32;(1998).&#32;"Optimization of beam orientation in radiotherapy using planar geometry". <it>Physics in Medicine and Biology</it>&#32;<b>43</b>&#32;(8): 2179–2193. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1088%2F0031-9155%2F43%2F8%2F013">
10.1088/0031-9155/43/8/013</weblink>.</cite>&nbsp;</entry>
<entry id="16">
 <cite style="font-style:normal">Ridao, M.; Riquelme, J.; Camacho, E.; Toro, M.&#32;(1998).&#32;"An evolutionary and local search algorithm for planning two manipulators motion". <it>Lecture Notes in Computer Science</it>&#32;<b>1416</b>: 105–114.&#32;Springer-Verlag.</cite>&nbsp;</entry>
<entry id="19">
 <cite style="font-style:normal">Augugliaro, A.; Dusonchet, L.; Riva-Sanseverino, E.&#32;(1998).&#32;"Service restoration in compensated distribution networks using a hybrid genetic algorithm". <it>Electric Power Systems Research</it>&#32;<b>46</b>&#32;(1): 59–66. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1016%2FS0378-7796%2898%2900025-X">
10.1016/S0378-7796(98)00025-X</weblink>.</cite>&nbsp;</entry>
<entry id="18">
 <cite style="font-style:normal">Harris, S.; Ifeachor, E.&#32;(1998).&#32;"Automatic design of frequency sampling filters by hybrid genetic algorithm techniques". <it>IEEE Transactions on Signal Processing</it>&#32;<b>46</b>&#32;(12): 3304–3314. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1109%2F78.735305">
10.1109/78.735305</weblink>.</cite>&nbsp;</entry>
<entry id="21">
 <cite style="font-style:normal">França, P.; Mendes, A.; Moscato, P.&#32;(1999). "Memetic algorithms to minimize tardiness on a single machine with sequence-dependent setup times".&#32;<it>Proceedings of the 5th International Conference of the Decision Sciences Institute</it>: 1708-1710.</cite>&nbsp;</entry>
<entry id="20">
 <cite style="font-style:normal">Wehrens, R.; Lucasius, C.; Buydens, L.; Kateman, G.&#32;(1993).&#32;"HIPS, A hybrid self-adapting expert system for nuclear magnetic resonance spectrum interpretation using genetic algorithms". <it>Analytica Chimica ACTA</it>&#32;<b>277</b>&#32;(2): 313–324. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1016%2F0003-2670%2893%2980444-P">
10.1016/0003-2670(93)80444-P</weblink>.</cite>&nbsp;</entry>
<entry id="23">
 <cite style="font-style:normal">Aickelin, U.&#32;(1998). "Nurse rostering with genetic algorithms".&#32;<it>Proceedings of young operational research conference 1998</it>.</cite>&nbsp;</entry>
<entry id="22">
 <cite style="font-style:normal">Costa, D.&#32;(1995).&#32;"An evolutionary tabu search algorithm and the NHL scheduling problem". <it>INFOR 33</it>: 161–178.</cite>&nbsp;</entry>
<entry id="25">
 <cite style="font-style:normal">Ozcan, E.; Onbasioglu, E.&#32;(2006).&#32;"Memetic Algorithms for Parallel Code Optimization". <it>International Journal of Parallel Programming</it>&#32;<b>35</b>&#32;(1): 33-61.</cite>&nbsp;</entry>
<entry id="24">
 <cite style="font-style:normal">Ozcan, E.&#32;(2007).&#32;"Memes, Self-generation and Nurse Rostering". <it>Lecture Notes in Computer Science</it>&#32;<b>3867</b>: 85-104.&#32;Springer-Verlag.</cite>&nbsp;</entry>
<entry id="27">
 <cite style="font-style:normal">Areibi, S., Yang, Z.&#32;(2004).&#32;"Effective memetic algorithms for VLSI design automation = genetic algorithms + local search + multi-level clustering". <it>Evolutionary Computation</it>&#32;<b>12</b>&#32;(3): 327–353.&#32;MIT Press. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1162%2F1063656041774947">
10.1162/1063656041774947</weblink>.</cite>&nbsp;</entry>
<entry id="26">
 <cite style="font-style:normal">Burke, E.; Smith, A.&#32;(1999).&#32;"A memetic algorithm to schedule planned maintenance for the national grid". <it>Journal of Experimental Algorithmics</it>&#32;(4): 1–13. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1145%2F347792.347801">
10.1145/347792.347801</weblink>.</cite>&nbsp;</entry>
<entry id="28">
 <cite style="font-style:normal" class="book">Merz, P.; Zell, A.&#32;(2002).&#32;"Clustering Gene Expression Profiles with Memetic Algorithms", Parallel Problem Solving from Nature — PPSN VII.&#32;<link xlink:type="simple" xlink:href="../367/1098367.xml">
Springer</link>,&#32;811-820. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1007/3-540-45712-7_78">
10.1007/3-540-45712-7_78</weblink>.</cite>&nbsp;</entry>
</reflist>
</p>


</sec>
</bdy>
</algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</article>
