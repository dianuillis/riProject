<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 15:39:44[mciao0825] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<event  confidence="0.8" wordnetid="100029378">
<rule  confidence="0.8" wordnetid="105846932">
<act  confidence="0.8" wordnetid="100030358">
<psychological_feature  confidence="0.8" wordnetid="100023100">
<procedure  confidence="0.8" wordnetid="101023820">
<activity  confidence="0.8" wordnetid="100407535">
<algorithm  confidence="0.8" wordnetid="105847438">
<header>
<title>Genetic algorithm</title>
<id>40254</id>
<revision>
<id>244530271</id>
<timestamp>2008-10-11T07:44:19Z</timestamp>
<contributor>
<username>LieAfterLie</username>
<id>5993873</id>
</contributor>
</revision>
<categories>
<category>Search algorithms</category>
<category>Intelligence</category>
<category>Evolutionary algorithms</category>
<category>Optimization algorithms</category>
<category>Cybernetics</category>
<category>Genetic algorithms</category>
</categories>
</header>
<bdy>

A <b>genetic algorithm (GA)</b> is a <link xlink:type="simple" xlink:href="../149/19386149.xml">
search</link>  used in <link xlink:type="simple" xlink:href="../213/5213.xml">
computing</link> to find exact or <link xlink:type="simple" xlink:href="../271/336271.xml">
approximate</link> solutions to <link xlink:type="simple" xlink:href="../033/52033.xml">
optimization</link> and <link xlink:type="simple" xlink:href="../149/19386149.xml">
search</link> <link xlink:type="simple" xlink:href="../760/608760.xml">
problem</link>s.  Genetic algorithms are <link xlink:type="simple" xlink:href="../717/72717.xml">
categorize</link>d as <link xlink:type="simple" xlink:href="../854/563854.xml">
global search heuristics</link>. Genetic algorithms are a particular class of <link xlink:type="simple" xlink:href="../837/190837.xml">
evolutionary algorithm</link>s (also known as <link xlink:type="simple" xlink:href="../020/268020.xml">
evolutionary computation</link>) that use techniques inspired by <link xlink:type="simple" xlink:href="../101/418101.xml">
evolutionary biology</link> such as <link xlink:type="simple" xlink:href="../457/13457.xml">
inheritance</link>, <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../213/555213.xml">
mutation</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
, <link xlink:type="simple" xlink:href="../886/1105886.xml">
selection</link>, and <link xlink:type="simple" xlink:href="../546/554546.xml">
crossover</link> (also called <link xlink:type="simple" xlink:href="../002/158002.xml">
recombination</link>).
<sec>
<st>
Methodology</st>

<p>

Genetic algorithms are <link xlink:type="simple" xlink:href="../704/407704.xml">
implement</link>ed as a <link xlink:type="simple" xlink:href="../416/375416.xml">
computer simulation</link> in which a <link xlink:type="simple" xlink:href="../949/22949.xml">
population</link> of abstract representations (called <link xlink:type="simple" xlink:href="../480/555480.xml">
chromosomes</link> or the <link xlink:type="simple" xlink:href="../796/12796.xml">
genotype</link> of the <link xlink:type="simple" xlink:href="../388/12388.xml">
genome</link>) of <link xlink:type="simple" xlink:href="../808/1556808.xml">
candidate solutions</link> (called individuals, creatures, or <link xlink:type="simple" xlink:href="../543/24543.xml">
phenotype</link>s) to an optimization problem evolves toward better solutions. Traditionally, solutions are represented in binary as strings of 0s and 1s, but other encodings are also possible. The evolution usually starts from a population of randomly generated individuals and happens in generations. In each generation, the fitness of every individual in the population is evaluated, multiple individuals are <link xlink:type="simple" xlink:href="../222/292222.xml">
stochastically</link> selected from the current population (based on their fitness), and modified (recombined and possibly randomly mutated) to form a new population. The new population is then used in the next iteration of the <link xlink:type="simple" xlink:href="../775/775.xml">
algorithm</link>. Commonly, the algorithm terminates when either a maximum number of generations has been produced, or a satisfactory fitness level has been reached for the population. If the algorithm has terminated due to a maximum number of generations, a satisfactory solution may or may not have been reached.</p>
<p>

Genetic algorithms find application in <link xlink:type="simple" xlink:href="../214/4214.xml">
bioinformatics</link>, <link xlink:type="simple" xlink:href="../962/23962.xml">
phylogenetics</link>, <link xlink:type="simple" xlink:href="../008/1181008.xml">
computational science</link>, <link xlink:type="simple" xlink:href="../251/9251.xml">
engineering</link>, <link xlink:type="simple" xlink:href="../223/9223.xml">
economics</link>, <link xlink:type="simple" xlink:href="../180/5180.xml">
chemistry</link>, <link xlink:type="simple" xlink:href="../388/39388.xml">
manufacturing</link>, <link xlink:type="simple" xlink:href="../831/18831.xml">
mathematics</link>, <link xlink:type="simple" xlink:href="../939/22939.xml">
physics</link> and other fields. </p>
<p>

A typical genetic algorithm requires two things to be defined: </p>
<p>

<list>
<entry level="1" type="number">

 a <link xlink:type="simple" xlink:href="../944/3558944.xml">
genetic representation</link> of the solution <entity wordnetid="100001740" confidence="0.8">
<link xlink:type="simple" xlink:href="../714/47714.xml">
domain</link></entity>
, </entry>
<entry level="1" type="number">

 a <link xlink:type="simple" xlink:href="../285/412285.xml">
fitness function</link> to evaluate the solution domain.</entry>
</list>
</p>
<p>

A standard representation of the solution is as an <link xlink:type="simple" xlink:href="../937/1189937.xml">
array of bit</link>s. Arrays of other types and structures can be used in essentially the same way. The main property that makes these genetic representations convenient is that their parts are easily aligned due to their fixed size, that facilitates simple crossover operation. Variable length representations may also be used, but crossover implementation is more complex in this case. Tree-like representations are explored in <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../424/12424.xml">
Genetic programming</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
 and graph-form representations are explored in <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../689/460689.xml">
Evolutionary programming</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
.</p>
<p>

The fitness function is defined over the genetic representation and measures the <it>quality</it> of the represented solution. The fitness function is always problem dependent. For instance, in the <link xlink:type="simple" xlink:href="../974/16974.xml">
knapsack problem</link> we want to maximize the total value of objects that we can put in a knapsack of some fixed capacity. A representation of a solution might be an array of bits, where each bit represents a different object, and the value of the bit (0 or 1) represents whether or not the object is in the knapsack. Not every such representation is valid, as the size of objects may exceed the capacity of the knapsack. The <it>fitness</it> of the solution is the sum of values of all objects in the knapsack if the representation is valid, or 0 otherwise. In some problems, it is hard or even impossible to define the fitness expression; in these cases, <link xlink:type="simple" xlink:href="../162/901162.xml">
interactive genetic algorithm</link>s are used.</p>
<p>

Once we have the genetic representation and the fitness function defined, GA proceeds to initialize a population of solutions randomly, then improve it through repetitive application of mutation, crossover, inversion and selection operators.</p>

<ss1>
<st>
Initialization </st>

<p>

Initially many individual solutions are randomly generated to form an initial population. The population size depends on the nature of the problem, but typically contains several hundreds or thousands of possible solutions. Traditionally, the population  is generated randomly, covering the entire range of possible solutions (the <it>search space</it>). Occasionally, the solutions may be "seeded" in areas where optimal solutions are likely to be found.</p>

</ss1>
<ss1>
<st>
 Selection </st>

<p>

<indent level="1">

<it>Main article: <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../886/1105886.xml">
Selection (genetic algorithm)</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</it>
</indent>
During each successive generation, a proportion of the existing population is <link xlink:type="simple" xlink:href="../886/1105886.xml">
selected</link> to breed a new generation. Individual solutions are selected through a <it>fitness-based</it> process, where <link xlink:type="simple" xlink:href="../849/187849.xml">
fitter</link> solutions (as measured by a <link xlink:type="simple" xlink:href="../285/412285.xml">
fitness function</link>) are typically more likely to be selected. Certain selection methods rate the fitness of each solution and preferentially select the best solutions. Other methods rate only a random sample of the population, as this process may be very time-consuming.</p>
<p>

Most functions are <link xlink:type="simple" xlink:href="../222/292222.xml">
stochastic</link> and designed so that a small proportion of less fit solutions are selected. This helps keep the diversity of the population large, preventing premature convergence on poor solutions. Popular and well-studied selection methods include <link xlink:type="simple" xlink:href="../703/371703.xml">
roulette wheel selection</link> and <link xlink:type="simple" xlink:href="../156/491156.xml">
tournament selection</link>.</p>

</ss1>
<ss1>
<st>
 Reproduction </st>

<p>

<indent level="1">

<it>Main articles: <link xlink:type="simple" xlink:href="../546/554546.xml">
crossover (genetic algorithm)</link>&#32;and&#32;<link xlink:type="simple" xlink:href="../213/555213.xml">
mutation (genetic algorithm)</link></it>
</indent>

The next step is to generate a second generation population of solutions from those selected through <link xlink:type="simple" xlink:href="../709/371709.xml">
genetic operator</link>s: <link xlink:type="simple" xlink:href="../546/554546.xml">
crossover</link> (also called recombination), and/or <link xlink:type="simple" xlink:href="../213/555213.xml">
mutation</link>.</p>
<p>

For each new solution to be produced, a pair of "parent" solutions is selected for breeding from the pool selected previously. By producing a "child" solution using the above methods of crossover and mutation, a new solution is created which typically shares many of the characteristics of its "parents". New parents are selected for each child, and the process continues until a new population of solutions of appropriate size is generated.</p>
<p>

These processes ultimately result in the next generation population of chromosomes that is different from the initial generation. Generally the average fitness will have increased by this procedure for the population, since only the best organisms from the first generation are selected for breeding, along with a small proportion of less fit solutions, for reasons already mentioned above.</p>

</ss1>
<ss1>
<st>
 Termination </st>

<p>

This generational process is repeated until a termination condition has been reached. Common terminating conditions are</p>
<p>

<list>
<entry level="1" type="bullet">

 A solution is found that satisfies minimum criteria</entry>
<entry level="1" type="bullet">

 Fixed number of generations reached</entry>
<entry level="1" type="bullet">

 Allocated budget (computation time/money) reached</entry>
<entry level="1" type="bullet">

 The highest ranking solution's fitness is reaching or has reached a plateau such that successive iterations no longer produce better results</entry>
<entry level="1" type="bullet">

 Manual inspection</entry>
<entry level="1" type="bullet">

 Combinations of the above.</entry>
</list>
</p>

</ss1>
<ss1>
<st>
Pseudo-code algorithm</st>
<p>

<list>
<entry level="1" type="number">

 Choose initial <link xlink:type="simple" xlink:href="../949/22949.xml">
population</link></entry>
<entry level="1" type="number">

 Evaluate the <link xlink:type="simple" xlink:href="../849/187849.xml">
fitness</link> of each <link xlink:type="simple" xlink:href="../593/14593.xml">
individual</link> in the population </entry>
<entry level="1" type="number">

 Repeat until termination:</entry>
<entry level="2" type="number">

 Select best-ranking individuals to <link xlink:type="simple" xlink:href="../310/26310.xml">
reproduce</link></entry>
<entry level="2" type="number">

 <link xlink:type="simple" xlink:href="../933/267933.xml">
Breed</link> new <link xlink:type="simple" xlink:href="../535/94535.xml">
generation</link> through <link xlink:type="simple" xlink:href="../546/554546.xml">
crossover</link> and <link xlink:type="simple" xlink:href="../213/555213.xml">
mutation</link> (genetic operations) and give birth to <link xlink:type="simple" xlink:href="../628/96628.xml">
offspring</link></entry>
<entry level="2" type="number">

 Evaluate the individual fitnesses of the offspring</entry>
<entry level="2" type="number">

 Replace worst ranked part of population with offspring</entry>
</list>
</p>

</ss1>
<ss1>
<st>
Observations</st>
<p>

There are several general observations about the generation of solutions via a genetic algorithm:</p>
<p>

<list>
<entry level="1" type="bullet">

 In many problems, GAs may have a tendency to converge towards <link xlink:type="simple" xlink:href="../451/774451.xml">
local optima</link> or even arbitrary points rather than the <link xlink:type="simple" xlink:href="../285/914285.xml">
global optimum</link> of the problem. This means that it does not "know how" to sacrifice short-term fitness to gain longer-term fitness. The likelihood of this occurring depends on the shape of the <link xlink:type="simple" xlink:href="../599/310599.xml">
fitness landscape</link>: certain problems may provide an easy ascent towards a global optimum, others may make it easier for the function to find the local optima. This problem may be alleviated by using a different fitness function, increasing the rate of mutation, or by using selection techniques that maintain a diverse population of solutions, although the <link xlink:type="simple" xlink:href="../402/1297402.xml">
No Free Lunch</link> theorem proves that there is no general solution to this problem.  A common technique to maintain diversity is to impose a "niche penalty", wherein, any group of individuals of sufficient similarity (niche radius) have a penalty added, which will reduce the representation of that group in subsequent generations, permitting other (less similar) individuals to be maintained in the population. This trick, however, may not be effective, depending on the landscape of the problem. Diversity is important in <link xlink:type="simple" xlink:href="../254/40254.xml">
genetic algorithms</link> (and <link xlink:type="simple" xlink:href="../424/12424.xml">
genetic programming</link>) because crossing over a homogeneous population does not yield new solutions. In <link xlink:type="simple" xlink:href="../033/940033.xml">
evolution strategies</link> and <link xlink:type="simple" xlink:href="../689/460689.xml">
evolutionary programming</link>, diversity is not essential because of a greater reliance on mutation.</entry>
<entry level="1" type="bullet">

 Operating on dynamic data sets is difficult, as genomes begin to converge early on towards solutions which may no longer be valid for later data. Several methods have been proposed to remedy this by increasing genetic diversity somehow and preventing early convergence, either by increasing the probability of mutation when the solution quality drops (called <it>triggered hypermutation</it>), or by occasionally introducing entirely new, randomly generated elements into the gene pool (called <it>random immigrants</it>). Again, <link xlink:type="simple" xlink:href="../033/940033.xml">
evolution strategies</link> and <link xlink:type="simple" xlink:href="../689/460689.xml">
evolutionary programming</link> can be implemented with a so-called "comma strategy" in which parents are not maintained and new parents are selected only from offspring. This can be more effective on dynamic problems.</entry>
<entry level="1" type="bullet">

 GAs cannot effectively solve problems in which the only fitness measure is right/wrong, as there is no way to converge on the solution (no hill to climb). In these cases, a random search may find a solution as quickly as a GA.</entry>
<entry level="1" type="bullet">

 Selection is clearly an important genetic operator, but opinion is divided over the importance of crossover versus mutation. Some argue that crossover is the most important, while mutation is only necessary to ensure that potential solutions are not lost. Others argue that crossover in a largely uniform population only serves to propagate innovations originally found by mutation, and in a non-uniform population crossover is nearly always equivalent to a very large mutation (which is likely to be catastrophic). There are many references in <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<research_worker wordnetid="110523076" confidence="0.8">
<link xlink:type="simple" xlink:href="../049/8170049.xml">
Fogel</link></research_worker>
</scientist>
</causal_agent>
</person>
</physical_entity>
 (2006) that support the importance of mutation-based search, but across all problems the <link xlink:type="simple" xlink:href="../402/1297402.xml">
No Free Lunch</link> theorem holds, so these opinions are without merit unless the discussion is restricted to a particular problem.</entry>
<entry level="1" type="bullet">

 Often, GAs can rapidly locate <it>good</it> solutions, even for difficult search spaces. The same is of course also true for <link xlink:type="simple" xlink:href="../033/940033.xml">
evolution strategies</link> and <link xlink:type="simple" xlink:href="../689/460689.xml">
evolutionary programming</link>.</entry>
<entry level="1" type="bullet">

 For specific optimization problems and problem instantiations, simpler optimization algorithms may find better solutions than genetic algorithms (given the same amount of computation time). Alternative and complementary algorithms include <link xlink:type="simple" xlink:href="../033/940033.xml">
evolution strategies</link>, <link xlink:type="simple" xlink:href="../689/460689.xml">
evolutionary programming</link>, <link xlink:type="simple" xlink:href="../244/172244.xml">
simulated annealing</link>, <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../345/9210345.xml">
Gaussian adaptation</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
, <link xlink:type="simple" xlink:href="../002/364002.xml">
hill climbing</link>, and <link xlink:type="simple" xlink:href="../988/762988.xml">
swarm intelligence</link> (e.g.: <link xlink:type="simple" xlink:href="../615/588615.xml">
ant colony optimization</link>, <link xlink:type="simple" xlink:href="../083/337083.xml">
particle swarm optimization</link>).</entry>
<entry level="1" type="bullet">

 As with all current machine learning problems it is worth tuning the parameters such as <link xlink:type="simple" xlink:href="../702/19702.xml">
mutation</link> probability, <link xlink:type="simple" xlink:href="../002/158002.xml">
recombination</link> probability and population size to find reasonable settings for the problem class being worked on. A very small mutation rate may lead to <link xlink:type="simple" xlink:href="../016/72016.xml">
genetic drift</link>  (which is non- in nature). A recombination rate that is too high may lead to premature convergence of the genetic algorithm. A mutation rate that is too high may lead to loss of good solutions unless there is elitist selection. There are theoretical but not yet practical upper and lower bounds for these parameters that can help guide selection.</entry>
<entry level="1" type="bullet">

 The implementation and evaluation of the fitness function is an important factor in the speed and efficiency of the algorithm.</entry>
</list>
</p>

</ss1>
</sec>
<sec>
<st>
Variants</st>

<p>

The simplest algorithm represents each chromosome as a  <link xlink:type="simple" xlink:href="../364/3364.xml">
bit</link> string. Typically, numeric parameters can be represented by <link xlink:type="simple" xlink:href="../563/14563.xml">
integer</link>s, though it is possible to use <link xlink:type="simple" xlink:href="../376/11376.xml">
floating point</link> representations. The floating point representation is natural to <link xlink:type="simple" xlink:href="../033/940033.xml">
evolution strategies</link> and <link xlink:type="simple" xlink:href="../689/460689.xml">
evolutionary programming</link>. The notion of real-valued genetic algorithms has been offered but is really a misnomer because it does not really represent the building block theory that was proposed by Holland in the 1970s. This theory is not without support though, based on theoretical and experimental results (see below). The basic algorithm performs crossover and mutation at the bit level. Other variants treat the chromosome as a list of numbers which are indexes into an instruction table, nodes in a <link xlink:type="simple" xlink:href="../167/18167.xml">
linked list</link>, <link xlink:type="simple" xlink:href="../154/95154.xml">
hashes</link>, <link xlink:type="simple" xlink:href="../665/169665.xml">
objects</link>, or any other imaginable <link xlink:type="simple" xlink:href="../519/8519.xml">
data structure</link>. Crossover and mutation are performed so as to respect data element boundaries. For most data types, specific variation operators can be designed. Different chromosomal data types seem to work better or worse for different specific problem domains.</p>
<p>

When bit strings representations of integers are used, <link xlink:type="simple" xlink:href="../564/50564.xml">
Gray coding</link> is often employed.  In this way, small changes in the integer can be readily effected through mutations or crossovers.  This has been found to help prevent premature convergence at so called <it>Hamming walls</it>, in which too many simultaneous mutations (or crossover events) must occur in order to change the chromosome to a better solution. </p>
<p>

Other approaches involve using arrays of real-valued numbers instead of bit strings to represent chromosomes.  Theoretically, the smaller the alphabet, the better the performance, but paradoxically, good results have been obtained from using real-valued chromosomes.</p>
<p>

A very successful (slight) variant of the general process of constructing a new population is to allow some of the better organisms from the current generation to carry over to the next, unaltered. This strategy is known as <it>elitist selection</it>.</p>
<p>

Parallel implementations of genetic algorithms come in two flavours. Coarse grained parallel genetic algorithms assume a population on each of the computer nodes and migration of individuals among the nodes. Fine grained parallel genetic algorithms assume an individual on each processor node which acts with neighboring individuals for selection and reproduction.
Other variants, like genetic algorithms for online optimization problems, introduce time-dependence or noise in the fitness function.</p>
<p>

It can be quite effective to combine GA with other optimization methods.  GA tends to be quite good at finding generally good global solutions, but quite inefficient at finding the last few mutations to find the absolute optimum.  Other techniques (such as simple hill climbing) are quite efficient at finding absolute optimum in a limited region.  Alternating GA and hill climbing can improve the efficiency of GA while overcoming the lack of robustness of hill climbing.</p>
<p>

An algorithm that maximizes mean fitness (without any need for the definition of mean fitness as a criterion function) is <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../345/9210345.xml">
Gaussian adaptation</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
, See Kjellström 1970<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref>, provided that the <link xlink:type="simple" xlink:href="../469/22469.xml">
ontogeny</link> of an individual may be seen as a modified recapitulation of evolutionary random steps in the past and that the sum of many random steps tend to become Gaussian distributed (according to the <link xlink:type="simple" xlink:href="../406/39406.xml">
central limit theorem</link>).</p>
<p>

This means that the rules of genetic variation may have a different meaning in the natural case. For instance - provided that steps are stored in consecutive order - crossing over may sum a number of steps from maternal DNA adding a number of steps from paternal DNA and so on. This is like adding vectors that more probably may follow a ridge in the phenotypic landscape. Thus, the efficiency of the process may be increased by many orders of magnitude. Moreover, the <link xlink:type="simple" xlink:href="../073/11557073.xml">
inversion operator</link> has the opportunity to place steps in consecutive order or any other suitable order in favour of survival or efficiency. (See for instance <weblink xlink:type="simple" xlink:href="http://www.evolution-in-a-nutshell.se/traveller.htm">
http://www.evolution-in-a-nutshell.se/traveller.htm</weblink> or example in <link xlink:type="simple" xlink:href="../248/31248.xml">
travelling salesman problem</link>.)</p>
<p>

Gaussian  adaptation is able to approximate the natural process by an adaptation of the moment matrix of the Gaussian. So, because very many quantitative characters are Gaussian distributed in a large population, Gaussian adaptation may serve as a genetic algorithm replacing the rules of genetic variation by a Gaussian random number generator working on the phenotypic level. See Kjellström 1996<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref></p>
<p>

<event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../122/12698122.xml">
Population-based incremental learning</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
 is a variation where the population as a whole is evolved rather than its individual members.</p>

</sec>
<sec>
<st>
Problem domains</st>
<p>

Problems which appear to be particularly appropriate for solution by genetic algorithms include <link xlink:type="simple" xlink:href="../433/277433.xml">
timetabling</link> and <link xlink:type="simple" xlink:href="../851/4941851.xml">
scheduling</link> problems, and many scheduling software packages are based on GAs. GAs have also been applied to <link xlink:type="simple" xlink:href="../251/9251.xml">
engineering</link>. Genetic algorithms are often applied as an approach to solve <link xlink:type="simple" xlink:href="../854/563854.xml">
global optimization</link> problems.</p>
<p>

As a general rule of thumb genetic algorithms might be useful in problem domains that have a complex <link xlink:type="simple" xlink:href="../599/310599.xml">
fitness landscape</link> as <link xlink:type="simple" xlink:href="../002/158002.xml">
recombination</link> is designed to move the population away from <link xlink:type="simple" xlink:href="../451/774451.xml">
local optima</link> that a  traditional <link xlink:type="simple" xlink:href="../002/364002.xml">
hill climbing</link> algorithm might get stuck in.</p>

</sec>
<sec>
<st>
History</st>

<p>

Computer simulations of evolution started as early as in 1954 with the work of <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<mathematician wordnetid="110301261" confidence="0.8">
<link xlink:type="simple" xlink:href="../217/16752217.xml">
Nils Aall Barricelli</link></mathematician>
</scientist>
</causal_agent>
</person>
</physical_entity>
, who was using the computer at the <institute wordnetid="108407330" confidence="0.8">
<association wordnetid="108049401" confidence="0.8">
<link xlink:type="simple" xlink:href="../179/184179.xml">
Institute for Advanced Study</link></association>
</institute>
 in <region wordnetid="108630985" confidence="0.8">
<center wordnetid="108523483" confidence="0.8">
<area wordnetid="108497294" confidence="0.8">
<administrative_district wordnetid="108491826" confidence="0.8">
<seat wordnetid="108647945" confidence="0.8">
<location wordnetid="100027167" confidence="0.8">
<municipality wordnetid="108626283" confidence="0.8">
<geographical_area wordnetid="108574314" confidence="0.8">
<town wordnetid="108665504" confidence="0.8">
<district wordnetid="108552138" confidence="0.8">
<capital wordnetid="108518505" confidence="0.8">
<urban_area wordnetid="108675967" confidence="0.8">
<link xlink:type="simple" xlink:href="../658/84658.xml">
Princeton, New Jersey</link></urban_area>
</capital>
</district>
</town>
</geographical_area>
</municipality>
</location>
</seat>
</administrative_district>
</area>
</center>
</region>
.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%223%22])">3</ref>  <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%224%22])">4</ref>  His 1954 publication was not widely noticed.  Starting in 1957 <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%225%22])">5</ref>, the Australian quantitative geneticist <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<link xlink:type="simple" xlink:href="../140/2995140.xml">
Alex Fraser</link></scientist>
</causal_agent>
</person>
</physical_entity>
 published a series of papers on simulation of <link xlink:type="simple" xlink:href="../039/49039.xml">
artificial selection</link> of organisms with multiple loci controlling a measurable trait.  From these beginnings, computer simulation of evolution by biologists became more common in the early 1960s, and the methods were described in books by Fraser and Burnell (1970)<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref> and Crosby (1973)<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%227%22])">7</ref>. Fraser's simulations included all of the essential elements of modern genetic algorithms. In addition, <link>
Hans Bremermann</link> published a series of papers in the 1960s that also adopted a population of solution to optimization problems, undergoing recombination, mutation, and selection. Bremermann's research also included the elements of modern genetic algorithms. Other noteworthy early pioneers include Richard Friedberg, George Friedman, and Michael Conrad. Many early papers are reprinted by <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<research_worker wordnetid="110523076" confidence="0.8">
<link xlink:type="simple" xlink:href="../049/8170049.xml">
Fogel</link></research_worker>
</scientist>
</causal_agent>
</person>
</physical_entity>
 (1998).<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%228%22])">8</ref></p>
<p>

Although Barricelli, in work he reported in 1963, had simulated the evolution of ability to play a simple game,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%229%22])">9</ref> <link xlink:type="simple" xlink:href="../837/190837.xml">
artificial evolution</link> became a widely recognized optimization method as a result of the work of <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<link xlink:type="simple" xlink:href="../355/11554355.xml">
Ingo Rechenberg</link></scientist>
</causal_agent>
</person>
</physical_entity>
 and <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<link xlink:type="simple" xlink:href="../976/15449976.xml">
Hans-Paul Schwefel</link></scientist>
</causal_agent>
</person>
</physical_entity>
 in the 1960s and early 1970s - his group was able to solve complex engineering problems through <link xlink:type="simple" xlink:href="../033/940033.xml">
evolution strategies</link>  <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2210%22])">10</ref> <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2211%22])">11</ref> <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2212%22])">12</ref>. Another approach was the evolutionary programming technique of <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<link xlink:type="simple" xlink:href="../186/8170186.xml">
Lawrence J. Fogel</link></scientist>
</causal_agent>
</person>
</physical_entity>
, which was proposed for generating artificial intelligence. <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../689/460689.xml">
Evolutionary programming</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
 originally used finite state machines for predicting environments, and used variation and selection to optimize the predictive logics. Genetic algorithms in particular became popular through the work of <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<psychologist wordnetid="110488865" confidence="0.8">
<link xlink:type="simple" xlink:href="../373/1713373.xml">
John Holland</link></psychologist>
</scientist>
</causal_agent>
</person>
</physical_entity>
 in the early 1970s, and particularly his book <it>Adaptation in Natural and Artificial Systems</it> (1975).  His work originated with studies of <link xlink:type="simple" xlink:href="../342/54342.xml">
cellular automata</link>, conducted by <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<psychologist wordnetid="110488865" confidence="0.8">
<link xlink:type="simple" xlink:href="../373/1713373.xml">
Holland</link></psychologist>
</scientist>
</causal_agent>
</person>
</physical_entity>
 and his students at the <university wordnetid="108286163" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../740/31740.xml">
University of Michigan</link></university>
. Holland introduced a formalized framework for predicting the quality of the next generation, known as <link xlink:type="simple" xlink:href="../360/4329360.xml">
Holland's Schema Theorem</link>. Research in GAs remained largely theoretical until the mid-1980s, when The First International Conference on Genetic Algorithms was held in <village wordnetid="108672738" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../101/25101.xml">
Pittsburgh, Pennsylvania</link></village>
.</p>
<p>

As academic interest grew, the dramatic increase in desktop computational power allowed for practical application of the new technique. In the late 1980s, General Electric started selling the world's first genetic algorithm product, a mainframe-based toolkit designed for industrial processes.  In 1989, Axcelis, Inc. released <link xlink:type="simple" xlink:href="../872/3119872.xml">
Evolver</link>, the world's second GA product and the first for desktop computers.  <newspaper wordnetid="106267145" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../680/30680.xml">
The New York Times</link></newspaper>
 technology writer <journalist wordnetid="110224578" confidence="0.9173553029164789">
<link xlink:type="simple" xlink:href="../189/667189.xml">
John Markoff</link></journalist>
 wrote<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2213%22])">13</ref> about Evolver in 1990.</p>

</sec>
<sec>
<st>
Related techniques</st>
<p>

<list>
<entry level="1" type="bullet">

 <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../615/588615.xml">
Ant colony optimization</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
 (ACO) uses many ants (or agents) to traverse the solution space and find locally productive areas. While usually inferior to genetic algorithms and other forms of local search, it is able to produce results in problems where no global or up-to-date perspective can be obtained, and thus the other methods cannot be applied.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <link>
Bacteriologic Algorithms</link> (BA) inspired by <link xlink:type="simple" xlink:href="../011/1261011.xml">
evolutionary ecology</link> and, more particularly,  bacteriologic adaptation. Evolutionary ecology is the study of living organisms in the context of their environment, with the aim of discovering how they adapt. Its basic concept is that in a heterogeneous environment, you can’t find one individual that fits the whole environment. So, you need to reason at the population level. BAs have shown better results than GAs on problems such as complex positioning problems (antennas for cell phones, urban planning, and so on) or data mining.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2214%22])">14</ref></entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <know-how wordnetid="105616786" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<method wordnetid="105660268" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../980/5767980.xml">
Cross-entropy method</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</method>
</rule>
</event>
</know-how>
 The Cross-entropy (CE) method generates candidates solutions via a parameterized probability distribution. The parameters are updated via cross-entropy minimization, so as to generate better samples in the next iteration.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../962/13478962.xml">
Cultural algorithm</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
 (CA) consists of the population component almost identical to that of the genetic algorithm and, in addition, a knowledge component called the belief space. </entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../033/940033.xml">
Evolution strategies</link> (ES, see Rechenberg, 1971) evolve individuals by means of mutation and intermediate and discrete recombination. ES algorithms are designed particularly to solve problems in the real-value domain. They use self-adaptation to adjust control parameters of the search.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../689/460689.xml">
Evolutionary programming</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
 (EP) involves populations of solutions with primarily mutation and selection and arbitrary representations. They use self-adaptation to adjust parameters, and can include other variation operations such as combining information from multiple parents.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../828/4832828.xml">
Extremal optimization</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
 (EO) Unlike GAs, which work with a population of candidate solutions, EO evolves a single solution and makes <link xlink:type="simple" xlink:href="../942/313942.xml">
local</link> modifications to the worst components. This requires that a suitable representation be selected which permits individual solution components to be assigned a quality measure ("fitness").  The governing principle behind this algorithm is that of <it>emergent</it> improvement through selectively removing low-quality components and replacing them with a randomly selected component. This is decidedly at odds with a GA that selects good solutions in an attempt to make better solutions.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../345/9210345.xml">
Gaussian adaptation</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
 (normal or natural adaptation, abbreviated NA to avoid confusion with GA) is intended for the maximisation of manufacturing yield of signal processing systems. It may also be used for ordinary parametric optimisation. It relies on a certain theorem valid for all regions of acceptability and all Gaussian distributions. The efficiency of NA relies on information theory and a certain theorem of efficiency. Its efficiency is defined as information divided by the work needed to get the information<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2215%22])">15</ref>. Because NA maximises mean fitness rather than the fitness of the individual, the landscape is smoothed such that valleys between peaks may disappear. Therefore it has a certain “ambition” to avoid local peaks in the fitness landscape. NA is also good at climbing sharp crests by adaptation of the moment matrix, because NA may maximise the disorder (<link xlink:type="simple" xlink:href="../445/15445.xml">
average information</link>) of the Gaussian simultaneously keeping the <link xlink:type="simple" xlink:href="../849/187849.xml">
mean fitness</link> constant.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../424/12424.xml">
Genetic programming</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
 (GP) is a related technique popularized by <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<link xlink:type="simple" xlink:href="../867/147867.xml">
John Koza</link></scientist>
</causal_agent>
</person>
</physical_entity>
 in which computer programs, rather than function parameters, are optimized.  Genetic programming often uses <link xlink:type="simple" xlink:href="../806/30806.xml">
tree-based</link> internal <link xlink:type="simple" xlink:href="../519/8519.xml">
data structure</link>s to represent the computer programs for adaptation instead of the <link xlink:type="simple" xlink:href="../382/208382.xml">
list</link> structures typical of genetic algorithms.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <link>
Grouping Genetic Algorithm</link> (GGA) is an evolution of the GA where the focus is shifted from individual items, like in classical GAs, to groups or subset of items.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2216%22])">16</ref> The idea behind this GA evolution proposed by <link>
Emanuel Falkenauer</link> is that solving some complex problems, a.k.a. <it>clustering</it> or <it>partitioning</it> problems where a set of items must be split into disjoint group of items in an optimal way, would better be achieved by making characteristics of the groups of items equivalent to genes. These kind of problems include <condition wordnetid="113920835" confidence="0.8">
<state wordnetid="100024720" confidence="0.8">
<problem wordnetid="114410605" confidence="0.8">
<difficulty wordnetid="114408086" confidence="0.8">
<link xlink:type="simple" xlink:href="../015/287015.xml">
Bin Packing</link></difficulty>
</problem>
</state>
</condition>
, Line Balancing, Clustering w.r.t. a distance measure, Equal Piles, etc., on which classic GAs proved to perform poorly. Making genes equivalent to groups implies chromosomes that are in general of variable length, and special genetic operators that manipulate whole groups of items. For <condition wordnetid="113920835" confidence="0.8">
<state wordnetid="100024720" confidence="0.8">
<problem wordnetid="114410605" confidence="0.8">
<difficulty wordnetid="114408086" confidence="0.8">
<link xlink:type="simple" xlink:href="../015/287015.xml">
Bin Packing</link></difficulty>
</problem>
</state>
</condition>
 in particular, a GGA hybridized with the Dominance Criterion of Martello and Toth, is arguably the best technique to date.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../902/9485902.xml">
Harmony search</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
 (HS) is an algorithm mimicking musicians behaviors in improvisation process.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../162/901162.xml">
Interactive evolutionary algorithm</link>s are evolutionary algorithms that use human evaluation. They are usually applied to domains where it is hard to design a computational fitness function, for example, evolving images, music, artistic designs and forms to fit users' aesthetic preference.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../208/3989208.xml">
Memetic algorithm</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
 (MA), also called <it>hybrid genetic algorithm</it> among others, is a relatively new evolutionary method where local search is applied during the evolutionary cycle. The idea of memetic algorithms comes from <link xlink:type="simple" xlink:href="../312/19312.xml">
meme</link>s, which unlike genes, can adapt themselves. In some problem areas they are shown to be more efficient than traditional evolutionary algorithms.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../244/172244.xml">
Simulated annealing</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
 (SA) is a related global optimization technique that traverses the search space by testing random mutations on an individual solution.  A mutation that increases fitness is always accepted.  A mutation that lowers fitness is accepted probabilistically based on the difference in fitness and a decreasing temperature parameter.  In SA parlance, one speaks of seeking the lowest energy instead of the maximum fitness. SA can also be used within a standard GA algorithm by starting with a relatively high rate of mutation and decreasing it over time along a given schedule.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../543/7325543.xml">
Stochastic optimization</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
 is an umbrella set of methods that includes GAs and numerous other approaches.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../937/381937.xml">
Tabu search</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
 (TS) is similar to Simulated Annealing in that both traverse the solution space by testing mutations of an individual solution. While simulated annealing generates only one mutated solution, tabu search generates many mutated solutions and moves to the solution with the lowest energy of those generated. In order to prevent cycling and encourage greater movement through the solution space, a tabu list is maintained of partial or complete solutions. It is forbidden to move to a solution that contains elements of the tabu list, which is updated as the solution traverses the solution space.</entry>
</list>
</p>

</sec>
<sec>
<st>
Building block hypothesis</st>
<p>

Genetic algorithms are relatively simple to implement, but their behavior is difficult to understand. In particular it is difficult to understand why they are often successful in generating solutions of high fitness. The building block hypothesis (BBH) consists of:</p>
<p>

<list>
<entry level="1" type="number">

 A description of an abstract adaptive mechanism that performs adaptation by recombining "building blocks", i.e. low order, low defining-length schemata with  above average fitness. </entry>
<entry level="1" type="number">

 A hypothesis that a genetic algorithm performs adaptation by implicitly and efficiently implementing this abstract adaptive mechanism.  </entry>
</list>
</p>
<p>

(Goldberg 1989:41) describes the abstract adaptive mechanism as follows:</p>
<p>

<indent level="1">

Short, low order, and highly fit <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../671/17808671.xml">
schema</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
ta are sampled, <link xlink:type="simple" xlink:href="../546/554546.xml">
recombined</link> [crossed over], and resampled to form strings of potentially higher fitness. In a way, by working with these particular schemata [the building blocks], we have reduced the complexity of our problem; instead of building high-performance strings by trying every conceivable combination, we construct better and better strings from the best partial solutions of past samplings.
</indent>

<indent level="1">

Just as a child creates magnificent fortresses through the arrangement of simple blocks of wood [building blocks], so does a genetic algorithm seek near optimal performance through the juxtaposition of short, low-order, high-performance schemata, or building blocks.
</indent>

(Goldberg 1989) claims that the building block hypothesis is supported by <statement wordnetid="106722453" confidence="0.8">
<message wordnetid="106598915" confidence="0.8">
<theorem wordnetid="106752293" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<proposition wordnetid="106750804" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../360/4329360.xml">
Holland's schema theorem</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</proposition>
</rule>
</event>
</theorem>
</message>
</statement>
.</p>
<p>

The building block hypothesis has been sharply criticized on the grounds that it lacks theoretical justification and   experimental results have been published that draw its veracity into question. On the theoretical side, for example, Wright et al. state that 
<indent level="1">

"The various claims about GAs that are traditionally made under the name of the <it>building block hypothesis</it> have, to date, no basis in theory and, in some cases, are simply incoherent"<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2217%22])">17</ref>
</indent>

On the experimental side uniform crossover was seen to outperform one-point and two-point crossover on many of the fitness functions studied by Syswerda.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2218%22])">18</ref> Summarizing these results, Fogel remarks that </p>
<p>

<indent level="1">

"Generally, uniform crossover yielded better performance than two-point crossover, which in turn yielded better performance than one-point crossover"<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2219%22])">19</ref>
</indent>

Syswerda's results contradict the building block hypothesis because uniform crossover is extremely disruptive of short schemata whereas one and two-point crossover are more likely to conserve short schemata and combine their defining bits in children produced during recombination.</p>
<p>

The debate over the building block hypothesis demonstrates that the issue of how GAs "work", (i.e. perform adaptation) is currently far from settled.</p>

</sec>
<sec>
<st>
See also</st>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../128/145128.xml">
Algorithmic efficiency</link></entry>
</list>

</p>
</sec>
<sec>
<st>
Applications</st>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../571/16300571.xml">
Artificial Creativity</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../354/173354.xml">
Automated</link> design, including research on <link xlink:type="simple" xlink:href="../616/157616.xml">
composite material</link> design and <link>
multi-objective</link> design of automotive components for <link xlink:type="simple" xlink:href="../156/4135156.xml">
crashworthiness</link>, weight savings, and other characteristics.</entry>
<entry level="1" type="bullet">

 Automated design of <link xlink:type="simple" xlink:href="../604/304604.xml">
mechatronic</link> systems using <link xlink:type="simple" xlink:href="../853/3783853.xml">
bond graphs</link> and <link xlink:type="simple" xlink:href="../424/12424.xml">
genetic programming</link> (NSF).</entry>
<entry level="1" type="bullet">

 Automated design of industrial equipment using catalogs of exemplar lever patterns.</entry>
<entry level="1" type="bullet">

 Automated design of sophisticated trading systems in the financial sector.</entry>
<entry level="1" type="bullet">

 Building <link xlink:type="simple" xlink:href="../326/149326.xml">
phylogenetic tree</link>s.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2220%22])">20</ref></entry>
<entry level="1" type="bullet">

 Calculation of <link xlink:type="simple" xlink:href="../912/696912.xml">
Bound state</link>s and <link xlink:type="simple" xlink:href="../707/3146707.xml">
Local-density approximation</link>s.</entry>
<entry level="1" type="bullet">

 Chemical kinetics (<weblink xlink:type="simple" xlink:href="http://www.personal.leeds.ac.uk/~fuensm/project.html">
gas</weblink> and <weblink xlink:type="simple" xlink:href="http://repositories.cdlib.org/postprints/1154">
solid</weblink> phases)</entry>
<entry level="1" type="bullet">

 Configuration applications, particularly physics applications of optimal molecule configurations for particular systems like C60 (<link xlink:type="simple" xlink:href="../628/10628.xml">
buckyballs</link>).</entry>
<entry level="1" type="bullet">

 Container loading optimization.</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../715/5715.xml">
Code-breaking</link>, using the GA to search large solution spaces of <link xlink:type="simple" xlink:href="../244/5244.xml">
cipher</link>s for the one correct decryption.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2221%22])">21</ref></entry>
<entry level="1" type="bullet">

 Design of <link>
water distribution systems</link>.</entry>
<entry level="1" type="bullet">

 <link>
Distributed computer network</link> <link xlink:type="simple" xlink:href="../954/29954.xml">
topologies</link>.</entry>
<entry level="1" type="bullet">

 Electronic circuit design, known as <link xlink:type="simple" xlink:href="../654/783654.xml">
Evolvable hardware</link>.</entry>
<entry level="1" type="bullet">

 File allocation for a <link xlink:type="simple" xlink:href="../501/8501.xml">
distributed system</link>.</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../162/145162.xml">
Parallelization</link> of GAs/GPs including use of <link>
hierarchical decomposition</link> of <link xlink:type="simple" xlink:href="../733/1705733.xml">
problem domains</link> and design spaces <link xlink:type="simple" xlink:href="../347/791347.xml">
nesting</link> of irregular shapes using <link>
feature matching</link> and GAs.</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../924/11924.xml">
Game Theory</link> Equilibrium Resolution.</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../073/4007073.xml">
Gene expression profiling</link> analysis.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2222%22])">22</ref></entry>
<entry level="1" type="bullet">

 Learning <link xlink:type="simple" xlink:href="../781/25781.xml">
Robot</link> behavior using Genetic Algorithms.</entry>
<entry level="1" type="bullet">

 Learning fuzzy rule base using genetic algorithms.</entry>
<entry level="1" type="bullet">

 Linguistic analysis, including <link xlink:type="simple" xlink:href="../576/4375576.xml">
Grammar Induction</link> and other aspects of <link xlink:type="simple" xlink:href="../652/21652.xml">
Natural Language Processing</link> (NLP) such as word sense disambiguation.</entry>
<entry level="1" type="bullet">

 <link>
Marketing Mix Analysis</link></entry>
<entry level="1" type="bullet">

 Mobile communications infrastructure <link xlink:type="simple" xlink:href="../033/52033.xml">
optimization</link>.</entry>
<entry level="1" type="bullet">

 Molecular Structure Optimization (Chemistry).</entry>
<entry level="1" type="bullet">

 Multiple criteria production scheduling.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2223%22])">23</ref></entry>
<entry level="1" type="bullet">

 Multiple population <link xlink:type="simple" xlink:href="../954/29954.xml">
topologies</link> and interchange <link xlink:type="simple" xlink:href="../667/620667.xml">
methodologies</link>.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../670/176670.xml">
Operon</link> prediction.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2224%22])">24</ref></entry>
<entry level="1" type="bullet">

 Optimisation of data compression systems, for example using <link xlink:type="simple" xlink:href="../903/50903.xml">
wavelet</link>s.</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../624/24624.xml">
Pop music</link> record producer<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2225%22])">25</ref>.</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../085/52085.xml">
Protein folding</link> and protein/<link xlink:type="simple" xlink:href="../623/2292623.xml">
ligand docking</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2226%22])">26</ref></entry>
<entry level="1" type="bullet">

 <link>
Plant floor layout</link>.</entry>
<entry level="1" type="bullet">

 Representing rational agents in economic models such as the <link xlink:type="simple" xlink:href="../440/1476440.xml">
cobweb model</link>.</entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../214/4214.xml">
Bioinformatics</link>: <link xlink:type="simple" xlink:href="../758/25758.xml">
RNA</link> structure prediction.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2227%22])">27</ref></entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../214/4214.xml">
Bioinformatics</link>: [Multiple Sequence Alignment].<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2228%22])">28</ref>. SAGA is available on: <weblink xlink:type="simple" xlink:href="http://www.tcoffee.org/homepage.html">
http://www.tcoffee.org/homepage.html</weblink>.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../214/4214.xml">
Bioinformatics</link> <link xlink:type="simple" xlink:href="../308/4066308.xml">
Multiple sequence alignment</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2229%22])">29</ref></entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 Scheduling applications, including job-shop scheduling.  The objective being to schedule jobs in a <link>
sequence dependent</link> or non-sequence dependent setup environment in order to maximize the volume of production while minimizing penalties such as tardiness.</entry>
<entry level="1" type="bullet">

 Selection of optimal mathematical model to describe biological systems.</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../010/27010.xml">
Software engineering</link></entry>
<entry level="1" type="bullet">

 Solving the machine-component grouping problem required for <link xlink:type="simple" xlink:href="../578/9515578.xml">
cellular manufacturing</link> systems.</entry>
<entry level="1" type="bullet">

 <link>
Tactical asset</link> <link xlink:type="simple" xlink:href="../616/227616.xml">
allocation</link> and <link>
international equity</link> strategies.</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../433/277433.xml">
Timetabling</link> problems, such as designing a non-conflicting class timetable for a large university.</entry>
<entry level="1" type="bullet">

 Training <link xlink:type="simple" xlink:href="../523/21523.xml">
artificial neural networks</link> when pre-classified training examples are not readily obtainable (<link xlink:type="simple" xlink:href="../706/440706.xml">
neuroevolution</link>).</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../248/31248.xml">
Traveling Salesman Problem</link>.</entry>
<entry level="1" type="bullet">

 Finding hardware bugs. <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2230%22])">30</ref> <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2231%22])">31</ref></entry>
<entry level="1" type="bullet">

 Wireless Sensor/Ad-hoc Networks. <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2232%22])">32</ref></entry>
<entry level="1" type="bullet">

 Data Center/Server Farm. <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2233%22])">33</ref></entry>
</list>
</p>

</sec>
<sec>
<st>
References</st>

<p>

<reflist>
<entry id="1">
 <cite style="font-style:normal">Kjellström, G.&#32;(1970).&#32;"Optimization of electrical Networks with respect to Tolerance Costs.". <it>Ericsson Technics</it>&#32;(3): 157–175.</cite>&nbsp;</entry>
<entry id="2">
 <cite style="font-style:normal">Kjellström, G.&#32;(January 1996).&#32;"Evolution as a statistical optimization algorithm". <it>Evolutionary Theory</it>&#32;(11): 105–117.</cite>&nbsp;</entry>
<entry id="3">
 <cite style="font-style:normal"><physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<mathematician wordnetid="110301261" confidence="0.8">
<link xlink:type="simple" xlink:href="../217/16752217.xml">
Barricelli, Nils Aall</link></mathematician>
</scientist>
</causal_agent>
</person>
</physical_entity>
&#32;(1954).&#32;"Esempi numerici di processi di evoluzione". <it>Methodos</it>: 45–68.</cite>&nbsp;</entry>
<entry id="4">
 <cite style="font-style:normal"><physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<mathematician wordnetid="110301261" confidence="0.8">
<link xlink:type="simple" xlink:href="../217/16752217.xml">
Barricelli, Nils Aall</link></mathematician>
</scientist>
</causal_agent>
</person>
</physical_entity>
&#32;(1957).&#32;"Symbiogenetic evolution processes realized by artificial methods". <it>Methodos</it>: 143–182.</cite>&nbsp;</entry>
<entry id="5">
 <cite style="font-style:normal"><physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<link xlink:type="simple" xlink:href="../140/2995140.xml">
Fraser, Alex</link></scientist>
</causal_agent>
</person>
</physical_entity>
&#32;(1957).&#32;"Simulation of genetic systems by automatic digital computers. I. Introduction". <it>Aust. J. Biol. Sci.</it>&#32;<b>10</b>: 484–491.</cite>&nbsp;</entry>
<entry id="6">
 <cite id="Reference-Fraser-1970" style="font-style:normal" class="book"><physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<link xlink:type="simple" xlink:href="../140/2995140.xml">
Fraser, Alex</link></scientist>
</causal_agent>
</person>
</physical_entity>
;&#32;Donald Burnell&#32;(1970). Computer Models in Genetics.&#32;New York:&#32;McGraw-Hill.</cite>&nbsp;</entry>
<entry id="7">
 <cite id="Reference-Crosby-1973" style="font-style:normal" class="book">Crosby, Jack L.&#32;(1973). Computer Simulation in Genetics.&#32;London:&#32;John Wiley &amp; Sons.</cite>&nbsp;</entry>
<entry id="8">
 <cite id="Reference-Fogel-1998" style="font-style:normal" class="book">Fogel, David B. (editor)&#32;(1998). Evolutionary Computation: The Fossil Record.&#32;New York:&#32;IEEE Press.</cite>&nbsp;</entry>
<entry id="9">
 <cite style="font-style:normal">Barricelli, Nils Aall&#32;(1963).&#32;"Numerical testing of evolution theories.  Part II. Preliminary tests of performance, symbiogenesis and terrestrial life". <it>Acta Biotheoretica</it>&#32;(16): 99–126.</cite>&nbsp;</entry>
<entry id="10">
 <cite id="Reference-Schwefel-1974" style="font-style:normal" class="book">Schwefel, Hans-Paul&#32;(1974). Numerische Optimierung von Computer-Modellen (PhD thesis).</cite>&nbsp;</entry>
<entry id="11">
 <cite id="Reference-Schwefel-1977" style="font-style:normal" class="book">Schwefel, Hans-Paul&#32;(1977). Numerische Optimierung von Computor-Modellen mittels der Evolutionsstrategie : mit einer vergleichenden Einführung in die Hill-Climbing- und Zufallsstrategie.&#32;Birkhäuser. ISBN 3764308761.</cite>&nbsp;</entry>
<entry id="12">
 <cite id="Reference-Schwefel-1981" style="font-style:normal" class="book">Schwefel, Hans-Paul&#32;(1981). Numerical optimization of computer models (Translation of 1977 'Numerische Optimierung von Computor-Modellen mittels der Evolutionsstrategie'.&#32;Wiley. ISBN 0471099880.</cite>&nbsp;</entry>
<entry id="13">
Markoff, John&#32;(1989).&#32;"<weblink xlink:type="simple" xlink:href="http://query.nytimes.com/gst/fullpage.html?res=9C0CE1D6153BF93AA1575BC0A966958260">
What's the Best Answer? It's Survival of the Fittest</weblink>".&#32;  New York Times.</entry>
<entry id="14">
 <cite style="font-style:normal">Baudry, Benoit; Franck Fleurey, <link>
Jean-Marc Jézéquel</link>, and Yves Le Traon&#32;(March/April 2005).&#32;"<weblink xlink:type="simple" xlink:href="http://www.irisa.fr/triskell/publis/2005/Baudry05d.pdf">
Automatic Test Case Optimization: A Bacteriologic Algorithm</weblink>". <it>IEEE Software</it>&#32;<b>22</b>: 76–82.&#32;IEEE Computer Society. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1109%2FMS.2005.30">
10.1109/MS.2005.30</weblink>.</cite>&nbsp;</entry>
<entry id="15">
 <cite style="font-style:normal">Kjellström, G.&#32;(Dec. 1991).&#32;"On the Efficiency of Gaussian Adaptation". <it>Journal of Optimization Theory and Applications</it>&#32;<b>71</b>&#32;(3): 589–597. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1007%2FBF00941405">
10.1007/BF00941405</weblink>.</cite>&nbsp;</entry>
<entry id="17">
 <cite style="font-style:normal">Wright, A.H.;&#32;et al.&#32;(2003). "Implicit Parallelism".&#32;<it>Proceedings of the Genetic and Evolutionary Computation Conference</it>.</cite>&nbsp;</entry>
<entry id="16">
 <cite id="Reference-Falkenauer-1997" style="font-style:normal" class="book"><link>
Falkenauer, Emanuel</link>&#32;(1997). Genetic Algorithms and Grouping Problems.&#32;Chichester, England:&#32;John Wiley &amp; Sons Ltd. ISBN 978-0-471-97150-4.</cite>&nbsp;</entry>
<entry id="19">
 <cite id="Reference-Fogel-2000" style="font-style:normal" class="book">Fogel, David B.&#32;(2000). Evolutionary Computation: Towards a New Philosophy of Machine Intelligence.&#32;New York:&#32;IEEE Press,&#32;140.</cite>&nbsp;</entry>
<entry id="18">
 <cite style="font-style:normal">Syswerda, G.&#32;(1989). "Uniform crossover in genetic algorithms".&#32;J. D. Schaffer&#32;<it>Proceedings of the Third International Conference on Genetic Algorithms</it>, Morgan Kaufmann.</cite>&nbsp;</entry>
<entry id="21">
Joachim De Zutter <weblink xlink:type="simple" xlink:href="http://byterage.hackaholic.org/kb/codebreaking.pdf">
"Codebreaking"</weblink> 
</entry>
<entry id="20">
 <cite style="font-style:normal">Hill T, Lundgren A, Fredriksson R, Schiöth HB&#32;(2005).&#32;"Genetic algorithm for large-scale maximum parsimony phylogenetic analysis of proteins". <it>Biochimica et Biophysica Acta</it>&#32;<b>1725</b>: 19–29. PMID 15990235.</cite>&nbsp;</entry>
<entry id="23">
 <cite style="font-style:normal">Bagchi Tapan P&#32;(1999).&#32;"Multiobjective Scheduling by Genetic Algorithms".</cite>&nbsp;</entry>
<entry id="22">
 <cite style="font-style:normal">To CC, Vohradsky J&#32;(2007).&#32;"A parallel genetic algorithm for single class pattern classification and its application for gene expression profiling in Streptomyces coelicolor". <it>BMC Genomics</it>&#32;<b>8</b>: 49. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1186%2F1471-2164-8-49">
10.1186/1471-2164-8-49</weblink>. PMID 17298664.</cite>&nbsp;</entry>
<entry id="25">
<weblink xlink:type="simple" xlink:href="http://news.bbc.co.uk/1/hi/entertainment/123983.stm">
BBC News | Entertainment | To the beat of the byte</weblink></entry>
<entry id="24">
 <cite style="font-style:normal">Wang S, Wang Y, Du W, Sun F, Wang X, Zhou C, Liang Y&#32;(2007).&#32;"A multi-approaches-guided genetic algorithm with application to operon prediction". <it>Artificial Intelligence in Medicine</it>&#32;<b>41</b>: 151–159. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1016%2Fj.artmed.2007.07.010">
10.1016/j.artmed.2007.07.010</weblink>. PMID 17869072.</cite>&nbsp;</entry>
<entry id="27">
 <cite style="font-style:normal">van Batenburg FH, Gultyaev AP, Pleij CW&#32;(1995).&#32;"An APL-programmed genetic algorithm for the prediction of RNA secondary structure". <it>Journal of Theoretical Biology</it>&#32;<b>174</b>: 269–280. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1006%2Fjtbi.1995.0098">
10.1006/jtbi.1995.0098</weblink>. PMID 7545258.</cite>&nbsp;</entry>
<entry id="26">
 <cite style="font-style:normal">Willett P&#32;(1995).&#32;"Genetic algorithms in molecular recognition and design". <it>Trends in Biotechnology</it>&#32;<b>13</b>: 516–521. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1016%2FS0167-7799%2800%2989015-0">
10.1016/S0167-7799(00)89015-0</weblink>. PMID 8595137.</cite>&nbsp;</entry>
<entry id="29">
 <cite style="font-style:normal">Gondro C, Kinghorn BP&#32;(2007).&#32;"A simple genetic algorithm for multiple sequence alignment". <it>Genetics and Molecular Research</it>&#32;<b>6</b>: 964–982. PMID 18058716.</cite>&nbsp;</entry>
<entry id="28">
 <cite style="font-style:normal">Notredame C, Higgins DG&#32;(1995).&#32;"SAGA a Genetic Algorithm for Multiple Sequence Alignment". <it>Nulceic Acids Research</it>&#32;<b>174</b>: 1515. PMID 8628686.</cite>&nbsp;</entry>
<entry id="31">
Ibrahim, W. and Amer, H.: An Adaptive Genetic Algorithm for VLSI Test Vector Selection</entry>
<entry id="30">
Hitoshi Iba, Sumitaka Akiba, Tetsuya Higuchi, Taisuke Sato: BUGS: A Bug-Based Search Strategy using Genetic Algorithms. PPSN 1992: </entry>
<entry id="32">
<weblink xlink:type="simple" xlink:href="http://dssg.cs.umb.edu/wiki/index.php/BiSNET/e">
BiSNET/e - Distributed Software Systems Group, University of Massachusetts, Boston</weblink></entry>
<entry id="33">
<weblink xlink:type="simple" xlink:href="http://dssg.cs.umb.edu/wiki/index.php/SymbioticSphere">
SymbioticSphere - Distributed Software Systems Group, University of Massachusetts, Boston</weblink></entry>
</reflist>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <cite style="font-style:normal">Bies, Robert R; Muldoon, Matthew F; Pollock, Bruce G; Manuck, Steven; Smith, Gwenn and Sale, Mark E&#32;(2006).&#32;"A Genetic Algorithm-Based, Hybrid Machine Learning Approach to Model Selection". <it>Journal of Pharmacokinetics and Pharmacodynamics</it>: 196–221.&#32;Netherlands:&#32;Springer.</cite>&nbsp;</entry>
<entry level="1" type="bullet">

 <cite style="font-style:normal">Fraser, Alex S.&#32;(1957).&#32;"Simulation of Genetic Systems by Automatic Digital Computers. I. Introduction". <it>Australian Journal of Biological Sciences</it>&#32;<b>10</b>: 484–491.</cite>&nbsp;</entry>
<entry level="1" type="bullet">

Goldberg, David E (1989), <it>Genetic Algorithms in Search, Optimization and Machine Learning,</it> Kluwer Academic Publishers, Boston, MA.</entry>
<entry level="1" type="bullet">

Goldberg, David E (2002), <it>The Design of Innovation: Lessons from and for Competent Genetic Algorithms,</it> Addison-Wesley, Reading, MA.</entry>
<entry level="1" type="bullet">

Fogel, David B (2006), <it>Evolutionary Computation: Toward a New Philosophy of Machine Intelligence,</it> IEEE Press, Piscataway, NJ. Third Edition</entry>
<entry level="1" type="bullet">

Holland, John H (1975), <it>Adaptation in Natural and Artificial Systems</it>, University of Michigan Press, Ann Arbor</entry>
<entry level="1" type="bullet">

Koza, John (1992), <it>Genetic Programming: On the Programming of Computers by Means of Natural Selection</it>, <company wordnetid="108058098" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../601/719601.xml">
MIT Press</link></company>
. ISBN 0-262-11170-5</entry>
<entry level="1" type="bullet">

Michalewicz, Zbigniew (1999), <it>Genetic Algorithms + Data Structures = Evolution Programs</it>, Springer-Verlag.</entry>
<entry level="1" type="bullet">

Mitchell, Melanie, (1996), <it>An Introduction to Genetic Algorithms</it>, MIT Press, Cambridge, MA.</entry>
<entry level="1" type="bullet">

 <cite style="font-style:normal" class="book">Poli, R., Langdon, W. B., McPhee, N. F.&#32;(2008). A Field Guide to Genetic Programming.&#32;Lulu.com, freely available from the internet. ISBN 978-1-4092-0073-4.</cite>&nbsp;</entry>
<entry level="1" type="bullet">

Rechenberg, Ingo (1971): Evolutionsstrategie - Optimierung technischer Systeme nach Prinzipien der biologischen Evolution (PhD thesis). Reprinted by Fromman-Holzboog (1973).</entry>
<entry level="1" type="bullet">

Schmitt, Lothar M, Nehaniv Chrystopher N, Fujii Robert H (1998), <it>Linear analysis of genetic algorithms</it>, Theoretical Computer Science (208), pp. 111-148</entry>
<entry level="1" type="bullet">

Schmitt, Lothar M (2001),  <it>Theory of Genetic Algorithms</it>, Theoretical Computer Science (259), pp. 1-61</entry>
<entry level="1" type="bullet">

Schmitt, Lothar M (2004),  <it>Theory of Genetic Algorithms II: models for genetic operators over the string-tensor representation of populations and convergence to global optima for arbitrary fitness function under scaling</it>, Theoretical Computer Science (310), pp. 181-231</entry>
<entry level="1" type="bullet">

 Schwefel, Hans-Paul (1974): Numerische Optimierung von Computer-Modellen (PhD thesis). Reprinted by Birkhäuser (1977).</entry>
<entry level="1" type="bullet">

Vose, Michael D (1999), <it>The Simple Genetic Algorithm: Foundations and Theory</it>, MIT Press, Cambridge, MA.</entry>
<entry level="1" type="bullet">

Whitley, D. (1994). <it>A genetic algorithm tutorial</it>. Statistics and Computing 4, 65–85.</entry>
</list>
</p>


</sec>
<sec>
<st>
External links</st>



<p>

<list>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://ti.arc.nasa.gov/projects/esg/research/antenna.htm">
Antenna optimization for NASA</weblink> A successful application of genetic algorithms.</entry>
</list>
</p>

<ss1>
<st>
Tutorials</st>
<p>

<list>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.gp-field-guide.org.uk/">
A Field Guide to Genetic Programming</weblink> A book, freely downloadable under a Creative Commons license.</entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.obitko.com/tutorials/genetic-algorithms/">
Introduction to Genetic Algorithms with interactive Java applets</weblink> For experimenting with GAs online</entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://fog.neopages.org/helloworldgeneticalgorithms.php">
A Practical Tutorial on Genetic Algorithm</weblink> Programming a Genetic Algorithm step by step.  </entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://samizdat.mines.edu/ga_tutorial/ga_tutorial.ps">
A Genetic Algorithm Tutorial by Darrell Whitley Computer Science Department Colorado State University</weblink> An excellent tutorial with lots of theory</entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://evoadaptation.wordpress.com/2007/09/04/the-dubious-history-of-the-building-block-hypothesis/">
The Dubious History of the Building Block Hypothesis</weblink> </entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.talkorigins.org/faqs/genalg/genalg.html">
Cross discipline example applications for GAs with references.</weblink></entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.it-weise.de/projects/book.pdf">
Global Optimization Algorithms - Theory and Application</weblink></entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://dssg.cs.umb.edu/wiki/index.php/Multiobjective_Optimization_of_SLA-aware_Service_Composition">
Multiobjective Optimization of SLA-aware Service Composition</weblink></entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.learnartificialneuralnetworks.com/geneticalg.html">
Using Genetic Algorithms</weblink> A commercial site.</entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.heatonresearch.com/online/introduction-neural-networks-java-edition-2/chapter-6">
Genetic Algorithms in Java</weblink> An online chapter about programming genetic algorithms in Java.</entry>
</list>
</p>

</ss1>
<ss1>
<st>
Libraries</st>
<p>

<list>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://paradiseo.gforge.inria.fr">
ParadisEO</weblink> A powerful C++ framework dedicated to the reusable design of metaheuristics, included genetic algorithms. </entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://evoadaptation.wordpress.com/2007/01/25/january-23-2007-untitled/">
VectorGA</weblink> A vectorized implementation of a genetic algorithm in Matlab. </entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://ai4r.rubyforge.org/geneticAlgorithms.html">
Genetic Algorithms in Ruby</weblink> </entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://lancet.mit.edu/ga/">
GAlib</weblink> A C++ Library of Genetic Algorithm Components </entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://laurel.datsi.fi.upm.es/projects/gaedalib">
GAEDALib</weblink> A C++ Library of Evolutive Algotithms (GAs, EDAs, DEs and others) based in GAlib, and supporting to MOS and parallel computing</entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.hao.ucar.edu/Public/models/pikaia/pikaia.html">
A Fortran code (PIKAIA) with a tutorial by Paul Charbonneau and Barry Knapp, National Center for Atmospheric Research.</weblink> An excellent tutorial and a versatile public domain code. PIKAIA is also available in <weblink xlink:type="simple" xlink:href="http://www.ecy.wa.gov/programs/eap/models.html">
a version for Microsoft Excel</weblink>, as well as <weblink xlink:type="simple" xlink:href="http://whitedwarf.org/index.html?parallel/&amp;0">
a parallel processing version</weblink>.</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.mathworks.com/access/helpdesk/help/toolbox/gads/ga.html">
ga</weblink> Genetic Algorithm in MATLAB (<weblink xlink:type="simple" xlink:href="http://www.mathworks.com/access/helpdesk/help/toolbox/gads/index.html?/access/helpdesk/help/toolbox/gads/f6187.html">
How GA in MATLAB works</weblink>)</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.mathworks.com/access/helpdesk/help/toolbox/gads/gamultiobj.html">
gamultiobj</weblink> Mulitobjective Genetic Algorithm in MATLAB</entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://garage.cse.msu.edu/">
GARAGe</weblink> Michigan State University's Genetic Algorithm library in C, GALLOPS</entry>
</list>






</p>

</ss1>
</sec>
</bdy>
</algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</article>
