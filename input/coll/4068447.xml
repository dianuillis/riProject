<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 20:54:25[mciao0826] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Successive over-relaxation</title>
<id>4068447</id>
<revision>
<id>223928420</id>
<timestamp>2008-07-06T15:41:07Z</timestamp>
<contributor>
<username>Jitse Niesen</username>
<id>14515</id>
</contributor>
</revision>
<categories>
<category>Articles with example pseudocode</category>
<category>Numerical linear algebra</category>
</categories>
</header>
<bdy>

<b>Successive over-relaxation</b> (<b>SOR</b>) is a <link xlink:type="simple" xlink:href="../506/21506.xml">
numerical method</link> used to speed up convergence of the <link>
Gauss–Seidel method</link> for solving a <link xlink:type="simple" xlink:href="../087/113087.xml">
linear system of equations</link>. A similar method can be used for any slowly converging iterative process. It was devised simultaneously by David M. Young 
and by H. Frankel in 1950 for the purpose of automatically solving linear systems on digital computers.
Over-relaxation methods have been used before the work of Young and Frankel. For instance, the method of <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../456/430456.xml">
Lewis Fry Richardson</link></scientist>
</person>
, and the methods developed by R. V. Southwell. However, these methods 
were designed for computation by human calculators, and they required some expertise to ensure convergence
to the solution which made them inapplicable for programming on digital computers. These aspects are discussed in the thesis of David M. Young. 
<sec>
<st>
Formulation</st>
<p>

We seek the solution to a set of linear equations 
<indent level="1">

<math> A \phi = b. \,</math> 
</indent>
Write the matrix <it>A</it> as <it>A</it> = <it>D</it> + <it>L</it> + <it>U</it>, where <it>D</it>, <it>L</it> and <it>U</it> denote the diagonal, strictly lower triangular, and strictly upper triangular parts of <math>A</math>, respectively.</p>
<p>

The successive over-relaxation (SOR) iteration is defined by the recurrence relation
<indent level="1">

<math> 
(D+\omega L) \phi^{(k+1)} = (-\omega U + (1-\omega)D) \phi^{(k)} + \omega b. \qquad (*)
</math>
</indent>
Here, φ(<it>k</it>) denotes the <it>k</it>th iterate and <math> \omega </math> is a relaxation factor. This iteration reduces to the <link xlink:type="simple" xlink:href="../824/4046824.xml">
Gauss–Seidel</link> iteration for ω = 1.  As with the Gauss–Seidel method, the computation may be done in place, and the iteration is continued until the changes made by an iteration are below some tolerance.</p>
<p>

The choice of relaxation factor is not necessarily easy, and depends upon the properties of the coefficient matrix.  For <link xlink:type="simple" xlink:href="../474/126474.xml">
symmetric</link>, <link xlink:type="simple" xlink:href="../326/40326.xml">
positive-definite</link> <link xlink:type="simple" xlink:href="../728/19008728.xml">
matrices</link> it can be proven that <math>0&amp;lt;\omega&amp;lt;2</math> will lead to convergence, but we are generally interested in faster convergence rather than just convergence. </p>
<p>

As in the Gauss–Seidel method, in order to implement the iteration (&amp;lowast;) it is only necessary to solve a triangular system of linear equations, which is much simpler than solving the original arbitrary system. The iteration formula is:</p>
<p>

<indent level="1">

<math> 
\phi^{(k+1)}_i  = (1-\omega)\phi^{(k)}_i+\frac{\omega}{a_{ii}} \left(b_i - \sum_{j=1}^{i-1} a_{ij}\phi^{(k+1)}_j - \sum_{j=i+1}^n a_{ij}\phi^{(k)}_j\right),\, i=1,2,\ldots,n.
</math>
</indent>

</p>
</sec>
<sec>
<st>
 Algorithm </st>

<p>

Inputs: <it>A</it> , <it>b</it>, ω 
Output: φ</p>
<p>

Choose an initial guess <math>\phi</math> to the solution 
<b>repeat</b> until convergence
<indent level="1">

<b>for</b> <it>i</it> <b>from</b> 1 <b>until</b> <it>n</it> <b>do</b>
</indent>
::σ ← 0
<indent level="2">

<b>for</b> <it>j</it> <b>from</b> 1 <b>until</b> <it>i</it> &amp;minus; 1 <b>do</b>
</indent>
:::σ ← σ + a<it>ij</it> φ<it>j</it>
<indent level="2">

<b>end</b> (<it>j</it>-loop)
</indent>
::<b>for</b> <it>j</it> <b>from</b> <it>i</it> + 1 <b>until</b> <it>n</it> <b>do</b> 
<indent level="3">

σ ← σ + a<it>ij</it> φ<it>j</it>
</indent>
::<b>end</b> (<it>j</it>-loop) 
<indent level="2">

<math> \phi_i \leftarrow (1-\omega)\phi_i + \frac{\omega}{a_{ii}} (b_i - \sigma) </math>
</indent>
:<b>end</b> (<it>i</it>-loop)
<indent level="1">

check if convergence is reached
</indent>
<b>end</b> (repeat)</p>

</sec>
<sec>
<st>
Other applications of the method</st>
<p>

A similar technique can be used for any iterative method. Values of <math>\omega&amp;gt;1</math> are used to speedup convergence of a slow-converging process, while values of <math>\omega&amp;lt;1</math> are often used to help establish convergence of a diverging iterative process.</p>
<p>

There are various methods that adaptively set the relaxation parameter <math>\omega</math> based on the observed behavior of the converging process. Usually they help to reach a super-linear convergence for some problems but fail for the others</p>

</sec>
<sec>
<st>
References</st>
<p>

<list>
<entry level="1" type="bullet">

This article incorporates text from the article <weblink xlink:type="simple" xlink:href="http://www.cfd-online.com/Wiki/Successive_over-relaxation_method_-_SOR">
Successive_over-relaxation_method_-_SOR</weblink> on <weblink xlink:type="simple" xlink:href="http://www.cfd-online.com/Wiki/Main_Page">
CFD-Wiki</weblink> that is under the <link xlink:type="simple" xlink:href="../782/18938782.xml">
GFDL</link> license.</entry>
<entry level="1" type="bullet">

Yousef Saad, <it><weblink xlink:type="simple" xlink:href="http://www-users.cs.umn.edu/%7Esaad/books.html">
Iterative Methods for Sparse Linear Systems</weblink></it>, 1st edition, PWS, 1996.</entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.netlib.org/utk/papers/templates/node11.html">
Netlib</weblink>'s copy of Jack Dongarra's section of "Templates for the Solution of Linear Systems"</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.cs.utexas.edu/users/young/">
Web page of David M. Young</weblink> </entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.cs.utexas.edu/users/young/david_young_thesis.pdf">
PhD Thesis of David M. Young</weblink> (Harvard, 1950)</entry>
</list>
</p>

</sec>
<sec>
<st>
External links</st>
<p>

<list>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://math.fullerton.edu/mathews/n2003/SORmethodMod.html">
Module for the SOR Method</weblink></entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.redbrick.dcu.ie/~hyperion/files/Project.pdf">
The Successive Over–Relaxation (S.O.R.) Algorithm &amp; its Application to Numerical Solutions of Elliptic Partial Differential Equations</weblink></entry>
</list>
</p>


</sec>
</bdy>
</article>
