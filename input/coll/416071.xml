<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 17:00:35[mciao0827] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Relationship between latency and throughput</title>
<id>416071</id>
<revision>
<id>242212589</id>
<timestamp>2008-10-01T10:17:23Z</timestamp>
<contributor>
<username>SmackBot</username>
<id>433328</id>
</contributor>
</revision>
<categories>
<category>Computing comparisons</category>
<category>Information theory</category>
</categories>
</header>
<bdy>

A common concern in the development or procurement of a telecommunications system is a simple question: "will my data arrive fast enough?". This question in fact contains many subtle parts, based on the interplay of several factors. The perceived 'fastness' (speed being a scientific quantity related to propagation and so is not used in this context) is highly dependent on user requirements and measurement technique. A common misunderstanding is that having greater <link xlink:type="simple" xlink:href="../932/30932.xml">
throughput</link> means a "faster" connection. However, throughput, <link xlink:type="simple" xlink:href="../933/17933.xml">
latency</link>, the type of information transmitted, and the way that information is applied all affect the <it>perceived speed</it> of a connection.
<sec>
<st>
Terms</st>

<p>

<indent level="1">

<it>Main article: <link xlink:type="simple" xlink:href="../933/17933.xml">
latency (engineering)</link></it>
</indent>
<it>Latency</it> is the delay between the initiation of a network transmission by a sender and the receipt of that transmission by a receiver. In two-way communication, it may be measured as the time from the transmission of a request for a message, to the time when the message is successfully received. </p>

<p>

<indent level="1">

<it>Main article: <link xlink:type="simple" xlink:href="../932/30932.xml">
throughput</link></it>
</indent>
<it>Throughput</it> is the number of messages successfully delivered per unit time. Throughput is controlled by available bandwidth, as well as the available signal-to-noise ratio and hardware limitations. Throughput for the purpose of this article will be understood to be measured from the arrival of the first bit of data at the receiver, to decouple the concept of throughput from the concept of latency. For discussions of this type the terms 'throughput' and 'bandwidth' are often used interchangeably.</p>
<p>

The <it>Time Window</it> is the period over which the throughput is measured. Choice of an appropriate time window will often dominate calculations of throughput, and whether latency is taken into account or not will determine whether the latency affects the throughput or not.</p>

</sec>
<sec>
<st>
Interplay of factors</st>

<p>

All of the factors above, coupled with user requirements and user perceptions, play a role in determining the perceived 'fastness' or utility, of a network connection. The relationship between throughput, latency, and user experience is most aptly understood in the context of a shared network medium, and as a scheduling problem. For systems that are heavily dominated by either latency or throughput considerations. </p>

<ss1>
<st>
Physical limitations</st>

<p>

<list>
<entry level="1" type="bullet">

 The <link xlink:type="simple" xlink:href="../736/28736.xml">
Speed of light</link> imposes a minimum propagation time on all electromagnetic signals. It is not possible to reduce the latency below t=(distance)/(speed of light).</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 The available channel bandwidth and achievable signal-to-noise ratio dominate the throughput. It is not generally possible to send more data than dictated by the <link xlink:type="simple" xlink:href="../085/71085.xml">
Shannon-Hartley Theorem</link>.</entry>
</list>
</p>

</ss1>
<ss1>
<st>
Algorithms and protocols</st>

<p>

For some systems, latency and throughput are coupled entities. In TCP/IP, latency can also directly affect throughput. In <link xlink:type="simple" xlink:href="../538/30538.xml">
TCP</link> connections, the large <link xlink:type="simple" xlink:href="../063/3586063.xml">
bandwidth-delay product</link> of high latency connections, combined with relatively small TCP window sizes on many devices, effectively causes the throughput of a high latency connection to drop sharply with latency.  This can be remedied with various techniques, such as increasing the TCP congestion window size, or more drastic solutions, such as packet coalescing, TCP acceleration, and forward error correction, all of which are commonly used for high latency satellite links.  </p>
<p>

TCP acceleration converts the TCP packets into a stream that is similar to <message wordnetid="106598915" confidence="0.8">
<protocol wordnetid="106665108" confidence="0.8">
<standard wordnetid="107260623" confidence="0.8">
<direction wordnetid="106786629" confidence="0.8">
<rule wordnetid="106652242" confidence="0.8">
<system_of_measurement wordnetid="113577171" confidence="0.8">
<link xlink:type="simple" xlink:href="../929/31929.xml">
UDP</link></system_of_measurement>
</rule>
</direction>
</standard>
</protocol>
</message>
.  Because of this, the TCP acceleration software must provide its own mechanisms to ensure the reliability of the link, taking the latency and bandwidth of the link into account, and both ends of the high latency link must support the method used.</p>

</ss1>
</sec>
<sec>
<st>
Examples of latency or throughput dominated systems</st>

<p>

Many systems can be characterized as dominated either by throughput limitations or by latency limitations in terms of end-user utility or experience. In some cases, hard limit s such as the speed of light present unique problems to such systems and nothing can be done to correct this. Other systems allow for significant balancing and optimization for best user experience.</p>

<ss1>
<st>
Satellite telephony</st>

<p>

A telecom satellite in geosynchronous orbit imposes a path length of at least 71000 km between transmitter and receiver. <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref> which means a minimum delay between message request and message receipt, or latency of 473 ms. This delay can be very noticeable and affects satellite phone service regardless of available throughput capacity.</p>

</ss1>
<ss1>
<st>
Deep space communication</st>

<p>

These long path length considerations are exacerbated when communicating with space probes and other long-range targets beyond Earth's atmosphere. The <observatory wordnetid="103839671" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../522/231522.xml">
Deep Space Network</link></observatory>
 implemented by NASA is one such system that must cope with these problems. Largely latency driven, the GAO has criticized the current architecture. <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref> Several different methods have been proposed to handle the intermittent connectivity and long delays between packets, such as <message wordnetid="106598915" confidence="0.8">
<protocol wordnetid="106665108" confidence="0.8">
<direction wordnetid="106786629" confidence="0.8">
<rule wordnetid="106652242" confidence="0.8">
<link xlink:type="simple" xlink:href="../684/2710684.xml">
Delay Tolerant Networking</link></rule>
</direction>
</protocol>
</message>
 <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%223%22])">3</ref>. </p>

</ss1>
<ss1>
<st>
Even deeper space communication</st>

<p>

At interstellar distances, the difficulties in designing radio systems that can achieve any throughput at all is massive. In these cases, maintaining communication is a bigger issue than how long that communication takes.</p>

</ss1>
<ss1>
<st>
Offline data transport</st>

<p>

Transportation is concerned almost entirely with throughput, which is why physical deliveries of backup tape archives are still largely done by vehicle.</p>

</ss1>
</sec>
<sec>
<st>
Examples of optimizable systems</st>

<ss1>
<st>
Web surfing</st>
<p>

Users browsing the <link xlink:type="simple" xlink:href="../539/14539.xml">
Internet</link> are usually tolerant of a latency of between 1000 and 3000 ms between mouse click and page download . Latency and throughput together affect the perceived speed of a connection. However, the perceived fastness of a connection can still vary widely, depending in part on the type of information transmitted and how it is used.</p>
<p>

For example, to view a web page over a <link xlink:type="simple" xlink:href="../510/35510.xml">
56-kbit/s</link> <link xlink:type="simple" xlink:href="../900/19443900.xml">
modem</link> transmitted from a server 4,800 km (~3,000 <link xlink:type="simple" xlink:href="../159/19159.xml">
mi.</link>) away, latency over the Internet is fairly low – typically about a quarter of a second – and an average web page of 30-100 kilobytes would transfer in 10-30 seconds.</p>
<p>

However, to transfer the contents of a <medium wordnetid="106254669" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../498/11014498.xml">
DVD</link></medium>
 over a modem could take a week or more at this rate. Simply <link xlink:type="simple" xlink:href="../939/521939.xml">
packing the DVD into an envelope and mailing it</link> could be faster.</p>
<p>

Using a <link xlink:type="simple" xlink:href="../542/907542.xml">
T1</link> line with similar latencies, one could download the same web page in under a second. To download a 5-<link xlink:type="simple" xlink:href="../570/12570.xml">
GB</link> DVD over this 1.5-Mbit/s connection would take about 7.4 hours.</p>

</ss1>
<ss1>
<st>
Internet gaming</st>

<p>

Network gaming requires very low latency, but requires limited throughput, often as low as a few kilobits per second. The required maximum latency is game type dependent. In first person shooters under 100 ms is required (sometimes even lower) . In strategy games the maximum latency could be allowed to reach 600 ms, depending on the game. </p>

</ss1>
</sec>
<sec>
<st>
 Notes </st>


<p>

<reflist>
<entry id="1">
 Roddy, 2001, 67 - 90 </entry>
<entry id="2">
 GAO, 2006 </entry>
<entry id="3">
 Fall, 2003 </entry>
</reflist>
</p>

</sec>
<sec>
<st>
 References </st>

<p>

<list>
<entry level="1" type="bullet">

Rappaport, Theodore S. <it>Wireless Communications, Principles and Practice</it> second edition, <link xlink:type="simple" xlink:href="../050/5421050.xml">
Prentice Hall</link>, <link xlink:type="simple" xlink:href="../502/35502.xml">
2002</link>, ISBN 0130422320</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

Roddy, Dennis, <it>Satellite Communications</it> third edition, <company wordnetid="108058098" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../269/651269.xml">
McGraw-Hill</link></company>
, <link xlink:type="simple" xlink:href="../551/34551.xml">
2001</link>, ISBN 0071371761</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

Fall, Kevin, "A Delay-Tolerant Network Architecture for Challenged Internets", Intel Corporation, February, 2003, Doc No: IRB-TR-03-003 <weblink xlink:type="simple" xlink:href="http://www.dtnrg.org/docs/papers/IRB-TR-03-003.pdf">
The File</weblink></entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

Government Accountability Office (GAO) report 06-445, NASA'S DEEP SPACE NETWORK: Current Management Structure is Not Conducive to Effectively Matching Resources with Future Requirements, April 27, 2006</entry>
</list>
</p>

</sec>
<sec>
<st>
 External links </st>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://deepspace.jpl.nasa.gov/dsn/">
Nasa's Deep Space Network Website</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.stuartcheshire.org/rants/Latency.html">
It's the Latency, Stupid</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.stuartcheshire.org/papers/LatencyQuest.html">
more formal paper by same author</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.cs.ucsd.edu/~varghese/PAPERS/webinfocom.pdf">
A technical article from Infocom 2001 on techniques for reducing web latency</weblink>  "As network technology becomes less dominated by bandwidth limitations, the round-trip times spent for protocol handshakes will become a dominant component in the overall transfer time" for many web pages.</entry>
</list>
</p>

</sec>
</bdy>
</article>
