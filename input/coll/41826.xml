<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 15:39:55[mciao0825] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<event  confidence="0.8" wordnetid="100029378">
<act  confidence="0.8" wordnetid="100030358">
<psychological_feature  confidence="0.8" wordnetid="100023100">
<procedure  confidence="0.8" wordnetid="101023820">
<activity  confidence="0.8" wordnetid="100407535">
<header>
<title>Trusted computing base</title>
<id>41826</id>
<revision>
<id>241029818</id>
<timestamp>2008-09-26T00:55:10Z</timestamp>
<contributor>
<username>Sesshomaru</username>
<id>3753540</id>
</contributor>
</revision>
<categories>
<category>CISSP</category>
<category>Computer security procedures</category>
</categories>
</header>
<bdy>

The <b>trusted computing base</b> (TCB) of a <link xlink:type="simple" xlink:href="../457/7878457.xml">
computer system</link> is the set of all <link xlink:type="simple" xlink:href="../310/5310.xml">
hardware</link>, <link xlink:type="simple" xlink:href="../155/41155.xml">
firmware</link>, and/or <link xlink:type="simple" xlink:href="../309/5309.xml">
software</link> components that are critical to its <link xlink:type="simple" xlink:href="../398/7398.xml">
security</link>, in the sense that <invertebrate wordnetid="101905661" confidence="0.8">
<arthropod wordnetid="101767661" confidence="0.8">
<bug wordnetid="102236355" confidence="0.8">
<insect wordnetid="102159955" confidence="0.8">
<animal wordnetid="100015388" confidence="0.8">
<link xlink:type="simple" xlink:href="../085/37085.xml">
bugs</link></animal>
</insect>
</bug>
</arthropod>
</invertebrate>
 occurring inside the TCB might jeopardize the security properties of the entire system. By contrast, parts of a computer system outside the TCB supposedly cannot misbehave in a way that would leak any more <link xlink:type="simple" xlink:href="../860/1692860.xml">
privilege</link>s than was granted to them in the first place in accordance to the <link xlink:type="simple" xlink:href="../539/2842539.xml">
security policy</link>.<p>

The careful design and implementation of a system's trusted computing base is paramount to its overall security. Modern <link xlink:type="simple" xlink:href="../194/22194.xml">
operating system</link>s strive to reduce the size of the TCB so that an exhaustive examination of its code base (by means of manual or computer-assisted <link xlink:type="simple" xlink:href="../731/4930731.xml">
software audit</link> or <link xlink:type="simple" xlink:href="../054/270054.xml">
program verification</link>) becomes feasible.</p>

<sec>
<st>
 Definition and characterization </st>

<p>

In the classic paper <it>Authentication in Distributed Systems: Theory and Practice</it><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref> <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../249/77249.xml">
Lampson</link></scientist>
</person>
 et al define the <b>trusted computing base</b> of a <link xlink:type="simple" xlink:href="../457/7878457.xml">
computer system</link> as simply
<indent level="1">

 <it>a small amount of software and hardware that security depends on and that we distinguish from a much larger amount that can misbehave without affecting security.</it>
</indent>

This pedagogical definition, while clear and convenient to get hold of the concept, is neither theoretically exact not intended to be, as e.g. a <link xlink:type="simple" xlink:href="../116/42116.xml">
network server</link> <link xlink:type="simple" xlink:href="../178/45178.xml">
process</link> under a <link xlink:type="simple" xlink:href="../642/31642.xml">
UNIX</link>-like operating system might fall victim to a <link xlink:type="simple" xlink:href="../398/7398.xml">
security breach</link> and compromise an important part of the system's security, yet is not part of the operating system's TCB. The <link xlink:type="simple" xlink:href="../389/60389.xml">
Orange Book</link>, another classic <link xlink:type="simple" xlink:href="../398/7398.xml">
computer security</link> literature reference, therefore provides<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref> a more formal definition of the TCB of a computer system, as</p>
<p>

<indent level="1">

 <it>the totality of protection mechanisms within it, including hardware, firmware, and software, the combination of which is responsible for enforcing a computer security policy.</it>
</indent>

The Orange Book further explains that</p>
<p>

<indent level="1">

 <it>[t]he ability of a trusted computing base to enforce correctly a unified security policy depends on the correctness of the mechanisms within the trusted computing base, the protection of those mechanisms to ensure their correctness, and the correct <link xlink:type="simple" xlink:href="../264/41264.xml">
input</link> of parameters related to the security policy.</it>
</indent>

In other words, a given piece of hardware or software is a part of the TCB if and only if it has been designed to be a part of the mechanism that provides its security to the computer system. In <link xlink:type="simple" xlink:href="../194/22194.xml">
operating system</link>s, this typically consists of the <link xlink:type="simple" xlink:href="../394/50394.xml">
kernel</link> (or <link xlink:type="simple" xlink:href="../023/20023.xml">
microkernel</link>) and a select set of system utilities (for example, <link xlink:type="simple" xlink:href="../629/1054629.xml">
setuid</link> programs and <link xlink:type="simple" xlink:href="../759/8759.xml">
daemons</link> in UNIX systems). In <link xlink:type="simple" xlink:href="../015/23015.xml">
programming language</link>s that have security features designed in such as <message wordnetid="106598915" confidence="0.8">
<request wordnetid="106513366" confidence="0.8">
<link xlink:type="simple" xlink:href="../881/15881.xml">
Java</link></request>
</message>
 and <programming_language wordnetid="106898352" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../046/1377046.xml">
E</link></programming_language>
, the TCB is formed of the language runtime and standard library<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%223%22])">3</ref>.</p>

</sec>
<sec>
<st>
 Properties of the TCB </st>


<ss1>
<st>
 Predicated upon the security policy: “TCB is in the eye of the consultant” </st>

<p>

It should be pointed out that as a consequence of the above Orange Book definition, the boundaries of the TCB depend closely upon the specifics of how the security policy is fleshed out. In the network server example above, even though, say, a <link xlink:type="simple" xlink:href="../455/33455.xml">
Web server</link> that serves a <link xlink:type="simple" xlink:href="../751/39751.xml">
multi-user</link> application is not part of the operating system's TCB, it has the responsibility of performing <link xlink:type="simple" xlink:href="../684/40684.xml">
access control</link> so that the users cannot usurp the identity and privileges of each other. In this sense, it definitely is part of the TCB of the larger computer system that comprises the UNIX server, the user's browsers and the Web application; in other words, breaching into the Web server through e.g. a <link xlink:type="simple" xlink:href="../373/4373.xml">
buffer overflow</link> may not be regarded as a compromise of the operating system proper, but it certainly constitutes a damaging <link xlink:type="simple" xlink:href="../875/9875.xml">
exploit</link> on the Web application.</p>
<p>

This fundamental relativity of the boundary of the TCB is exemplifed by the concept of the <b>target of evaluation</b> (TOE) in the <standard wordnetid="107260623" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<system_of_measurement wordnetid="113577171" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<link xlink:type="simple" xlink:href="../625/57625.xml">
Common Criteria</link></activity>
</procedure>
</system_of_measurement>
</psychological_feature>
</act>
</event>
</standard>
 security process: in the course of a Common Criteria security evaluation, one of the first decisions that must be made is the boundary of the audit in terms of the list of system components that will come under scrutiny.</p>

</ss1>
<ss1>
<st>
 A prerequisite to security </st>

<p>

Systems that don't have a trusted computing base as part of their design do not provide security of their own: they are only secure insofar as security is provided to them by external means (e.g. a computer sitting in a locked room without a network connection may be considered secure depending on the policy, regardless of the software it runs). This is because, as <physical_entity wordnetid="100001930" confidence="0.8">
<peer wordnetid="109626238" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<colleague wordnetid="109935990" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<academician wordnetid="109759069" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<adult wordnetid="109605289" confidence="0.8">
<professional wordnetid="110480253" confidence="0.8">
<educator wordnetid="110045713" confidence="0.8">
<associate wordnetid="109816771" confidence="0.8">
<link xlink:type="simple" xlink:href="../549/584549.xml">
David J. Farber</link></associate>
</educator>
</professional>
</adult>
</scientist>
</academician>
</causal_agent>
</colleague>
</person>
</peer>
</physical_entity>
 et al. put it<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%224%22])">4</ref>, <it>[i]n a computer system, the integrity of lower layers is typically treated as axiomatic by higher layers</it>. As far as computer security is concerned, reasoning about the security properties of a computer system requires being able to make sound assumptions about what it can, and more importantly, cannot do; however, barring any reason to believe otherwise, a computer is able to do everything that a general <link xlink:type="simple" xlink:href="../986/41986.xml">
Von Neumann machine</link> can. This obviously includes operations that would be deemed contrary to all but the simplest security policies, such as divulging an <link xlink:type="simple" xlink:href="../738/9738.xml">
email</link> or <link xlink:type="simple" xlink:href="../304/24304.xml">
password</link> that should be kept secret; however, barring special provisions in the architecture of the system, there is no denying that the computer <it>could be programmed</it> to perform these undesirable tasks.</p>
<p>

These special provisions that aim at preventing certain kinds of actions from being executed, in essence, constitute the trusted computing base. For this reason, the <link xlink:type="simple" xlink:href="../389/60389.xml">
Orange Book</link> (still a reference on the design of secure operating systems design <link xlink:type="simple" xlink:href="../165/36165.xml">
as of 2007</link>) characterizes the various security assurance levels that it defines mainly in terms of the structure and security features of the TCB.</p>

</ss1>
<ss1>
<st>
 Software parts of the TCB need to protect themselves </st>

<p>

As outlined by the aforementioned Orange Book, software portions of the trusted computing base need to protect themselves against tampering to be of any effect. This is due to the <link xlink:type="simple" xlink:href="../091/478091.xml">
von Neumann architecture</link> implemented by virtually all modern computers: since <link xlink:type="simple" xlink:href="../683/20683.xml">
machine code</link> can be processed as just another kind of data, it can be read and overwritten by any program barring special <link xlink:type="simple" xlink:href="../924/66924.xml">
memory management</link> provisions that subsequently have to be treated as part of the TCB. Specifically, the trusted computing base must at least prevent its own software from being written to.</p>
<p>

In many modern <link xlink:type="simple" xlink:href="../218/5218.xml">
CPU</link>s, the protection of the memory that hosts the TCB is achieved by adding in a specialized piece of hardware called the <link xlink:type="simple" xlink:href="../112/177112.xml">
memory management unit</link> (MMU), which is programmable by the operating system to allow and deny access to specific ranges of the system memory to the programs being run. Of course, the operating system is also able to disallow such programming to the other programs. This technique is called <link>
supervisor mode</link>; compared to more crude approaches (such as storing the TCB in <link xlink:type="simple" xlink:href="../934/18934934.xml">
ROM</link>, or equivalently, using the <link xlink:type="simple" xlink:href="../019/58019.xml">
Harvard architecture</link>), it has the advantage of allowing the security-critical software to be upgraded in the field, although allowing secure upgrades of the trusted computing base poses bootstrap problems of its own<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%225%22])">5</ref>.</p>

</ss1>
<ss1>
<st>
 Trusted vs. trustworthy </st>

<p>

As stated <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22A+prerequisite+to+security%22])">
above</link>, trust in the trusted computing base is required to make any progress in ascertaining the security of the computer system. In other words, the trusted computing base is “trusted” first and foremost in the sense that it <it>has</it> to be trusted, and not necessarily that it is trustworthy. Real-world operating systems routinely have security-critical bugs discovered in them, which attests of the practical limits of such trust<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref>. </p>
<p>

The <message wordnetid="106598915" confidence="0.8">
<information wordnetid="106634376" confidence="0.8">
<electronic_database wordnetid="106588511" confidence="0.8">
<lexical_database wordnetid="106638868" confidence="0.8">
<wordnet wordnetid="106639428" confidence="0.8">
<database wordnetid="106637824" confidence="0.8">
<link xlink:type="simple" xlink:href="../689/3654689.xml">
Coyotos</link></database>
</wordnet>
</lexical_database>
</electronic_database>
</information>
</message>
 project intends to bring the techniques of formal <link xlink:type="simple" xlink:href="../989/665989.xml">
software verification</link> into the craft of operating systems design, with the aim of providing a general-purpose really secure TCB. Similarly, researchers at <company wordnetid="108058098" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../384/2518384.xml">
NICTA</link></company>
 and its spinout <weblink xlink:type="simple" xlink:href="http://www.ok-labs.com">
Open Kernel Labs</weblink> are working on the formal verification of a new version of the <link xlink:type="simple" xlink:href="../763/95763.xml">
L4 microkernel</link>, with a completely verified kernel due to be delivered by mid-2008.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%227%22])">7</ref>
Meanwhile, careful, mostly manual code reviews of the TCB codebase and the <link>
patch treadmill</link> process are the best one can do to minimize the gap between trust and trustworthiness.</p>

</ss1>
<ss1>
<st>
 TCB size </st>

<p>

Due to the aforementioned need to apply costly techniques such as formal verification or manual review, the size of the TCB has immediate consequences on the economics of the TCB assurance process, and the trustworthiness of the resulting product (in terms of the <link xlink:type="simple" xlink:href="../653/9653.xml">
mathematical expectation</link> of the number of bugs not found during the verification or review). In order to reduce costs and security risks, the TCB should therefore be kept as small as possible. This is a key argument in the debate opposing <link xlink:type="simple" xlink:href="../023/20023.xml">
microkernel</link> proponents and <link xlink:type="simple" xlink:href="../825/20825.xml">
monolithic kernel</link> aficionados<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%228%22])">8</ref>. The aforementioned Coyotos kernel will be of the microkernel kind for this reason, despite the possible performance issues that this choice entails.</p>

</ss1>
</sec>
<sec>
<st>
 Examples </st>

<p>

<link xlink:type="simple" xlink:href="../ury/22nd_century.xml">
AIX</link> materializes the trusted computing base as an optional component in its install-time package management system<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%229%22])">9</ref>.</p>

</sec>
<sec>
<st>
 See also </st>

<p>

<list>
<entry level="1" type="bullet">

 <event wordnetid="100029378" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<link xlink:type="simple" xlink:href="../300/6687300.xml">
Orange Book</link></activity>
</procedure>
</psychological_feature>
</act>
</event>
</entry>
</list>
</p>

<ss1>
<st>
 References </st>

<p>

<reflist>
<entry id="1">
B. Lampson, M. Abadi, M. Burrows and E. Wobber, <weblink xlink:type="simple" xlink:href="http://citeseer.ist.psu.edu/lampson92authentication.html">
Authentication in Distributed Systems: Theory and Practice</weblink>, <link>
ACM Transactions on Computer Systems</link> 1992, on page 6.</entry>
<entry id="2">
<weblink xlink:type="simple" xlink:href="http://csrc.nist.gov/secpubs/rainbow/std001.txt">
 Department of Defense trusted computer system evaluation criteria</weblink>, DoD 5200.28-STD, 1985. In the glossary under entry <b>Trusted Computing Base (TCB)</b>.</entry>
<entry id="3">
M. Miller, C. Morningstar and B. Frantz, <weblink xlink:type="simple" xlink:href="http://www.erights.org/elib/capability/ode/ode-linear.html">
Capability-based Financial Instruments (An Ode to the Granovetter diagram)</weblink>, in paragraph <it>Subjective Aggregation</it>.</entry>
<entry id="4">
 W. Arbaugh, D. Farber and J. Smith, <weblink xlink:type="simple" xlink:href="http://citeseer.ist.psu.edu/article/arbaugh97secure.html">
A Secure and Reliable Bootstrap Architecture</weblink>, 1997, also known as the “aegis papers”.</entry>
<entry id="5">
<weblink xlink:type="simple" xlink:href="http://citeseer.ist.psu.edu/article/arbaugh97secure.html">
A Secure and Reliable Bootstrap Architecture</weblink>, <it>op. cit.''</it></entry>
<entry id="6">
<person wordnetid="100007846" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../732/36732.xml">
Bruce Schneier</link></person>
, <weblink xlink:type="simple" xlink:href="http://www.schneier.com/crypto-gram-0103.html#1">
The security patch treadmill</weblink> (2001)</entry>
<entry id="7">
 <cite style="font-style:normal"><person wordnetid="100007846" confidence="0.9638700866880419">
<link xlink:type="simple" xlink:href="../382/10400382.xml">
Heiser, Gernot</link></person>
; Elphinstone, Kevin; Kuz, Ihor; Klein, Gerwin, Petters, Stefan M.&#32;(July 2007).&#32;"<weblink xlink:type="simple" xlink:href="http://www.ertos.nicta.com.au/publications/papers/Heiser_EKKP_07.abstract">
Towards Trustworthy Computing Systems: Taking Microkernels to the Next Level</weblink>". <it>Operating Systems Review</it>&#32;<b>41</b>&#32;(3): 3&ndash;11. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1145%2F1278901.1278904">
10.1145/1278901.1278904</weblink>.</cite>&nbsp;</entry>
<entry id="8">
<person wordnetid="100007846" confidence="0.9508927676800064">
<professor wordnetid="110480730" confidence="0.9173553029164789">
<link xlink:type="simple" xlink:href="../110/3110.xml">
Andrew S. Tanenbaum</link></professor>
</person>
, <weblink xlink:type="simple" xlink:href="http://www.cs.vu.nl/~ast/reliable-os/">
Tanenbaum-Torvalds debate, part II</weblink> (may 12, <link xlink:type="simple" xlink:href="../164/36164.xml">
2006</link>)</entry>
<entry id="9">
<weblink xlink:type="simple" xlink:href="http://www.redbooks.ibm.com/pubs/pdfs/redbooks/sg245962.pdf">
AIX 4.3 Elements of Security</weblink>, August 2000, chapter 6.</entry>
</reflist>
</p>

</ss1>
<ss1>
<st>
 External links </st>

<p>

<list>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.unet.univie.ac.at/aix/aixbman/admnconc/tcb.htm">
AIX TCB overview article</weblink></entry>
</list>
</p>


<p>

<list>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.afcea.org/wiki/index.php?title=Trusted_Computing_Base">
Trustifier TCB overview</weblink></entry>
</list>
</p>
</ss1>
</sec>
</bdy>
</activity>
</procedure>
</psychological_feature>
</act>
</event>
</article>
