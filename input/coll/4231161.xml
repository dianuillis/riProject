<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 21:02:23[mciao0826] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<event  confidence="0.8" wordnetid="100029378">
<rule  confidence="0.8" wordnetid="105846932">
<act  confidence="0.8" wordnetid="100030358">
<psychological_feature  confidence="0.8" wordnetid="100023100">
<procedure  confidence="0.8" wordnetid="101023820">
<activity  confidence="0.8" wordnetid="100407535">
<algorithm  confidence="0.8" wordnetid="105847438">
<header>
<title>ALOPEX</title>
<id>4231161</id>
<revision>
<id>228949386</id>
<timestamp>2008-07-31T04:03:00Z</timestamp>
<contributor>
<username>Redirect fixer</username>
<id>7523687</id>
</contributor>
</revision>
<categories>
<category>Neural networks</category>
<category>Machine learning</category>
<category>Classification algorithms</category>
</categories>
</header>
<bdy>

<b>ALOPEX</b> (an acronym from "<b><it>AL</it></b><it>gorithms </it>'O<b>f </b>P<b>attern </b>EX<b>traction<it>") is a correlation based machine learning algorithm first proposed by <link>
 Tzanakou</link> and Harth in 1974.</it></b>
<sec>
<st>
Principle</st>
<p>

In <link xlink:type="simple" xlink:href="../488/233488.xml">
machine learning</link>, the goal is to train a system to minimize a cost function or (referring to ALOPEX) a response function.  Many training algorithms, such as <link xlink:type="simple" xlink:href="../091/1360091.xml">
backpropagation</link>, have an inherent susceptibility to getting "stuck" in local minima or maxima of the response function.  ALOPEX uses a cross-correlation of differences and a stochastic process to overcome this in an attempt to reach the absolute minimum (or maximum) of the response function.</p>

</sec>
<sec>
<st>
Method</st>
<p>

ALOPEX, in its simplest form is defined by an updating equation:</p>
<p>

<math>\Delta\ W_{ij}(n) = \gamma\ \Delta\ W_{ij}(n-1) \Delta\ R(n) + r_i(n) </math> </p>
<p>

Where:
<list>
<entry level="1" type="bullet">

<math>n \geq 0</math> is the iteration or time-step.</entry>
<entry level="1" type="bullet">

<math>\Delta\ W_{ij}(n)</math> is the difference between the current and previous value of system variable <math>\ W_{ij}</math> at iteration <math>n \ </math>.</entry>
<entry level="1" type="bullet">

<math>\Delta\ R(n)</math> is the difference between the current and previous value of the response function <math>\ R,</math> at iteration <math>n \ </math>.</entry>
<entry level="1" type="bullet">

<math>\gamma\ </math> is the learning rate parameter <math>(\gamma\ &amp;lt; 0 </math> minimizes <math>R, \ </math> and <math>\gamma\ &amp;gt; 0 </math> maximizes <math>R \ )</math></entry>
<entry level="1" type="bullet">

<math>r_i(n) \sim\ N(0,\sigma\ ^2)</math></entry>
</list>
</p>

</sec>
<sec>
<st>
Discussion</st>
<p>

Essentially, ALOPEX changes each system variable <math>W_{ij}(n)</math> based on a product of: the previous change in the variable <math>\Delta</math><math>W_{ij}(n-1)</math>, the resulting change in the cost function <math>\Delta</math><math>R(n)</math>, and the learning rate parameter <math>\gamma</math>.  Further, to find the absolute minimum (or maximum), the stochastic process <math>r_{ij}(n)</math> (Gaussian or other) is added to stochastically "push" the algorithm out of any local minima.</p>

</sec>
<sec>
<st>
References</st>
<p>

<list>
<entry level="1" type="bullet">

Harth, E., &amp; Tzanakou, E. (1974) Alopex: A stochastic method for determining visual receptive fields. Vision Research, <b>14</b>:1475-1482. <weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1016/0042-6989(74)90024-8">
Abstract from ScienceDirect</weblink></entry>
</list>





</p>
</sec>
</bdy>
</algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</article>
