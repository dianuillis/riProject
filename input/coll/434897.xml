<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 17:03:22[mciao0827] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Hough transform</title>
<id>434897</id>
<revision>
<id>238690350</id>
<timestamp>2008-09-15T23:18:41Z</timestamp>
<contributor>
<username>Laffernandes</username>
<id>7865585</id>
</contributor>
</revision>
<categories>
<category>Computer vision</category>
<category>Image processing</category>
</categories>
</header>
<bdy>

The <b>Hough transform</b> (pronounced , rhymes with <it>tough</it>) is a <link xlink:type="simple" xlink:href="../190/242190.xml">
feature extraction</link> technique used in <link xlink:type="simple" xlink:href="../382/346382.xml">
image analysis</link>, <link xlink:type="simple" xlink:href="../596/6596.xml">
computer vision</link>, and <link xlink:type="simple" xlink:href="../922/97922.xml">
digital image processing</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref>  The purpose of the technique is to find imperfect instances of objects within a certain class of shapes by a voting procedure. This voting procedure is carried out in a parameter space, from which object candidates are obtained as local maxima in a so-called accumulator space that is explicitly constructed by the algorithm for computing the Hough transform. <p>

The classical Hough transform was concerned with the identification of <link xlink:type="simple" xlink:href="../975/946975.xml">
line</link>s in the image, but later the Hough transform has been extended to identifying positions of arbitrary shapes, most commonly circles or ellipses. The Hough transform as it is universally used today was invented by <link>
Richard Duda</link> and <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<intellectual wordnetid="109621545" confidence="0.8">
<alumnus wordnetid="109786338" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scholar wordnetid="110557854" confidence="0.8">
<link xlink:type="simple" xlink:href="../790/11897790.xml">
Peter Hart</link></scholar>
</causal_agent>
</alumnus>
</intellectual>
</person>
</physical_entity>
 in <link xlink:type="simple" xlink:href="../671/34671.xml">
1972</link>, who called it a "generalized Hough transform"<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref> after the related <link xlink:type="simple" xlink:href="../717/34717.xml">
1962</link> patent of <link xlink:type="simple" xlink:href="../665/18416665.xml">
Paul Hough</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%223%22])">3</ref> The transform was popularized in the <link xlink:type="simple" xlink:href="../596/6596.xml">
computer vision</link> community by <link>
Dana H. Ballard</link> through a 1981 journal article titled "Generalizing the Hough transform to detect arbitrary shapes".</p>

<sec>
<st>
Theory</st>

<p>

In automated analysis of digital images, a subproblem often arises of detecting simple shapes, such as straight lines, circles or ellipses. In many cases an <link xlink:type="simple" xlink:href="../680/331680.xml">
edge detector</link> can be used as a pre-processing stage to obtain image points or image pixels that are on the desired curve in the image space. Due to imperfections in either the image data or the edge detector, however, there may be missing points or pixels on the desired curves as well as spatial deviations between the ideal line/circle/ellipse and the noisy edge points as they are obtained from the edge detector. For these reasons, it is often non-trivial to group the extracted edge features to an appropriate set of lines, circles or ellipses. The purpose of the Hough transform is to address this problem by making it possible to perform groupings of edge points into object candidates by performing an explicit voting procedure over a set of parameterized image objects(Shapiro and Stockman, 304).</p>
<p>

The simplest case of Hough transform is the linear transform for detecting straight lines. In the image space, the straight line can be described as y = mx + b and can be graphically plotted for each pair of image points (x,y). In the Hough transform, a main idea is to consider the characteristics of the straight line not as image points x or y, but in terms of its parameters, here the slope parameter m and the intercept parameter b. Based on that fact, the straight line y = mx + b can be represented as a point (b, m) in the parameter space. However, one faces the problem that vertical lines give rise to unbounded values of the parameters m and b. For computational reasons, it is therefore better to parameterize the lines in the Hough transform with two other parameters, commonly referred to as <math>r</math> and <math>\theta</math> (<it>theta</it>). The parameter <math>r</math> represents the distance between the line and the <link xlink:type="simple" xlink:href="../432/1313432.xml">
origin</link>, while <math>\theta</math> is the angle of the vector from the origin to this closest point (see <link xlink:type="simple" xlink:href="../698/433698.xml">
Coordinates</link>). Using this parametrization, the equation of the line can be written as<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%224%22])">4</ref>  </p>
<p>

<indent level="1">

<math>y = \left(-{\cos\theta\over\sin\theta}\right)x + \left({r\over{\sin\theta}}\right)</math>,
</indent>

which can be rearranged to <math>r = x \cos \theta+y\sin \theta</math> (Shapiro and Stockman, 304).</p>
<p>

It is therefore possible to associate to each line of the image, a couple (<it>r,θ</it>) which is unique if <math>\theta \in [0,\pi] </math> and <math>r \in \mathbf{R}</math>, or if <math>\theta \in [0,2\pi]</math> and <math>r \geq 0</math>. The (<it>r,θ</it>) plane is sometimes referred to as <it>Hough space</it> for the set of straight lines in two dimensions. This representation makes the Hough transform conceptually very close to the two-dimensional <link xlink:type="simple" xlink:href="../378/503378.xml">
Radon transform</link>.</p>
<p>

An infinite number of lines can pass through a single point of the plane. If that point has coordinates <math>(x_0,y_0)</math> in the image plane, all the lines that go through it obey the following equation: </p>
<p>

<math>r(\theta) = x_{0}\cdot\cos \theta+y_{0}\cdot\sin \theta</math></p>
<p>

This corresponds to a <link xlink:type="simple" xlink:href="../749/324749.xml">
sinusoid</link>al curve in the (<it>r,θ</it>) plane, which is unique to that point. If the curves corresponding to two points are superimposed, the location (in the <it>Hough space</it>) where they cross correspond to lines (in the original image space) that pass through both points. More generally, a set of points that form a straight line will produce sinusoids which cross at the parameters for that line. Thus, the problem of detecting colinear points can be converted to the problem of finding concurrent curves.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%225%22])">5</ref></p>

</sec>
<sec>
<st>
Implementation</st>

<p>

The Hough transform <link xlink:type="simple" xlink:href="../775/775.xml">
algorithm</link> uses an array, called accumulator, to detect the existence of a line y = mx + b.  The <link xlink:type="simple" xlink:href="../398/8398.xml">
dimension</link> of the accumulator is equal to the number of unknown parameters of the Hough transform problem.  For example, the linear Hough transform problem has two unknown parameters: m and b.  The two dimensions of the accumulator array would correspond to quantized values for m and b.  For each pixel and its neighborhood, the Hough transform algorithm determines if there is enough evidence of an edge at that pixel.  If so, it will calculate the parameters of that line, and then look for the accumulator's bin that the parameters fall into, and increase the value of that bin. 
By finding the bins with the highest values, typically by looking for local maxima in the accumulator space, the most likely lines can be extracted, and their (approximate) geometric definitions read off. (Shapiro and Stockman, 304)  The simplest way of finding these <it>peaks</it> is by applying some form of threshold, but different techniques may yield better results in different circumstances - determining which lines are found as well as how many.  Since the lines returned do not contain any length information, it is often next necessary to find which parts of the image match up with which lines. Moreover, due to imperfection errors in the edge detection step, there will usually be errors in the accumulator space, which may make it non-trivial to find the appropriate peaks, and thus the appropriate lines.</p>

</sec>
<sec>
<st>
Example</st>

<p>

Consider three data points, shown here as black dots.</p>
<p>

<image width="150px" src="Hough_transform_diagram.png">
<caption>

Hough transform diagram.png
</caption>
</image>
</p>
<p>

<list>
<entry level="1" type="bullet">

For each data point, a number of lines are plotted going through it, all at different angles. These are shown here as solid lines.</entry>
<entry level="1" type="bullet">

For each solid line a line is plotted which is <link xlink:type="simple" xlink:href="../944/76944.xml">
perpendicular</link> to it and which intersects the <link xlink:type="simple" xlink:href="../432/1313432.xml">
origin</link>. These are shown as dashed lines.</entry>
<entry level="1" type="bullet">

The length and angle of each dashed line is measured. In the diagram above, the results are shown in tables.</entry>
<entry level="1" type="bullet">

This is repeated for each data point.</entry>
<entry level="1" type="bullet">

A graph of length against angle, known as a Hough space graph, is then created.</entry>
</list>
</p>
<p>

<image width="150px" src="Hough_space_plot_example.png">
<caption>

Hough space plot example.png
</caption>
</image>
</p>
<p>

The point where the lines intersect gives a distance and angle. This distance and angle indicate the line which bisects the points being tested. In the graph shown the lines intersect at the purple point; this corresponds to the solid purple line in the diagrams above, which bisects the three points.</p>
<p>

The following is a different example showing the results of a Hough transform on a raster image containing two thick lines.</p>
<p>

<image width="800px" src="Hough-example-result-en.png">
</image>
</p>
<p>

The results of this transform were stored in a matrix. Cell value represents the number of curves through any point. Higher cell values are rendered brighter. The two distinctly bright spots are the Hough parameters of the two lines. From these spots' positions, angle and distance from image center of the two lines in the input image can be determined.</p>

</sec>
<sec>
<st>
Variations and extensions</st>

<ss1>
<st>
Using the gradient direction to reduce the number of votes</st>
<p>

An improvement suggested by O'Gorman and Clowes can be used to detect lines if one takes into account that the local <link xlink:type="simple" xlink:href="../461/12461.xml">
gradient</link> of the image intensity will necessarily be orthogonal to the edge. Since <link xlink:type="simple" xlink:href="../680/331680.xml">
edge detection</link> generally involves computing the intensity <link xlink:type="simple" xlink:href="../461/12461.xml">
gradient</link> magnitude, the gradient direction is often found as a side effect. If a given point of coordinates (<it>x,y</it>) happens to indeed be on a line, then the local direction of the gradient gives the <it>θ</it> parameter corresponding to said line, and the <it>r</it> parameter is then immediately obtained. (Shapiro and Stockman, 305) In fact, the real gradient direction is only estimated with a given amount of accuracy (approximately ±20°), which means that the sinusoid must be traced around the estimated angle, ±20°. This however reduces the computation time and has the interesting effect of reducing the number of useless votes, thus enhancing the visibility of the spikes corresponding to real lines in the image.</p>

</ss1>
<ss1>
<st>
Kernel-based Hough transform</st>
<p>

Fernandes and Oliveira <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref> suggested an improved voting scheme for the Hough transform that allows a software implementation to achieve real-time performance even on relatively large images (e.g., 1280×960). The <it><weblink xlink:type="simple" xlink:href="http://www.inf.ufrgs.br/~laffernandes/kht.html">
Kernel-based Hough transform</weblink></it> uses the same <math>(r,\theta)</math> parameterization proposed by Duda and Hart but operates on clusters of approximately collinear pixels. For each cluster, votes are cast using an oriented elliptical-Gaussian kernel that models the uncertainty associated with the best-fitting line with respect to the corresponding cluster. The approach not only significantly improves the performance of the voting scheme, but also produces a much cleaner accumulator and makes the transform more robust to the detection of spurious lines.</p>

</ss1>
<ss1>
<st>
Hough transform of curves, and Generalised Hough transform</st>
<p>

Although the version of the transform described above applies only to finding straight lines, a similar transform can be used for finding any shape which can be represented by a set of parameters.  A circle, for instance, can be transformed into a set of three parameters, representing its center and radius, so that the Hough space becomes three dimensional.  Arbitrary ellipses and curves can also be found this way, as can any shape easily expressed as a set of parameters.  For more complicated shapes, the <link xlink:type="simple" xlink:href="../142/11023142.xml">
Generalised Hough transform</link> is  used, which allows a feature to vote for a particular position, orientation and/or scaling of the shape using a predefined look-up table.</p>

</ss1>
<ss1>
<st>
Using weighted features</st>
<p>

One common variation  detail.  That is, finding the bins with the highest count in one stage can be used to constrain the range of values searched in the next.</p>

</ss1>
</sec>
<sec>
<st>
Limitations</st>
<p>

The Hough Transform is only efficient if a high number of votes fall in the right bin, so that the bin can be easily detected amid the background noise. This means that the bin must not be too small, or else some votes will fall in the neighboring bins, thus reducing the visibility of the main bin.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%227%22])">7</ref></p>
<p>

Also, when the number of parameters is large (that is, when we are using the Hough Transform with typically more than three parameters), the average number of votes cast in a single bin is very low, and those bins corresponding to a real figure in the image do not necessarily appear to have a much higher number of votes than their neighbors. Thus, the Hough Transform must be used with great care to detect anything other than lines or circles. This also, increases the complexity with each additional parameter. <math>\mathcal{O}\left({A^{m-2}}\right)</math> where <math>A</math> is the image space and <math>m</math> is the number of parameters. (Shapiro and Stockman, 310)</p>
<p>

Finally, much of the efficiency of the Hough Transform is dependent on the quality of the input data: the edges must be detected well for the Hough Transform to be efficient. Use of the Hough Transform on noisy images is a very delicate matter and generally, a denoising stage must be used before. In the case where the image is corrupted by speckle, as is the case in radar images, the <link xlink:type="simple" xlink:href="../378/503378.xml">
Radon transform</link> is sometimes preferred to detect lines, since it has the nice effect of attenuating the noise through summation.</p>

</sec>
<sec>
<st>
 History </st>
<p>

It was initially invented for machine analysis of <link xlink:type="simple" xlink:href="../466/204466.xml">
bubble chamber</link> photographs (Hough, 1959). </p>
<p>

The Hough transform was patented as <weblink xlink:type="simple" xlink:href="http://patft.uspto.gov/netacgi/nph-Parser?patentnumber=3069654">
U.S. Patent 3,069,654</weblink><weblink xlink:type="simple" xlink:href="http://www.pat2pdf.org/pat2pdf/foo.pl?number=3069654">
&nbsp;</weblink> in <link xlink:type="simple" xlink:href="../717/34717.xml">
1962</link> by <company wordnetid="108058098" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../259/18622259.xml">
IBM</link></company>
 with the name "Method and Means for Recognizing Complex Patterns".("Hough Transform," Planet Math)  This patent uses a slope-intercept parametrization for straight lines, which awkwardly  leads to an unbounded transform space since the slope can go to infinity.</p>
<p>

The rho-theta parametrization universally used today was first described in</p>
<p>

<indent level="1">

Duda, R. O. and P. E. Hart, "Use of the Hough Transformation to Detect Lines and Curves in Pictures," <it>Comm. ACM, Vol. 15</it>, pp. 11&ndash;15 (January, 1972),
</indent>

although it was already standard for the <link xlink:type="simple" xlink:href="../378/503378.xml">
Radon transform</link> since at least the 1930s.</p>
<p>

O'Gorman and Clowes' variation is described in</p>
<p>

<indent level="1">

Frank O'Gorman, MB Clowes: Finding Picture Edges Through Collinearity of Feature Points. IEEE Trans. Computers 25(4): 449-456 (1976)
</indent>

</p>
</sec>
<sec>
<st>
References</st>

<p>

<reflist>
<entry id="1">
Shapiro, Linda and Stockman, George. “Computer Vision,” Prentice-Hall, Inc. 2001
</entry>
<entry id="2">
Duda, R. O. and P. E. Hart, "Use of the Hough Transformation to Detect Lines and Curves in Pictures," <it>Comm. ACM, Vol. 15</it>, pp. 11&ndash;15 (January, 1972)</entry>
<entry id="3">
P.V.C. Hough, <it>Machine Analysis of Bubble Chamber Pictures,</it> Proc. Int. Conf. High Energy Accelerators and Instrumentation, 1959</entry>
<entry id="4">
"<weblink xlink:type="simple" xlink:href="http://www.ai.sri.com/pubs/files/tn036-duda71.pdf">
Use of the Hough Transformation to Detect Lines and Curves in Pictures</weblink>".</entry>
<entry id="5">
"<weblink xlink:type="simple" xlink:href="http://planetmath.org/encyclopedia/HoughTransform.html">
Hough Transform</weblink>".</entry>
<entry id="6">
<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1016/j.patcog.2007.04.003">
Fernandes, L.A.F. and Oliveira, M.M., "Real-time line detection through an improved Hough transform voting scheme," <it>Pattern Recognition, Elsevier, Volume 41, Issue 1</it>, pp. 299&ndash;314 (January, 2008)</weblink>.</entry>
<entry id="7">
<weblink xlink:type="simple" xlink:href="http://homepages.inf.ed.ac.uk/rbf/HIPR2/hough.htm">
Image Transforms - Hough Transform</weblink></entry>
</reflist>
</p>



</sec>
<sec>
<st>
External links</st>
<p>

<list>
<entry level="1" type="bullet">

 http://www.rob.cs.tu-bs.de/content/04-teaching/06-interactive/Hough.html - Java Applet + Source for learning the Hough transformation in slope-intercept form</entry>
<entry level="1" type="bullet">

 http://www.rob.cs.tu-bs.de/content/04-teaching/06-interactive/HNF.html - Java Applet + Source for learning the Hough-Transformation in normal form</entry>
<entry level="1" type="bullet">

 http://homepages.inf.ed.ac.uk/rbf/HIPR2/hough.htm</entry>
<entry level="1" type="bullet">

 http://imaging.gmse.net/articledeskew.html - Deskew images using Hough transform (Visual Basic source code)</entry>
</list>

Tarsha-Kurdi, F., Landes, T., Grussenmeyer, P., 2007a. Hough-transform and extended RANSAC algorithms for automatic detection of 3d building roof planes from Lidar data. ISPRS Proceedings. Workshop Laser scanning. Espoo, Finland, September 12-14, 2007.</p>

</sec>
<sec>
<st>
See also</st>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../585/11023585.xml">
Generalised Hough Transform</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../378/503378.xml">
Radon Transform</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../247/52247.xml">
Fourier Transform</link></entry>
</list>
</p>


</sec>
</bdy>
</article>
