<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 17:03:11[mciao0825] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<law  confidence="0.8" wordnetid="108441203">
<collection  confidence="0.8" wordnetid="107951464">
<group  confidence="0.8" wordnetid="100031264">
<header>
<title>Heaps&apos; law</title>
<id>436287</id>
<revision>
<id>185391097</id>
<timestamp>2008-01-19T09:11:01Z</timestamp>
<contributor>
<username>SmackBot</username>
<id>433328</id>
</contributor>
</revision>
<categories>
<category>Empirical laws</category>
<category>Statistical laws</category>
<category>Computational linguistics</category>
</categories>
</header>
<bdy>

In <link xlink:type="simple" xlink:href="../526/17526.xml">
linguistics</link>, <b>Heaps' law</b> is an <link xlink:type="simple" xlink:href="../629/244629.xml">
empirical law</link> which describes the portion of a <link xlink:type="simple" xlink:href="../445/191445.xml">
vocabulary</link> which is represented by an instance <link xlink:type="simple" xlink:href="../228/161228.xml">
document</link> (or set of instance documents) consisting of words chosen from the vocabulary. This can be formulated as<p>

<indent level="1">

<math> V_R(n) = Kn^\beta </math>
</indent>

Where <it>VR</it> is the subset of the vocabulary <it>V</it> represented by the instance text of size <it>n</it>. <it>K</it> and β are free parameters determined empirically.</p>
<p>

With English <link xlink:type="simple" xlink:href="../887/53887.xml">
text corpora</link>, typically <it>K</it> is between 10 and 100, and β is between 0.4 and 0.6.</p>
<p>

<image width="150px" src="Heaps_law_plot.png">
<caption>

Heaps_law_plot.png
</caption>
</image>
 
<it>A typical Heaps-law plot. The x-axis represents the text size, and the y-axis represents the number of distinct vocabulary elements present in the text. Compare the values of the two axes.</it></p>
<p>

Heaps' law means that as more instance text is gathered, there will be diminishing returns in terms of discovery of the full vocabulary from which the distinct terms are drawn.</p>
<p>

It is interesting to note that Heaps' law applies in the general case where the "vocabulary" is just some set of distinct types which are attributes of some collection of objects. For example, the objects could be people, and the types could be country of origin of the person. If persons are selected randomly (that is, we are not selecting based on country of origin), then Heaps' law says we will quickly have representatives from most countries (in proportion to their population) but it will become increasingly difficult to cover the entire set of countries by continuing this method of sampling.</p>

<sec>
<st>
See also</st>
<p>

<list>
<entry level="1" type="bullet">

 <law wordnetid="108441203" confidence="0.8">
<structure wordnetid="105726345" confidence="0.8">
<arrangement wordnetid="105726596" confidence="0.8">
<collection wordnetid="107951464" confidence="0.8">
<group wordnetid="100031264" confidence="0.8">
<distribution wordnetid="105729036" confidence="0.8">
<link xlink:type="simple" xlink:href="../218/43218.xml">
Zipf's law</link></distribution>
</group>
</collection>
</arrangement>
</structure>
</law>
</entry>
</list>
</p>

</sec>
<sec>
<st>
 References </st>
<p>

<list>
<entry level="1" type="bullet">

 H. S. Heaps. <it>Information Retrieval - Computational and Theoretical Aspects</it>. Academic Press, 1978.</entry>
<entry level="1" type="bullet">

 Baeza-Yates and Ribeiro-Neto, <it>Modern Information Retrieval</it>, ACM Press, 1999.</entry>
</list>
</p>
<p>

----</p>
<p>

<it>This article incorporates material from  on <web_site wordnetid="106359193" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../623/161623.xml">
PlanetMath</link></web_site>
, which is licensed under the .</it></p>

</sec>
</bdy>
</group>
</collection>
</law>
</article>
