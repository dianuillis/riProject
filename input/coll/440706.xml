<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 17:04:06[mciao0827] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<event  confidence="0.8" wordnetid="100029378">
<rule  confidence="0.8" wordnetid="105846932">
<act  confidence="0.8" wordnetid="100030358">
<psychological_feature  confidence="0.8" wordnetid="100023100">
<procedure  confidence="0.8" wordnetid="101023820">
<activity  confidence="0.8" wordnetid="100407535">
<algorithm  confidence="0.8" wordnetid="105847438">
<header>
<title>Neuroevolution</title>
<id>440706</id>
<revision>
<id>227622553</id>
<timestamp>2008-07-24T13:16:43Z</timestamp>
<contributor>
<username>DumZiBoT</username>
<id>6085301</id>
</contributor>
</revision>
<categories>
<category>Evolutionary algorithms</category>
</categories>
</header>
<bdy>

<b>Neuroevolution</b>, or <b>neuro-evolution</b>, is a form of <link xlink:type="simple" xlink:href="../488/233488.xml">
machine learning</link> that uses <link xlink:type="simple" xlink:href="../254/40254.xml">
genetic algorithm</link>s to train <link xlink:type="simple" xlink:href="../542/1729542.xml">
artificial neural networks</link>. It is useful for applications such as <link xlink:type="simple" xlink:href="../512/1336512.xml">
games</link> and <link xlink:type="simple" xlink:href="../781/25781.xml">
robot</link> motor control, where it is easy to measure a network's performance at a task but difficult or impossible to create a syllabus of correct input-output pairs for use with a <link xlink:type="simple" xlink:href="../926/20926.xml">
supervised learning algorithm</link>.  In the <link>
classification scheme for neural network learning</link> these methods usually belong in the <link xlink:type="simple" xlink:href="../294/66294.xml">
reinforcement learning</link> category.
<sec>
<st>
Features</st>

<p>

There are many neuroevolutionary algorithms. A distinction is made between those that evolve the values of the connection weights for a network of pre-specified topology, vs. those that evolve the topology of the network in addition to the weights. Although there are no standardized terms for this distinction as a whole, adding or removing a network's connections during evolution may be referred to as complexification or simplification, respectively <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref>. Networks that have both their connection weights and topology evolved are referred to as TWEANNs (Topology &amp; Weight Evolving Artificial Neural Networks).</p>
<p>

A further distinction is made between methods that evolve the structure (topology) of the neural networks in parallel to the parameters (e.g. synaptic weights) and those that develop them separately.  <weblink xlink:type="simple" xlink:href="http://www.ks.informatik.uni-kiel.de/~vision/doc/Publications/nts/SiebelKrauseSommer-EANT2RobotControl-DAGM2007.pdf">
A comparison between two such methods applied to robot control can be found here</weblink>.</p>

</sec>
<sec>
<st>
Direct and Indirect Encoding of Networks</st>

<p>

<it>Direct</it> encoding schemes specify in the genome every connection and node that appear in the network. In contrast, <it>indirect</it> encoding methods usually only specify rules for constructing a network <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%223%22])">3</ref>.</p>

</sec>
<sec>
<st>
Examples</st>

<p>

Examples of Neuroevolution methods that evolve both network structure and parameters include:</p>
<p>

<list>
<entry level="1" type="bullet">

 GNARL by Angeline et al., 1994<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%224%22])">4</ref></entry>
<entry level="1" type="bullet">

 EPNet by Yao and Liu, 1997<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%225%22])">5</ref></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../922/344922.xml">
NeuroEvolution of Augmented Topologies</link> (NEAT) by Stanley and Miikkulainen, 2005<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%227%22])">7</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref>.</entry>
<entry level="1" type="bullet">

 <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../071/15702071.xml">
Evolutionary Acquisition of Neural Topologies</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
 (EANT/EANT2) by Kassahun and Sommer, 2005<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%228%22])">8</ref> / Siebel and Sommer, 2007<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%229%22])">9</ref></entry>
</list>
</p>

</sec>
<sec>
<st>
See also</st>

<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../922/344922.xml">
NeuroEvolution of Augmented Topologies</link> (NEAT)</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../071/15702071.xml">
Evolutionary Acquisition of Neural Topologies</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
 (EANT/EANT2)</entry>
</list>
</p>

</sec>
<sec>
<st>
References</st>
<p>

<reflist>
<entry id="1">
http://www.ucs.louisiana.edu/~dxj2534/james_gecco04.pdf</entry>
<entry id="2">
<weblink xlink:type="simple" xlink:href="http://nn.cs.utexas.edu/downloads/papers/stanley.alife03.pdf">
/c/1997c/tops/dvips</weblink></entry>
<entry id="3">
Yohannes Kassahun, Mark Edgington, Jan Hendrik Metzen, Gerald Sommer and Frank Kirchner.  Common Genetic Encoding for Both Direct and Indirect Encodings of Networks. In
Proceedings of the Genetic and Evolutionary Computation Conference (GECCO 2007), London, UK, 1029-1036, 2007.</entry>
<entry id="4">
Peter J Angeline, Gregory M Saunders, and Jordan B Pollack. An evolutionary algorithm that constructs recurrent neural networks. IEEE Transactions on Neural Networks, 5:54–65, 1994. <weblink xlink:type="simple" xlink:href="http://demo.cs.brandeis.edu/papers/ieeenn.pdf">
http://demo.cs.brandeis.edu/papers/ieeenn.pdf</weblink></entry>
<entry id="5">
Xin Yao and Yong Liu. A new evolutionary system for evolving artiﬁcial neural networks. IEEE Transactions on Neural Networks, 8(3):694–713, May 1997. <weblink xlink:type="simple" xlink:href="http://www.cs.bham.ac.uk/~axk/evoNN2.pdf">
http://www.cs.bham.ac.uk/~axk/evoNN2.pdf</weblink></entry>
<entry id="6">
http://nn.cs.utexas.edu/downloads/papers/stanley.ieeetec05.pdf</entry>
<entry id="7">
http://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf</entry>
<entry id="8">
Yohannes Kassahun and Gerald Sommer. Efficient reinforcement learning through evolutionary acquisition of neural topologies. In Proceedings of the 13th European Symposium on Artificial Neural Networks (ESANN 2005), pages 259–266, Bruges, Belgium, April 2005. <weblink xlink:type="simple" xlink:href="http://www.ks.informatik.uni-kiel.de/~yk/ESANN2005EANT.pdf">
http://www.ks.informatik.uni-kiel.de/~yk/ESANN2005EANT.pdf</weblink></entry>
<entry id="9">
Nils T Siebel and Gerald Sommer. Evolutionary reinforcement learning of artificial neural networks.  International Journal of Hybrid Intelligent Systems 4(3): 171-183, October 2007. <weblink xlink:type="simple" xlink:href="http://www.ks.informatik.uni-kiel.de/~vision/doc/Publications/nts/SiebelSommer-IJHIS2007.pdf">
http://www.ks.informatik.uni-kiel.de/~vision/doc/Publications/nts/SiebelSommer-IJHIS2007.pdf</weblink></entry>
</reflist>
</p>


</sec>
<sec>
<st>
External links</st>

<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://nn.cs.utexas.edu/keyword?neuroevolution">
University of Texas neuroevolution page</weblink> (has downloadable papers on NEAT and applications)</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://ANNEvolve.sourceforge.net">
ANNEvolve is an Open Source AI Research Project</weblink> (Has downloadable source code in C and Python for a variety of interesting problems. Also a tutorial &amp; miscellaneous writings and illustrations)</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.siebel-research.de/evolutionary_learning/">
Web page on evolutionary learning with EANT/EANT2</weblink> (information and articles on EANT/EANT2 with applications to robot learning)</entry>
</list>
</p>


</sec>
</bdy>
</algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</article>
