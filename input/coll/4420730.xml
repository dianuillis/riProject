<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 21:08:11[mciao0825] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<person  confidence="0.9508927676800064" wordnetid="100007846">
<scientist  confidence="0.9511911446218017" wordnetid="110560637">
<header>
<title>Marcus Hutter</title>
<id>4420730</id>
<revision>
<id>210901771</id>
<timestamp>2008-05-07T22:16:18Z</timestamp>
<contributor>
<username>David Eppstein</username>
<id>2051880</id>
</contributor>
</revision>
<categories>
<category>All pages needing cleanup</category>
<category>Living people</category>
<category>Wikipedia introduction cleanup</category>
<category>Machine learning researchers</category>
<category>German computer scientists</category>
<category>1967 births</category>
</categories>
</header>
<bdy>

 <p>

<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-style" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="40x40px" src="Ambox_style.png">
</image>
</p>
</col>
<col style="" class="mbox-text">
 <b>To comply with Wikipedia's , the introduction of this article may need to be rewritten.</b>
Please discuss this issue on the  and read the to make sure the section will be inclusive of all essential details.</col>
</row>
</table>


<b>Marcus Hutter</b> (born 1967) was born and educated in <location wordnetid="100027167" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../058/19058.xml">
Munich</link></location>
, where he studied <link xlink:type="simple" xlink:href="../939/22939.xml">
physics</link> and <link xlink:type="simple" xlink:href="../323/5323.xml">
computer science</link>. In 2000 he joined <link>
JÃ¼rgen Schmidhuber</link>'s group at the Swiss <link xlink:type="simple" xlink:href="../268/1268.xml">
AI</link> lab <point wordnetid="108620061" confidence="0.8">
<institute wordnetid="108407330" confidence="0.8">
<geographic_point wordnetid="108578706" confidence="0.8">
<location wordnetid="100027167" confidence="0.8">
<association wordnetid="108049401" confidence="0.8">
<workplace wordnetid="104602044" confidence="0.8">
<lab wordnetid="103629986" confidence="0.8">
<link xlink:type="simple" xlink:href="../607/4103607.xml">
IDSIA</link></lab>
</workplace>
</association>
</location>
</geographic_point>
</institute>
</point>
, where he developed the first mathematical theory of optimal Universal <link>
Artificial Intelligence</link>, based on <link xlink:type="simple" xlink:href="../635/1635.xml">
Kolmogorov complexity</link> and  <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<theorist wordnetid="110706812" confidence="0.8">
<intellectual wordnetid="109621545" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../673/402673.xml">
Ray Solomonoff</link></causal_agent>
</intellectual>
</theorist>
</person>
</physical_entity>
's theory of universal <link xlink:type="simple" xlink:href="../562/405562.xml">
inductive inference</link>. In 2006 he also accepted a professorship at the <university wordnetid="108286163" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../106/285106.xml">
Australian National University</link></university>
 in <site wordnetid="108651247" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../983/51983.xml">
Canberra</link></site>
.</p>
<p>

The central idea of Hutter's type of universal AI is this: Suppose you want to maximize your future expected reward in some unknown dynamic environment, up to some future horizon. This is the general <link xlink:type="simple" xlink:href="../294/66294.xml">
reinforcement learning</link> problem. Solomonoff/Hutter's only assumption is that the reactions of the environment in response to your actions follow some unknown but <link xlink:type="simple" xlink:href="../084/3244084.xml">
computable</link> <link xlink:type="simple" xlink:href="../543/23543.xml">
probability distribution</link>. At any time, given the limited observation sequence so far, what is the <link xlink:type="simple" xlink:href="../631/417631.xml">
Bayes</link>-optimal way of selecting the next action? Hutter proved that the answer is: use Solomonoff's universal <link>
prior</link> to predict the future, and execute the first action of the action sequence that will maximize the predicted reward up to the horizon. </p>
<p>

This is mainly a theoretical result. To overcome the problem that Solomonoff's prior is <link xlink:type="simple" xlink:href="../795/54795.xml">
incomputable</link>, in 2002 he also published an <link xlink:type="simple" xlink:href="../503/3469503.xml">
asymptotically</link> fastest algorithm for all well-defined problems. Given some formal description of a problem class, the algorithm systematically generates all <link xlink:type="simple" xlink:href="../384/62384.xml">
proofs</link> in a sufficiently powerful <link xlink:type="simple" xlink:href="../401/188401.xml">
axiomatic system</link> that allows for proving time <link xlink:type="simple" xlink:href="../228/548228.xml">
bounds</link> of solution-computing programs. Simultaneously, whenever a proof has been found that shows that a particular program has a better time bound than the previous best, a clever resource allocation scheme will assign most of the remaining search time to this program. Hutter showed that his method is essentially as fast as the unknown fastest program for solving problems from the given class, save for an additive <link xlink:type="simple" xlink:href="../453/12860453.xml">
constant</link> independent of the problem instance. For example, if the problem size is <math>n</math>, and there exists an initially unknown program that solves any problem in the class within <math>n^7</math> computational steps, then Hutter's method will solve it within <math>5n^7 + O(1)</math> steps. It should be noted, however, that the additive constant hidden in the <math>O()</math> notation may be large enough to render the algorithm practically infeasible despite its useful theoretical properties.</p>

<sec>
<st>
Hutter Prize for Lossless Compression of Human Knowledge</st>

<p>

On August 6, 2006, Professor Hutter announced the <b><symbol wordnetid="106806469" confidence="0.8">
<award wordnetid="106696483" confidence="0.8">
<signal wordnetid="106791372" confidence="0.8">
<link xlink:type="simple" xlink:href="../846/7687846.xml">
Hutter Prize</link></signal>
</award>
</symbol>
 for Lossless Compression of Human Knowledge</b> with an initial purse of 50,000 Euros, the intent of which is to encourage the advancement of <link xlink:type="simple" xlink:href="../164/1164.xml">
artificial intelligence</link> through the exploitation of Hutter's theory of optimal universal artificial intelligence.</p>

</sec>
<sec>
<st>
Partial bibliography</st>

<p>

<list>
<entry level="1" type="bullet">

<it>Universal Artificial Intelligence: Sequential Decisions Based On Algorithmic Probability</it> ISBN 3-540-22139-5</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

On Generalized Computable Universal Priors and their Convergence. Theoretical Computer Science, 2005.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.jmlr.org/papers/volume4/hutter03a/hutter03a.pdf">
Optimality of Universal Bayesian Sequence Prediction for General Loss and Alphabet</weblink>. Journal of Machine Learning Research 4, 971-1000, 2003.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

The Fastest and Shortest Algorithm for All Well-Defined Problems. International Journal of Foundations of Computer Science, 13:3 (2002) 431-443, 2002.</entry>
</list>
</p>

</sec>
<sec>
<st>
 External links </st>
<p>

<list>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.idsia.ch/~marcus/official/index.htm">
Home page</weblink></entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://prize.hutter1.net">
Hutter Prize for Lossless Compression of Human Knowledge</weblink></entry>
</list>
</p>



<p>

<table id="persondata" class="persondata">
<header colspan="2">
 </header>
<row>
<col class="persondata-label">
NAME</col>
<col>
Hutter, Marcus</col>
</row>
<row>
<col class="persondata-label">
ALTERNATIVE NAMES</col>

</row>
<row>
<col class="persondata-label">
SHORT DESCRIPTION</col>
<col>
Computer scientist</col>
</row>
<row>
<col class="persondata-label">
DATE OF BIRTH</col>
<col>
1967</col>
</row>
<row>
<col class="persondata-label">
PLACE OF BIRTH</col>

</row>
<row>
<col class="persondata-label">
DATE OF DEATH</col>

</row>
<row>
<col class="persondata-label">
PLACE OF DEATH</col>

</row>
</table>
</p>


</sec>
</bdy>
</scientist>
</person>
</article>
