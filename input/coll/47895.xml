<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 15:42:55[mciao0828] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<model  confidence="0.9511911446218017" wordnetid="110324560">
<type  confidence="0.9511911446218017" wordnetid="105840188">
<header>
<title>Stochastic process</title>
<id>47895</id>
<revision>
<id>241872439</id>
<timestamp>2008-09-29T22:03:22Z</timestamp>
<contributor>
<username>John Nevard</username>
<id>5585333</id>
</contributor>
</revision>
<categories>
<category>Stochastic processes</category>
<category>Statistical data types</category>
<category>Statistical models</category>
<category>Telecommunication theory</category>
</categories>
</header>
<bdy>

A <b>stochastic process</b>, or sometimes <b>random process</b>, is  the counterpart to a deterministic process (or <link xlink:type="simple" xlink:href="../958/522958.xml">
deterministic system</link>) in <link xlink:type="simple" xlink:href="../542/23542.xml">
probability theory</link>. Instead of dealing with only one possible 'reality' of how the process might evolve under time (as is the case, for example, for solutions of an <link xlink:type="simple" xlink:href="../297/8297.xml">
ordinary differential equation</link>), in a stochastic or random process there is some indeterminacy in its future evolution described by probability distributions. This means that even if the initial condition (or starting point) is known, there are many possibilities the process might go to, but some paths are more probable and others less.<p>

In the simplest possible case (<link xlink:type="simple" xlink:href="../688/564688.xml">
'discrete time'</link>), a stochastic process amounts to a <link xlink:type="simple" xlink:href="../838/27838.xml">
sequence</link> of random variables known as a <link xlink:type="simple" xlink:href="../624/406624.xml">
time series</link> (for example, see <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../876/60876.xml">
Markov chain</link></causal_agent>
</worker>
</assistant>
</model>
</person>
</physical_entity>
). Another basic type of a stochastic process is a <link xlink:type="simple" xlink:href="../838/540838.xml">
random field</link>, whose domain is a region of <link xlink:type="simple" xlink:href="../667/27667.xml">
space</link>, in other words, a random function whose arguments are drawn from a range of continuously changing values. One approach to stochastic processes treats them as <link xlink:type="simple" xlink:href="../427/185427.xml">
function</link>s of one or several deterministic arguments ('inputs', in most cases regarded as 'time') whose values ('outputs') are <link xlink:type="simple" xlink:href="../685/25685.xml">
random variables</link>: non-deterministic (single) quantities which have certain <link xlink:type="simple" xlink:href="../543/23543.xml">
probability distribution</link>s.  Random variables corresponding to various times (or points, in the case of random fields) may be completely different. The main requirement is that these different random quantities all have the same 'type'.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref> Although the random values of a stochastic process at different times may be <link xlink:type="simple" xlink:href="../593/27593.xml">
independent random variables</link>, in most commonly considered situations they exhibit complicated statistical correlations.</p>
<p>

Familiar examples of <link xlink:type="simple" xlink:href="../766/4746766.xml">
process</link>es modeled as stochastic time series include <link xlink:type="simple" xlink:href="../328/52328.xml">
stock market</link> and <link xlink:type="simple" xlink:href="../311/180311.xml">
exchange rate</link> fluctuations, signals such as <link xlink:type="simple" xlink:href="../649/2917649.xml">
speech</link>, <link xlink:type="simple" xlink:href="../087/18994087.xml">
audio</link> and <link xlink:type="simple" xlink:href="../441/32441.xml">
video</link>, <link xlink:type="simple" xlink:href="../957/18957.xml">
medical</link> data such as a patient's <link xlink:type="simple" xlink:href="../988/76988.xml">
EKG</link>, <process wordnetid="105701363" confidence="0.8">
<inquiry wordnetid="105797597" confidence="0.8">
<thinking wordnetid="105770926" confidence="0.8">
<problem_solving wordnetid="105796750" confidence="0.8">
<experiment wordnetid="105798043" confidence="0.8">
<trial wordnetid="105799212" confidence="0.8">
<higher_cognitive_process wordnetid="105770664" confidence="0.8">
<link xlink:type="simple" xlink:href="../647/153647.xml">
EEG</link></higher_cognitive_process>
</trial>
</experiment>
</problem_solving>
</thinking>
</inquiry>
</process>
, <link xlink:type="simple" xlink:href="../558/56558.xml">
blood pressure</link> or <link xlink:type="simple" xlink:href="../300/19572300.xml">
temperature</link>, and random movement such as <link xlink:type="simple" xlink:href="../436/4436.xml">
Brownian motion</link> or <link xlink:type="simple" xlink:href="../451/235451.xml">
random walk</link>s. Examples of random fields include static images, random <link xlink:type="simple" xlink:href="../839/586839.xml">
terrain</link> (landscapes), or composition variations of an inhomogeneous material.</p>

<sec>
<st>
 Formal definition and basic properties </st>


<ss1>
<st>
 Definition </st>
<p>

Given a <link xlink:type="simple" xlink:href="../325/43325.xml">
probability space</link> <math>(\Omega, \mathcal{F}, P)</math>,
a <b>stochastic process</b> (or <b>random process</b>) with state space <it>X</it> is a collection of <it>X</it>-valued
<link>
 random variables</link> indexed by a set <it>T</it> ("time"). That is, a stochastic process <it>F</it> is a collection
<indent level="1">

 <math> \{ F_t : t \in T \}</math>
</indent>
where each <math>F_t</math> is an <it>X</it>-valued random variable.</p>
<p>

A <b>modification</b> <it>G</it> of the process <it>F</it> is a stochastic process on the same state space, with the same parameter set <it>T</it> such that
<indent level="1">

<math> P ( F_t = G_t) =1 \qquad \forall t \in T.</math>
</indent>

</p>
</ss1>
<ss1>
<st>
 Finite-dimensional distributions </st>

<p>

Let <it>F</it> be an <it>X</it>-valued stochastic process. For every finite subset <math>T' \subseteq T</math>, we may write
<math>T'=\{ t_1, \ldots, t_k \}</math>, where <math>k=\#T'</math> and the restriction <math>F|_{T'}=(F_{t_1}, F_{t_2},\ldots, F_{t_k})</math>  is a random variable taking values in <math>X^{\#T'}</math>. The distribution <math>\mathbb{P}_{T'}= \mathbb{P} F|_{T'}^{-1}</math> of this random variable is a probability measure on <math>X^{\#T^\prime}</math>.
Such random variables are called the <link xlink:type="simple" xlink:href="../303/6594303.xml">
finite-dimensional distribution</link>s of <it>F</it>.  </p>
<p>

Under suitable topological restrictions, a suitably "consistent" collection of finite-dimensional distributions can be used to define a stochastic process (see Kolmogorov extension in the next section).</p>

</ss1>
</sec>
<sec>
<st>
 Constructing stochastic processes </st>

<p>

In the ordinary <link xlink:type="simple" xlink:href="../401/188401.xml">
axiomatization</link> of <link xlink:type="simple" xlink:href="../542/23542.xml">
probability theory</link> by means of <link xlink:type="simple" xlink:href="../873/19873.xml">
measure theory</link>, the problem is to construct a <link xlink:type="simple" xlink:href="../586/29586.xml">
sigma-algebra</link> of <link xlink:type="simple" xlink:href="../873/19873.xml">
measurable subsets</link> of the space of all functions, and then put a finite <link xlink:type="simple" xlink:href="../873/19873.xml">
measure</link> on it. For this purpose one traditionally uses a method called <link xlink:type="simple" xlink:href="../161/91161.xml">
Kolmogorov</link> extension.  </p>
<p>

There is at least one alternative axiomatization of probability theory by means of <link xlink:type="simple" xlink:href="../653/9653.xml">
expectations</link> on <link xlink:type="simple" xlink:href="../184/7184.xml">
C-star</link> <link xlink:type="simple" xlink:href="../120/1217120.xml">
algebras of random variables</link>. In this case the method goes by the name of <link>
Gelfand-Naimark-Segal</link> construction.</p>
<p>

This is analogous to the two approaches to measure and integration, where one has the choice to construct measures of sets first and define integrals later, or construct integrals first and define set measures as integrals of characteristic functions.</p>

<ss1>
<st>
 The Kolmogorov extension </st>

<p>

The Kolmogorov extension proceeds along the following lines: assuming that a <link>
probability measure</link> on the space of all functions <math>f: X \to Y</math> exists, then it can be used to specify the joint probability distribution of finite-dimensional random variables <math>f(x_1),\dots,f(x_n)</math>. Now, from this <it>n</it>-dimensional probability distribution we can deduce an (<it>n</it>&nbsp;&amp;minus;&nbsp;1)-dimensional <link xlink:type="simple" xlink:href="../077/506077.xml">
marginal probability distribution</link> for <math>f(x_1),\dots,f(x_{n-1})</math>. Note that the obvious compatibility condition, namely, that this marginal probability distribution be in the same class as the one derived from the full-blown stochastic process, is not a requirement.  Such a condition only holds, for example, if the stochastic process is a Wiener process (in which case the marginals are all gaussian distributions of the exponential class) but not in general for all stochastic processes. When this condition is expressed in terms of <link xlink:type="simple" xlink:href="../487/43487.xml">
probability densities</link>, the result is called the <link xlink:type="simple" xlink:href="../075/526075.xml">
Chapman-Kolmogorov equation</link>. </p>
<p>

The <statement wordnetid="106722453" confidence="0.8">
<message wordnetid="106598915" confidence="0.8">
<theorem wordnetid="106752293" confidence="0.8">
<proposition wordnetid="106750804" confidence="0.8">
<link xlink:type="simple" xlink:href="../542/6674542.xml">
Kolmogorov extension theorem</link></proposition>
</theorem>
</message>
</statement>
 guarantees the existence of a stochastic process with a given family of finite-dimensional <link xlink:type="simple" xlink:href="../543/23543.xml">
probability distribution</link>s satisfying the Chapman-Kolmogorov compatibility condition.</p>

</ss1>
<ss1>
<st>
 Separability, or what the Kolmogorov extension does not provide </st>

<p>

Recall that, in the Kolmogorov axiomatization, <link xlink:type="simple" xlink:href="../873/19873.xml">
measurable</link> sets are the sets which have a probability or, in other words, the sets corresponding to yes/no questions that have a probabilistic answer.  </p>
<p>

The Kolmogorov extension starts by declaring to be measurable all sets of functions where finitely many coordinates <math>[f(x_1), \dots , f(x_n)]</math> are restricted to lie in measurable subsets of <math>Y_n</math>. In other words, if a yes/no question about f can be answered by looking at the values of at most finitely many coordinates, then it has a probabilistic answer.</p>
<p>

In measure theory, if we have a <link xlink:type="simple" xlink:href="../026/6026.xml">
countably infinite</link> collection of measurable sets, then the union and intersection of all of them is a measurable set. For our purposes, this means that yes/no questions that depend on countably many coordinates have a probabilistic answer.</p>
<p>

The good news is that the Kolmogorov extension makes it possible to construct stochastic processes with fairly arbitrary finite-dimensional distributions. Also, every question that one could ask about a sequence has a probabilistic answer when asked of a random sequence. The bad news is that certain questions about functions on a continuous domain don't have a probabilistic answer. One might hope that the questions that depend on uncountably many values of a function be of little interest, but the really bad news is that virtually all concepts of <link xlink:type="simple" xlink:href="../176/5176.xml">
calculus</link> are of this sort. For example:
<list>
<entry level="1" type="number">

<link xlink:type="simple" xlink:href="../509/311509.xml">
boundedness</link></entry>
<entry level="1" type="number">

<link xlink:type="simple" xlink:href="../122/6122.xml">
continuity</link></entry>
<entry level="1" type="number">

<link xlink:type="simple" xlink:href="../921/7921.xml">
differentiability</link> </entry>
</list>

all require knowledge of uncountably many values of the function. </p>
<p>

One solution to this problem is to require that the stochastic process be <link xlink:type="simple" xlink:href="../854/27854.xml">
separable</link>. In other words, that there be some countable set of coordinates <math>\{f(x_i)\}</math> whose values determine the whole random function <it>f</it>.</p>
<p>

The <statement wordnetid="106722453" confidence="0.8">
<message wordnetid="106598915" confidence="0.8">
<theorem wordnetid="106752293" confidence="0.8">
<proposition wordnetid="106750804" confidence="0.8">
<link xlink:type="simple" xlink:href="../378/7080378.xml">
Kolmogorov continuity theorem</link></proposition>
</theorem>
</message>
</statement>
 guarantees that processes that satisfy certain constraints on the <link xlink:type="simple" xlink:href="../684/368684.xml">
moments</link> of their increments are continuous.</p>

</ss1>
</sec>
<sec>
<st>
 Examples and special cases </st>


<ss1>
<st>
 The time </st>

<p>

A notable special case is where the time is a discrete set, for example the nonnegative integers {0, 1, 2, 3, ...}. Another important special case is <math>T = \mathbb{R}</math>.</p>
<p>

Stochastic processes may be defined in higher dimensions by attaching a <link xlink:type="simple" xlink:href="../821/49821.xml">
multivariate random variable</link> to each point in the index set, which is equivalent to using a multidimensional index set. Indeed a multivariate random variable can itself be viewed as a stochastic process with index set T = {1, ..., <it>n</it>}.</p>

</ss1>
<ss1>
<st>
 Examples </st>

<p>

The paradigm of continuous stochastic process is that of the <link xlink:type="simple" xlink:href="../984/149984.xml">
Wiener process</link>. In its original form the problem was concerned with a particle floating on a liquid surface, receiving "kicks" from the molecules of the liquid. The particle is then viewed as being subject to a random force which, since the molecules are very small and very close together, is treated as being continuous and, since the particle is constrained to the surface of the liquid by surface tension, is at each point in time a vector parallel to the surface. Thus the random force is described by a two component stochastic process; two real-valued random variables are associated to each point in the index set, time, (note that since the liquid is viewed as being  the force is independent of the spatial coordinates) with the domain of the two random variables being <b>R</b>, giving the <it>x</it> and <it>y</it> components of the force. A treatment of <link xlink:type="simple" xlink:href="../436/4436.xml">
Brownian motion</link> generally also includes the effect of viscosity, resulting in an equation of motion known as the <link xlink:type="simple" xlink:href="../890/166890.xml">
Langevin equation</link>.</p>
<p>

If the index set of the process is <b>N</b> (the <link xlink:type="simple" xlink:href="../474/21474.xml">
natural numbers</link>), and the range  is <b>R</b> (the real numbers), there are some natural questions to ask about the sample sequences of a process {<b>X</b><it>i</it>}<it>i</it> ∈ <b>N</b>, where a sample sequence is 
{<b>X</b>(ω)<it>i</it>}<it>i</it> ∈ <b>N</b>.</p>
<p>

<list>
<entry level="1" type="number">

 What is the <link xlink:type="simple" xlink:href="../934/22934.xml">
probability</link> that each sample sequence is <link xlink:type="simple" xlink:href="../509/311509.xml">
bounded</link>? </entry>
<entry level="1" type="number">

 What is the probability that each sample sequence is <link>
monotonic</link>?</entry>
<entry level="1" type="number">

 What is the probability that each sample sequence has a <link xlink:type="simple" xlink:href="../401/19616401.xml">
limit</link> as the index approaches ∞?</entry>
<entry level="1" type="number">

 What is the probability that the <link xlink:type="simple" xlink:href="../287/15287.xml">
series</link> obtained from a sample sequence from <math>f(i)</math> <link xlink:type="simple" xlink:href="../779/349779.xml">
converges</link>?</entry>
<entry level="1" type="number">

 What is the probability <link xlink:type="simple" xlink:href="../543/23543.xml">
distribution</link> of the sum?</entry>
</list>
</p>
<p>

Similarly, if the index space  <it>I</it> is a finite or infinite <link xlink:type="simple" xlink:href="../879/14879.xml">
interval</link>, we can ask about the sample paths {<b>X</b>(ω)<it>t</it>}<it>t </it> ∈ <it>I</it>
<list>
<entry level="1" type="number">

 What is the probability that it is bounded/<link xlink:type="simple" xlink:href="../492/602492.xml">
integrable</link>/<link xlink:type="simple" xlink:href="../122/6122.xml">
continuous</link>/<link xlink:type="simple" xlink:href="../921/7921.xml">
differentiable</link>...? </entry>
<entry level="1" type="number">

 What is the probability that it has a limit at ∞</entry>
<entry level="1" type="number">

 What is the probability distribution of the integral?</entry>
</list>
</p>

</ss1>
</sec>
<sec>
<st>
See also</st>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../229/1896229.xml">
List of stochastic processes topics</link></entry>
<entry level="1" type="bullet">

 <know-how wordnetid="105616786" confidence="0.8">
<method wordnetid="105660268" confidence="0.8">
<link xlink:type="simple" xlink:href="../763/4438763.xml">
Gillespie algorithm</link></method>
</know-how>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../876/60876.xml">
Markov Chain</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../001/228001.xml">
Stochastic calculus</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../137/5235137.xml">
DMP</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../263/9793263.xml">
Covariance function</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../463/11071463.xml">
Entropy rate</link> for a stochastic process</entry>
</list>
</p>

</sec>
<sec>
<st>
 Notes </st>
<p>

<reflist>
<entry id="1">
Mathematically speaking, the 'type' refers to the <link xlink:type="simple" xlink:href="../264/50264.xml">
codomain</link> of the function. </entry>
</reflist>
</p>

</sec>
<sec>
<st>
References</st>

<p>

<list>
<entry level="1" type="number">

 <cite style="font-style:normal" class="book">Papoulis, Athanasios &amp; Pillai, S. Unnikrishna&#32;(2001). Probability, Random Variables and Stochastic Processes.&#32;McGraw-Hill Science/Engineering/Math. ISBN 0-07-281725-9.</cite>&nbsp;</entry>
<entry level="1" type="number">

<physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<mathematician wordnetid="110301261" confidence="0.8">
<link xlink:type="simple" xlink:href="../441/1661441.xml">
Boris Tsirelson</link></mathematician>
</scientist>
</causal_agent>
</person>
</physical_entity>
.&#32;"<weblink xlink:type="simple" xlink:href="http://www.math.tau.ac.il/~tsirel/Courses/AdvProb03/lect3.html">
Lecture notes in Advanced probability theory</weblink>".</entry>
<entry level="1" type="number">

 <cite style="font-style:normal" class="book">J. L. Doob&#32;(1953). Stochastic Processes.&#32;Wiley.</cite>&nbsp;</entry>
<entry level="1" type="number">

"<weblink xlink:type="simple" xlink:href="http://www.ifp.uiuc.edu/~hajek/Papers/randomprocesses.html">
An Exploration of Random Processes for Engineers</weblink>".&#32;<it>Free e-book</it>&#32;(July).</entry>
</list>
</p>




</sec>
<sec>
<st>
External links</st>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://sitmo.com/eqcat/1">
Stochastic Processes used in Quantitative Finance</weblink>, sitmo.com</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.goldsim.com/Content.asp?PageID=455">
Addressing Risk and Uncertainty</weblink></entry>
</list>
</p>


</sec>
</bdy>
</type>
</model>
</article>
