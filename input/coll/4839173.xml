<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 21:24:12[mciao0825] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Info-gap decision theory</title>
<id>4839173</id>
<revision>
<id>215428201</id>
<timestamp>2008-05-28T03:50:30Z</timestamp>
<contributor>
<username>WÃ¶lffReik</username>
<id>5977822</id>
</contributor>
</revision>
<categories>
<category>Decision theory</category>
</categories>
</header>
<bdy>

<b>Info-gap decision theory</b> is a non-probabilistic <link xlink:type="simple" xlink:href="../216/446216.xml">
decision theory</link> seeking to optimize robustness to failure, or opportuneness for windfall, under severe uncertainty. <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref> <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref><p>

It is common to make uncertain decisions.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%223%22])">3</ref> What can be done to make good (or at least the best possible) decisions under conditions of uncertainty? Info-gap <b>robustness</b> analysis evaluates each feasible decision by asking: how much deviation from an estimate of a parameter value, function, or set, is permitted and yet "guarantee" acceptable performance? In everyday terms, the "robustness" of a decision is set by the size of deviation from an estimate that still leads to performance within requirements when using that decision. It is sometimes difficult to judge how much robustness is needed or sufficient. However, according to info-gap theory,  the ranking of feasible decisions in terms of their degree of robustness is independent of such judgments.</p>
<p>

Info-gap theory also proposes an <b>opportuneness</b> function which evaluates the potential for windfall outcomes resulting from favorable uncertainty.</p>
<p>

In the framework of classical <link xlink:type="simple" xlink:href="../216/446216.xml">
decision theory</link>, info-gap's robustness model is an instance of <scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../430/1239430.xml">
Wald</link></scientist>
's <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> model and its opportuneness model is an instance of the classical Minimin model. Both operate in the neighborhood of an estimate of the parameter of interest whose true value is subject to <it>severe</it> uncertainty and therefore is likely to be <it>substantially wrong</it>. Moreover, the considerations brought to bear upon the decision process itself also originate in the locality of this unreliable estimate, and so may or may not be reflective of the entire range of decisions and uncertainties.</p>

<sec>
<st>
 Background, working assumptions, and a look ahead </st>

<p>

Decision under severe uncertainty is a formidable task and the development of methodologies capable of handling this task is even a more arduous undertaking.  Indeed, over the past sixty years an enormous effort has gone into the development of such methodologies.  Yet, for all the knowledge and expertise that have accrued in this area of decision theory, no fully satisfactory general methodology is available to date. </p>
<p>

Now, as portrayed in the info-gap literature, Info-Gap was designed expressly as a methodology for solving decision problems that are subject to severe uncertainty.  And what is more, its aim is to seek solutions that are <b>robust</b>. </p>
<p>

Thus, to have a clear picture of info-gap's modus operandi and its role and place in decision theory and robust optimization, it is imperative to examine it within this context.  In other words, it is necessary to establish info-gap's relation to classical decision theory and robust optimization. 
To this end, the following questions must be addressed:
<list>
<entry level="1" type="bullet">

 What are the characteristics of decision problems that are subject to severe uncertainty?</entry>
<entry level="1" type="bullet">

 What difficulties arise in the modelling and solution of such problems?</entry>
<entry level="1" type="bullet">

 What type of robustness is sought?</entry>
<entry level="1" type="bullet">

 How does info-gap theory address these issues?</entry>
<entry level="1" type="bullet">

 In what way is info-gap decision theory similar to and/or different from other theories for decision under uncertainty?</entry>
</list>
</p>
<p>

Two important points need to be elucidated in this regard at the outset:
<list>
<entry level="1" type="bullet">

 Considering the <b>severity</b> of the uncertainty that info-gap was designed to tackle, it is essential to clarify the difficulties posed by severe uncertainty.</entry>
<entry level="1" type="bullet">

 Since info-gap is a <b>non-probabilistic</b> method that seeks to <b>maximize robustness</b> to uncertainty, it is imperative to compare it to the single most important "non-probabilistic" model in classical decision theory, namely Wald's <b>Maximin</b> paradigm (Wald 1945, 1950).  After all, this paradigm has dominated the scene in classical decision theory for well over sixty years now.</entry>
</list>
</p>
<p>

So, first let us clarify the assumptions that are implied by <b>severe</b> uncertainty.</p>

<ss1>
<st>
 Working assumptions </st>

<p>

Info-gap decision theory employs three simple constructs to capture the uncertainty associated with decision problems:
<list>
<entry level="1" type="number">

 A parameter <math>\displaystyle u</math> whose true value is subject to severe uncertainty.</entry>
<entry level="1" type="number">

 A region of uncertainty <math>\displaystyle \mathfrak{U}\ </math> where the true value of <math>\displaystyle u \ </math> lies.</entry>
<entry level="1" type="number">

 An estimate <math>\ \displaystyle \tilde{u}\ </math> of the true value of <math>\displaystyle u \ </math>.</entry>
</list>
</p>
<p>

It should be pointed out, though, that as such these constructs are generic, meaning that they can be employed to model situations where the uncertainty is not severe but mild, indeed very mild.  So it is vital to be clear that to give apt expression to the  <b>severity</b> of the uncertainty, in the Info-Gap framework these three constructs  are given specific meaning.</p>
<p>

<image location="right" width="150px" src="Assumption.png">
</image>

<it>Working Assumptions</it>
<list>
<entry level="1" type="number">

 The region of uncertainty <math>\displaystyle \mathfrak{U}\ </math> is <b>relatively large.</b> In fact, Ben-Haim (2006, p. 210) indicates that in the context of info-gap decision theory most of the commonly encountered regions of uncertainty are <b>unbounded.</b></entry>
<entry level="1" type="number">

 The estimate <math>\displaystyle \tilde{u}\ </math> is a <b>poor</b> approximation of the true value of <math>\displaystyle \ u\ </math>. That is, the estimate is a <b>poor</b> indication of the true value of <math>\displaystyle \ u\ </math> (Ben-Haim, 2006, p. 280) and is likely to be <b>substantially wrong</b> (Ben-Haim, 2006, p. 281). </entry>
</list>
</p>
<p>

In the picture <math>\displaystyle  u^{\circ}\ </math> represents the true (unknown) value of <math>\ \displaystyle u\ </math>. </p>
<p>

The point to note here is that conditions of severe uncertainty entail that the estimate <math>\displaystyle  \tilde{u}\ </math>  can -- relatively speaking -- be very distant from the true value <math>\displaystyle  u^{\circ}\ </math>. This is particularly pertinent for methodologies, like info-gap,  that seek <b>robustness</b> to uncertainty. Indeed, assuming otherwise  would  -- methodologically speaking -- be tantamount to engaging in wishful thinking. </p>

<p>

In short, the situations that info-gap is designed to take on are demanding in the extreme.  Hence, the challenge that one faces conceptually, methodologically and technically is considerable.  It is essential therefore to examine whether info-gap robustness analysis succeeds in this task, and whether the tools that it deploys in this effort are different from those made available by Wald's (1945) Maximin paradigm especially for robust optimization. </p>
<p>

So let us take a quick look at this stalwart of classical decision theory and robust optimization.</p>

</ss1>
<ss1>
<st>
 Wald's Maximin paradigm </st>

<p>

The basic idea behind this famous paradigm can be expressed in plain language as follows:</p>
<p>

<it>Maximin Rule</it>
The maximin rule tells us to rank alternatives by their worst possible outcomes: we are to adopt the alternative the worst outcome of which is superior to the worst outcome of the others.<philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../612/123612.xml">
Rawls</link></philosopher>
 <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%224%22])">4</ref>(1971, p. 152)</p>


<p>

Thus,  according to this paradigm,  in the framework of decision-making under severe uncertainty, the robustness of an alternative is a measure of how well this alternative can cope with the <b>worst uncertain outcome</b> that it can generate. Needless to say, this attitude towards severe uncertainty often leads to the selection of highly <b>conservative</b> alternatives.  This is precisely the reason that this paradigm is not always a satisfactory methodology for decision-making under severe uncertainty (Tintner 1952).</p>
<p>

As indicated in the overview, info-gap's robustness model is a Maximin model in disguise. More specifically, it is a simple instance of Wald's Maximin model where:
<list>
<entry level="1" type="number">

 The region of uncertainty associated with an alternative decision is an immediate neighborhood of the estimate <math>\displaystyle \tilde{u}\ </math>.</entry>
<entry level="1" type="number">

 The uncertain outcomes of an alternative are determined by a characteristic function of the performance requirement under consideration.</entry>
</list>
</p>
<p>

Thus, aside from the <b>conservatism</b> issue, a far more serious issue must be addressed.  This is the <b>validity</b> issue arising from  the <b>local</b>  nature of info-gap's robustness analysis.</p>

</ss1>
<ss1>
<st>
 Local vs global robustness </st>

<p>

<image location="right" width="150px" src="Maximin_assumption.png">
</image>

The validity of the results generated by info-gap's robustness analysis are crucially contingent on the quality of the estimate <math>\displaystyle \tilde{u}\ </math>.  Alas, according to info-gap's own working assumptions, this estimate is poor and likely to be substantially wrong (Ben-Haim, 2006, p. 280-281). </p>
<p>

The trouble with this feature of info-gap's robustness model is brought out more forcefully by the picture. The white circle represents the immediate neighborhood of the estimate <math>\ \displaystyle \tilde{u}\ </math> on which the Maximin analysis is conducted. Since the region of uncertainty is large and the quality of the estimate is poor, it is very likely that the true value of <math>\ \displaystyle u\ </math> is distant from the point at which the Maximin analysis is conducted.</p>
<p>

So given the severity of the uncertainty under consideration, how valid/useful can this type of Maximin analysis really be?</p>
<p>

The critical issue here is then to what extent can a <b>local</b> robustness analysis a la Maximin in the immediate neighborhood of a poor estimate aptly represent a large region of uncertainty. This is a serious issue that must be dealt with in this article.</p>
<p>

It should be pointed out that, in comparison, robust optimization methods invariably take a far more global view of robustness. So much so that <b>scenario planning</b>  and <b>scenario generation</b> are central issues in this area.  This reflects a strong commitment to an adequate representation of the entire region of uncertainty in the definition of robustness and in the robustness analysis itself.     </p>
<p>

And finally there is another reason why the intimate relation to Maximin is crucial to this discussion. This has to do with the portrayal of info-gap's contribution to the state of the art in decision theory, and its role and place vis-a-vis other methodologies.</p>

</ss1>
<ss1>
<st>
 Role and place in decision theory </st>

<p>

Info-gap is emphatic about its advancement of the state of the art in decision theory (color is used here for emphasis):</p>
<p>

Info-gap decision theory is radically different from all current theories of decision under uncertainty. The difference originates in the modelling of uncertainty as an information gap rather than as a probability.  Ben-Haim (2006, p.xii)</p>
<p>

In this book we concentrate on the fairly new concept of information-gap uncertainty, whose differences from more classical approaches to uncertainty are real and deep. Despite the power of classical decision theories, in many areas such as engineering, economics, management, medicine and public policy, a need has arisen for a different format for decisions based on severely uncertain evidence. Ben-Haim (2006, p. 11)   </p>

<p>

These strong claims must be substantiated. In particular, a clear-cut, unequivocal answer must be given to the following question: in what way is info-gap's generic robustness model different, indeed radically different, from worst-case analysis a la  Maximin? </p>
<p>

Subsequent sections of this article describe various aspects of info-gap decision theory and its applications, how it  proposes to cope with the working assumptions outlined above, the local nature of info-gap's robustness analysis and its intimate  relationship with Wald's classical Maximin paradigm and worst-case analysis.</p>

</ss1>
</sec>
<sec>
<st>
Illustrative example</st>

<p>

Here is an illustrative example, which will introduce the basic concepts of information gap theory. More rigorous description and discussion follows.</p>

<ss1>
<st>
Resource allocation</st>
<p>

Suppose you are a project manager, supervising two teams: red team and blue team. Each of the teams will yield some revenue at the end of the year. This revenue depends on the investment in the team Ã± higher investments will yield higher revenues. You have a limited amount of resources, and you wish to decide how to allocate these resources between the two groups, so that the total revenues of the project will be as high as possible.</p>
<p>

If you have an estimate of the correlation between the investment in the teams and their revenues, as illustrated in Figure 1, you can also estimate the total revenue as a function of the allocation. This is exemplified in Figure 2 Ã± the left-hand side of the graph corresponds to allocating all resources to the red team, while the right-hand side of the graph corresponds to allocating all resources to the blue team. A simple optimization will reveal the optimal allocation Ã± the allocation that, under your estimate of the revenue functions, will yield the highest revenue.
<image location="right" width="150px" src="IGT-example1.png" type="thumb">
<caption>

Figure 1 Ã± Revenue per investment
</caption>
</image>

<image location="right" width="150px" src="IGT-example2.png" type="thumb">
<caption>

Figure 2 Ã± Revenue per allocation
</caption>
</image>
</p>

</ss1>
<ss1>
<st>
Introducing uncertainty</st>
<p>

However, this analysis does not take uncertainty into account. Since the revenue functions are only a (possibly rough) estimate, the actual revenue functions may be quite different. For any level of uncertainty (or <it>horizon of uncertainty</it>) we can define an envelope within which we assume the actual revenue functions are. Higher uncertainty would correspond to a more inclusive envelope. Two of these uncertainty envelopes, surrounding the revenue function of the red team, are represented in Figure 3. As illustrated in Figure 4, the actual revenue function may be any function within a given uncertainty envelope. Of course, some instances of the revenue functions are only possible when the uncertainty is high, while small deviations from the estimate are possible even when the uncertainty is small.
<image location="right" width="150px" src="IGT-example3.png" type="thumb">
<caption>

Figure 3 Ã± Revenue uncertainty envelopes
</caption>
</image>

<image location="right" width="150px" src="IGT-example4.png" type="thumb">
<caption>

Figure 4 Ã± Revenue function instance
</caption>
</image>
</p>
<p>

These envelopes is called <it>info-gap models of uncertainty</it>, since they describe are understanding of the uncertainty surrounding the revenue functions.</p>
<p>

From the info-gap models (or uncertainty envelopes) of the revenue functions, we can determine an info-gap model for the total amount of revenues. Figure 5 illustrates two of the uncertainty envelopes defined by the info-gap model of the total amount of revenues.
<image location="right" width="150px" src="IGT-example5.png" type="thumb">
<caption>

Figure 5 Ã± Total revenue uncertainty envelopes
</caption>
</image>
</p>

</ss1>
<ss1>
<st>
Robustness</st>
<p>

Now, assume that as a project manager, high revenues will earn you the senior management's respect, but if the total revenues are below some threshold, it will mean your job. We will define such a threshold as a <it>critical revenue</it>, since total revenues beneath the critical revenue will be considered as failure.</p>
<p>

For any given allocation, the <it>robustness</it> of the allocation, with respect to the critical revenue, is the maximal uncertainty that will still guaranty that the total revenue will exceed the critical revenue. This is demonstrated in Figure 6. If the uncertainty will increase, the envelope of uncertainty will become more inclusive, to include instances of the total revenue function that, for the specific allocation, yields a revenue smaller than the critical revenue.
<image location="right" width="150px" src="IGT-example6.png" type="thumb">
<caption>

Figure 6 - Robustness
</caption>
</image>
</p>
<p>

The robustness measures the immunity of a decision to failure. A <it>robust satisficer</it> is a decision maker that prefers choices with higher robustness.</p>
<p>

If, for some allocation <math>q</math>, we will illustrate the correlation between the critical revenue and the robustness, we will have a graph somewhat similar to Figure 7. This graph, called <it>robustness curve</it> of allocation <math>q</math>, has two important features, that are common to (most) robustness curves:
<image location="right" width="150px" src="IGT-example7.png" type="thumb">
<caption>

Figure 7 Ã± Robustness curve
</caption>
</image>
</p>
<p>

<list>
<entry level="1" type="number">

 The curve is non-increasing. This captures the notion that when we have higher requirements (higher critical revenue), we are less immune to failure (lower robustness). This is the tradeoff between quality and robustness.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="number">

 At the nominal revenue, that is, when the critical revenue equals the revenue under the nominal model (our estimate of the revenue functions), the robustness is zero. This is since a slight deviation from the estimate may decrease the total revenue.</entry>
</list>
</p>
<p>

If we compare the robustness curves of two allocations, <math>q</math> and <math>q'</math>, it is not uncommon that the two curves will intersect, as illustrated in Figure 8. In this case, none of the allocations is strictly more robust than the other: for critical revenues smaller than the crossing point, allocation <math>q'</math> is more robust than allocation <math>q</math>, while the other way around holds for critical revenues higher than the crossing point. That is, the preference between the two allocations depends on the criterion of failure Ã± the critical revenue.
<image location="right" width="150px" src="IGT-example8.png" type="thumb">
<caption>

Figure 8 Ã± Robustness curves cross
</caption>
</image>
</p>

</ss1>
<ss1>
<st>
Opportuneness</st>
<p>

Suppose, in addition to the threat of losing your job, the senior management offers you a carrot: if the revenues are <it>higher</it> than some revenue, you will be awarded a considerable bonus. Although revenues lower than this revenue will not be considered to be a failure (as you may still keep your job), a higher revenue will be considered a windfall success. We will therefore denote this threshold by <it>windfall revenue</it>.</p>
<p>

For any given allocation, the <it>opportuneness</it> of the allocation, with respect to the critical revenue, is the minimal uncertainty for which it is possible for the total revenue to exceed the critical revenue. This is demonstrated in Figure 9. If the uncertainty will decrease, the envelope of uncertainty will become less inclusive, to exclude all instances of the total revenue function that, for the specific allocation, yields a revenue higher than the windfall revenue.
<image location="right" width="150px" src="IGT-example9.png" type="thumb">
<caption>

Figure 9 - Opportuneness
</caption>
</image>
</p>
<p>

The opportuneness may be considered as the immunity to windfall success. Therefore, lower opportuneness is preferred to higher opportuneness.</p>
<p>

If, for some allocation <math>q</math>, we will illustrate the correlation between the windfall revenue and the robustness, we will have a graph somewhat similar to Figure 10. This graph, called <it>opportuneness curve</it> of allocation <math>q</math>, has two important features, that are common to (most) opportuneness curves:
<image location="right" width="150px" src="IGT-example10.png" type="thumb">
<caption>

Figure 10 Ã± Opportuneness curves
</caption>
</image>
</p>
<p>

<list>
<entry level="1" type="number">

 The curve is non-decreasing. This captures the notion that when we have higher requirements (higher windfall revenue), we are more immune to failure (higher opportuneness, which is less desirable). That is, we need a more substantial deviation from the estimate in order to achieve our ambitious goal. This is the tradeoff between quality and opportuneness.</entry>
<entry level="1" type="number">

 At the nominal revenue, that is, when the critical revenue equals the revenue under the nominal model (our estimate of the revenue functions), the opportuneness is zero. This is since no deviation from the estimate is needed in order to achieve the windfall revenue.</entry>
</list>
</p>

</ss1>
<ss1>
<st>
 Treatment of severe uncertainty </st>

<p>

The logic underlying the above illustration is that the (unknown) true revenue is somewhere in the immediate neighborhood of the (known) estimate of the revenue. For if this is not the case, what is the point of conducting the analysis exclusively in this neighborhood?</p>
<p>

Therefore, to remind ourselves that info-gap's manifest objective is to seek robust solutions for problems that are subject to <b>severe</b> uncertainty, it is instructive to exhibit in the display of the results also those associated with the <b>true</b> value of the revenue. Of course, given the severity of the uncertainty we do not know the true value.</p>
<p>

What we do know, however,  is that according to our working assumptions the estimate we have is a <b>poor</b>  indication of the true value of the revenue and is likely to be <b>substantially wrong.</b>  So, methodologically speaking, we have to display the true value at a distance from its estimate. In fact, it would be even more enlightening to display a number of <it> possible true values .</it></p>
<p>

In short, methodolocially speaking the picture is this:</p>
<p>

<image width="650px" src="Investment_example.png">
</image>
</p>

<p>

Note that in addition to the results generated by the estimate,  two "possible" true values of the revenue are also displayed at a distance from the estimate.</p>
<p>

As indicated by the picture, since info-gap robustness model applies its Maximin analysis in an immediate neighborhood of the estimate, there is no assurance that the analysis is in fact conducted in the neighborhood of the true value of the revenue. In fact, under conditions of severe uncertainty this -- methodologically speaking -- is very unlikely.</p>
<p>

This raises the question: how valid/useful/meaningful are the results? Aren't we sweeping the severity of the uncertainty under the carpet? </p>
<p>

For example, suppose that a given  allocation is found to be very fragile in the neighborhood of the estimate. Does this means that this allocation is also fragile elsewhere in the region of uncertainty? Conversely, what guarantee is there that an allocation that is robust in the neighborhood of the estimate is also robust elsewhere in the region of uncertainty, indeed in the neighborhood of the true value of the revenue?</p>
<p>

More fundamentally, given that the results generated by info-gap are based on a <b>local</b> revenue/allocation analysis in the neighborhood of an estimate that is likely to be substantially wrong, we have no other choice -- methodologically speaking -- but to assume that the results generated by this analysis are equally likely to be substantially wrong. In other words, in accordance with the universal <link>
Garbage In - Garbage Out Axiom</link>, we have to assume that the quality of the results generated by info-gap's analysis is only as good as the quality of the estimate on which the results are based. </p>
<p>

The picture speaks for itself.</p>
<p>

What emerges then is that info-gap theory is yet to explain in what way, if any,  it actually attempts to deal with the severity of the uncertainty under consideration. Subsequent sections of this article will address this <b>severity</b> issue and its methodological and practical implications.</p>
<p>

A more detailed analysis of an illustrative numerical investment problem of this type can be found in Sniedovich (2007).</p>


</ss1>
</sec>
<sec>
<st>
 Info-gap models </st>
<p>

Info-gaps are quantified by <b>info-gap models of uncertainty.</b> An info-gap model is an unbounded family of nested sets. For example, a frequently encountered example is a family of nested <link xlink:type="simple" xlink:href="../381/145381.xml">
ellipsoid</link>s all having the same shape. The structure of the sets in an info-gap model derives from the information about the uncertainty. In general terms, the structure of an info-gap model of uncertainty is chosen to define the smallest or strictest family of sets whose elements are consistent with the prior information. Since there is, usually, no known worst case, the family of sets may be unbounded.</p>
<p>

A common example of an info-gap model is the <b>fractional error model.</b> The best estimate of an uncertain function <math>u(x)\!\,</math> is <math>{\tilde{u}}(x)</math>, but the fractional error of this estimate is unknown. The following unbounded family of nested sets of functions is a fractional-error info-gap model:
<indent level="1">

<math>
\mathcal{U}(\alpha, {\tilde{u}}) = \left \{ u(x): \ 
|u(x) - {\tilde{u}}(x) | \le \alpha {\tilde{u}}(x), \ \mbox{for all}\ x \right \} , \ \ \ \alpha \ge 0
</math>
</indent>
At any <b>horizon of uncertainty</b> <math>\alpha</math>, the set <math>\mathcal{U}(\alpha, {\tilde{u}})</math> contains all functions <math>u(x)\!\,</math> whose fractional deviation from <math>{\tilde{u}}(x)</math> is no greater than <math>\alpha</math>. However, the horizon of uncertainty is unknown, so the info-gap model is an unbounded family of sets, and there is no worst case or greatest deviation.</p>
<p>

There are many other types of info-gap models of uncertainty. All info-gap models obey two basic <link xlink:type="simple" xlink:href="../928/928.xml">
axiom</link>s:</p>
<p>

<list>
<entry level="1" type="bullet">

<b>Nesting.</b> The info-gap model <math>\mathcal{U}(\alpha, {\tilde{u}})</math> is nested if <math>\alpha &amp;lt; \alpha^\prime</math> implies that:</entry>
<entry level="2" type="indent">

<math>
\mathcal{U}(\alpha, {\tilde{u}}) \ \subseteq \ \mathcal{U}(\alpha^\prime, {\tilde{u}})
</math></entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

<b>Contraction.</b> The info-gap model <math>\mathcal{U}(0,{\tilde{u}})</math> is a singleton set containing its center point:</entry>
<entry level="2" type="indent">

<math>
\mathcal{U}(0,{\tilde{u}}) = \{ {\tilde{u}} \}
</math></entry>
</list>
</p>
<p>

The nesting axiom imposes the property of "clustering" which is characteristic of info-gap uncertainty. Furthermore, the nesting axiom implies that the uncertainty sets <math>\mathcal{U}(\alpha, u)</math> become more inclusive as <math>\alpha</math> grows, thus endowing <math>\alpha</math> with its meaning as an horizon of uncertainty. The contraction axiom implies that, at horizon of uncertainty zero, the estimate <math>{\tilde{u}}</math> is correct.</p>
<p>

Recall that the uncertain element <math>u</math> may be a parameter, vector, function or set. The info-gap model is then an unbounded family of nested sets of parameters, vectors, functions or sets.</p>

</sec>
<sec>
<st>
 Robustness and opportuneness </st>
<p>

Uncertainty may be either  or . That is, uncertain variations may be either adverse or favorable. Adversity entails the possibility of failure, while favorability is the opportunity for sweeping success. Info-gap decision theory is based on quantifying these two aspects of uncertainty, and choosing an action which addresses one or the other or both of them simultaneously. The pernicious and propitious aspects of uncertainty are quantified by two "immunity functions": the robustness function expresses the immunity to failure, while the opportuneness function expresses the immunity to windfall gain.</p>
<p>

The <b>robustness function</b> expresses the greatest level of uncertainty at which failure cannot occur; the <b>opportuneness function</b> is the least level of uncertainty which entails the possibility of sweeping success. The robustness and opportuneness functions address, respectively, the pernicious and propitious facets of uncertainty.</p>
<p>

Let <math>q</math> be a decision vector of parameters such as design variables, time of initiation, model parameters or operational options. We can verbally express the robustness and opportuneness functions as the maximum or minimum of a set of values of the uncertainty parameter <math>\alpha</math> of an info-gap model:
<indent level="1">

| width="100%" border="0"
</indent>
|<math>
{\hat{\alpha}}(q) = \max \{ \alpha: \ \mbox{minimal requirements are always satisfied}\}
</math>
| (robustness)
| (1)
|-
|<math>
{\hat{\beta}}(q) = \min \{ \alpha: \ \mbox{sweeping success is possible}\}
</math>
| (opportuneness)
| (2)
|}
We can "read" eq.&nbsp;(1) as follows. The robustness <math>{\hat{\alpha}}(q)</math> of decision vector <math>q</math> is the greatest value of the horizon of uncertainty <math>\alpha</math> for which specified minimal requirements are always satisfied. <math>{\hat{\alpha}}(q)</math> expresses robustness Ã³ the degree of resistance to uncertainty and immunity against failure Ã³ so a large value of <math>{\hat{\alpha}}(q)</math> is desirable. Eq.&nbsp;(2) states that the opportuneness <math>{\hat{\beta}}(q)</math>
is the least level of uncertainty <math>\alpha</math> which must be tolerated in order to enable the possibility of sweeping success as a result of decisions <math>q</math>. <math>{\hat{\beta}}(q)</math> is the immunity against windfall reward, so a small value of <math>{\hat{\beta}}(q)</math> is desirable. A small value of <math>{\hat{\beta}}(q)</math> reflects the opportune situation that
great reward is possible even in the presence of little ambient uncertainty. The immunity functions <math>{\hat{\alpha}}(q)</math> and <math>{\hat{\beta}}(q)</math> are complementary and are defined in an anti-symmetric sense. Thus "bigger is better" for <math>{\hat{\alpha}}(q)</math> while "big is bad" for <math>{\hat{\beta}}(q)</math>. The immunity functions Ã³ robustness and opportuneness Ã³ are the basic decision functions in info-gap decision theory.</p>
<p>

The robustness function involves a maximization, but not of the performance or outcome of the decision. The greatest tolerable uncertainty is found at which decision <math>q</math> <b><link xlink:type="simple" xlink:href="../401/70401.xml">
satisfices</link></b> the performance at a critical survival-level. One may establish one's preferences among the available actions <math>q, \, q^\prime,\, \ldots </math> according to their robustnesses <math>{\hat{\alpha}}(q),\, {\hat{\alpha}}(q^\prime), \, \ldots </math>, whereby larger robustness engenders higher preference. In this way the robustness function underlies a satisficing decision algorithm which maximizes the immunity to pernicious uncertainty.</p>
<p>

The opportuneness function in eq.&nbsp;(2) involves a minimization, however not, as might be expected, of the damage which can accrue from unknown adverse events. The least horizon of uncertainty is sought at which decision <math>q</math> enables (but does not necessarily guarantee) large windfall gain. Unlike the robustness function, the opportuneness function does not satisfice, it "windfalls". Windfalling preferences are those which prefer actions for which the opportuneness function takes a small value. When <math>{\hat{\beta}}(q)</math> is used to choose an action <math>q</math>, one is "windfalling" by optimizing the opportuneness from propitious uncertainty in an attempt to enable highly ambitious goals or rewards.</p>
<p>

Given a scalar reward function <math>R(q,u)</math>, depending on the decision vector <math>q</math> and the info-gap-uncertain function <math>u</math>, the minimal requirement in eq.&nbsp;(1) is that the reward <math>R(q,u)</math> be no less than a critical value <math>{r_{\rm c}}</math>. Likewise, the sweeping success in eq. (2) is attainment of a "wildest dream" level of reward <math>{r_{\rm w}}</math> which is much greater than <math>{r_{\rm c}}</math>. Usually neither of these threshold values, <math>{r_{\rm c}}</math> and <math>{r_{\rm w}}</math>, is chosen irrevocably before performing the decision analysis. Rather, these parameters enable the decision maker to explore a range of options. In any case the windfall reward <math>{r_{\rm w}}</math> is greater, usually much greater, than the critical reward <math>{r_{\rm c}}</math>:
<indent level="1">

<math>
{r_{\rm w}} &amp;gt; {r_{\rm c}}
</math>
</indent>

The robustness and opportuneness functions of eqs.&nbsp;(1) and (2) can now be expressed more explicitly:
<indent level="1">

| border="0" width="100%"
</indent>
| <math>
{\hat{\alpha}}(q, {r_{\rm c}}) = \max \left \{ \alpha: \ 
\left ( \min_{u \in \mathcal{U}(\alpha, \tilde{u})} R(q,u) \right ) \ge {r_{\rm c}} \right \}
</math>
| (3)
|-
|<math>
{\hat{\beta}}(q, {r_{\rm w}}) = \min \left \{ \alpha: \ 
\left ( \max_{u \in \mathcal{U}(\alpha, \tilde{u})} R(q,u) \right ) \ge {r_{\rm w}} \right \}
</math>
| (4)
|}
<math>{\hat{\alpha}}(q, {r_{\rm c}})</math> is the greatest level of uncertainty consistent with guaranteed reward no less than the critical reward <math>{r_{\rm c}}</math>, while <math>{\hat{\beta}}(q, {r_{\rm w}})</math> is the least level of uncertainty which must be accepted in order to facilitate (but not guarantee) windfall as great as <math>{r_{\rm w}}</math>. The complementary or anti-symmetric structure of the immunity functions is evident from eqs.&nbsp;(3) and (4).</p>
<p>

These definitions can be modified to handle multi-criterion reward functions. Likewise, analogous definitions apply when <math>R(q,u)</math> is a loss rather than a reward.</p>
<p>

The robustness function generates <b>robust-satisficing preferences</b> on the options. A robust-satisficing decision maker will prefer a decision option <math>q\,\!</math> over an alternative <math>q^\prime</math> if the robustness of <math>q\,\!</math> is greater than the robustness of <math>q^\prime</math> at the same value of critical reward <math>{r_{\rm c}}</math>. That is:
<indent level="1">

| border="0" width="100%"
</indent>
|<math>q \succ _{\rm r} q^\prime
</math>&nbsp;&nbsp;&nbsp;&nbsp;    if    &nbsp;&nbsp;&nbsp;&nbsp;<math>
{\hat{\alpha}}(q, {r_{\rm c}}) &amp;gt; {\hat{\alpha}}(q^\prime, {r_{\rm c}})</math>
| (5) 
|}</p>
<p>

Let <math>\mathcal{Q}</math> be the set of all available or feasible decision vectors <math>q</math>. A robust-satisficing decision is one which maximizes the robustness on the set <math>\mathcal{Q}</math> of available <math>q</math>-vectors and satisfices the performance at the critical level <math>{r_{\rm c}}</math>:
<indent level="1">

<math>
{\hat{q}_{{\rm c}}}({r_{\rm c}}) = \arg \max_{q \in \mathcal{Q}} {\hat{\alpha}}(q, {r_{\rm c}})
</math>
</indent>
Usually, though not invariably, the robust-satisficing action <math>{\hat{q}_{{\rm c}}}({r_{\rm c}})</math> depends on the critical reward <math>{r_{\rm c}}</math>.</p>
<p>

The opportuneness function generates <b>opportune-windfalling preferences</b> on the options. An opportune-windfalling  decision maker will prefer a decision <math>q</math> over an alternative <math>q^\prime</math> if <math>q</math> is more opportune than <math>q^\prime</math> at the same level of reward <math>{r_{\rm w}}</math>. Formally:
<indent level="1">

| border=0 width="100%"
</indent>
|<math>q \succ _{\rm o} q^\prime
</math>&nbsp;&nbsp;&nbsp;&nbsp;    if    &nbsp;&nbsp;&nbsp;&nbsp; <math>
{\hat{\beta}}(q, {r_{\rm w}}) &amp;lt; {\hat{\beta}}(q^\prime, {r_{\rm w}})</math>
| (6) 
|}
The opportune-windfalling decision, <math>{\hat{q}_{{\rm w}}}({r_{\rm w}})</math>, <it>minimizes</it> the opportuneness function on the set of available decisions:
<indent level="1">

<math>
{\hat{q}_{{\rm w}}}({r_{\rm w}}) = \arg \min_{q \in \mathcal{Q}} {\hat{\beta}}(q, {r_{\rm w}})
</math>
</indent>

The two preference rankings, eqs.&nbsp;(5) and (6), as well as the corresponding the optimal decisions
<math>{\hat{q}_{{\rm c}}}({r_{\rm c}})</math> and <math>{\hat{q}_{{\rm w}}}({r_{\rm w}})</math>, may be different.</p>

</sec>
<sec>
<st>
 Invariance property </st>

<p>

The main point to keep in mind here is that info-gap's raison d'&amp;ecirc;tre is to provide a methodology for decision under <b>severe</b> uncertainty.  This means that its primary test would be in the efficacy of its handling of and coping with  <b>severe</b> uncertainty.  To this end it must be established first how Info-Gap's robustness/opportuneness models behave/fare, as the <b>severity</b> of the uncertainty is increased/decreased. </p>
<p>

Second, it must be established whether info-gap's robustness/opportuneness models give adequate expression to the potential variability of the performance function over the entire region of uncertainty.  This is particularly important because Info--Gap is usually concerned with relatively large, indeed unbounded, regions of uncertainty. </p>
<p>

So, let <math>\ \displaystyle \mathfrak{U} \ </math> denote the total region of uncertainty and consider these key questions:</p>
<p>

<list>
<entry level="1" type="bullet">

 How does the robustness/opportuneness analysis respond to an increase/decrease in the size of <math>\ \displaystyle \mathfrak{U} \ </math>? </entry>
<entry level="1" type="bullet">

 How does an increase/decrease in the size of <math>\ \displaystyle \mathfrak{U} \ </math> affect the robustness or opportuneness of a decision?</entry>
<entry level="1" type="bullet">

 How representative are the results generated by info-gap's robustness/opportuness analysis of what occurs in the relatively large total region of uncertainty <math>\ \displaystyle \mathfrak{U} \ </math>? </entry>
</list>
</p>

<p>

<image location="right" width="150px" src="Invariance_gray1.png">
</image>
</p>
<p>

Suppose then that the robustness <math>\ \displaystyle \hat{\alpha}(q,r_{c}) \ </math> has been computed for a decision <math>\ \displaystyle q\in \mathcal{Q}\ </math>  and it is observed that <math>\ \displaystyle \ \mathcal{U}(\alpha^{*},\tilde{u}) \subseteq \mathfrak{U}\ </math> where <math>\ \displaystyle \alpha^{*}=\hat{\alpha}(q,r_{c}) + \varepsilon \ </math>&nbsp; for some <math>\ \displaystyle \varepsilon &amp;gt; 0\ </math>.</p>
<p>

The question is then: how would the robustness of <math>\ \displaystyle q \ </math>, namely  <math>\ \displaystyle \hat{\alpha}(q,r_{c}) \ </math>, be affected if the region of uncertainty would be say, twice as large as <math>\ \displaystyle \mathfrak{U} \ </math>, or perhaps even 10 times as large as <math>\ \displaystyle \mathfrak{U} \ </math>?</p>
<p>

Consider then the following result which is a direct consequence of the local nature of info-gap's robustness/oppurtnueness analysis and the nesting property of info-gaps' regions of uncertainty (Sniedovich 2007):   </p>

<ss1>
<st>
 Invariance Theorem </st>
<p>
 
The robustness of decision <math>\ \displaystyle q \ </math> is invariant with the size of the total region of uncertainty <math>\ \displaystyle \mathfrak{U} \ </math> for all <math>\ \displaystyle \mathfrak{U} \ </math> such that 
<indent level="1">

| width="70%" border="0"
</indent>
| (7)
|<math>\mathcal{U}(\hat{\alpha}(q,r_{c})+\varepsilon,\tilde{u}) \subseteq \mathfrak{U}\ </math>&nbsp; for some <math>\ \displaystyle \varepsilon &amp;gt; 0\ .</math> &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;  &nbsp;&nbsp;&nbsp;<math> \Box</math>
|}</p>

<p>

In other words, for any given decision, info-gap's analysis yields the same results for all total regions of uncertainty that contain <math>\ \displaystyle \ \mathcal{U}(\alpha^{*},\tilde{u}) \ </math>. This applies to both the robustness and opportuneness models. </p>
<p>

This is illustrated in the picture: the robustness of a given decision does not change notwithstanding an increase in the region of uncertainty from <math>\ \displaystyle \mathfrak{U} \ </math> to  <math>\ \displaystyle \mathfrak{U}''' \ </math>.</p>
<p>

In short, by dint of focusing exclusively on the immediate neighborhood of the estimate <math>\ \displaystyle \tilde{u} \ </math> info-gap's robustness/opportuneness models are inherently <b>local</b>.  For this reason they are --  <b>in principle</b> -- incapable of incorporating in the analysis of  <math>\ \displaystyle \hat{\alpha}(q,r_{c}) \ </math> and <math>\ \displaystyle \hat{\beta}(q,r_{c}) \ </math> regions of uncertainty that lie outside the neighborhoods <math>\mathcal{U}(\hat{\alpha}(q,r_{c}),\tilde{u})\ </math> and <math>\mathcal{U}(\hat{\beta}(q,r_{c}),\tilde{u})\ </math> of the estimate <math>\ \displaystyle \tilde{u} \ </math>, respectively.</p>
<p>

To illustrate, consider a simple numerical example where the total region of uncertainty is <math>\mathfrak{U}=(-\infty,\infty),\ </math> the estimate is <math>\ \displaystyle \tilde{u}=0 \ </math>  and for some decision <math>\ \displaystyle \hat{q} \ </math> we obtain <math>\mathcal{U}(\hat{\alpha}(\hat{q},r_{c}),\tilde{u})=(-2,2)</math>. The picture is this:
<image location="center" width="150px" src="Nomansland.png">
</image>
</p>
<p>

where the term <it> "No man's land" </it>&nbsp; refers to the part of the total region of uncertainty that is outside the region <math>\ \displaystyle \mathcal{U}(\hat{\alpha}(q,r_{c})+\varepsilon,\tilde{u}) \ </math>.</p>
<p>

Note that in this case the robustness of decision <math>\ \displaystyle \hat{q} \ </math> is based on its (worst-case) performance over no more than a minuscule part of the total region of uncertainty that is an immediate neighborhood of the estimate <math>\ \displaystyle \tilde{u} \ </math>. Since usually info-gap's total region of uncertainty is unbounded, this illustration represents a <it>usual</it> &nbsp; case rather than an exception. </p>
<p>

The thing to note then is that info-gap's robustness/opportuneness are <b>by definition local properties.</b>  As such they cannot assess the performance of decisions over the total region of uncertainty. For this reason it is not clear how Info-Gap's Robustness/Opportuneness models can provide a meaningful/sound/useful basis for decision under sever uncertainty where the estimate is poor and is likely to be substantially wrong.</p>
<p>

This crucial issue is addressed in subsequent sections of this article.</p>

</ss1>
</sec>
<sec>
<st>
 Some applications </st>
<p>

Info-gap theory has generated a lot of literature. Info-gap theory has been studied or applied in a range of applications including engineering </p>
<p>

<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%225%22])">5</ref>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%227%22])">7</ref>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%228%22])">8</ref>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%229%22])">9</ref>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2210%22])">10</ref>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2211%22])">11</ref>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2212%22])">12</ref>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2213%22])">13</ref>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2214%22])">14</ref>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2215%22])">15</ref>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2216%22])">16</ref>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2217%22])">17</ref>,
biological conservation
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2218%22])">18</ref>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2219%22])">19</ref> 
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2220%22])">20</ref>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2221%22])">21</ref>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2222%22])">22</ref>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2223%22])">23</ref>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2224%22])">24</ref>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2225%22])">25</ref>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2226%22])">26</ref>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2227%22])">27</ref>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2228%22])">28</ref>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2229%22])">29</ref>, theoretical biology  
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2230%22])">30</ref>, homeland security 
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2231%22])">31</ref>, economics 
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2232%22])">32</ref>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2233%22])">33</ref>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2234%22])">34</ref>, 
project management 
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2235%22])">35</ref>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2236%22])">36</ref>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2237%22])">37</ref>
and statistics 
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2238%22])">38</ref>. Foundational issues related to info-gap theory have also been studied
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2239%22])">39</ref>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2240%22])">40</ref>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2241%22])">41</ref>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2242%22])">42</ref>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2243%22])">43</ref>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2244%22])">44</ref>.</p>
<p>

The remainder of this section describes in a little more detail the kind of uncertainties addressed by info-gap theory. Although many published works are mentioned below, no attempt is made here to present insights from these papers. The emphasis is not upon elucidation of the  concepts of info-gap theory, but upon the context where it is used and the goals.</p>
<p>

A typical engineering application is the vibration analysis of a cracked beam, where the location, size, shape and orientation of the crack is unknown and greatly influence the vibration dynamics.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%228%22])">8</ref> Very little is usually known about these spatial and geometrical uncertainties. The info-gap analysis allows one to model these uncertainties, and to determine the degree of robustness - to these uncertainties - of properties such as vibration amplitude, natural frequencies, and natural modes of vibration. Another example is the structural design of a building subject to uncertain loads such as from wind or earthquakes.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%227%22])">7</ref> <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%229%22])">9</ref> The response of the structure depends strongly on the spatial and temporal distribution of the loads. However, storms and earthquakes are highly idiosyncratic events, and the interaction between the event and the structure involves very site-specific mechanical properties which are rarely known. The info-gap analysis enables the design of the structure to enhance structural immunity against uncertain deviations from design-base or estimated worst-case loads. Another engineering application involves the design of a neural net for detecting faults in a mechanical system, based on real-time measurements. A major difficulty is that faults are highly idiosyncratic, so that training data for the neural net will tend to differ substantially from data obtained from real-time faults after the net has been trained. The info-gap robustness strategy enables one to design the neural net to be robust to the disparity between training data and future real events.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2210%22])">10</ref> <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2212%22])">12</ref></p>
<p>

Biological systems are vastly more complex and subtle than our best models, so the conservation biologist faces substantial info-gaps in using biological models. For instance, Levy <it>et al</it> <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2218%22])">18</ref> use an info-gap robust-satisficing "methodology for identifying management alternatives that are robust to environmental uncertainty, but nonetheless meet specified socio-economic and environmental goals." They use info-gap robustness curves to select among management options for spruce-budworm populations in Eastern Canada. <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<biologist wordnetid="109855630" confidence="0.8">
<intellectual wordnetid="109621545" confidence="0.8">
<alumnus wordnetid="109786338" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<ecologist wordnetid="110043163" confidence="0.8">
<scholar wordnetid="110557854" confidence="0.8">
<link xlink:type="simple" xlink:href="../497/17630497.xml">
Burgman</link></scholar>
</ecologist>
</scientist>
</causal_agent>
</alumnus>
</intellectual>
</biologist>
</person>
</physical_entity>

<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2245%22])">45</ref> uses the fact that the robustness curves of different alternatives can intersect, to illustrate a change in preference between conservation strategies for the orange-bellied parrot. </p>
<p>

Project management is another area where info-gap uncertainty is common. The project manager often has very limited information about the duration and cost of some of the tasks in the project, and info-gap robustness can assist in project planning and integration.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2236%22])">36</ref> Financial economics is another area where the future is fraught with surprises, which may be either pernicious or propitious. Info-gap robustness and opportuness analyses can assist in portfolio design, credit rationing, and other applications.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2232%22])">32</ref></p>

<ss1>
<st>
Disclaimer and Summary</st>
<p>

The robustness and opportuneness functions can inform decision. For example, a change in decision increasing robustness may increase or decrease opportuneness. From a subjective stance, robustness and opportuneness both trade-off against aspiration for outcome: robustness and opportuneness deteriorate as the decision maker's aspirations increase. Robustness is zero for model-best anticipated outcomes. Robustness curves for alternative decisions may cross as a function of aspiration, implying reversal of preference. </p>
<p>

Various theorems identify conditions where larger info-gap robustness implies larger probability of success, regardless of the underlying probability distribution. However, these conditions are technical, and do not translate into any common-sense, verbal recommendations, placing info-gap theory entirely in the hands of experts.</p>

</ss1>
</sec>
<sec>
<st>
 Maximin/Minimin: playing robustness/opportuneness games with Nature </st>

<p>

For well over sixty years now  <scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../430/1239430.xml">
Wald</link></scientist>
's  <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link>  model has figured in classical <link xlink:type="simple" xlink:href="../216/446216.xml">
decision theory</link> and related areas Ã± such as <link xlink:type="simple" xlink:href="../682/8232682.xml">
robust optimization</link> - as the foremost non-probabilistic paradigm for modeling and treatment of severe uncertainty.  </p>
<p>

Info-gap is propounded (eg. Ben-Haim 2001, 2006) as a new non-probabilistic theory that is radically different from all current decision theories for decision under uncertainty. So, it is imperative to examine in this discussion  in what way, if any, is info-gap's robustness model radically different from <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link>. For one thing, there is a well-established assessment of the utility of <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link>. For example, Berger (Chapter 5)<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2246%22])">46</ref> suggests that even in situations where no prior information is available (a best case for <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link>), <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> can lead to bad decision rules and be hard to implement. He recommends <link xlink:type="simple" xlink:href="../571/49571.xml">
Bayesian methodology</link>. And as indicated above,</p>
<p>

It should also be remarked that the minimax principle even if it is applicable leads to an extremely conservative policy.
Tintner (1952, p. 25)<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2247%22])">47</ref></p>

<p>

However, quite apart from the ramifications that establishing this point might have for the utility of info-gaps' robustness model, the reason that it behooves us to clarify the relationship between info-gap and <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> is the centrality of the latter in decision theory.  After all, this is a major classical decision methodology.  So, any theory claiming to furnish a new non-probabilistic methodology for decision under severe uncertainty would be expected to be compared to this stalwart of decision theory.  And yet, not only is a comparison of info-gap's robustness model to <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> absent from the three books expounding info-gap  (Ben-Haim 1996, 2001, 2006), <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> is not even mentioned in them as the major decision theoretic methodology for severe uncertainty that it is. </p>
<p>

Elsewhere in the info-gap literature, one can find discussions dealing with similarities and differences between these two paradigms, as well as discussions on the relationship between info-gap and worst-case analysis, <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref> <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2215%22])">15</ref> <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2234%22])">34</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2236%22])">36</ref> <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2248%22])">48</ref> <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2249%22])">49</ref>. However, the general impression is that the intimate connection between these two paradigms has not been identified.  Indeed, the opposite is argued. For instance, Ben-Haim (2005<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2234%22])">34</ref>) argues that info-gap's robustness model is similar to  <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> but, is not a <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> model.</p>
<p>

The following quote eloquently expresses Ben-Haim's assessment of info-gap's relationship to Maximin and it provides ample motivation for the analysis that follows.
We note that robust reliability is emphatically <it> not </it> a worst-case analysis. In classical worst-case min-max analysis the designer minimizes the impact of the maximally damaging case. But an info-gap model of uncertainty is an unbounded family of nested sets: <math> \ \displaystyle \mathcal{U}(\alpha,\tilde{u}) \ </math>, for all  <math>\ \displaystyle \alpha\ge 0 \ </math>. Consequently, there is no worst case: any adverse occurrence is less damaging than some other more extreme event occurring at a larger value of <math>\ \displaystyle \alpha \ </math>. What Eq. (1) expresses is the greatest level of uncertainty consistent with no-failure. When the designer chooses q to maximize  <math>\ \displaystyle \hat{\alpha}(q, r_{c}) \ </math> he is maximizing his immunity to an unbounded ambient uncertainty. The closest this comes to "min-maxing" is that the design is chosen so that "bad" events (causing reward <math>\ \displaystyle  R\ </math> less than <math>\ \displaystyle  r_{c}\ </math>) occur as "far away" as possible (beyond a maximized value of  <math>\ \displaystyle \hat{\alpha} \ </math>).
Ben-Haim , 1999, pp. 271-2<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2250%22])">50</ref></p>

<p>

The point to note here is that this statement misses the fact that the horizon of uncertainty <math>\ \displaystyle \alpha \ </math> is bounded above (implicitly) by the performance requirement</p>
<p>

<math> r_{c} \le R(q,u),\forall u\in \mathcal{U}(\alpha,\tilde{u})</math> </p>
<p>

and that info-gap conducts its worst-case analysis -- one analysis at a time for a given <math>\ \displaystyle \alpha \ge 0 \ </math>&nbsp; -- within each of the regions of uncertainty <math>\displaystyle \ \mathcal{U}(\alpha,\tilde{u}), \alpha\ge 0 \ </math> .</p>
<p>

In short, given the discussions in the info-gap literature on this issue, it is obvious that the kinship between info-gap's robustness model and <link xlink:type="simple" xlink:href="../430/1239430.xml">
Wald's</link> <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> model, as well as info-gap's kinship with other models of classical decision theory must be brought to light. So,  the  objective in this section is to place info-gap's robustness and opportuneness models in their proper context, namely within the wider frameworks of classical <link xlink:type="simple" xlink:href="../216/446216.xml">
decision theory</link> and <link xlink:type="simple" xlink:href="../682/8232682.xml">
robust optimization</link>.</p>
<p>

The discussion is based on the classical decision theoretic perspective outlined by Sniedovich (2007<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2251%22])">51</ref>) and on standard texts in this area (eg. Resnik 1987<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2252%22])">52</ref>, French 1988<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2253%22])">53</ref>).</p>

<p>

Certain parts of the exposition that follows have a mathematical slant.  This is unavoidable because info-gap's models are mathematical. </p>


<ss1>
<st>
 Generic models </st>

<p>

The basic conceptual framework that classical decision theory provides for dealing with uncertainty is that of a two-player game.  The two players are the decision maker (DM) and <b>Nature,</b> where Nature represents uncertainty. More specifically, Nature represents the DM's attitude towards uncertainty and risk.</p>
<p>

Note that a clear distinction is made in this regard between a <b>pessimistic</b> decision maker and an <b>optimistic</b> decision maker,  namely between a <b>worst-case</b> attitude and a <b>best-case</b> attitude. A pessimistic decision maker assumes that Nature plays <b>against</b> him whereas an optimistic decision maker assumes that Nature plays <b>with</b> him.</p>
<p>

To express these intuitive notions mathematically, classical <link xlink:type="simple" xlink:href="../216/446216.xml">
decision theory</link> uses a simple model consisting of the following three constructs:</p>
<p>

<list>
<entry level="1" type="bullet">

 A set <math>\ \displaystyle D</math> representing the <it>decision space</it> available to the DM.</entry>
<entry level="1" type="bullet">

 A set of sets <math>\ \displaystyle \{S(d): d\in D\}\ </math> representing <it>state spaces</it> associated with the decisions in  <math>\ \displaystyle D </math>.</entry>
<entry level="1" type="bullet">

 A function <math>\ \displaystyle g=g(d,s)</math> stipulating the <it>outcomes</it> generated by the  decision-state pairs <math>\ \displaystyle (d,s)\ </math>.</entry>
</list>
</p>

<p>

The function <math>\ \displaystyle g \ </math> is called <it>objective function, payoff function, return function, cost function</it>  etc. </p>
<p>

The decision-making process (game) defined by these objects consists of three steps:</p>
<p>

<list>
<entry level="1" type="bullet">

 <b>Step 1:</b> The DM selects a decision  <math>\ \displaystyle d\in D \ </math>.</entry>
<entry level="1" type="bullet">

 <b>Step 2:</b> In response, given <math>\ \displaystyle d\ </math>,  Nature  selects a state <math>\ \displaystyle s\in S(d)\ </math>.</entry>
<entry level="1" type="bullet">

 <b>Step 3:</b> The outcome <math>\ \displaystyle g(d,s)</math> is alloted to DM.</entry>
</list>
</p>

<p>

Note that in contrast to games considered in classical <link xlink:type="simple" xlink:href="../924/11924.xml">
game theory</link>, here the first player (DM) moves first so that the second player (Nature) knows what decision was selected by the first player prior to selecting her decision. Thus, the conceptual and technical complications regrding the existence of <equilibrium wordnetid="113934900" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../337/45337.xml">
Nash equilibrium point</link></equilibrium>
 are not pertinent here. Nature is not an independent player, it is a conceptual device describing the DM's attitude towards uncertainty and risk.   </p>
<p>

At first sight, the simplicity of this framework may strike one as naive.  Yet, as attested by the variety of specific instances that it encompasses it is rich in possibilities, flexible, and versatile. For the purposes of this discussion it suffices to consider the following classical generic setup:</p>
<p>

<math>
\begin{array}{cccc}
z^{*}= &amp; \stackrel{DM}{\mathop{Opt}}&amp;\stackrel{Nature}{\mathop{opt}}\quad &amp; g(d,s)\\[-0.05in]
&amp; d\in D &amp; s\in S(d) &amp;
\end{array}
</math></p>

<p>

where <math>\ \displaystyle \mathop{Opt} \ </math> and <math> \displaystyle \mathop{opt}\ </math> represent the DM's and Nature's optimality criteria, respectively, that is, each is equal to either <math>\ \displaystyle \max\ </math>  or <math>\ \displaystyle \min\ </math>.</p>
<p>

If <math>\ \displaystyle \mathop{Opt} = \mathop{opt}\ </math> then the game is <b>cooperative,</b> and if <math>\ \displaystyle \mathop{Opt} \neq \mathop{opt}\ </math> then the game is <b>non-cooperative.</b>  Thus, this format represents four cases: two non-cooperative games (Maximin and Minimax) and two cooperative games (Minimin, and Maximax). The respective formulations are as follows:</p>
<p>

<math>
\begin{array}{c||c}
\textit{Worst-Case\ Pessimism} &amp; \textit{Best-Case\ Optimism}\\
\hline
Maximin \ \ \ \ \ \ \ \ \ \ \ Minimax &amp; Minimin \ \ \ \ \ \ \ \ \ \ \ \ \ Maximax\\
\displaystyle \max_{d\in D}\,\min_{s\in S(d)}\,g(d,s) \ \ \  \displaystyle \min_{d\in D}\,\max_{s\in S(d)}\,g(d,s)  &amp; \displaystyle \min_{d\in D}\,\min_{s\in S(d)}\,g(d,s) \ \ \ \displaystyle \max_{d\in D}\,\max_{s\in S(d)}\,g(d,s)
\end{array}
</math></p>

<p>

Each case is specified by a pair of optimality criteria employed by DM and Nature. For example, <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> depicts a situation where DM strives to maximize the outcome and Nature strives to minimize it. Similarly, the Minimin paradigm represents situations where both DM and Nature are striving to in minimize the outcome.</p>
<p>

Of particular interest to this discussion are the Maximin and Minimin paradigms because they subsume info-gap's robustness and opportuneness models, respectively. So, here they are:</p>
<p>

<table>
<row valign="top">
<col>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Maximin Game: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</col>
<col>
<math>\ \displaystyle \max_{d\in D}\,\min_{s\in S(d)}\,g(d,s)</math></col>
</row>
</table>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <b>Step 1:</b> The DM selects a decision  <math>\ \displaystyle d\in D \ </math> with a view to maximize the outcome <math>\ \displaystyle g(d,s) \ </math>.</entry>
<entry level="1" type="bullet">

 <b>Step 2:</b> In response, given <math>\ \displaystyle d\ </math>,  Nature  selects a state in <math>\ \displaystyle S(d)\ </math> that minimizes <math> \ \displaystyle g(d,s) \ </math> over <math>\ \displaystyle S(d) \ </math>.</entry>
<entry level="1" type="bullet">

 <b>Step 3:</b> The outcome <math>\ \displaystyle g(d,s)</math> is alloted to DM.</entry>
</list>
</p>


<p>

<table>
<row valign="top">
<col>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Minimin Game: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</col>
<col>
<math>\ \displaystyle \min_{d\in D}\,\min_{s\in S(d)}\,g(d,s)</math></col>
</row>
</table>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <b>Step 1:</b> The DM selects a decision  <math>\ \displaystyle d\in D \ </math> with a view to minimizes the outcome <math>\ \displaystyle g(d,s) \ </math>.</entry>
<entry level="1" type="bullet">

 <b>Step 2:</b> In response, given <math>\ \displaystyle d\ </math>,  Nature  selects a state in <math>\ \displaystyle S(d)\ </math> that minimizes <math> \ \displaystyle g(d,s) \ </math> over <math>\ \displaystyle S(d) \ </math>.</entry>
<entry level="1" type="bullet">

 <b>Step 3:</b> The outcome <math>\ \displaystyle g(d,s)</math> is alloted to DM.</entry>
</list>
</p>

<p>

With this in mind,  consider now info-gap's robustness and opportuneness models.</p>

</ss1>
<ss1>
<st>
 Info-gap's robustness model </st>

<p>

From a classical decision theoretic point of view info-gap's robustness model is a game between the DM and Nature, where the DM selects the value of <math>\ \displaystyle \alpha \ </math> (aiming for the largest possible) whereas Nature selects the worst value of <math>\ \displaystyle  u \ </math> in <math>\ \displaystyle \mathcal{U}(\alpha,\tilde{u}) \ </math>. In this context the worst value of <math>\ \displaystyle u \ </math> pertaining to a given <math>\ \displaystyle (q,\alpha) \ </math> pair  is a <math>\ \displaystyle  u\in \mathcal{U}(\alpha,\tilde{u}) \ </math> that violates the performance requirement <math>\ \displaystyle r_{c} \le R(q,u) \ </math>. This is achieved by minimizing <math>\ \displaystyle R(q,u)\ </math> over <math>\ \displaystyle \mathcal{U}(\alpha,\tilde{u})\ </math>.  </p>
<p>

There are various ways to incorporate the DM's objective and Nature's antagonistic response in a single outcome. For instance, one can use the following characteristic function for this purpose:</p>
<p>

<math>
\varphi(q,\alpha,u):=\begin{cases}
\quad \alpha &amp;, \ \ r_{c} \le R(q,u) \\
-\infty &amp;, \ \ r_{c} &amp;gt; R(q,u)
\end{cases}  \ , \  q\in \mathcal{Q}, \alpha\ge 0, u\in \mathcal{U}(\alpha,\tilde{u})
</math></p>

<p>

Note that, as desired, for any triplet <math>\ \ (q,\alpha,u)\ </math> of interest we have</p>
<p>

<math>
r_{c} \le R(q,u) \ \ \ \longleftrightarrow \ \ \ \alpha \le \varphi(q,\alpha,u)
</math></p>

<p>

hence from the DM's point of view satisficing the performance constraint is equivalent to maximizing &nbsp; <math>\ \displaystyle \varphi(q,\alpha,u)\ </math>.</p>
<p>

In short,  </p>
<p>

<table>
<row valign="top">
<col>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Info-gap's Maximin Robustness Game for decision <math>\ \displaystyle q \ </math>: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</col>
<col>
<math>\ \displaystyle \hat{\alpha}(q,r_{c}):=\max_{\alpha \ge 0}\,\min_{u\in \mathcal{U}(\alpha,\tilde{u})}\,\varphi(q,\alpha,u)</math></col>
</row>
</table>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <b>Step 1:</b> The DM selects an horizon of uncertainty  <math>\ \displaystyle \alpha\ge 0 \ </math> with a view to maximize the outcome <math>\ \displaystyle \varphi(q,\alpha,u) \ </math>.</entry>
<entry level="1" type="bullet">

 <b>Step 2:</b> In response, given <math>\ \displaystyle \alpha \ </math>, Nature  selects a <math>\ \displaystyle u \in \mathcal{U}(\alpha,\tilde{u})\ </math> that minimizes <math> \ \displaystyle \varphi(q,\alpha,u) \ </math> over <math>\ \displaystyle \mathcal{U}(\alpha,\tilde{u}) \ </math>.</entry>
<entry level="1" type="bullet">

 <b>Step 3:</b> The outcome <math>\ \displaystyle \varphi(q,\alpha,u)</math> is alloted to DM.</entry>
</list>
</p>

<p>

Clearly, the DM's optimal alternative is to select the largest value of <math>\ \displaystyle \alpha \ </math> such that the worst <math>\ \displaystyle u\in \mathcal{U}(\alpha,\tilde{u})\ </math> satisfies the performance requirement.</p>

</ss1>
<ss1>
<st>
 Maximin Theorem </st>

<p>

As shown in Sniedovich (2007) , Info-gap's robustness model is a simple instance of <link xlink:type="simple" xlink:href="../645/1688645.xml">
Wald's</link> <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> model. Specifically, 
<math>
{\hat{\alpha}}(q, {r_{c}}) = \max \left \{ \alpha: \  {r_{\rm c}} \le  \min_{u \in \mathcal{U}(\alpha, \tilde{u})} R(q,u) \right \} = \max_{\alpha \ge 0} \min_{u \in \mathcal{U}(\alpha,\tilde{u})} \varphi(q,\alpha,u) \quad \quad \Box
</math></p>

</ss1>
<ss1>
<st>
 Info-gap's opportuneness model </st>

<p>

By the same token,  info-gap's opportuneness model is a simple instance of the generic Minimin model. That is,
<math>
{\hat{\beta}}(q, {r_{c}}) = \min \left \{ \alpha: \  {r_{c}} \le  \max_{u \in \mathcal{U}(\alpha, \tilde{u})} R(q,u) \right \} = \min_{\alpha \ge 0} \min_{u \in \mathcal{U}(\alpha,\tilde{u})} \psi(q,\alpha,u)
</math>
where
<math>
\psi(q,\alpha,u) = \left\{\begin{matrix} \alpha &amp;,&amp; {r_{c}} \le  R(q,u)\\ \infty &amp;,&amp;{r_{ c}} &amp;gt; R(q,u) \end{matrix}\right. \ , \ \alpha \ge 0, u \in \mathcal{U}(\alpha,\tilde{u})
</math></p>
<p>

observing that, as desired, for any triplet <math>\ \ (q,\alpha,u)\ </math> of interest we have</p>
<p>

<math>
r_{w} \le R(q,u) \ \ \ \longleftrightarrow \ \ \ \alpha \ge \psi(q,\alpha,u)
</math></p>
<p>

hence, for a given pair <math>\ \displaystyle (q,\alpha)\ </math>, the DM would satisfy the performance requirement via  minimizing the outcome <math>\ \displaystyle \psi(q,\alpha,u)\ </math> over <math>\ \displaystyle \mathcal{U}(\alpha,\tilde{u}) \ </math>. Nature's behavior is a reflection of her sympathetic stance here.</p>
<p>

<b>Remark:</b> This attitude towards risk and uncertainty which assumes that  Nature will play <it> with us,</it>&nbsp; is rather naive. As noted by Resnik (1987, p. 32<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2252%22])">52</ref>) "... But that rule surely would have few adherence...". Nevetheless it is often used in combination with the <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> rule in the formulation of <link xlink:type="simple" xlink:href="../658/10326658.xml">
Hurwicz</link>'s <it> optimism-pessimisim </it>&nbsp; rule (Resnik 1987<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2252%22])">52</ref>, French 1988<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2253%22])">53</ref>) with a view to mitigate the extreme conservatism of <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link>.    </p>

</ss1>
<ss1>
<st>
 Mathematical programming formulations </st>

<p>

To bring out more forcefully that info-gap's robustness model is an instance of the generic <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> model, and info-gap's opportuneness model an instance of the generic Minimin model, it is instructive to examine the equivalent so called <it>Mathematical Programming </it> (MP) formats of these generic models (Ecker and Kupferschmid<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2254%22])">54</ref>, 1988, pp. 24-25; Thie 1988<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2255%22])">55</ref> pp. 314-317;  Kouvelis and Yu,  1997, p. 27):</p>
<p>

<math>
\begin{array}{c|c|c}
\textit{Model} &amp; \textit{Classical\  Format} &amp;  \textit{MP\ Format}  \\
\hline 
\textit{Maximin:} &amp; \displaystyle \max_{d\in D}\ \min_{s\in S(d)}\ g(d,s) &amp;
\displaystyle \max_{d\in D,\alpha\in \mathbb{R}}\{\alpha: \alpha \le \min_{s\in S(d)} g(d,s)\} \\
\textit{Minimin:} &amp; \displaystyle \min_{d\in D}\ \min_{s\in S(d)}\ g(d,s) &amp;
\displaystyle \min_{d\in D,\alpha\in \mathbb{R}}\{\alpha: \alpha \ge \min_{s\in S(d)} g(d,s)\}
\end{array}
</math></p>

<p>

Thus, in the case of info-gap we have</p>
<p>

<math>
\begin{array}{c|c|c|c}
\textit{Model} &amp; \textit{Info-Gap\ Format} &amp; \textit{MP\ Format} &amp;  \textit{Classical\ Format}  \\
\hline 
\textit{Robustness} &amp;\displaystyle \max\{\alpha: r_{c}\le \min_{u\in \mathcal{U}(\alpha,\tilde{u})} R(q,u)\}  &amp;\displaystyle  \displaystyle \max\{\alpha: \alpha \le \min_{u\in \mathcal{U}(\alpha,\tilde{u})}\varphi(q,\alpha,u)\} &amp; \displaystyle \max_{\alpha\ge 0}\ \min_{u\in \mathcal{U}(\alpha,\tilde{u})}\ \varphi(q,\alpha,u) \\
\textit{Opportuneness} &amp;\displaystyle \min\{\alpha: r_{c}\le \max_{u\in \mathcal{U}(\alpha,\tilde{u})} R(q,u)\}  &amp;\displaystyle  \displaystyle \min\{\alpha: \alpha \ge \min_{u\in \mathcal{U}(\alpha,\tilde{u})}\psi(q,\alpha,u)\} &amp; \displaystyle \min_{\alpha\ge 0}\ \min_{u\in \mathcal{U}(\alpha,\tilde{u})}\ \psi(q,\alpha,u)
\end{array}
</math></p>

<p>

To verify the equivalence between info-gap's formats and the respective decision theoretic formats, recall that, by construction, for any triplet <math>\ \displaystyle (q,\alpha,u)\ </math> of interest we have</p>
<p>

<math>
\alpha \le \varphi(q,\alpha,u)\ \ \  \longleftrightarrow \ \ \  r_{c} \le R(q,u) </math>
<math>
\alpha \ge \psi(q,\alpha,u) \ \ \ \longleftrightarrow \ \ \ r_{w} \le R(q,u)
</math></p>

<p>

This means that in the case of robustness/<link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link>, an antagonistic Nature will (effectively) minimize <math>\ \displaystyle R(q,u) \ </math> by minimizing  <math>\ \displaystyle \varphi(q,\alpha,u) \ </math> whereas in the case of  opportuneness/Minimin a sympathetic Nature will (effectively) maximize <math>\ \displaystyle R(q,u) \ </math> by minimizing <math>\ \displaystyle \psi(q,\alpha,u) \ </math>.</p>

</ss1>
<ss1>
<st>
 Summary </st>

<p>

Info-gap's robustness analysis stipulates that given a pair <math>\ \displaystyle (q,\alpha)\ </math>, the worst element of <math>\ \displaystyle \mathcal{U}(\alpha,\tilde{u})\ </math> is realized. This of course is a typical <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> analysis. In the parlance of classical <link xlink:type="simple" xlink:href="../216/446216.xml">
decision theory</link>:</p>
<p>

The <b>Robustness</b> of decision <math>\ \displaystyle q \ </math> is the largest horizon of uncertainty, <math>\ \displaystyle \alpha \ </math>,  such that the worst value of <math>\ \displaystyle u \ </math> in <math>\ \displaystyle \mathcal{U}(\alpha,\tilde{u}) \ </math> satisfies the performance requirement <math>\ \displaystyle r_{c} \le R(q,u) \ </math>.</p>

<p>

Similarly, info-gap's opportuneness analysis stipulates that given a pair <math>\ \displaystyle (q,\alpha)\ </math>, the best element of <math>\ \displaystyle \mathcal{U}(\alpha,\tilde{u})\ </math> is realized. This of course is a typical Minimin analysis. In the parlance of classical <link xlink:type="simple" xlink:href="../216/446216.xml">
decision theory</link>:</p>
<p>

The <b>Opportuneness</b> of decision <math>\ \displaystyle q \ </math>  is the smallest horizon of uncertainty, <math>\ \displaystyle \alpha \ </math> ,  such that the best value of <math>\ \displaystyle u \ </math> in <math>\ \displaystyle \mathcal{U}(\alpha,\tilde{u}) \ </math> satisfies the performance requirement <math>\ \displaystyle r_{w} \le R(q,u) \ </math>.</p>

<p>

The mathematical transliterations of these concepts are straightforward, resulting in typical Maximin/Minimin models, respectively.</p>
<p>

Far from being restrictive, the generic Maximin/Minimin models' lean structure is a blessing in disguise. The main point here is that the abstract character of the three basic constructs of the generic models</p>
<p>

<list>
<entry level="1" type="bullet">

 Decision</entry>
<entry level="1" type="bullet">

 State</entry>
<entry level="1" type="bullet">

 Outcome</entry>
</list>
</p>

<p>

in effect allows for great flexibility in modeling.</p>
<p>

A more detailed analysis is therefore required to bring out the full force of the relationship between info-gap and generic classical decision theoretic models. See <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Notes+on+the+art+of+math+modeling%22])">
<list>
<entry level="1" type="number">

Notes on the art of math modeling</entry>
</list>
</link>.</p>

</ss1>
</sec>
<sec>
<st>
 Criticism </st>

<p>

Sniedovich  has challenged the validity of info-gap theory for making decisions under severe uncertainty. He questions the effectiveness of info-gap theory in situations where the best estimate <math>\displaystyle \tilde{u}</math> is a poor indication of the true value of <math>\displaystyle u</math>. Sniedovich notes that the info-gap robustness function is "local" to the region around <math>\displaystyle \tilde{u}</math>, where <math>\displaystyle \tilde{u}</math> is likely to be substantially in error. He concludes that therefore the info-gap robustness function is an unreliable assessment of immunity to error.</p>
<p>

The following is a pictorial summary of Sniedovich's (2007) discussion on local vs global robustness. For illustrative purposes it is cast here as a <it>Treasure Hunt.</it> It shows how the elements of info-gap's robustness model relate to one another and how the severe uncertainty is treated in the model.</p>


<p>

<table width="100%" cellpadding="5" bborder="0" cellspacing="0">
<row align="left" vvalign="top">
<col style="border-bottom:1px solid skyblue" width="145px" valign="top">
<image width="150px" src="Australia_plain.png">
<caption>

Australia_plain.png
</caption>
</image>
</col>
<col style="border-bottom:1px solid skyblue" width="280px" valign="top">
(1) You are in charge of a treasure hunt on a large island   somewhere in the Asia/Pacific region. You consult a portfolio of search strategies.  You need to decide which strategy would be best for this particular expedition.</col>
<col style="border-left:1px solid skyblue;border-bottom:1px solid skyblue" width="145px" valign="top">
<image width="150px" src="Australia_q.png">
<caption>

 Australia_q.png
</caption>
</image>
</col>
<col style="border-bottom:1px solid skyblue" width="280px" valign="top">
(2) The difficulty is that the treasure's exact location on the island is unknown.  There is a severe gap between what you need to know -- the true location of the treasure -- and what you actually know -- a poor  estimate of the true location.</col>
<col style="border-left:1px solid skyblue;border-bottom:1px solid skyblue;" width="145px" valign="top">
<image width="150px" src="Australia_dot.png">
<caption>

 Australia_dot.png
</caption>
</image>
</col>
<col style="border-bottom:1px solid skyblue" width="280px" valign="top">
(3) Somehow you compute an estimate of the true location of the treasure. Since we are dealing here with severe uncertainty,  we assume -- methodologically speaking -- that this estimate is a poor indication of the true location and is likely to be substantially wrong.</col>
</row>
<row align="left" valign="top">
<col width="145px" valign="top" sstyle="border-left:1px solid skyblue" vvalign="top">
<image width="150px" src="Australia_regions.png">
<caption>

Australia_regions.png
</caption>
</image>
</col>
<col width="280px" valign="top">
(4) To determine the robustness of a given strategy, you conduct a local worst-case analysis in the immediate neighborhood of the poor estimate. Specifically,  you compute the largest safe deviation from the poor estimate that does not violate the performance requirement.</col>
<col style="border-left:1px solid skyblue" width="145px" valign="top" vvalign="top">
<image width="150px" src="Australia_max.png">
<caption>

Australia_max.png
</caption>
</image>
</col>
<col width="280px" valign="top">
(5) You compute the robustness of each search strategy in your portfolio  and you select the one whose robustness is the largest.</col>
<col colspan="2" style="border-left:1px solid skyblue" align="left" valign="top">
(6) To remind yourself and the financial backers of the expedition that this analysis is subject to severe uncertainty in the true location of the treasure, it is important -- methodologically speaking -- to display the <b>true location</b> on the map. Of course, you do not know the true location. But given the severity of the uncertainty, you place it at some distance from the poor estimate. The more severe the uncertainty, the greater should the distance (gap) between the true location and the estimate be.</col>
</row>
<row>
<col style="border-top:1px solid skyblue" width="145px" valign="top" vvalign="top">
<image width="150px" src="Australia_true.png">
<caption>

Australia_true.png
</caption>
</image>
</col>
<col colspan="5" style="border-top:1px solid skyblue" align="left" valign="top">
<b>Epilogue:</b><p>

According to Sniedovich (2007) this is an important reminder of the central issue in decision-making under severe uncertainty. The estimate we have is a poor indication of the true value of the parameter of interest and is likely to be substantially wrong. Therefore, in the case of info-gap it is important to show the gap on the map by displaying the true value of <math>\ \displaystyle u \ </math> somewhere in the region of uncertainty.</p>
<p>

The small red <math>\ \clubsuit\ </math> represents the true (unknown) location of the treasure.</p>
</col>
</row>
</table>
</p>



<p>

<b>In summary:</b>
Info-gap's robustness model is a mathematical representation of  a local worst-case analysis in the neighborhood of a given estimate of the true value of the parameter of interest. Under severe uncertainty the estimate is assumed to be a poor indication of the true value of the parameter and is likely to be substantially wrong. </p>
<p>

The fundamental question therefore is: Given the </p>
<p>

<list>
<entry level="1" type="bullet">

Severity of the uncertainty</entry>
<entry level="1" type="bullet">

Local nature of the analysis</entry>
<entry level="1" type="bullet">

Poor quality of the estimate</entry>
</list>
</p>
<p>

how meaningful and useful are the results generated by the analysis, and how sound is the methodology as a whole?</p>
<p>

More on this criticism can be found on <weblink xlink:type="simple" xlink:href="http://www.moshe-online.com/infogap">
Sniedovich's web site.</weblink></p>

</sec>
<sec>
<st>
 Discussion </st>


<ss2>
<st>
Satisficing and bounded rationality </st>
<p>

It is correct that the info-gap robustness function is local, and has restricted quantitative value in some cases. However, a major purpose of decision analysis is to provide focus for subjective judgments. That is, regardless of the formal analysis, a framework for discussion is provided. Without entering into any particular framework, or characteristics of frameworks in general, discussion follows about proposals for such frameworks.</p>
<p>

Simon <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2256%22])">56</ref> 
introduced the idea of <link xlink:type="simple" xlink:href="../400/70400.xml">
bounded rationality</link>. Limitations on knowledge, understanding, and computational capability constrain the ability of decision makers to identify optimal choices. Simon advocated <link xlink:type="simple" xlink:href="../401/70401.xml">
satisficing</link> rather than optimizing: seeking adequate (rather than optimal) outcomes given available resources. Schwartz
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2257%22])">57</ref>,
Conlisk
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2258%22])">58</ref>
and others discuss extensive evidence for the phenomenon of bounded rationality among human decision makers, as well as for the advantages of satisficing when knowledge and understanding are deficient. The info-gap robustness function provides a means of implementing a satisficing strategy under bounded rationality. For instance, in discussing bounded rationality and satisficing in conservation and environmental management, Burgman notes that "Info-gap theory ... can function sensibly when there are 'severe' knowledge gaps." The info-gap robustness and opportuneness functions provide "a formal framework to explore the kinds of speculations that occur intuitively when examining decision options."
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2259%22])">59</ref> Burgman then proceeds to develop an info-gap robust-satisficing strategy for protecting the endangered orange-bellied parrot. Similarly, Vinot, Cogan and Cipolla <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2260%22])">60</ref> discuss engineering design and note that "the downside of a model-based analysis lies in the knowledge that the model behavior is only an approximation to the real system behavior. Hence the question of the honest designer: how sensitive is my measure of design success to uncertainties in my system representation? ... It is evident that if model-based analysis is to be used with any level of confidence then ... [one must] attempt to satisfy an acceptable sub-optimal level of performance while remaining maximally robust to the system uncertainties."<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2261%22])">61</ref> They proceed to develop an info-gap robust-satisficing design procedure for an aerospace application.</p>

</ss2>
<ss1>
<st>
Alternatives to info-gap</st>
<p>
   
Of course, decision in the face of uncertainty is nothing new, and attempts to deal with it have a long history. A number of authors have noted and discussed similarities and differences between info-gap robustness and <link xlink:type="simple" xlink:href="../589/19589.xml">
minimax</link> or worst-case methods
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref> <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2215%22])">15</ref> <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2234%22])">34</ref> <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2236%22])">36</ref>   
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2262%22])">62</ref>   
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2263%22])">63</ref>.   
Sniedovich <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2264%22])">64</ref>   
has demonstrated formally that the info-gap robustness function can be represented as a minimax optimization, and is thus related to Wald's minimax theory. Sniedovich <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2264%22])">64</ref> has claimed that info-gap's robustness analysis is conducted in the neighborhood of an estimate that is likely to be substantially wrong, concluding that the resulting robustness function is equally likely to be substantially wrong.    </p>
<p>

On the other hand, the estimate is the best one has, so it is useful to know if it can err greatly and still yield an acceptable outcome. This critical question clearly raises the issue of whether robustness (as defined by info-gap theory) is qualified to judge whether confidence is warranted,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2265%22])">65</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2266%22])">66</ref>    
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2267%22])">67</ref> and how it compares to methods used to inform decisions under uncertainty using considerations <b>not</b> limited to the neighborhood of a bad initial guess. Answers to these questions vary with the particular problem at hand. Some general comments follow.   </p>

<ss2>
<st>
 Robust optimization </st>

<p>

The robust optimization literature <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2268%22])">68</ref>   
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2269%22])">69</ref>   
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2270%22])">70</ref>   
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2271%22])">71</ref>   
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2272%22])">72</ref>   
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2273%22])">73</ref> provides methods and techniques that take a <b>global</b> approach to robustness analysis. These methods directly address decision under <b>severe</b> uncertainty, and have been used for this purpose for more than thirty years now. <scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../430/1239430.xml">
Wald</link></scientist>
's <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> model is the main instrument used by these methods.   </p>
<p>

The principal difference between the <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> model employed by info-gap and the various <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> models employed by robust optimization methods is in the manner in which the total region of uncertainty is incorporated in the robustness model. Info-gap takes a local approach that concentrates on the immediate neighborhood of the estimate. In sharp contrast, robust optimization methods set out to incorporate in the analysis the entire region of uncertainty, or at least an adequate representation thereof. In fact, some of these methods do not even use an estimate. </p>

</ss2>
</ss1>
<ss1>
<st>
Comparative analysis</st>

<p>

Classical decision theory <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2252%22])">52</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2253%22])">53</ref> offers two approaches to decision-making under severe uncertainty, namely <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> and Laplaces' <link xlink:type="simple" xlink:href="../701/285701.xml">
Principle of insufficient reason</link>. </p>
<p>

As indicated above, info-gap's robustness model is a simple instance of the generic <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> model. Therefore, all that needs to be pointed out here is that whatever info-gap's robustness model can do the generic <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> model can do -- and much more. Indeed, as attested by the rich literature on robust optimization, <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> provides a wide range of methods for decision making in the face of severe uncertainty.</p>
<p>

As for Laplaces' <link xlink:type="simple" xlink:href="../701/285701.xml">
Principle of insufficient reason</link>, in this context it is convenient to view it as an ``instance<it> of <representation wordnetid="105926676" confidence="0.8">
<interpretation wordnetid="105928513" confidence="0.8">
<link xlink:type="simple" xlink:href="../890/4890.xml">
Bayesian analysis</link></interpretation>
</representation>
.</it></p>
<p>

The essence of the <representation wordnetid="105926676" confidence="0.8">
<interpretation wordnetid="105928513" confidence="0.8">
<link xlink:type="simple" xlink:href="../890/4890.xml">
Bayesian analysis</link></interpretation>
</representation>
 is applying probabilities for different possible realizations of the uncertain parameters. In the case of Knightian (non-probabilistic) uncertainty, these probabilities represent the decision makerÃ­s "degree of belief" in a specific realization.</p>
<p>

In our example, suppose there are only five possible realizations of the uncertain revenue to allocation function. The decision maker believes that the estimated function is the most likely, and that the likelihood decreases as the difference from the estimate increases. Figure 11 exemplifies such a probability distribution.
<image location="right" width="150px" src="IGT-example11.png" type="thumb">
<caption>

Figure 11 Ã± Probability distribution of the revenue function realizations
</caption>
</image>
</p>
<p>

Now, for any allocation, one can construct a probability distribution of the revenue, based on his prior beliefs. The decision maker can then choose the allocation with the highest expected revenue, with the lowest probability for an unacceptable revenue, etc.</p>
<p>

The most problematic step of this analysis is the choice of the realizations probabilities. When there is an extensive and relevant past experience, an expert may use this experience to construct a probability distribution. But even with extensive past experience, when some parameters change, the expert may only be able to estimate that <math>A</math> is more likely than <math>B</math>, but will not be able to reliably quantify this difference. Furthermore, when conditions change drastically, or when there is no past experience at all, it may prove to be difficult even estimating whether <math>A</math> is more likely than <math>B</math>.</p>
<p>

Nevertheless, methodologically speaking, this difficulty is not as problematic as  basing the analysis of a problem subject to severe uncertainty on a single point estimate and its immediate neighborhood, as done by info-gap. And what is more, contrary to info-gap, this approach is global, rather than local.</p>
<p>

Still, it must be stressed that <link xlink:type="simple" xlink:href="../890/4890.xml">
Bayesian analysis</link> does not expressly concern itself with the question of robustness.</p>
<p>

It should also be noted that Bayesian analysis raises the issue of <it>learning from experience</it> and adjusting probabilities accordingly. In other words, decision is not a one-stop process, but profits from a sequence of decisions and observations.</p>

</ss1>
</sec>
<sec>
<st>
 External links </st>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.technion.ac.il/yakov/IGT/igt.htm">
Further information on info-gap theory</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.moshe-online.com/infogap/">
Further analysis and critique of info-gap</weblink></entry>
</list>

</p>
</sec>
<sec>
<st>
See also</st>
<p>

<list>
<entry level="1" type="bullet">

<social_science wordnetid="106143154" confidence="0.8">
<knowledge_domain wordnetid="105999266" confidence="0.8">
<economics wordnetid="106149484" confidence="0.8">
<discipline wordnetid="105996646" confidence="0.8">
<science wordnetid="105999797" confidence="0.8">
<link xlink:type="simple" xlink:href="../216/446216.xml">
Decision theory</link></science>
</discipline>
</economics>
</knowledge_domain>
</social_science>
</entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../842/1190842.xml">
Decision analysis</link></entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../571/49571.xml">
Bayesian inference</link></entry>
<entry level="1" type="bullet">

<representation wordnetid="105926676" confidence="0.8">
<interpretation wordnetid="105928513" confidence="0.8">
<link xlink:type="simple" xlink:href="../890/4890.xml">
Bayesian probability</link></interpretation>
</representation>
</entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../815/6978815.xml">
Bayesian estimation</link></entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../547/3332547.xml">
Hierarchical Bayes model</link></entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../879/708879.xml">
List of publications in statistics</link></entry>
<entry level="1" type="bullet">

<know-how wordnetid="105616786" confidence="0.8">
<method wordnetid="105660268" confidence="0.8">
<link xlink:type="simple" xlink:href="../801/236801.xml">
Markov chain Monte Carlo</link></method>
</know-how>
</entry>
</list>
</p>

</sec>
<sec>
<st>
 Notes on the art of math modeling </st>



<ss1>
<st>
 Constraint satisficing vs payoff  optimization </st>

<p>

Any satisficing problem can be formulated as an optimization problem. To see that this is so, let the objective function of the optimization problem be the <link xlink:type="simple" xlink:href="../790/240790.xml">
indicator function</link> of the constraints pertaining to the satisficing problem. Thus, if our concern is to identify a worst-case scenario pertaining to a constraint, this can be done via a suitable Maximin/Minimax worst-case analysis of the indicator function of the constraint. </p>
<p>

This means that the generic decision theoretic models can handle outcomes that are induced by <b>constraint satisficing</b> requirements rather than by say <b>payoff maximization.</b></p>
<p>

In particular, note the equivalence</p>
<p>

<math> r \le f(x) \ \ \longleftrightarrow \ \ 1 \le I(x)
</math></p>
<p>

where </p>
<p>

<math> I(x):= \begin{cases}
1 &amp;, \ \  r \le f(x) \\
0 &amp;,\ \ r &amp;gt; f(x)
\end{cases}\ , \ x\in X
</math></p>
<p>

and therefore</p>
<p>

<math>
x\in X, r \le f(x) \ \ \ \longleftrightarrow \ \ \ x=\arg\, \max_{x\in X} I(x)
</math></p>

<p>

In practical terms, this means that an antagonistic Nature will aim to select a state that will violate the constraint whereas a sympathetic Nature will aim to select a state that will satisfy the constraint. As for the outcome, the penalty for violating the constraint is such that the decision maker will refrain from selecting a decision that will allow Nature to violate the constraint within the state space pertaining to the selected decision.</p>

</ss1>
<ss1>
<st>
 The role of "min" and "max" </st>

<p>

It should be stressed that the feature according info-gap's robustness model its typical <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> character is not the presence of both <math>\ \displaystyle \min \ </math> and <math>\ \displaystyle \max \ </math> in the formulation of the info-gap model. Rather, the reason for this is a deeper one.  It goes to the heart of the conceptual framework that the <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> model captures: Nature playing against the DM.  This is what is crucial here.</p>
<p>

To see that this is so, let us generalize info-gap's robustness model and consider the following modified model instead:</p>
<p>

<math>
 z(q):= \max\{\alpha: R(q,u) \in C, \forall u \in \mathcal{U}(\alpha,\tilde{u})\}
</math></p>

<p>

where in this context <math>\ \displaystyle C \ </math> is some set and <math>\ R\  </math> is some function on <math>\ \displaystyle \mathcal{Q}\times \mathfrak{U} </math>. Note that it is not assumed that <math>\ \displaystyle R \ </math> is a real-valued function.  Also note that "min" is absent from this model.</p>
<p>

All we need to do to incorporate a <it>min</it>&nbsp; into this model is to express the constraint </p>
<p>

<math>
R(q,u) \in C \ , \ \forall u \in \mathcal{U}(\alpha,\tilde{u})
</math></p>

<p>

as a worst-case requirement. This is a straightforward task, observing that for any triplet <math>\ \displaystyle  (q,\alpha.u)\ </math> of interest we have  </p>
<p>

<math>
R(q,u) \in C \ \ \ \longleftrightarrow \ \ \ \alpha \le I(q,\alpha,u)
</math></p>

<p>

where</p>
<p>

<math>
I(q,\alpha,u):= \begin{cases}
\quad \alpha &amp;, \ \  R(q,u) \in C\\
-\infty &amp;, \ \ R(q,u) \notin C
\end{cases} \ , \ q\in \mathcal{Q}, u\in \mathcal{U}(\alpha,\tilde{u}) 
</math></p>

<p>

hence, </p>

<p>

<math>
\begin{array}{ccl}
\max\{\alpha: R(q,u) \in C, \forall u \in \mathcal{U}(\alpha,\tilde{u})\} &amp;=&amp; \max\{\alpha: \alpha \le I(q,\alpha,u), \forall u \in \mathcal{U}(\alpha,\tilde{u})\} \\
&amp;=&amp; \max\{\alpha: \alpha \le\displaystyle  \min_{u \in \mathcal{U}(\alpha,\tilde{u})} I(q,\alpha,u)\}
\end{array}
</math></p>

<p>

which, of course, is a <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> model a la Mathematical Programming.</p>
<p>

In short, </p>

<p>

<math>
\max\{\alpha: R(q,u) \in C, \forall u \in \mathcal{U}(\alpha,\tilde{u})\} = \max_{\alpha\ge 0}\ \min_{u \in \mathcal{U}(\alpha,\tilde{u})} I(q,\alpha,u)\}
</math></p>

<p>

Note that although the model on the left does not include an explicit "min", it is nevertheless a typical Maximin model. The feature rendering it a <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> model is the <math>\ \displaystyle \forall  \ </math> requirement which lends itself to an intuitive  worst-case formulation and interpretation.</p>
<p>

In fact, the presence of a double "max" in an info-gap robustness model does not necessarily alter the fact that this model is a <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> model. For instance, consider the robustness model</p>
<p>

<math>
\max\{\alpha: r_{c}\ge \max_{u\in \mathcal{U}(\alpha,\tilde{u})} R(q,u)\}
</math></p>

<p>

This is an instance of the following <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> model</p>

<p>

<math>
\max_{\alpha \ge 0} \min_{u\in \mathcal{U}(\alpha,\tilde{u})} \vartheta(q,\alpha,u)
</math></p>
<p>

where</p>
<p>

<math>
\vartheta(q,\alpha,u):= \begin{cases}
\quad \alpha  &amp;, \ \  r_{c} \ge R(q,\alpha)\\
-\infty &amp;,\ \  r_{c} &amp;lt; R(q,\alpha)
\end{cases}
</math></p>

<p>

The "inner min" indicates that Nature plays against the DM -- the "max" player -- hence the model is a robustness model.</p>

</ss1>
<ss1>
<st>
 The nature of the info-gap/Maximin/Minimin connection  </st>

<p>

This modeling issue is discussed here because claims have been made that although there is a close relationship between info-gap's robustness and opportuneness models and the generic <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> and Minimin models, respectively, the description of info-gap as an <it> instance of </it>&nbsp; these models is too strong.  The argument put forward is that although it is true that info-gap's robustness model can be expressed as a <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> model, the former is not an instance of the latter. </p>
<p>

This objection apparently stems from the fact that any optimization problem can be formulated as a Maximin model by a simple employment of <it>dummy</it>&nbsp; variables. That is, clearly</p>
<p>

<math>
\min_{x\in X} f(x) = \max_{y\in Y}\min_{x\in X} g(y,x)
</math></p>
<p>

where </p>
<p>

<math>
g(y,x) = f(x) \ , \ \forall x\in X, y\in Y
</math></p>
<p>

for any arbitrary non-empty set <math>\ \displaystyle Y \ </math>.</p>
<p>

The point of this objection seems to be that we are running the risk of watering down the meaning of the term <it> instance </it>&nbsp; if we thus contend that any minimization problem is an instance of the <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> model.</p>
<p>

It must therefore be pointed out that this concern is utterly unwarranted in the case of the info-gap/Maximin/Minimin relation. The correspondence between info-gap's robustness model and the generic <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> model is neither contrived nor is it formulated with the aid of dummy objects. The correspondence is immediate, intuitive, and compelling hence, aptly described by the term <it> instance of </it>. </p>
<p>

Specifically, as shown above, info-gap's robustness model is an instance of the generic Maximin model specified by the following constructs:</p>
<p>

<math>
\begin{array}{rccl}
\text{Decision Space} &amp; D &amp; = &amp; (0,\infty)\\ 
\text{State Spaces} &amp; S(d) &amp; = &amp; \mathcal{U}(d,\tilde{u})\\
\text{Outcomes} &amp; g(d,s) &amp; = &amp; \varphi(q,d,s) 
\end{array}
</math></p>

<p>

Furthermore, those objecting to the use of the term <it> instance of </it>&nbsp;  should note that the Maximin model formulated above has an equivalent so called <it> Mathematical Programming </it>&nbsp; (MP) formulation deriving from the fact that
<math>
\begin{array}{ccc}
\text{Classical Maximin Format}&amp;&amp; \text{MP Maximin Format}\\
 \displaystyle \max_{d\in D} \ \min_{s \in S(d)}\ g(d,s) &amp;=&amp;  \displaystyle \max_{d\in D,\alpha \in \mathbb{R}}\{\alpha: \alpha \le  \min_{s\in S(d)} g(d,s)\} 
\end{array}
</math></p>

<p>

where <math>\ \mathbb{R} \ </math> denotes the real line.</p>
<p>

So here are side by side info-gap's robustness model and the two equivalent formulations of the generic <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> paradigm: </p>

<p>

<math>
\begin{array}{c}\textit{Robustness\   Model}
\end{array}</math>
&nbsp;
<math>
\begin{array}{c|c|c}
\text{Info-gap Format}&amp; \text{MP Maximin Format}&amp;\text{Classical Maximin Format}\\
\hline \\[-0.18in]
\displaystyle \max\{\alpha: r_{c} \le \min_{u\in \mathcal{U}(\alpha,\tilde{u})} R(q,u)\}&amp;\displaystyle \max\{\alpha: \alpha \le \min_{u \in \mathcal{U}(\alpha,\tilde{u})}\ \varphi(q,\alpha,u)\}&amp;\displaystyle \max_{\alpha\ge 0} \ \min_{u\in \mathcal{U}(\alpha,\tilde{u})} \varphi(q,\alpha,u)
\end{array} 
</math></p>

<p>

Note that the equivalence between these three representations of the same decision-making situation makes no use of dummy variables. It is based on the equivalence </p>
<p>

<math>
r_{c} \le R(q,u)  \longleftrightarrow \alpha \le \varphi(q,\alpha,u)
</math> </p>
<p>

deriving directly from the definition of the characteristic function <math>\ \displaystyle \varphi \ </math>. </p>
<p>

Clearly then, info-gap's robustness model is an instance of the generic <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> model.</p>
<p>

Similarly, for info-gap's opportuneness model we have</p>

<p>

<math>
\begin{array}{c}\textit{Opportuneness\   Model}
\end{array}</math>
&nbsp;
<math>
\begin{array}{c|c|c}
\text{Info-gap Format}&amp; \text{MP Minimin Format}&amp;\text{Classical Minimin Format}\\
\hline \\[-0.18in]
\displaystyle \min\{\alpha: r_{w} \le \max_{u\in \mathcal{U}(\alpha,\tilde{u})} R(q,u)\} &amp; \displaystyle \min\{\alpha: \alpha \ge \min_{u \in \mathcal{U}(\alpha,\tilde{u})}\ \psi(q,\alpha,u)\} &amp; \displaystyle \min_{\alpha\ge 0} \ \min_{u\in \mathcal{U}(\alpha,\tilde{u})} \psi(q,\alpha,u)
\end{array} 
</math></p>

<p>

Again, it should be stressed that the equivalence between these three representations of the same decision-making situation makes no use of dummy variables. It is based on the equivalence </p>
<p>

<math>
r_{c} \le R(q,u)  \longleftrightarrow \alpha \ge \psi(q,\alpha,u)
</math> </p>
<p>

deriving directly from the definition of the characteristic function <math>\ \displaystyle \psi \ </math>. </p>
<p>

Thus, to "help" the DM minimize <math>\ \displaystyle \alpha \ </math>, a sympathetic Nature will select a <math>u \in \mathcal{U}(\alpha,\tilde{u})\ </math> that minimizes <math>\ \psi(q,\alpha,u) \ </math> over <math>\ \displaystyle  \mathcal{U}(\alpha,\tilde{u})\ </math> .</p>
<p>

Clearly, info-gap's opportuneness model is an instance of the generic Minimin model.</p>

</ss1>
<ss1>
<st>
 Other formulations </st>

<p>

There are of course other valid representations of the robustness/opportuneness models.  For instance, in the case of the robustness model, the outcomes can be defined as follows (Sniedovich 2007<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2251%22])">51</ref>) :</p>
<p>

<math>
g(\alpha,u):= \alpha \cdot \left(r_{c} \preceq R(q,u)\right)
</math></p>
<p>

where the binary operation <math>\ \ \preceq \ \ </math>  is defined as follows:</p>
<p>

<math>
 a \preceq b := \begin{cases}
1 &amp;, \ \ a\le b \\
0 &amp;,\ \  a&amp;gt;b
\end{cases}
</math></p>

<p>

The corresponding MP format of the <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> model would then be as follows:</p>
<p>

<math>
\max\{\alpha: \alpha \le \min_{u\in \mathcal{U}(\alpha,\tilde{u})} \alpha \cdot \left(r_{c} \preceq R(q,u)\right) \} = \max\{\alpha: 1 \le \min_{u\in \mathcal{U}(\alpha,\tilde{u})} \left(r_{c} \preceq R(q,u)\right)\}
</math></p>

<p>

In words, to maximize the robustness, the DM selects the largest value of <math>\ \alpha \ </math> such that the performance  constraint <math>\ r_{c} \le R(q,u) \ </math> is satisfied by all <math>\ u\in \mathcal{U}(\alpha,\tilde{u})\ </math>. In plain language: the DM selects the largest value of  <math>\ \displaystyle \alpha \ </math> whose worst outcome in the region of uncertainty of size   <math>\ \displaystyle \alpha \ </math> satisfies the performance requirement.</p>

</ss1>
<ss1>
<st>
 Simplifications </st>

<p>

As a rule the classical <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> formulations are not particularly useful when it comes to <b>solving</b> the problems they represent, as no "general purpose" <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> solver is available (Rustem and Howe 2002 <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2271%22])">71</ref>). </p>
<p>

It is common practice therefore to simplify the classical formulation with a view to derive a formulation that would be readily amenable to solution. This is a problem-specific task which involves exploiting a problem's specific features. The mathematical programming format of <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> is often more user-friendly in this regard.</p>
<p>

The best example is of course the classical <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> model of <link xlink:type="simple" xlink:href="../924/11924.xml">
2-person zero-sum games</link> which after streamlining is reduced to a standard <link xlink:type="simple" xlink:href="../730/43730.xml">
linear programming</link> model (Thie 1988<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2255%22])">55</ref>, pp. 314-317) that is readily solved by <link xlink:type="simple" xlink:href="../730/43730.xml">
linear programming</link> <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../458/349458.xml">
algorithms</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
.</p>
<p>

To reiterate,  this <link xlink:type="simple" xlink:href="../730/43730.xml">
linear programming</link> model is an instance of the generic <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
 model obtained via simplification of the classical <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> formulation of the <link xlink:type="simple" xlink:href="../924/11924.xml">
2-person zero-sum game</link>.</p>
<p>

Another example is <link xlink:type="simple" xlink:href="../297/125297.xml">
dynamic programming</link> where the Maximin paradigm is incorporated in the dynamic programming functional equation representing sequential decision processes that are subject to severe uncertainty (eg. Sniedovich 2003<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2274%22])">74</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2275%22])">75</ref>).</p>

</ss1>
<ss1>
<st>
 Summary </st>
<p>

Recall that in plain language the <link xlink:type="simple" xlink:href="../589/19589.xml">
Maximin</link> paradigm maintains the following:</p>
<p>

<it>Maximin Rule</it>
The maximin rule tells us to rank alternatives by their worst possible outcomes: we are to adopt the alternative the worst outcome of which is superior to the worst outcome of the others.Rawls (1971, p. 152)</p>

<p>

Info-gap's robustness model is a simple instance of this paradigm that is characterized by a specific decision space, state spaces and objective function, as discussed above.</p>
<p>

Much can be gained by viewing info-gap's theory in this light.</p>

</ss1>
</sec>
<sec>
<st>
 References </st>

<p>

<reflist>
<entry id="1">
 Yakov Ben-Haim, <it>Information-Gap Theory: Decisions Under Severe Uncertainty,</it> Academic Press, London, 2001. </entry>
<entry id="2">
 Yakov Ben-Haim, <it>Info-Gap Theory: Decisions Under Severe Uncertainty,</it> 2nd edition, Academic Press, London, 2006. </entry>
<entry id="3">
Here are some examples: In many fields, including <link xlink:type="simple" xlink:href="../251/9251.xml">
engineering</link>, <link xlink:type="simple" xlink:href="../223/9223.xml">
economics</link>, <link xlink:type="simple" xlink:href="../881/19881.xml">
management</link>, <link xlink:type="simple" xlink:href="../216/216216.xml">
biological conservation</link>, <link xlink:type="simple" xlink:href="../957/18957.xml">
medicine</link>, <link xlink:type="simple" xlink:href="../105/42105.xml">
homeland security</link>, and more, analysts use models and data to evaluate and formulate <link xlink:type="simple" xlink:href="../216/446216.xml">
decisions</link>. An <b>info-gap</b> is the disparity between what <it>is known</it> and what <it>needs to be known</it> in order to make a reliable and responsible decision. Info-gaps are <link xlink:type="simple" xlink:href="../033/1473033.xml">
Knightian uncertainties</link>: a lack of knowledge, an incompleteness of understanding. Info-gaps are non-probabilistic and cannot be insured against or modelled <link xlink:type="simple" xlink:href="../542/23542.xml">
probabilistically</link>. A common info-gap, though not the only kind, is uncertainty in the value of a parameter or of a vector of parameters, such as the durability of a new material or the future rates or return on stocks. Another common info-gap is uncertainty in the shape of a <link xlink:type="simple" xlink:href="../543/23543.xml">
probability distribution</link>. Another info-gap is uncertainty in the functional form of a property of the system, such as <link xlink:type="simple" xlink:href="../062/11062.xml">
friction</link> force in engineering, or the <curve wordnetid="113867641" confidence="0.8">
<line wordnetid="113863771" confidence="0.8">
<shape wordnetid="100027807" confidence="0.8">
<link xlink:type="simple" xlink:href="../390/153390.xml">
Phillips curve</link></shape>
</line>
</curve>
 in economics. Another info-gap is in the shape and size of a set of possible vectors or functions. For instance, one may have very little knowledge about the relevant set of cardiac waveforms at the onset of heart failure in a specific individual.</entry>
<entry id="4">
Rawls, J. Theory of Justice, 1971, Belknap Press, Cambridge, MA.</entry>
<entry id="5">
Keith W. Hipel and Yakov Ben-Haim, 1999, Decision making in an uncertain world: Information-gap modelling in water resources management, <it>IEEE Trans., Systems, Man and Cybernetics</it>, Part C: Applications and Reviews, 29: 506-517. </entry>
<entry id="6">
 Yakov Ben-Haim, 2005, Info-gap Decision Theory For Engineering Design. Or: Why `Good' is Preferable to `Best', appearing as chapter 11 in <it>Engineering Design Reliability Handbook</it>, Edited by Efstratios Nikolaidis, Dan M.Ghiocel and Surendra Singhal, CRC Press, Boca Raton. </entry>
<entry id="7">
 Y. Kanno and I. Takewaki, Robustness analysis of trusses with separable load and structural uncertainties, <it>International Journal of Solids and Structures,</it> Volume 43, Issue 9, May 2006, pp.2646-2669.</entry>
<entry id="8">
Kaihong Wang, 2005, Vibration Analysis of Cracked Composite Bending-torsion Beams for Damage Diagnosis, PhD thesis, Virginia Politechnic Institute, Blacksburg, Virginia. </entry>
<entry id="9">
Y. Kanno and I. Takewaki, 2006, Sequential semidefinite program for maximum robustness design of structures under load uncertainty, <it>Journal of Optimization Theory and Applications</it>, vol.130, #2, pp.265-287. </entry>
<entry id="10">
 S.G. Pierce, K. Worden and G. Manson, 2006, A novel information-gap technique to assess reliability of neural network-based damage detection <it>Journal of Sound and Vibration,</it> 293: Issues 1-2, pp.96-111.</entry>
<entry id="11">
S.Gareth Pierce, Yakov Ben-Haim, Keith Worden, Graeme Manson, 2006, Evaluation of neural network robust reliability using information-gap theory, <it>IEEE Transactions on Neural Networks</it>, vol.17, No.6, pp.1349-1361. </entry>
<entry id="12">
Chetwynd, D., Worden, K., Manson, G., 2006, An application of interval-valued neural networks to a regression problem, <it>Proceedings of the Royal Society - Mathematical, Physical and Engineering Sciences</it>, (Series A), 462 (2074) pp.3097-3114. </entry>
<entry id="13">
D. Lim, Y. S. Ong, Y. Jin, B. Sendhoff, and B. S. Lee, 2006, Inverse Multi-objective Robust Evolutionary Design, <it>Genetic Programming and Evolvable Machines</it>, Vol. 7, No. 4, pp. 383-404. </entry>
<entry id="14">
 P. Vinot, S. Cogan and V. Cipolla, 2005, A robust model-based test planning procedure <it>Journal of Sound and Vibration</it>, 288, Issue 3, pp.571-585. </entry>
<entry id="15">
Izuru Takewaki and Yakov Ben-Haim, 2005, Info-gap robust design with load and model uncertainties, <it>Journal of Sound and Vibration</it>, 288: 551-570. </entry>
<entry id="17">
Francois M. Hemez and Yakov Ben-Haim, 2004, Info-gap robustness for the correlation of tests and simulations of a nonlinear transient, <it>Mechanical Systems and Signal Processing</it>, vol. 18, #6, pp.1443-1467. </entry>
<entry id="16">
Izuru Takewaki and Yakov Ben-Haim, 2007, Info-gap robust design of passively controlled structures with load and model uncertainties, <it>Structural Design Optimization Considering Uncertainties</it>, Yiannis Tsompanakis, Nikkos D. Lagaros and Manolis Papadrakakis, editors, Taylor and Francis Publishers. 
</entry>
<entry id="19">
 A. Moilanen, and B.A. Wintle, 2006, Uncertainty analysis favours selection of spatially aggregated reserve structures. <it>Biological Conservation,</it> Volume 129, Issue 3, May 2006, Pages 427-434.</entry>
<entry id="18">
 Levy, Jason K., Keith W. Hipel and D. Marc Kilgour, 2000, Using environmental indicators to quantify the robustness of policy alternatives to uncertainty, <it>Ecological Modelling</it>, vol.130, Issues 1-3, pp.79-86.</entry>
<entry id="21">
 Helen M. Regan, Yakov Ben-Haim, Bill Langford, Will G. Wilson, Per Lundberg, Sandy J. Andelman, Mark A. Burgman, 2005, Robust decision making under severe uncertainty for conservation management, <it>Ecological Applications</it>, vol.15(4): 1471-1477.
</entry>
<entry id="20">
Halpern, Benjamin S., Helen M. Regan, Hugh P. Possingham and Michael A. McCarthy, 2006, Accounting for uncertainty in marine reserve design, <it>Ecology Letters</it>, vol.9, pp.2-11.</entry>
<entry id="23">
Crone, Elizabeth E., Debbie Pickering and Cheryl B. Schultz, 2007, Can captive rearing promote recovery of endangered butterflies? An assessment in the face of uncertainty, <it>Biological Conservation</it>, vol. 139, #1-2,pp.103-112.</entry>
<entry id="22">
 McCarthy, M.A., Lindenmayer, D.B., 2007, Info-gap decision theory for assessing the management of catchments for timber production and urban water supply, <it>Environmental Management</it>, vol.39 (4) pp. 553-562. </entry>
<entry id="25">
M. A. Burgman, D.B. Lindenmayer, and J. Elith, Managing landscapes for conservation under uncertainty, <it>Ecology</it>, 86(8), 2005, pp. 2007Ã±-2017. </entry>
<entry id="24">
L. Joe Moffitt, John K. Stranlund and Craig D. Osteen, 2007, Robust detection protocols for uncertain introductions of invasive species, <it>Journal of Environmental Management</it>, In Press, Corrected Proof, Available online 27 August 2007. </entry>
<entry id="27">
Moilanen, Atte, Michael C. Runge, Jane Elith, Andrew Tyre, Yohay Carmel, Eric Fegraus, Brendan Wintle, Mark Burgman and Yakov Ben-Haim, 2006, Planning for robust reserve networks using uncertainty analysis, <it>Ecological Modelling</it>, vol. 199, issue 1, pp.115-124.</entry>
<entry id="26">
Moilanen, A., B.A. Wintle., J. Elith and M. Burgman, 2006, Uncertainty analysis for regional-scale reserve selection, <it>Conservation Biology</it>, Vol.20, No. 6, 1688Ã±1697. </entry>
<entry id="29">
 
Burgman, Mark, 2005, <it>Risks and Decisions for Conservation and Environmental Management</it>, Cambridge University Press, Cambridge. 
</entry>
<entry id="28">
Nicholson, Emily and Hugh P. Possingham, Making conservation decisions under uncertainty for the persistence of multiple species, <it>Ecological Applications</it>, vol. 17, pp.251-265. </entry>
<entry id="31">
 L. Joe Moffitt, John K. Stranlund, and Barry C. Field, 2005, Inspections to Avert Terrorism: Robustness Under Severe Uncertainty, <it>Journal of Homeland Security and Emergency Management,</it> Vol. 2: No. 3. http://www.bepress.com/jhsem/vol2/iss3/3
</entry>
<entry id="30">
 Yohay Carmel and Yakov Ben-Haim, 2005, Info-gap robust-satisficing model of foraging behavior: Do foragers optimize or satisfice?, <it>American Naturalist</it>, 166: 633-641.</entry>
<entry id="34">
 Yakov Ben-Haim, 2005, Value at risk with Info-gap uncertainty, <it>Journal of Risk Finance,</it> vol. 6, #5, pp.388-403.</entry>
<entry id="35">
 Yakov Ben-Haim and Alexander Laufer, 1998, Robust reliability of projects with activity-duration uncertainty, <it>ASCE Journal of Construction Engineering and Management</it>. 124: 125-132.</entry>
<entry id="32">
Beresford-Smith, Bryan and Colin J. Thompson, 2007, Managing credit risk with info-gap uncertainty, The Journal of Risk Finance, vol.8, issue 1, pp.24-34.</entry>
<entry id="33">
 John K. Stranlund and Yakov Ben-Haim, 2007, Price-based vs. quantity-based environmental regulation under Knightian uncertainty: An info-gap robust satisficing perspective, <it>Journal of Environmental Management</it>, In Press, Corrected Proof, Available online 28 March 2007.</entry>
<entry id="38">
 Fox, D.R., Ben-Haim, Y., Hayes, K.R., McCarthy, M., Wintle, B., and Dunstan, P., An Info-Gap Approach to Power and Sample-size calculations, <it>Environmetrics,</it> vol. 18, pp.189-203.</entry>
<entry id="39">
Yakov Ben-Haim, 1994, Convex models of uncertainty: Applications and Implications, <it>Erkenntnis: An International Journal of Analytic Philosophy</it>, 41:139-156.</entry>
<entry id="36">
 Meir Tahan and Joseph Z. Ben-Asher, 2005, Modeling and analysis of integration processes for engineering systems, <it>Systems Engineering</it>, Vol. 8, No. 1, pp.62-77. </entry>
<entry id="37">
 Sary Regev, Avraham Shtub and Yakov Ben-Haim, 2006, Managing project risks as knowledge gaps, <it>Project Management Journal</it>, vol. 37, issue #5, pp.17-25. </entry>
<entry id="42">
Yakov Ben-Haim, 2004, Uncertainty, probability and information-gaps, <it>Reliability Engineering and System Safety</it>, vol. 85: 249-266.</entry>
<entry id="43">
George J. Klir, 2006, <it>Uncertainty and Information: Foundations of Generalized Information Theory</it>, Wiley Publishers.</entry>
<entry id="40">
Yakov Ben-Haim, 1999, Set-models of information-gap uncertainty: Axioms and an inference scheme, <it>Journal of the Franklin Institute</it>, vol. 336: 1093-1117.</entry>
<entry id="41">
Yakov Ben-Haim, 2000, Robust rationality and decisions under severe uncertainty, <it>Journal of the Franklin Institute</it>, vol. 337: 171-199.</entry>
<entry id="46">
 <cite style="font-style:normal" class="book">James O Berger&#32;(2006; really 1985). <weblink xlink:type="simple" xlink:href="http://books.google.com/books?id=oY_x7dE15_AC&amp;pg=PA100&amp;dq=isbn:0387960988&amp;sig=AqRaO4FctKZ6JMJp60rRNekfIJk#PPA331,M1">
Statistical decision theory and Bayesian analysis</weblink>, Second Edition,&#32;New York:&#32;Springer Science + Business Media. ISBN 0-387-96098-8.</cite>&nbsp;
</entry>
<entry id="47">
Tintner, G., Ã¬Abraham WaldÃ­s contributions to econometricsÃ®,
<it>The Annals of Mathematical Statistics,</it>  23(1), 21-28, 1952.</entry>
<entry id="44">
Yakov Ben-Haim, 2007, Peirce, Haack and Info-gaps, in <it>Susan Haack, A Lady of Distinctions: The Philosopher Responds to Her Critics</it>, edited by Cornelis de Waal, Prometheus Books.</entry>
<entry id="45">
Burgman, Mark, 2005, <it>Risks and Decisions for Conservation and Environmental Management</it>, Cambridge University Press, Cambridge, pp.399.</entry>
<entry id="51">
M. Sniedovich, 2007, The art and science of modeling decision-making under severe uncertainty, <it>Decision-Making in Manufacturing and Services,</it> Volume 1, Issue 1-2, pp. 111-136. http://www.dmms.agh.edu.pl/Volume_1_2/Sniedovich.pdf</entry>
<entry id="50">
Ben-Haim, Y. (1999) Design certification with information-gap uncertainty, <it>Structural Safety,</it> 2,  269-289.</entry>
<entry id="49">
BabuËka, I., F. Nobile and R. Tempone, 2005, Worst case scenario analysis for elliptic problems with uncertainty, <it>Numerische Mathematik</it> (in English) vol.101 pp.185Ã219.</entry>
<entry id="48">
 Z. Ben-Haim and Y. C. Eldar, Maximum set estimators with bounded estimation error, <it>IEEE Trans. Signal Processing</it>, vol. 53, no. 8, August 2005, pp. 3172-3182.</entry>
<entry id="55">
Thie, P., <it> An Introduction to Linear Programming and Game Theory,</it> Wiley, NY, 1988.</entry>
<entry id="54">
Ecker J.G. and Kupferschmid, M., <it>Introduction to Operations Research,</it> Wiley, 1988.</entry>
<entry id="53">
French, S.D., <it>Decision Theory,</it> Ellis Horwood, 1988.</entry>
<entry id="52">
Resnik, M.D., <it>Choices: an Introduction to Decision Theory,</it> University
of Minnesota Press, Minneapolis, MN, 1987.</entry>
<entry id="59">
Burgman, Mark, 2005, <it>Risks and Decisions for Conservation and Environmental Management</it>, Cambridge University Press, Cambridge, pp.391, 394.</entry>
<entry id="58">
Conlisk, John, 1996, Why bounded rationality? <it>Journal of Economic Literature</it>, XXXIV, pp.669-700.</entry>
<entry id="57">
 Schwartz, Barry, 2004, <it>Paradox of Choice: Why More Is Less</it>, Harper Perennial.</entry>
<entry id="56">
 Simon, Herbert A., 1959, Theories of decision making in economics and behavioral science, <it>American Economic Review</it>, vol.49, pp.253-283.</entry>
<entry id="63">
  
BabuÃ¶ka, I., F. Nobile and R. Tempone, 2005, Worst case scenario analysis for elliptic problems with uncertainty, <it>Numerische Mathematik</it> (in English) vol.101 pp.185Ã±219.</entry>
<entry id="62">
 Z. Ben-Haim and Y. C. Eldar, Maximum set estimators with bounded estimation error, <it>IEEE Trans. Signal Processing</it>, vol. 53, no. 8, August 2005, pp. 3172-3182.</entry>
<entry id="61">
 P. Vinot, S. Cogan and V. Cipolla, 2005, <it>op. cit.''</it></entry>
<entry id="60">
 P. Vinot, S. Cogan and V. Cipolla, 2005, A robust model-based test planning procedure <it>Journal of Sound and Vibration</it>, 288, Issue 3, p.572</entry>
<entry id="68">
M.J. Rosenhead, M. Elton, and S.K. Gupta, 1972, Robustness and Optimality as Criteria for Strategic Decisions, Operational Research Quarterly, 23(4), 413-430.</entry>
<entry id="69">
M.J. Rosenblatt and H.L. Lee, 1987, A robustness approach to facilities design, International Journal of Production Research, 25(4), 479-486.</entry>
<entry id="70">
P. Kouvelis and G. Yu, 1997, Robust Discrete Optimization and Its Applications, Kluwer.</entry>
<entry id="71">
B. Rustem and M. Howe, 2002, Algorithms for Worst-case Design and Applications to Risk Management, Princeton University Press.</entry>
<entry id="64">
 M. Sniedovich, 2007, The art and science of modeling decision-making under severe uncertainty, <it>Decision-Making in Manufacturing and Services,</it> Volume 1, Issue 1-2, pp. 109-134.   
</entry>
<entry id="65">
Yakov Ben-Haim, Scott Cogan and Laetitia Sanseigne, 1998, Usability of Mathematical Models in Mechanical Decision Processes, <it>Mechanical Systems and Signal Processing</it>, vol. 12: 121-134.</entry>
<entry id="66">
 Yakov Ben-Haim, <it>Robust Reliability in the Mechanical Science,</it> Springer, Berlin ,1996.</entry>
<entry id="67">
(See also chapter 4 in Yakov Ben-Haim, Ref. 2.)</entry>
<entry id="72">
R.J. Lempert, S.W. Popper, and S.C. Bankes, 2003, Shaping the Next One Hundred Years: New Methods for Quantitative, Long-Term Policy Analysis, The Rand Corporation.</entry>
<entry id="73">
A. Ben-Tal, L. El Ghaoui, and A. Nemirovski, 2006, Mathematical Programming, Special issue on Robust Optimization, Volume 107(1-2).</entry>
<entry id="74">
Sniedovich M., OR/MS Games: 3. The Counterfeit coin problem, INFORMS Transactions in Education, Vol. 3(2), 32-41, 2003.</entry>
<entry id="75">
Sniedovich, M., OR/MS Games: 4. The joy of egg-dropping in Braunschweig and Hong Kong, INFORMS Transactions on Education, 4(1), 48-64, 2003.</entry>
</reflist>
</p>



</sec>
</bdy>
</article>
