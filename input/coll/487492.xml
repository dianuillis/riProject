<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 17:09:56[mciao0826] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Cryptographically strong</title>
<id>487492</id>
<revision>
<id>219271366</id>
<timestamp>2008-06-14T12:16:38Z</timestamp>
<contributor>
<username>Lightbot</username>
<id>7178666</id>
</contributor>
</revision>
<categories>
<category>Cryptography</category>
</categories>
</header>
<bdy>

This term <b>cryptographically strong</b> is often used to describe an <link xlink:type="simple" xlink:href="../294/10294.xml">
encryption</link> <link xlink:type="simple" xlink:href="../775/775.xml">
algorithm</link>, and implies, in comparison to some other algorithm (which is thus <link>
cryptographically weak</link>), greater resistance to attack. But it can also be used to describe hashing and unique identifier and filename creation algorithms. See for example the description of the Microsoft .NET runtime library function Path.GetRandomFileName. In this usage the term means <b>difficult to guess</b>.<p>

An encryption algorithm is intended to be unbreakable (in which case it is as strong as it can ever be), but might be breakable (in which case it is as weak as it can ever be) so there is not, in principle, a continuum of strength as the <link xlink:type="simple" xlink:href="../563/47563.xml">
idiom</link> would seem to imply: Algorithm A is stronger than Algorithm B which is stronger than Algorithm C, and so on. The situation is made more complex, and less subsumable into a single strength metric, by the fact that there are many types of <link xlink:type="simple" xlink:href="../715/5715.xml">
cryptanalytic</link> attack and that any given algorithm is likely to force the attacker to do more work to break it when using one attack than another. </p>
<p>

The usual sense in which this term is (loosely) used, is in reference to a particular attack, <operation wordnetid="100955060" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<attack wordnetid="100972621" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<link xlink:type="simple" xlink:href="../784/53784.xml">
brute force</link></activity>
</psychological_feature>
</act>
</attack>
</event>
</operation>
 key search &mdash; especially in explanations for newcomers to the field. Indeed, with this attack (always assuming keys to have been randomly chosen), there is a continuum of resistance depending on the length of the key used. But even so there are two major problems: many algorithms allow use of different length keys at different times, and any algorithm can forego use of the entire key length possible. Thus, <cipher wordnetid="106254239" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../940/3940.xml">
Blowfish</link></cipher>
 and <cipher wordnetid="106254239" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../600/102600.xml">
RC5</link></cipher>
 are <link xlink:type="simple" xlink:href="../594/4594.xml">
block cipher</link> algorithms whose design specifically allowed for several <link xlink:type="simple" xlink:href="../749/5749.xml">
key lengths</link>, and who cannot therefore be said to have any particular strength with respect to brute force key search. Furthermore, US export regulations restrict key length for exportable crypto products and in several cases in the '80s and '90s (eg, famously in the case of <link xlink:type="simple" xlink:href="../408/60408.xml">
Lotus Notes</link>' export approval) only partial keys were used, decreasing 'strength' against brute force attack for those (export) versions. More or less the same thing happened outside the <body wordnetid="107965085" confidence="0.8">
<social_group wordnetid="107950920" confidence="0.8">
<political_orientation wordnetid="106212839" confidence="0.8">
<colony wordnetid="108374049" confidence="0.8">
<state wordnetid="108168978" confidence="0.8">
<political_unit wordnetid="108359949" confidence="0.8">
<group wordnetid="100031264" confidence="0.8">
<democracy wordnetid="106217103" confidence="0.8">
<link xlink:type="simple" xlink:href="../750/3434750.xml">
US</link></democracy>
</group>
</political_unit>
</state>
</colony>
</political_orientation>
</social_group>
</body>
 as well, as for example in the case of more than one of the crypto algorithms in the <link xlink:type="simple" xlink:href="../808/12808.xml">
GSM</link> cellular telephone standard. </p>
<p>

The term is commonly used to convey that some algorithm is suitable for some task in <link xlink:type="simple" xlink:href="../432/18934432.xml">
cryptography</link> or <link xlink:type="simple" xlink:href="../036/15036.xml">
information security</link>, but also resists <link xlink:type="simple" xlink:href="../715/5715.xml">
cryptanalysis</link> and has no, or fewer, security weaknesses. Tasks are varied, and might include:</p>
<p>

<list>
<entry level="1" type="bullet">

 generating <link xlink:type="simple" xlink:href="../523/19196523.xml">
randomness</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../294/10294.xml">
encrypting</link> data</entry>
<entry level="1" type="bullet">

 providing a method to ensure <link xlink:type="simple" xlink:href="../995/40995.xml">
data integrity</link></entry>
</list>
</p>
<p>

<it>Cryptographically strong</it> would seem to mean that the described method has some kind of maturity, perhaps even approved for use against different kinds of systematic attacks in theory and/or practice. Indeed, that the method may resist those attacks long enough to protect the information carried (and what stands behind the information) for a useful length of time. But due to the complexity and subtlety of the field, neither is almost ever the case. Since such assurances are not actually available in real practice, sleight of hand in language which implies that they are will generally be misleading. </p>
<p>

There will be always uncertainty as advances (eg, in cryptanalytic theory or merely affordable computer capacity) may reduce the effort needed to successfully use some attack method against an algorithm. </p>
<p>

In addition, actual use of cryptographic algorithms requires their encapsulation in a <link xlink:type="simple" xlink:href="../383/506383.xml">
cryptosystem</link>, and doing so often introduces vulnerabilities which are not due to faults in an algorithm. For example, essentially all algorithms require random choice of keys, and any cryptosystem which does not provide such keys will be subject to attack regardless of any attack resistant qualities of the encryption algorithm(s) used.</p>

<sec>
<st>
 See also </st>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../432/18934432.xml">
Cryptography</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../091/183091.xml">
Unsolved problems in mathematics</link></entry>
<entry level="1" type="bullet">

 <accomplishment wordnetid="100035189" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<action wordnetid="100037396" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<feat wordnetid="100036762" confidence="0.8">
<link xlink:type="simple" xlink:href="../885/55885.xml">
Computer insecurity</link></feat>
</psychological_feature>
</act>
</action>
</event>
</accomplishment>
</entry>
</list>
</p>


</sec>
</bdy>
</article>
