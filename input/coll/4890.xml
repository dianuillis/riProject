<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 15:22:32[mciao0825] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<representation  confidence="0.8" wordnetid="105926676">
<interpretation  confidence="0.8" wordnetid="105928513">
<header>
<title>Bayesian probability</title>
<id>4890</id>
<revision>
<id>240171307</id>
<timestamp>2008-09-22T06:18:51Z</timestamp>
<contributor>
<username>Tomixdf</username>
<id>1645244</id>
</contributor>
</revision>
<categories>
<category>Articles lacking in-text citations</category>
<category>Probability interpretations</category>
<category>Philosophy of science</category>
<category>Philosophy of mathematics</category>
<category>Bayesian statistics</category>
</categories>
</header>
<bdy>

<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-style" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="50px" src="Text_document_with_red_question_mark.svg">
</image>
</p>
</col>
<col style="" class="mbox-text">
 This article or section includes a  or , but its sources remain unclear because it lacks <b>.</b>
You can  this article by introducing more precise citations . <it>(August 2007)''</it></col>
</row>
</table>


<b>Bayesian probability</b> interprets the concept of <link xlink:type="simple" xlink:href="../934/22934.xml">
probability</link> as 'a measure of a state of knowledge' <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref>. Broadly speaking, there are two views on Bayesian probability that interpret the 'state of knowledge' concept in different ways.  For the <b>objectivist school</b>, the rules of Bayesian statistics can be justified by <statement wordnetid="106722453" confidence="0.8">
<message wordnetid="106598915" confidence="0.8">
<theorem wordnetid="106752293" confidence="0.8">
<proposition wordnetid="106750804" confidence="0.8">
<link xlink:type="simple" xlink:href="../089/49089.xml">
desiderata of rationality and consistency</link></proposition>
</theorem>
</message>
</statement>
 and interpreted as an extension of <link xlink:type="simple" xlink:href="../019/499019.xml">
Aristotelian logic</link><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref>. For the <b>subjectivist school</b>, the state of knowledge corresponds to a 'personal belief' <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%223%22])">3</ref>.  Many of the modern <link xlink:type="simple" xlink:href="../488/233488.xml">
machine learning</link> methods are based on objectivist Bayesian principles <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%224%22])">4</ref>. 
<sec>
<st>
 History </st>

<p>

The term "Bayesian" refers to <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../117/149117.xml">
Thomas Bayes</link></scientist>
</person>
 (1702&ndash;1761), who proved a special case of what is now called <link xlink:type="simple" xlink:href="../569/49569.xml">
Bayes's theorem</link>. <scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../783/344783.xml">
Laplace</link></scientist>
 proved a more general version of the theorem and used it to approach problems in celestial mechanics, medical statistics, <link xlink:type="simple" xlink:href="../651/41651.xml">
reliability</link>, and <link xlink:type="simple" xlink:href="../366/16366.xml">
jurisprudence</link>. </p>
<p>

Although Bayes's theorem has been in use for more than two hundred years (<link xlink:type="simple" xlink:href="../571/49571.xml">
Bayesian inference</link>), the <b>Bayesian interpretation of probability</b> is more recent.  The idea that 'probability' should be interpreted as 'subjective degree of belief in a proposition' was proposed independently by <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<mathematician wordnetid="110301261" confidence="0.8">
<link xlink:type="simple" xlink:href="../825/180825.xml">
Bruno de Finetti</link></mathematician>
</scientist>
</causal_agent>
</person>
</physical_entity>
 in Italy, in <it>Fondamenti Logici del Ragionamento Probabilistico</it> (1930) and by <philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../285/238285.xml">
Frank Ramsey</link></philosopher>
 in Cambridge, in <it>The Foundations of Mathematics</it> (1931).<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%225%22])">5</ref> It was devised to solve problems with the <link xlink:type="simple" xlink:href="../778/917778.xml">
classical definition of probability</link>. </p>
<p>

The word "Bayesian" appeared in the 1950s, but by the 1960s, it became the term preferred by people who sought to escape the strictures of the narrower "<link xlink:type="simple" xlink:href="../869/10869.xml">
frequentist</link>" approach to probability theory.
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%227%22])">7</ref></p>
<p>

Bayesian analysis has been explored further by <scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../498/878498.xml">
Harold Jeffreys</link></scientist>
, <physical_entity wordnetid="100001930" confidence="0.8">
<physicist wordnetid="110428004" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<statistician wordnetid="110653238" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<mathematician wordnetid="110301261" confidence="0.8">
<link xlink:type="simple" xlink:href="../213/168213.xml">
Richard T. Cox</link></mathematician>
</scientist>
</causal_agent>
</statistician>
</person>
</physicist>
</physical_entity>
, <person wordnetid="100007846" confidence="0.9508927676800064">
<statistician wordnetid="110653238" confidence="0.9173553029164789">
<link xlink:type="simple" xlink:href="../404/404404.xml">
I. J. Good</link></statistician>
</person>
, <physical_entity wordnetid="100001930" confidence="0.8">
<president wordnetid="110468559" confidence="0.8">
<executive wordnetid="110069645" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<statistician wordnetid="110653238" confidence="0.8">
<leader wordnetid="109623038" confidence="0.8">
<administrator wordnetid="109770949" confidence="0.8">
<corporate_executive wordnetid="109966255" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<head wordnetid="110162991" confidence="0.8">
<mathematician wordnetid="110301261" confidence="0.8">
<link xlink:type="simple" xlink:href="../914/860914.xml">
L. J. Savage</link></mathematician>
</head>
</scientist>
</causal_agent>
</corporate_executive>
</administrator>
</leader>
</statistician>
</person>
</executive>
</president>
</physical_entity>
 and <scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../971/166971.xml">
Edwin Jaynes</link></scientist>
. Other well-known proponents of Bayesian probability theory have included <baron wordnetid="109840520" confidence="0.8">
<link xlink:type="simple" xlink:href="../973/37973.xml">
John Maynard Keynes</link></baron>
, <link xlink:type="simple" xlink:href="../218/2023218.xml">
B.O. Koopman</link> and <person wordnetid="100007846" confidence="0.9508927676800064">
<statistician wordnetid="110653238" confidence="0.9173553029164789">
<link xlink:type="simple" xlink:href="../225/3502225.xml">
Dennis Lindley</link></statistician>
</person>
, and many 20th-century philosophers.</p>
<p>

In Bayesian theory, the assessment of probability can be approached in several ways. One is based on <link xlink:type="simple" xlink:href="../479/865479.xml">
betting</link>: the degree of belief in a proposition is reflected in the odds that the assessor is willing to bet on the success of a trial of its truth. <physical_entity wordnetid="100001930" confidence="0.8">
<physicist wordnetid="110428004" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<statistician wordnetid="110653238" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<mathematician wordnetid="110301261" confidence="0.8">
<link xlink:type="simple" xlink:href="../213/168213.xml">
Richard T. Cox</link></mathematician>
</scientist>
</causal_agent>
</statistician>
</person>
</physicist>
</physical_entity>
 showed that Bayesian inference is the only inductive inference that is logically consistent.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref></p>

</sec>
<sec>
<st>
Varieties</st>
<p>

<b>Subjective Bayesian probability</b> interprets 'probability' as 'the <it>degree of belief</it> (or <it>strength of belief</it>) an individual has in the truth of a proposition', and is in that respect subjective. Some people who call themselves Bayesians do not accept this subjectivity, whereby they would regard this article's definition of Bayesian probability as mistaken. The chief exponents of this <b>objectivist school</b> were <scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../971/166971.xml">
Edwin Thompson Jaynes</link></scientist>
 and <scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../498/878498.xml">
Harold Jeffreys</link></scientist>
. Perhaps the main objectivist Bayesian now living is <link xlink:type="simple" xlink:href="../273/17086273.xml">
James Berger</link> of Duke University. <link>
José-Miguel Bernardo</link> and others accept some degree of subjectivity but believe a need exists for "<link>
reference priors</link>" in many practical situations.</p>

</sec>
<sec>
<st>
 Applications </st>
<p>

Since the 1950s, Bayesian theory and Bayesian probability have been widely applied through <statement wordnetid="106722453" confidence="0.8">
<message wordnetid="106598915" confidence="0.8">
<theorem wordnetid="106752293" confidence="0.8">
<proposition wordnetid="106750804" confidence="0.8">
<link xlink:type="simple" xlink:href="../089/49089.xml">
Cox's theorem</link></proposition>
</theorem>
</message>
</statement>
, Jaynes' <link xlink:type="simple" xlink:href="../718/201718.xml">
principle of maximum entropy</link> and the <link xlink:type="simple" xlink:href="../479/865479.xml">
Dutch book argument</link>.  In many applications, Bayesian methods are more general and appear to give better results than <link xlink:type="simple" xlink:href="../869/10869.xml">
frequency probability</link> <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref>. <link xlink:type="simple" xlink:href="../552/824552.xml">
Bayes factor</link>s have also been applied with <link xlink:type="simple" xlink:href="../797/36797.xml">
Occam's Razor</link>.  See <link xlink:type="simple" xlink:href="../571/49571.xml">
Bayesian inference</link> and <statement wordnetid="106722453" confidence="0.8">
<message wordnetid="106598915" confidence="0.8">
<theorem wordnetid="106752293" confidence="0.8">
<proposition wordnetid="106750804" confidence="0.8">
<link xlink:type="simple" xlink:href="../569/49569.xml">
Bayes' theorem</link></proposition>
</theorem>
</message>
</statement>
 for mathematical applications.</p>
<p>

Some regard the <link xlink:type="simple" xlink:href="../833/26833.xml">
scientific method</link> as an application of Bayesian probabilist inference <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref>. In this view, Bayes's theorem is explicitly or implicitly used to update the strength of prior scientific beliefs in the truth of <link xlink:type="simple" xlink:href="../281/14281.xml">
hypotheses</link> in the light of new information from observation or <link xlink:type="simple" xlink:href="../861/59861.xml">
experiment</link>. </p>
<p>

Bayesian techniques have recently been applied to filter <link xlink:type="simple" xlink:href="../847/459847.xml">
spam</link> e-mail. A Bayesian spam filter uses a reference set of e-mails to define what is originally believed to be spam.  After the reference has been defined, the filter then uses the characteristics in the reference to define new messages as either spam or legitimate e-mail.  New e-mail messages act as new information, and if mistakes in the definitions of spam and legitimate e-mail are identified by the user, this new information updates the information in the original reference set of e-mails with the hope that future definitions are more accurate. See <link xlink:type="simple" xlink:href="../571/49571.xml">
Bayesian inference</link> and <link xlink:type="simple" xlink:href="../957/3595957.xml">
Bayesian filtering</link>.</p>

</sec>
<sec>
<st>
 See also </st>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../538/23538.xml">
Probability interpretations</link></entry>
<entry level="1" type="bullet">

 <representation wordnetid="105926676" confidence="0.8">
<interpretation wordnetid="105928513" confidence="0.8">
<link xlink:type="simple" xlink:href="../869/10869.xml">
Frequency probability</link></interpretation>
</representation>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../778/63778.xml">
Uncertainty</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../465/317465.xml">
Inference</link></entry>
<entry level="1" type="bullet">

 <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../996/203996.xml">
Bayesian network</link></causal_agent>
</worker>
</assistant>
</model>
</person>
</physical_entity>
</entry>
<entry level="1" type="bullet">

 <process wordnetid="105701363" confidence="0.8">
<thinking wordnetid="105770926" confidence="0.8">
<explanation wordnetid="105793000" confidence="0.8">
<theory wordnetid="105989479" confidence="0.8">
<higher_cognitive_process wordnetid="105770664" confidence="0.8">
<link xlink:type="simple" xlink:href="../311/574311.xml">
Doomsday argument</link></higher_cognitive_process>
</theory>
</explanation>
</thinking>
</process>
 for a controversial use of Bayesian inference</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../758/3015758.xml">
Maximum entropy thermodynamics</link> - Bayesian view of thermodynamics</entry>
<entry level="1" type="bullet">

 <division wordnetid="108220714" confidence="0.8">
<administrative_unit wordnetid="108077292" confidence="0.8">
<branch wordnetid="108401248" confidence="0.8">
<link xlink:type="simple" xlink:href="../439/46439.xml">
Philosophy of mathematics</link></branch>
</administrative_unit>
</division>
</entry>
</list>
</p>

</sec>
<sec>
<st>
Footnotes</st>

<p>

<reflist>
<entry id="1">
ET. Jaynes. <it>Probability Theory: The Logic of Science</it> Cambridge University Press, (2003).  ISBN 0-521-59271-2</entry>
<entry id="2">
Richard T. Cox, Algebra of Probable Inference, The Johns Hopkins University Press, 2001</entry>
<entry id="3">
de Finetti, B. (1974) Theory of probability (2 vols.), J. Wiley &amp; Sons, Inc., New York</entry>
<entry id="4">
Bishop, CM., Pattern Recognition and Machine Learning. Springer, 2007</entry>
<entry id="5">
See p50-1, Gillies 2000 "The subjective theory of probability was discovered independently and at about the same time by Frank Ramsey in Cambridge and Bruno de Finetti in Italy." See Gillies' discussion for its explanation of how the wrong impression came about that Ramsey proposed it first.</entry>
<entry id="6">
Jeff Miller, <weblink xlink:type="simple" xlink:href="http://members.aol.com/jeff570/b.html">
"Earliest Known Uses of Some of the Words of Mathematics (B)"</weblink></entry>
<entry id="7">
Stephen. E. Fienberg, <weblink xlink:type="simple" xlink:href="http://ba.stat.cmu.edu/journal/2006/vol01/issue01/fienberg.pdf">
When did Bayesian Inference become "Bayesian"?</weblink> <it>Bayesian Analysis</it> (2006).</entry>
</reflist>
</p>

</sec>
<sec>
<st>
 External links and references </st>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://drambuie.lanl.gov/~bayes/tutorial.htm">
tutorial on Bayesian probabilities</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.inference.phy.cam.ac.uk/mackay/itila/book.html">
On-line textbook: Information Theory, Inference, and Learning Algorithms</weblink>, by David MacKay, has many chapters on Bayesian methods, including introductory examples; arguments in favour of Bayesian methods (in the style of <scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../971/166971.xml">
Edwin Jaynes</link></scientist>
); state-of-the-art <technique wordnetid="105665146" confidence="0.8">
<know-how wordnetid="105616786" confidence="0.8">
<method wordnetid="105660268" confidence="0.8">
<link xlink:type="simple" xlink:href="../098/56098.xml">
Monte Carlo method</link></method>
</know-how>
</technique>
s, <link xlink:type="simple" xlink:href="../745/12156745.xml">
message-passing method</link>s, and <link xlink:type="simple" xlink:href="../882/171882.xml">
variational methods</link>; and examples illustrating the intimate connections between Bayesian inference and <link xlink:type="simple" xlink:href="../013/8013.xml">
data compression</link>.</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.dcs.qmw.ac.uk/%7Enorman/BBNs/BBNs.htm">
A nice on-line introductory tutorial to Bayesian probability</weblink> from Queen Mary University of London</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://yudkowsky.net/bayes/bayes.html">
An Intuitive Explanation of Bayesian Reasoning</weblink> A very gentle introduction by Eliezer Yudkowsky</entry>
<entry level="1" type="bullet">

 Giffin, A. and Caticha, A. 2007 <weblink xlink:type="simple" xlink:href="http://arxiv.org/abs/0708.1593">
<it>Updating Probabilities with Data and Moments''</it></weblink></entry>
<entry level="1" type="bullet">

 Gillies, D.<it>Philosophical theories of probability</it> Routledge 2000 </entry>
<entry level="1" type="bullet">

 Hacking, I. 1965 <it>The Logic of Statistical Inference</it>  CUP</entry>
<entry level="1" type="bullet">

 Hacking, I. 1967 'Slightly More Realistic Personal Probability' <it>Philosophy of Science</it> vol34</entry>
<entry level="1" type="bullet">

 Hacking, I. 2006  <it>The Emergence of Probability: A Philosophical Study of Early Ideas about Probability, Induction and Statistical Inference: A Philosophical Study of Early ... on Statistical and Probabilistic Mathematics</it> Cambridge University Press </entry>
<entry level="1" type="bullet">

 Jaynes, E.T. (2003) <it>Probability Theory : The Logic of Science</it> Cambridge University Press.</entry>
<entry level="1" type="bullet">

 Jaynes, E.T. (1998) <weblink xlink:type="simple" xlink:href="http://www-biba.inrialpes.fr/Jaynes/prob.html">
<it>Probability Theory : The Logic of Science''</it></weblink>.</entry>
<entry level="1" type="bullet">

Jeffrey, R.C. 1983 <it>The Logic of Decision</it> University of Chicago Press</entry>
<entry level="1" type="bullet">

Jeffrey, R.C. 2004 <it>Subjective Probability: The Real Thing</it>, Cambridge University Press</entry>
<entry level="1" type="bullet">

Kyburg, H.E. 1974 <it>The Logical Foundations of Statistical Inference</it> Reidel</entry>
<entry level="1" type="bullet">

Kyburg, H.E. 1983 <it>Epistemology and Inference</it> University of Minnesota Press</entry>
<entry level="1" type="bullet">

Kyburg, H.E. 1987 'Bayesian versus non-Bayesian Evidential Updating' <it>Artificial   Intelligence</it> 31  </entry>
<entry level="1" type="bullet">

Kyburg &amp; Smokler (eds) 1980 <it>Studies in Subjective Probability</it> Robert E. Krieger</entry>
<entry level="1" type="bullet">

Lad, F. 1996 <it>Operational Subjective Statistical Methods: a mathematical, philosophical and historical introduction</it> New York: John Wiley, 484 pp.</entry>
<entry level="1" type="bullet">

Lakatos, I. 1968 'Changes in the Problem of Inductive Logic' published as Chapter 8 of <it>Philosophical Papers Volume 2</it> Cambridge University Press 1978</entry>
<entry level="1" type="bullet">

 Bretthorst, G. Larry, 1988, <weblink xlink:type="simple" xlink:href="http://bayes.wustl.edu/glb/book.pdf">
<it>Bayesian Spectrum Analysis and Parameter Estimation''</it></weblink> in Lecture Notes in Statistics, 48, Springer-Verlag, New York, New York;</entry>
<entry level="1" type="bullet">

 http://www-groups.dcs.st-andrews.ac.uk/history/Mathematicians/Ramsey.html</entry>
<entry level="1" type="bullet">

 David Howie: <it>Interpreting Probability, Controversies and Developments in the  Early Twentieth Century</it>, Cambridge University Press, 2002, ISBN 0-521-81251-8</entry>
<entry level="1" type="bullet">

 Colin Howson and Peter Urbach: <it>Scientific Reasoning: The Bayesian Approach</it>, Open Court Publishing, 2nd edition, 1993, ISBN 0-8126-9235-7, focuses on the philosophical underpinnings of Bayesian and frequentist statistics.  Argues for the subjective interpretation of probability.</entry>
<entry level="1" type="bullet">

 Luc Bovens and Stephan Hartmann: <it>Bayesian Epistemology</it>. Oxford: Oxford University Press 2003. Extends the Bayesian program to more complex decision scenarios (e.g. dependent and partially reliable witnesses and measurement instruments) using Bayesian Network models. The book also proofs an impossibility theorem for coherence orderings over information sets and offers a measure that induces a partial coherence ordering.</entry>
<entry level="1" type="bullet">

 Jeff Miller <weblink xlink:type="simple" xlink:href="http://members.aol.com/jeff570/b.html">
"Earliest Known Uses of Some of the Words of Mathematics (B)"</weblink></entry>
<entry level="1" type="bullet">

 James Franklin <weblink xlink:type="simple" xlink:href="http://www.press.jhu.edu/books/title_pages/2844.html">
The Science of Conjecture: Evidence and Probability Before Pascal</weblink>, history from a Bayesian point of view.</entry>
<entry level="1" type="bullet">

 Paul Graham <weblink xlink:type="simple" xlink:href="http://www.paulgraham.com/better.html">
"Bayesian spam filtering"</weblink> </entry>
<entry level="1" type="bullet">

 Howard Raiffa <it>Decision Analysis: Introductory Lectures on Choices under Uncertainty</it>. McGraw Hill, College Custom Series. (1997) ISBN 0-07-052579-X</entry>
<entry level="1" type="bullet">

 Devender Sivia, <it>Data Analysis: A Bayesian Tutorial</it>. Oxford: Clarendon Press (1996), pp. 7-8. ISBN 0-19-851889-7</entry>
<entry level="1" type="bullet">

Skyrms, B. 1987 'Dynamic Coherence and Probability Kinematics' <it>Philosophy of Science</it> vol 54</entry>
<entry level="1" type="bullet">

 Henk Tijms: <it>Understanding Probability</it>, Cambridge University Press, 2004</entry>
<entry level="1" type="bullet">

 Is the portrait of Thomas Bayes authentic? <weblink xlink:type="simple" xlink:href="http://www.york.ac.uk/depts/maths/histstat/bayespic.htm">
Who Is this gentleman? When and where was he born?</weblink> <it>The IMS Bulletin</it>, Vol. <b>17</b> (1988), No. 3, pp. 276-278</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.sciam.com/askexpert_question.cfm?articleID=3A86E7BA-E7F2-99DF-3F475245D8E9C780&amp;catID=3&amp;chanID=sa005">
Ask the experts</weblink> on Bayes's Theorem, from <weblink xlink:type="simple" xlink:href="http://sciam.com/">
Scientific American</weblink></entry>
</list>
</p>


</sec>
</bdy>
</interpretation>
</representation>
</article>
