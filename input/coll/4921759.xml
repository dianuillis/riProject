<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 21:29:14[mciao0826] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Corner detection</title>
<id>4921759</id>
<revision>
<id>242295996</id>
<timestamp>2008-10-01T17:58:05Z</timestamp>
<contributor>
<username>Sherurcij</username>
<id>120909</id>
</contributor>
</revision>
<categories>
<category>Computer vision</category>
<category>Image processing</category>
</categories>
</header>
<bdy>

<table style="width: 22em; text-align: left; font-size: 88%; line-height: 1.5em; width:20em;" class="infobox " cellspacing="5">
<row>
<col colspan="2" style="text-align:center; font-size: 125%; font-weight: bold; " class="">
<link xlink:type="simple" xlink:href="../224/1284224.xml">
Feature detection</link></col>
</row>
<row>
<col colspan="2" style="text-align:center; " class="">
 <image width="200px" src="Corner.png">
</image>
Output of a typical corner detection algorithm</col>
</row>
<row>
<header colspan="2" style="text-align:center; ">
<link xlink:type="simple" xlink:href="../680/331680.xml">
Edge detection</link></header>
</row>
<row>
<col colspan="2" style="text-align:center; " class="">
<link xlink:type="simple" xlink:href="../817/476817.xml">
Canny</link></col>
</row>
<row>
<col colspan="2" style="text-align:center; " class="">
<link xlink:type="simple" xlink:href="../817/476817.xml#xpointer(//*[./st=%22Conclusion%22])">
Canny-Deriche</link></col>
</row>
<row>
<col colspan="2" style="text-align:center; " class="">
<link xlink:type="simple" xlink:href="../680/331680.xml#xpointer(//*[./st=%22Differential+edge+detection%22])">
Differential</link></col>
</row>
<row>
<col colspan="2" style="text-align:center; " class="">
<link xlink:type="simple" xlink:href="../116/476116.xml">
Sobel</link></col>
</row>
<row>
<header colspan="2" style="text-align:center; ">
<link xlink:type="simple" xlink:href="../669/7046669.xml">
Interest point detection</link></header>
</row>
<row>
<header colspan="2" style="text-align:center; ">
<link xlink:type="simple" xlink:href="../759/4921759.xml">
Corner detection</link></header>
</row>
<row>
<col colspan="2" style="text-align:center; " class="">
<link xlink:type="simple" xlink:href="../759/4921759.xml#xpointer(//*[./st=%22The+Harris+=26+Stephens+/+Plessey+corner+detection+algorithm%22])">
Harris operator</link></col>
</row>
<row>
<col colspan="2" style="text-align:center; " class="">
<link xlink:type="simple" xlink:href="../759/4921759.xml#xpointer(//*[./st=%22The+Shi+and+Tomasi+corner+detection+algorithm%22])">
Shi and Tomasi</link></col>
</row>
<row>
<col colspan="2" style="text-align:center; " class="">
<link xlink:type="simple" xlink:href="../759/4921759.xml#xpointer(//*[./st=%22The+level+curve+curvature+approach%22])">
Level curve curvature</link></col>
</row>
<row>
<col colspan="2" style="text-align:center; " class="">
<link xlink:type="simple" xlink:href="../759/4921759.xml#xpointer(//*[./st=%22The+SUSAN+corner+detector%22])">
SUSAN</link></col>
</row>
<row>
<col colspan="2" style="text-align:center; " class="">
<link xlink:type="simple" xlink:href="../759/4921759.xml#xpointer(//*[./st=%22The+FAST+feature+detector%22])">
FAST</link></col>
</row>
<row>
<header colspan="2" style="text-align:center; ">
<link xlink:type="simple" xlink:href="../205/6840205.xml">
Blob detection</link></header>
</row>
<row>
<col colspan="2" style="text-align:center; " class="">
<link xlink:type="simple" xlink:href="../205/6840205.xml#xpointer(//*[./st=%22The+Laplacian+of+Gaussian%22])">
Laplacian of Gaussian (LoG)</link></col>
</row>
<row>
<col colspan="2" style="text-align:center; " class="">
<happening wordnetid="107283608" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<movement wordnetid="107309781" confidence="0.8">
<wave wordnetid="107352190" confidence="0.8">
<ripple wordnetid="107344663" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<link xlink:type="simple" xlink:href="../943/3334943.xml">
Difference of Gaussians (DoG)</link></psychological_feature>
</ripple>
</wave>
</movement>
</event>
</happening>
</col>
</row>
<row>
<col colspan="2" style="text-align:center; " class="">
<link xlink:type="simple" xlink:href="../205/6840205.xml#xpointer(//*[./st=%22The+determinant+of+the+Hessian%22])">
Determinant of Hessian  (DoH)</link></col>
</row>
<row>
<col colspan="2" style="text-align:center; " class="">
<link xlink:type="simple" xlink:href="../901/14669901.xml">
Maximally stable extremal regions</link></col>
</row>
<row>
<header colspan="2" style="text-align:center; ">
<mathematical_relation wordnetid="113783581" confidence="0.8">
<function wordnetid="113783816" confidence="0.8">
<link xlink:type="simple" xlink:href="../898/6185898.xml">
Ridge detection</link></function>
</mathematical_relation>
</header>
</row>
<row>
<header colspan="2" style="text-align:center; ">
Affine invariant feature detection</header>
</row>
<row>
<col colspan="2" style="text-align:center; " class="">
<link xlink:type="simple" xlink:href="../265/6866265.xml">
Affine shape adaptation</link></col>
</row>
<row>
<col colspan="2" style="text-align:center; " class="">
<link xlink:type="simple" xlink:href="../078/14664078.xml">
Harris affine</link></col>
</row>
<row>
<col colspan="2" style="text-align:center; " class="">
<link xlink:type="simple" xlink:href="../110/14664110.xml">
Hessian affine</link></col>
</row>
<row>
<header colspan="2" style="text-align:center; ">
Feature description</header>
</row>
<row>
<col colspan="2" style="text-align:center; " class="">
<link xlink:type="simple" xlink:href="../345/1208345.xml">
SIFT</link></col>
</row>
<row>
<col colspan="2" style="text-align:center; " class="">
<link xlink:type="simple" xlink:href="../697/12341697.xml">
SURF</link></col>
</row>
<row>
<col colspan="2" style="text-align:center; " class="">
<link xlink:type="simple" xlink:href="../751/12341751.xml">
GLOH</link></col>
</row>
<row>
<col colspan="2" style="text-align:center; " class="">
<link xlink:type="simple" xlink:href="../795/15895795.xml">
LESH</link></col>
</row>
<row>
<header colspan="2" style="text-align:center; ">
<link xlink:type="simple" xlink:href="../661/1703661.xml">
Scale-space</link></header>
</row>
<row>
<col colspan="2" style="text-align:center; " class="">
<link xlink:type="simple" xlink:href="../404/5481404.xml">
Scale-space axioms</link></col>
</row>
<row>
<col colspan="2" style="text-align:center; " class="">
<link xlink:type="simple" xlink:href="../059/5477059.xml">
Implementation details</link></col>
</row>
<row>
<col colspan="2" style="text-align:center; " class="">
<link xlink:type="simple" xlink:href="../023/15966023.xml">
Pyramids</link></col>
</row>
<row>
<col colspan="2" style="text-align:right;"></col>
</row>
</table>



<p>

<b>Corner detection</b> or the more general terminology <b><link xlink:type="simple" xlink:href="../669/7046669.xml">
interest point detection</link></b> is an approach used within <link xlink:type="simple" xlink:href="../596/6596.xml">
computer vision</link> systems to extract certain kinds of <link xlink:type="simple" xlink:href="../905/14784905.xml">
features</link> and infer the contents of an image. Corner detection is frequently used in <link xlink:type="simple" xlink:href="../935/1022935.xml">
motion detection</link>, <link>
image matching</link>, <link xlink:type="simple" xlink:href="../999/321999.xml">
tracking</link>, <link>
image mosaicing</link>, <link xlink:type="simple" xlink:href="../768/2889768.xml">
panorama stitching</link>, <link xlink:type="simple" xlink:href="../382/764382.xml">
3D modelling</link> and <link xlink:type="simple" xlink:href="../466/14661466.xml">
object recognition</link>. </p>

<sec>
<st>
 Formalization </st>

<p>

A corner can be defined as the intersection of two edges. A corner can also be defined as a point for which there are two dominant and different edge directions in a local neighbourhood of the point. An interest point is a point in an image which has a well-defined position and can be robustly detected.  This means that an interest point can be a corner but it can also be, for example, an isolated point of local intensity maximum or minimum, line endings, or a point on a curve where the curvature is locally maximal.  In practice, most so-called corner detection methods detect interest points in general rather than corners in particular.  As a consequence, if only corners are to be detected it is necessary to do a local analysis of detected interest points to determine which of these are real corners. Unfortunately, in the literature, "corner", "interest point" and "feature" are used somewhat interchangeably, which rather clouds the issue. Specifically, there are several <link xlink:type="simple" xlink:href="../205/6840205.xml">
blob detectors</link> that can be referred to as "interest point operators", but which are sometimes erroneously referred to as "corner detectors". Moreover, there exists a notion of <link xlink:type="simple" xlink:href="../898/6185898.xml">
ridge detection</link> to capture the presence of elongated objects.</p>
<p>

Corner detectors are not usually very robust and often require expert supervision or large redundancies introduced to prevent the effect of individual errors from dominating the recognition task.  The quality of a corner detector is often judged based on its ability to detect the same corner in multiple images, which are similar but not identical, for example having different lighting, translation, rotation and other transforms.  A simple approach to corner detection in images is using <link xlink:type="simple" xlink:href="../057/157057.xml">
correlation</link>, but this gets very computationally expensive and suboptimal.  An alternative approach used frequently is based on a method proposed by Harris and Stephens (below), which in turn is an improvement of a method by Moravec.</p>

</sec>
<sec>
<st>
 The Moravec corner detection algorithm </st>

<p>

This is one of the earliest corner detection algorithms and defines a corner to be a point with low self-similarity. The algorithm tests each pixel in the image to see if a corner is present, by considering how similar a patch centered on the pixel is to nearby, largely overlapping patches. The similarity is measured by taking the sum of squared differences (SSD) between the two patches. A lower number indicates more similarity.</p>
<p>

If the pixel is in a region of uniform intensity, then the nearby patches will look similar. If the pixel is on an edge, then nearby  patches in a direction perpendicular to the edge will look quite different, but nearby patches in a direction parallel to the edge will result only in a small change. If the pixel is on a feature with variation in all directions, then none of the nearby patches will look similar.</p>
<p>

The corner strength is defined as the smallest SSD between the patch and its neighbors (horizontal, vertical and on the two diagonals). If this number is locally maximal, then a feature of interest is present.</p>
<p>

As pointed out by Moravec, one of the main problems with this operator is that it is not <link xlink:type="simple" xlink:href="../865/14865.xml">
isotropic</link>: if an edge is present that is not in the direction of the neighbours, then it will not be detected as an interest point.</p>

</sec>
<sec>
<st>
 The Harris &amp; Stephens / Plessey corner detection algorithm </st>

<p>

Harris and Stephens improved upon Moravec's corner detector by considering the differential of the corner score with respect to direction directly, instead of using shifted patches. It should be noted that this corner score is often referred to as autocorrelation, since the term is used in the paper in which this detector is described. However, the mathematics in the paper clearly indicate that the SSD is used.</p>
<p>

Without loss of generality, we will assume a grayscale 2-dimensional image is used. Let this image be given by <math>I</math>. Consider taking an image patch over the area <math>(u, v)</math> and shifting it by <math>(x, y)</math>. The weighted <it>sum of square difference</it> between these two patches, denoted <math>S</math>, is given by:</p>
<p>

<indent level="1">

<math>
S(x,y) = \sum_u \sum_v w(u,v) \, \left( I(u,v) - I(u-x,v-y) \right)^2
</math>
</indent>

The Harris matrix <math>A</math> is found by approximating <math>S</math> with a second order Taylor series expansion.</p>
<p>

<indent level="1">

<math>
S(x,y) \approx S(0,0) + \begin{pmatrix} x &amp; y \end{pmatrix} \nabla S + \frac{1}{2} \begin{pmatrix} x &amp; y \end{pmatrix} A \begin{pmatrix} x \\ y \end{pmatrix}
</math>
</indent>

where <math> \nabla S </math> and <math> A </math> denote the <link xlink:type="simple" xlink:href="../461/12461.xml">
gradient</link> vector and the <link xlink:type="simple" xlink:href="../108/412108.xml">
Hessian matrix</link> (second derivatives) of <math> S </math>, respectively, both evaluated at <math> \begin{pmatrix} x &amp; y \end{pmatrix} = \begin{pmatrix} 0 &amp; 0 \end{pmatrix} </math>.  Due to the way that <math> S </math> is defined, both <math> S(0,0) </math> and <math> \nabla S </math> vanish, leading to</p>
<p>

<indent level="1">

<math>
S(x,y) \approx \frac{1}{2} \begin{pmatrix} x &amp; y \end{pmatrix} A \begin{pmatrix} x \\ y \end{pmatrix}
</math>
</indent>

which is valid for small <math> \begin{pmatrix} x &amp; y \end{pmatrix} </math>.</p>
<p>

Since <math> S </math> is a function of the image intensity <math> I </math>, <math> A </math> can also be expressed in derivatives of <math> I </math>, taking into account that <math> \begin{pmatrix} x &amp; y \end{pmatrix} = \begin{pmatrix} 0 &amp; 0 \end{pmatrix} </math>:</p>
<p>

<indent level="1">

<math>
A =
\sum_u \sum_v w(u,v)
\begin{bmatrix}
I_x^2 &amp; I_x I_y \\
I_x I_y &amp; I_y^2 
\end{bmatrix}
=
\begin{bmatrix}
\langle I_x^2 \rangle &amp; \langle I_x I_y \rangle\\
\langle I_x I_y \rangle &amp; \langle I_y^2 \rangle
\end{bmatrix},
</math>
</indent>

where angle brackets denote averaging (summation over <math>(u,v)</math>), and the typical notation for <link xlink:type="simple" xlink:href="../565/52565.xml">
partial derivatives</link> is used. If a circular window (or circularly weighted window, such as a <link xlink:type="simple" xlink:href="../552/245552.xml">
Gaussian</link>) is used, then the response will be isotropic.</p>
<p>

A corner (or in general an interest point) is characterized by a large variation of <math> S </math> in all directions of the vector <math> \begin{pmatrix} x &amp; y \end{pmatrix} </math>.  By analyzing the eigenvalues of <math> A </math>, this characterization can be expressed in the following way: <math> A </math> should have two "large" eigenvalues for an interest point.
Based on the magnitudes of the eigenvalues, the following inferences can be made based on this argument:
<list>
<entry level="1" type="number">

If <math>\lambda_1 \approx 0</math> and <math>\lambda_2 \approx 0</math> then there are no features of interest at this pixel <math>(x,y)</math>.</entry>
<entry level="1" type="number">

If <math>\lambda_1 \approx 0</math> and <math>\lambda_2</math> is some large positive values, then an edge is found.</entry>
<entry level="1" type="number">

If <math>\lambda_1</math> and <math>\lambda_2</math> are both large, distinct positive values, then a corner is found.</entry>
</list>
</p>
<p>

Harris and Stephens note that exact computation of the eigenvalues is computationally expensive, since it requires the computation of a <link xlink:type="simple" xlink:href="../208/29208.xml">
square root</link>, and instead suggest the
following function <math>M_c</math>, where <math>\kappa</math> is a tunable sensitivity parameter:</p>
<p>

<indent level="1">

<math>
M_c = \lambda_1 \lambda_2 - \kappa \, (\lambda_1 + \lambda_2)^2
= \operatorname{det}(A) - \kappa \, \operatorname{trace}^2(A)
</math>
</indent>

Therefore, the algorithm does not have to actually compute the <link xlink:type="simple" xlink:href="../495/123495.xml">
eigenvalue decomposition</link> of the matrix <math>A</math> and
instead it is sufficient to evaluate the <link xlink:type="simple" xlink:href="../468/8468.xml">
determinant</link> and <link>
 trace</link> of <math>A</math> to find
corners, or rather interest points in general.</p>
<p>

The value of <math>\kappa</math> has to be determined empirically, and in the literature values in the range 0.04 - 0.15 have been reported as feasible.</p>
<p>

The <link xlink:type="simple" xlink:href="../752/191752.xml">
covariance matrix</link> for the corner position is <math> A^{-1} </math>, i.e.
<math>
\frac{1}{\langle I_x^2 \rangle \langle I_y^2 \rangle - \langle I_x I_y \rangle^2}
\begin{bmatrix}
\langle I_y^2 \rangle &amp; -\langle I_x I_y \rangle\\
-\langle I_x I_y \rangle &amp; \langle I_x^2 \rangle
\end{bmatrix}.
</math></p>

</sec>
<sec>
<st>
 The multi-scale Harris operator </st>

<p>

The computation of the second moment matrix (sometimes also referred to as "structure tensor") <math>A</math> in the Harris operator, requires the computation of image derivatives <math>I_x, I_y</math> in the image domain as well as the summation of non-linear combinations of these derivatives over local neighbourhoods. Since the computation of derivatives usually involves a stage of scale-space smoothing, an operational definition of the Harris operator requires two scale parameters: (i) a <it>local scale</it> for smoothing prior to the computation of image derivatives, and (ii) an <it>integration scale</it> for accumulating the non-linear operations on derivative operators into an integrated image descriptor.</p>
<p>

With <math>I</math> denoting the original image brightness, let <math>L</math> denote the <link xlink:type="simple" xlink:href="../661/1703661.xml">
scale-space</link> representation of <math>I</math> obtained by convolution with a Gaussian kernel
<indent level="1">

<math>g(x, y, t) = \frac {1}{2{\pi} t}e^{-(x^2+y^2)/2t}</math>
</indent>
with local scale parameter <math>t</math>:
<indent level="1">

<math>L(x, y, t)\ = g(x, y, t) * I(x, y)</math>
</indent>
and let <math>L_x = \partial_x L</math> and <math>L_y = \partial_y L</math> denote the partial derivatives of <math>L</math>.
Moreover, introduce a Gaussian window function <math>g(x, y, s)</math> with integration scale parameter <math>s</math>. Then, the <it>multi-scale second-moment matrix</it> (Lindeberg and Garding 1997) can be defined as
<indent level="1">

<math>
\mu(x, y; t, s) =
\int_{\xi = -\infty}^{\infty} \int_{\eta = -\infty}^{\infty}
\begin{bmatrix}
 L_x^2(x-\xi, y-\eta; t)                               &amp; L_x(x-\xi, y-\eta; t) \, L_y(x-\xi, y-\eta; t) \\
L_x(x-\xi, y-\eta; t) \, L_y(x-\xi, y-\eta; t) &amp; L_y^2(x-\xi, y-\eta; t) 
\end{bmatrix}
g(\xi, \eta; s) \, d\xi \, d\eta.
</math>
</indent>
Then, we can compute eigenvalues of <math>\mu</math> in a similar way as the eigenvalues of <math>A</math> and define the <it>multi-scale Harris corner measure</it> as 
<indent level="1">

<math>M_c(x, y; t, s) = \operatorname{det}(\mu(x, y; t, s)) - \kappa \, \operatorname{trace}^2(\mu(x, y; t, s))</math>. 
</indent>
Concerning the choice of the local scale parameter <math>t</math> and the integration scale parameter <math>s</math>, these scale parameters are usually coupled by a relative integration scale parameter <math>\gamma</math> such that <math>s = \gamma^2 t</math>, where <math>\gamma</math> is usually chosen in the interval <math>[\sqrt{2}, 2]</math>. Thus, we can compute the multi-scale Harris corner measure <math>M_c(x, y; t, \gamma^2 t)</math> at any scale <math>t</math> in scale-space to obtain a multi-scale corner detector, which responds to corner structures of varying sizes in the image domain (Baumberg 2000).</p>
<p>

In practice, this multi-scale corner detector is often complemented by a <it>scale selection step</it>, where the scale-normalized Laplacian operator (Lindeberg 1998)
<indent level="1">

<math>\nabla^2_{norm} L(x, y; t)\ = t \nabla^2 L(x, y, t) = t (L_{xx}(x, y, t) + L_{yy}(x, y, t))</math> 
</indent>
is computed at every scale in scale-space and <it>scale adapted corner points with automatic scale selection</it> (the "Harris-Laplace operator") are computed from the points that are simultaneously (Mikolajczyk and Schmid 2004):</p>

<p>

spatial maxima of the multi-scale corner measure <math>M_c(x, y; t, \gamma^2 t)</math> 
<indent level="1">

<math>(\hat{x}, \hat{y}; t) = \operatorname{argmaxlocal}_{(x, y)} M_c(x, y; t, \gamma^2 t)</math>
</indent>

local maxima or minima over scales of the scale-normalized Laplacian operator <math>\nabla^2_{norm}(x, y, t)</math>
<indent level="1">

<math>\hat{t} = \operatorname{argmaxminlocal}_{t} \nabla^2_{norm}L(\hat{x}, \hat{y}; t)</math>.
</indent>
</p>

</sec>
<sec>
<st>
 The Shi and Tomasi corner detection algorithm </st>

<p>

Note that this is also sometimes referred to as the Kanade-Tomasi corner detector.</p>
<p>

The corner detector is strongly based on the Harris corner detector. The authors show that for image patches undergoing affine transformations, <math>min(\lambda_1, \lambda_2)</math> is a better measure of corner strength than <math>M_c</math>.</p>

</sec>
<sec>
<st>
 The level curve curvature approach </st>

<p>

An earlier approach to corner detection is to detect points where the <link xlink:type="simple" xlink:href="../770/60770.xml">
curvature</link> of level curves and the gradient magnitude are <it>simultaneously</it> high. A differential way to detect such points is to compute <it>the rescaled level curve curvature</it> (the product of the level curve curvature and the gradient magnitude raised to the power of three)
<indent level="1">

<math>\tilde{\kappa}(x, y;t) = L_x^2 L_{yy} + L_y^2 L_{xx} - 2 L_x L_y L_{xy}</math>
</indent>
and to detect positive maxima and negative minima of this differential expression at some scale <math>t</math> in the <link xlink:type="simple" xlink:href="../661/1703661.xml">
scale-space</link> representation <math>L</math> of the original image. A main problem with this approach, however, is that it is sensitive to noise and to the choice of the scale level. A better method is to compute the <it><math>\gamma</math>-normalized rescaled level curve curvature</it>
<indent level="1">

<math>\tilde{\kappa_{norm}}(x, y;t) = t^{2 \gamma} (L_x^2 L_{yy} + L_y^2 L_{xx} - 2 L_x L_y L_{xy})</math>
</indent>
with <math>\gamma = 7/8</math> and to detect <it>signed scale-space maxima</it> of this expression, that are points and scales that are positive maxima and negative minima with respect to both space and scale
<indent level="1">

<math>(\hat{x}, \hat{y}; \hat{t}) = \operatorname{argmaxlocal}_{(x, y; t)} \tilde{\kappa}_{norm}(x, y; t)</math>
</indent>
in combination with a complementary localization step to handle the increase in localization error at coarser scales (Lindeberg 1998). In this way, larger scale values will be associated with rounded corners of large spatial extent while smaller scale values will be associated with sharp corners with small spatial extent. This approach is the first corner detector with automatic scale selection (prior to the "Harris-Laplace operator" above) and has been used by (Bretzner and Lindeberg 1998) for tracking corners under large scale variations in the image domain.</p>

</sec>
<sec>
<st>
 LoG, DoG, and DoH feature detection </st>

<p>

LoG is an acronym standing for Laplacian of Gaussian, DoG is an acronym standing for Difference of Gaussians (DoG is an approximation of LoG), and DoH is an acronym standing for Determinant of the Hessian.</p>
<p>

These detectors are more completely described in <link xlink:type="simple" xlink:href="../205/6840205.xml">
blob detection</link>, however the LoG and DoG blobs do not necessarily make highly selective features, since these operators may also respond to edges. To improve the corner detection ability of the DoG detector, the feature detector used in the <link xlink:type="simple" xlink:href="../345/1208345.xml">
SIFT</link> system uses an additional post-processing stage, where the <link xlink:type="simple" xlink:href="../429/2161429.xml">
eigenvalue</link>s of the <link xlink:type="simple" xlink:href="../108/412108.xml">
Hessian</link> of the image at the detection scale are examined in a similar way as in the Harris operator. If the ratio of the eigenvalues is too high, then the local image is regarded as too edge-like, so the feature is rejected. The DoH operator on the other hand only responds when there are significant grey-level variations in two directions.</p>

</sec>
<sec>
<st>
 The Wang and Brady corner detection algorithm </st>

<p>

The Wang and Brady detector considers the image to be a surface, and looks for places where there is large <link xlink:type="simple" xlink:href="../770/60770.xml">
curvature</link> along an image edge. In other words, the algorithm looks for places where the edge changes direction rapidly. The corner score, <math>C</math>, is given by:</p>
<p>

<indent level="1">

<math>
C = \nabla^2I - c|\nabla I|^2,
</math>
</indent>

where <math>c</math> determines how edge-phobic the detector is. The authors also note that smoothing (Gaussian is suggested) is required to reduce noise. In this case, the first term of <math>C</math> becomes the Laplacian (single-scale) <link xlink:type="simple" xlink:href="../205/6840205.xml">
blob detector</link>.</p>
<p>

Smoothing also causes displacement of corners, so the authors derive an expression for the displacement of a 90 degree corner, and apply this as a correction factor to the detected corners.</p>

</sec>
<sec>
<st>
 The SUSAN corner detector </st>

<p>

SUSAN as an acronym standing for Smallest Univalue Segment Assimilating Nucleus.</p>
<p>

For feature detection, SUSAN places a circular mask over the pixel to be tested (the nucleus). The region of the mask is <math>M</math>, and a pixel in this mask is represented by <math>\vec{m} \in M</math>. The nucleus is at <math>\vec{m}_0</math>. Every pixel is compared to the nucleus using the comparison function:</p>
<p>

<math>
c(\vec{m}) = e^{\frac{(I(\vec{m}) - I(\vec{m}_0))^6}{t}}
</math></p>
<p>

where <math>t</math> determines the width, and the power of the exponent has been determined empirically. This function has the appearance of a smoothed <mathematical_relation wordnetid="113783581" confidence="0.8">
<function wordnetid="113783816" confidence="0.8">
<link xlink:type="simple" xlink:href="../615/1261615.xml">
top-hat or rectangular function</link></function>
</mathematical_relation>
. The area of the SUSAN is given by:</p>
<p>

<math>
n(M) = \sum_{\vec{m}\in M} c(\vec{m})
</math></p>
<p>

If <math>c</math> is the rectangular function, then <math>n</math> is the number of pixels in the mask which are within <math>t</math> of the nucleus. The response of the SUSAN operator is given by:</p>
<p>

<math>
R(M) =     \begin{cases}
               g - n(M) &amp; \mbox{if}\ n(M) &amp;lt; g\\
               0        &amp; \mbox{otherwise,}
           \end{cases}
</math></p>
<p>

where <math>g</math> is named the `geometric threshold'. In other words the SUSAN operator only has a positive score if the area is small enough. The smallest USAN locally can be found using non-maximal suppression, and this is the complete SUSAN operator.</p>
<p>

The value <math>t</math> determines how similar points have to be to the nucleus before they are considered to be part of the univalue segment. The value of <math>g</math> determines the minimum size of the univalue segment. If <math>g</math> is large enough, then this becomes an <link xlink:type="simple" xlink:href="../680/331680.xml">
edge detector</link>.</p>
<p>

For corner detection, two further steps are used. Firstly, the <link xlink:type="simple" xlink:href="../926/187926.xml">
centroid</link> of the USAN if found. A proper corner will have the centroid far from the nucleus. The second step insists that all points on the line from the nucleus through the centroid out to the edge of the mask are in the SUSAN.</p>
<p>

This technique is patented with UK patent  2272285.</p>

</sec>
<sec>
<st>
The Trajkovic and Hedley corner detector </st>

<p>

In a manner similar to SUSAN, this detector directly tests whether a patch under a pixel is self-similar by examining nearby pixels. <math>\vec{c}</math> is the pixel to be considered, and <math>\vec{p} \in P</math> is point on a circle <math>P</math> centered around <math>\vec{c}</math>. The point <math>\vec{p'}</math> is the point opposite to <math>\vec{p}</math> along the diameter.</p>
<p>

The response function is defined as:</p>
<p>

<math>
  r(\vec{c}) = \min_{\vec{p} \in P}\quad (I(\vec{p}) - I(\vec{c}))^2 + (I(\vec{p'}) - I(\vec{c})) ^2
</math></p>
<p>

This will be large when there is no direction in which the centre pixel is similar to two nearby pixels along a diameter. <math>P</math> is a discretised circle (a <link>
Bresenham circle</link>), so interpolation is used for intermediate diameters to give a more isotropic response. Since any computation gives an upper bound on <math>\lim</math>, the horizontal and vertical directions are checked to see if it is worth proceeding with the complete computation of <math>c</math>.</p>

</sec>
<sec>
<st>
 The FAST feature detector </st>

<p>

FAST is an acronym standing for Features from Accelerated Segment Test.</p>
<p>

The feature detector considers pixels in a <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../133/9732133.xml">
Bresenham circle</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
 of radius <math>r</math> around the candidate point. If <math>n</math> contiguous pixels are all brighter than the nucleus by at least <math>t</math> or all darker than the nucleus by <math>t</math>, then the pixel under the nucleus is considered to be a feature. 
Although <math>r</math> can in principle take any value, only a value of 3 is used (corresponding to a circle of 16 pixels circumference), and tests show that the best value of <math>n</math> is 9. This value of <math>n</math> is the lowest one at which edges are not detected. The resulting detector is reported to produce very stable features. Additionally,
the <plant wordnetid="100017222" confidence="0.8">
<tree wordnetid="113104059" confidence="0.8">
<vascular_plant wordnetid="113083586" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<woody_plant wordnetid="113103136" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../797/1966797.xml">
ID3</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</woody_plant>
</rule>
</event>
</vascular_plant>
</tree>
</plant>
 algorithm is used to optimize the order in which pixels are tested, resulting in the most computationally efficient feature detector available.</p>
<p>

Confusingly, the name of the detector is somewhat similar to the name of the paper describing Trajkovic and Hedley's detector.</p>

</sec>
<sec>
<st>
 Affine-adapted interest point operators </st>

<p>

The interest points obtained from the multi-scale Harris operator with automatic scale selection are invariant to translations, rotations and uniform rescalings in the spatial domain. The images that constitute the input to a computer vision system are, however, also subject to perspective distortions. To obtain an interest point operator that is more robust to perspective transformations, a natural approach is to devise a feature detector that is <it>invariant to affine transformations</it>. In practice, affine invariant interest points can be obtained by applying <link xlink:type="simple" xlink:href="../265/6866265.xml">
affine shape adaptation</link> where the shape of the smoothing kernel is iteratively warped to match the local image structure around the interest point or equivalently a local image patch is iteratively warped while the shape of the smoothing kernel remains rotationally symmetric (Lindeberg and Garding 1997; Baumberg 2000; Mikolajczyk and Schmid 2004). Hence, besides the commonly used multi-scale Harris operator, affine shape adaptation can be applied to other corner detectors as listed in this article as well as to <link xlink:type="simple" xlink:href="../205/6840205.xml">
differential blob detectors</link> such as the Laplacian/Difference of Gaussian operator, the determinant of the Hessian and the Hessian-Laplace operator.</p>

</sec>
<sec>
<st>
 References </st>

<p>

<list>
<entry level="1" type="bullet">

  <cite style="font-style:normal">A. Baumberg&#32;(2000). "<weblink xlink:type="simple" xlink:href="http://citeseer.ist.psu.edu/baumberg00reliable.html">
Reliable feature matching across widely separated views</weblink>".&#32;<it>Proceedings of IEEE Conference on Computer Vision and Pattern Recognition</it>: pages I:1774--1781.</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite style="font-style:normal">L. Bretzner and T. Lindeberg&#32;(1998).&#32;"<weblink xlink:type="simple" xlink:href="http://www.nada.kth.se/cvap/abstracts/cvap201.html">
Feature tracking with automatic selection of spatial scales</weblink>". <it>Computer Vision and Image Understanding</it>&#32;<b>71</b>: pp 385--392.</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite style="font-style:normal">M.J. Brooks and W. Chojnacki and D. Gawley and A. van den Hengel&#32;(2001). "<weblink xlink:type="simple" xlink:href="http://www.cs.adelaide.edu.au/users/mjb/Papers/iccv01.pdf">
What Value Covariance Information in Estimating Vision Parameters?</weblink>".&#32;<it>Proceedings of the 8th Int'l Conf. on Computer Vision</it>&#32;<b>1</b>: pp 302-308.</cite>&nbsp;</entry>
<entry level="1" type="bullet">

 K. Derpanis.&#32;"<it><weblink xlink:type="simple" xlink:href="http://www.cse.yorku.ca/~kosta/CompVis_Notes/harris_detector.pdf">
The Harris Corner Detector</weblink></it>".</entry>
<entry level="1" type="bullet">

  <cite style="font-style:normal">C. Harris and M. Stephens&#32;(1988). "<weblink xlink:type="simple" xlink:href="http://www.csse.uwa.edu.au/~pk/research/matlabfns/Spatial/Docs/Harris/A_Combined_Corner_and_Edge_Detector.pdf">
A combined corner and edge detector</weblink>".&#32;<it>Proceedings of the 4th Alvey Vision Conference</it>: pp 147--151.</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite style="font-style:normal" class="book">C. Harris.&#32;(1992).&#32;"Geometry from visual motion",&#32;in A. Blake and A. Yuille: Active Vision.&#32;MIT Press, Cambridge MA.</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite style="font-style:normal">T. Lindeberg&#32;(1998).&#32;"<weblink xlink:type="simple" xlink:href="http://www.nada.kth.se/cvap/abstracts/cvap198.html">
Feature detection with automatic scale selection</weblink>". <it>International Journal of Computer Vision</it>&#32;<b>30</b>&#32;(2): pp 77--116.</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite style="font-style:normal">T. Lindeberg and J. Garding&#32;(1997).&#32;"<weblink xlink:type="simple" xlink:href="http://www.nada.kth.se/~tony/abstracts/LG94-ECCV.html">
Shape-adapted smoothing in estimation of 3-{D} depth cues from affine distortions of local 2-{D} structure</weblink>". <it>International Journal of Computer Vision</it>&#32;<b>15</b>: pp 415--434.</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite style="font-style:normal">D. Lowe&#32;(2004).&#32;"<weblink xlink:type="simple" xlink:href="http://citeseer.ist.psu.edu/654168.html">
Distinctive Image Features from Scale-Invariant Keypoints</weblink>". <it>International     Journal of Computer Vision</it>.</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite style="font-style:normal">K. Mikolajczyk, K. and C. Schmid&#32;(2004).&#32;"<weblink xlink:type="simple" xlink:href="http://www.robots.ox.ac.uk/~vgg/research/affine/det_eval_files/mikolajczyk_ijcv2004.pdf">
Scale and affine invariant interest point detectors</weblink>". <it>International Journal of Computer Vision</it>&#32;<b>60</b>&#32;(1): pp 63 - 86.</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite style="font-style:normal">H. Moravec&#32;(1980).&#32;"<weblink xlink:type="simple" xlink:href="http://www.ri.cmu.edu/pubs/pub_22.html">
Obstacle Avoidance and Navigation in the Real World by a Seeing Robot Rover</weblink>". <it>Tech Report CMU-RI-TR-3 Carnegie-Mellon University, Robotics Institute</it>.</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite style="font-style:normal">E. Rosten and T. Drummond&#32;(May 2006). "<weblink xlink:type="simple" xlink:href="http://citeseer.ist.psu.edu/741064.html">
Machine learning for high-speed corner detection,</weblink>".&#32;<it>European Conference on Computer Vision</it>.</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite style="font-style:normal">J. Shi and C. Tomasi&#32;(June 1994). "<weblink xlink:type="simple" xlink:href="http://citeseer.ist.psu.edu/shi94good.html">
Good Features to Track,</weblink>".&#32;<it>9th IEEE Conference on Computer Vision and Pattern Recognition</it>, Springer.</cite>&nbsp;</entry>
<entry level="1" type="bullet">

 <cite style="font-style:normal">S. M. Smith and J. M. Brady&#32;(May 1997).&#32;"<weblink xlink:type="simple" xlink:href="http://citeseer.ist.psu.edu/smith95susan.html">
SUSAN - a new approach to low level image processing.</weblink>". <it>International Journal of Computer Vision</it>&#32;<b>23</b>: 45-78.</cite>&nbsp;</entry>
<entry level="1" type="bullet">

<it>S. M. Smith and J. M. Brady (January 1997), "Method for digitally processing images to determine the position of edges and/or corners therein for guidance of unmanned vehicle". UK Patent 2272285, Proprietor: Secretary of State for Defence, UK.''</it></entry>
<entry level="1" type="bullet">

  <cite style="font-style:normal">C. Tomasi and T. Kanade&#32;(2004).&#32;"<weblink xlink:type="simple" xlink:href="http://www.sciencedirect.com/science?_ob=ArticleURL&amp;_udi=B6V14-49D6WH0-1&amp;_user=10&amp;_rdoc=1&amp;_fmt=&amp;_orig=search&amp;_sort=d&amp;view=c&amp;_version=1&amp;_urlVersion=0&amp;_userid=10&amp;md5=cecb6ab80d45107f1cedb17aa4b211fb">
Detection and Tracking of Point Features</weblink>". <it>Pattern Recognition</it>.</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite style="font-style:normal">R. Dinesh and D.S. Guru&#32;(2004).&#32;"<weblink xlink:type="simple" xlink:href="http://www.sciencedirect.com/science?_ob=ArticleURL&amp;_udi=B6V09-3Y450Y2-8&amp;_coverDate=11%2F30%2F1995&amp;_alid=442214633&amp;_rdoc=1&amp;_fmt=&amp;_orig=search&amp;_qd=1&amp;_cdi=5641&amp;_sort=d&amp;view=c&amp;_acct=C000057551&amp;_version=1&amp;_urlVersion=0&amp;_userid=2493154&amp;md5=b0979efc3df88572ec71d07e2e9f14da">
Non-parametric adaptive region of support useful for corner detection: a novel approach</weblink>". <it>Pattern Recognition</it>.</cite>&nbsp;</entry>
<entry level="1" type="bullet">

 <cite style="font-style:normal">M. Trajkovic and M. Hedley&#32;(1998).&#32;"Fast corner detection". <it>Image and Vision Computing</it>&#32;<b>16</b>: 75-87.</cite>&nbsp;</entry>
<entry level="1" type="bullet">

  <cite style="font-style:normal">H. Wang and M. Brady&#32;(1995).&#32;"<weblink xlink:type="simple" xlink:href="http://www.sciencedirect.com/science?_ob=ArticleURL&amp;_udi=B6V09-3Y450Y2-8&amp;_coverDate=11%2F30%2F1995&amp;_alid=442214633&amp;_rdoc=1&amp;_fmt=&amp;_orig=search&amp;_qd=1&amp;_cdi=5641&amp;_sort=d&amp;view=c&amp;_acct=C000057551&amp;_version=1&amp;_urlVersion=0&amp;_userid=2493154&amp;md5=b0979efc3df88572ec71d07e2e9f14da">
Real-time corner detection algorithm for motion estimation.</weblink>". <it>Image and Vision Computing</it>&#32;<b>13</b>: 695-703.</cite>&nbsp;</entry>
</list>
</p>

</sec>
<sec>
<st>
 Reference Implementations </st>

<p>

This section provides external links to reference implementations of some of the detectors described above. These reference implementations are provided by the authors of the paper in which the detector is first described. These may contain details not present or explicit in the papers describing the features.</p>
<p>

<list>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.fmrib.ox.ac.uk/~steve/susan/susan2l.c">
SUSAN detector</weblink>, C source code</entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.cs.ubc.ca/spider/lowe/keypoints/siftDemoV4.zip">
DoG detection</weblink> (as part of the <link xlink:type="simple" xlink:href="../345/1208345.xml">
SIFT</link> system), <link xlink:type="simple" xlink:href="../890/18890.xml">
Windows</link> and <link xlink:type="simple" xlink:href="../198/34198.xml">
x86</link> <O wordnetid="106832680" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../297/6097297.xml">
Linux</link></O>
 executables</entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://lear.inrialpes.fr/people/dorko/ipld/ipld_static.tgz">
Harris-Laplace</weblink>, static <O wordnetid="106832680" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../297/6097297.xml">
Linux</link></O>
 executables. Also contains DoG and LoG detectors and affine adaptation for all detectors included.</entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://svr-www.eng.cam.ac.uk/~er258/work/fast.html">
FAST detector</weblink>, C, C++, MATLAB source code and executables for various operating systems and architectures.</entry>
<entry level="1" type="bullet">

http://www.sciencedirect.com/science?_ob=ArticleURL&amp;_udi=B6V14-49D6WH0-1&amp;_user=10&amp;_rdoc=1&amp;_fmt=&amp;_orig=search&amp;_sort=d&amp;view=c&amp;_version=1&amp;_urlVersion=0&amp;_userid=10&amp;md5=cecb6ab80d45107f1cedb17aa4b211fb</entry>
</list>
</p>

</sec>
<sec>
<st>
 See also </st>

<p>

<list>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../205/6840205.xml">
blob detection</link></entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../265/6866265.xml">
affine shape adaptation</link></entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../661/1703661.xml">
scale-space</link></entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../898/6185898.xml">
ridge detection</link></entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../669/7046669.xml">
interest point detection</link></entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../224/1284224.xml">
feature detection (computer vision)</link></entry>
</list>
</p>


</sec>
</bdy>
</article>
