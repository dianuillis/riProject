<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 21:30:57[mciao0825] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Reactive planning</title>
<id>5034376</id>
<revision>
<id>217522243</id>
<timestamp>2008-06-06T12:15:34Z</timestamp>
<contributor>
<username>Hawkestone</username>
<id>969493</id>
</contributor>
</revision>
<categories>
<category>Automated planning and scheduling</category>
</categories>
</header>
<bdy>

"Dynamic planning" redirects here. For the anime studio, see <company wordnetid="108058098" confidence="0.8">
<institution wordnetid="108053576" confidence="0.8">
<link xlink:type="simple" xlink:href="../265/7708265.xml">
Dynamic Planning</link></institution>
</company>
.<p>

In <link xlink:type="simple" xlink:href="../164/1164.xml">
artificial intelligence</link>, <b>reactive planning</b> denotes a group of techniques for <link xlink:type="simple" xlink:href="../373/5033373.xml">
action selection</link> by <link xlink:type="simple" xlink:href="../317/2711317.xml">
autonomous agents</link>. These techniques differ from <link xlink:type="simple" xlink:href="../641/1505641.xml">
classical planning</link> in two aspects. First, they operate in a timely fashion and hence can cope with highly dynamic and unpredictable <link>
 environments</link>. Second, they compute just one next action in every instant, based on the current context.  Reactive planners often (but not always) exploit <b>reactive plans</b>, which are stored structures describing the agent's priorities and behaviour.</p>
<p>

Although the term <it>reactive planning</it> goes back to at least <link xlink:type="simple" xlink:href="../670/34670.xml">
1988</link>, the term <link xlink:type="simple" xlink:href="../050/1290050.xml">
reactive</link> has now become a <link xlink:type="simple" xlink:href="../955/48955.xml">
pejorative</link> used as an <link xlink:type="simple" xlink:href="../930/147930.xml">
antonym</link> for <link xlink:type="simple" xlink:href="../145/3038145.xml">
proactive</link>.  Since nearly all agents using reactive planning <it>are</it> proactive, some researchers have begun referring to reactive planning as <b>dynamic planning</b>.</p>

<sec>
<st>
 Reactive plan representation </st>

<p>

There are several ways to represent a reactive plan. All require a basic representational unit and a means to compose these units into plans. </p>

<ss1>
<st>
 Condition-action rules (productions) </st>

<p>

A condition action rule, or if-then rule, is a rule in the form: <b>if</b> <it>condition</it> <b>then</b> <it>action</it>. These rules are called <link xlink:type="simple" xlink:href="../457/3157457.xml">
productions</link>. The meaning of the rule is as follows: if the condition holds, perform the action. The action can be either external (e.g., pick something up and move it), or internal (e.g., write a fact into the internal memory, or evaluate a new set of rules). Conditions are normally boolean and the action either can be performed, or not. </p>
<p>

Production rules may be organised in relatively flat structures, but more often are organized into a <link xlink:type="simple" xlink:href="../998/13998.xml">
hierarchy</link> of some kind.  For example,  <link xlink:type="simple" xlink:href="../552/83552.xml">
subsumption architecture</link> consists of layers of interconnected <it>behaviors</it>, each actually a <link xlink:type="simple" xlink:href="../931/10931.xml">
finite state machine</link> which acts in response to an appropriate input.  These layers are then organized into a simple stack, with higher layers subsuming the goals of the lower ones.  Other systems may use <link xlink:type="simple" xlink:href="../806/30806.xml">
trees</link>, or may include special mechanisms for changing which goal / rule subset is currently most important.  Flat structures are relatively easy to build, but allow only for description of simple behaviour, or require immensely complicated conditions to compensate for the lacking structure.</p>
<p>

An important part of any distributed <link xlink:type="simple" xlink:href="../373/5033373.xml">
action selection</link> algorithms is a conflict resolution mechanism. This is a mechanism for resolving conflicts between actions proposed when more than one rules' condition holds in a given instant. The conflict can be solved for example by 
<list>
<entry level="1" type="bullet">

 assigning fixed priorities to the rules in advance (e.g. in <weblink xlink:type="simple" xlink:href="http://www.bath.ac.uk/comp-sci/ai/AmonI-sw.html#BOD">
POSH</weblink> architecture), </entry>
<entry level="1" type="bullet">

 assigning preferences (e.g. in <link xlink:type="simple" xlink:href="../751/729751.xml">
Soar</link> architecture),</entry>
<entry level="1" type="bullet">

 learning relative utilities between rules (e.g. in <link xlink:type="simple" xlink:href="../071/821071.xml">
ACT-R</link>),  </entry>
<entry level="1" type="bullet">

 exploiting a form of <link xlink:type="simple" xlink:href="../641/1505641.xml">
planning</link>.</entry>
</list>
</p>
<p>

Expert systems often use other simpler <link xlink:type="simple" xlink:href="../452/63452.xml">
heuristic</link>s such as <link>
recency</link> for selecting rules, but it is difficult to guarantee good behaviour in a large system with simple approaches.</p>
<p>

Conflict resolution is only necessary for rules that want to take mutually exclusive actions (c.f. Blumberg 1996).</p>
<p>

Some limitations of this kind of reactive planning can be found in Brom (2005).</p>

</ss1>
<ss1>
<st>
 Finite State Machines </st>

<p>

<know-how wordnetid="105616786" confidence="0.8">
<method wordnetid="105660268" confidence="0.8">
<link xlink:type="simple" xlink:href="../931/10931.xml">
Finite state machine</link></method>
</know-how>
 (FSM) is model of behaviour of a system. FSMs are used widely in computer science. Modelling behaviour of <link xlink:type="simple" xlink:href="../317/2711317.xml">
agents</link> is only one of their possible applications.
A typical FSM, when used for describing behaviour of an agent, consists of a set of states and transitions between these states. The transitions are actually condition action rules. In every instant, just one state of the FSM is active, and its transitions are evaluated. If a transition is taken it activates another state. That means, in general transitions are the rules in the following form: <b>if</b> <it>condition</it> <b>then</b> <it>activate-new-state</it>. But transitions can also connect to the 'self' state in some systems, to allow execution of transition actions without actually changing the state.</p>
<p>

There are two ways of how to produce behaviour by a FSM. They depend on what is associated with the states by a designer --- they can be either 'acts', or scripts. An 'act' is an atomic action that should be performed by the agent if its FSM is the given state. This action is performed in every time step then. However, more often is the latter case. Here, every state is associated with a script, which describes a sequence of actions that the agent has to perform if its FSM is in a given state. If a transition activates a new state, the former script is simply interrupted, and the new one is started.</p>
<p>

If a script is more complicated, it can be broken down to several scripts and a hierarchical FSM can be exploited. In such an automaton, every state can contain substates. Only the states at the atomic level are associated with a script (which is not complicated) or an atomic action.</p>
<p>

Computationally, hierarchical FSMs are equivalent to FSMs. That means that each hierarchical FSM can be converted to a classical FSM. However, hierarchical approaches facilitate designs better.
See the <weblink xlink:type="simple" xlink:href="http://www.gamasutra.com/gdc2005/features/20050311/isla_pfv.htm">
paper</weblink> of Damian Isla (2005) for an example of ASM of <link xlink:type="simple" xlink:href="../583/1839583.xml">
computer game bot</link>s, which uses hierarchical FSMs.</p>

</ss1>
<ss1>
<st>
 Fuzzy approaches </st>

<p>

Both if-then rules and FSMs can be combined with <link xlink:type="simple" xlink:href="../180/49180.xml">
fuzzy logic</link>. The conditions, states and actions are no more boolean or "yes/no" respectively but are approximate and smooth. Consequently, resulted behaviour will transition smoother, especially in the case of transitions between two tasks. However, evalutation of the fuzzy conditions is much slower than evaluation of their crisp counterparts.</p>
<p>

See the <weblink xlink:type="simple" xlink:href="http://aigamedev.com/">
architecture of Alex Champandard</weblink>.</p>

</ss1>
<ss1>
<st>
 Connectionists approaches </st>

<p>

Reactive plans can be expressed also by <link xlink:type="simple" xlink:href="../636/263636.xml">
connectionist networks</link> like <link xlink:type="simple" xlink:href="../523/21523.xml">
artificial neural networks</link> or free-flow hierarchies. The basic representational unit is a unit with several input links that feed the unit with "an abstract activity" and output links that propagate the activity to following units. Each unit itself works as the activity transducer. Typically, the units are connected in a layered structure.</p>
<p>

Positives of connectionist networks is, first, that the resulted behaviour is more smooth than behaviour produced by crisp if-then rules and FSMs, second, the networks are often adaptive, and third, mechanism of inhibition can be used and hence, behaviour can be also described proscriptively (by means of rules one can describe behaviour only prescriptively). However, the methods have also several flaws. First, for a designer, it is much more complicated to describe behaviour by a network comparing with if-then rules. Second, only relatively simple behaviour can be described, especially if adaptive feature is to be exploited.  </p>

</ss1>
</sec>
<sec>
<st>
 Reactive planning algorithms </st>

<p>

Typical reactive planning algorithm just evaluates if-then rules or computes the state of a connectionist network. However, some algorithms have special features.</p>
<p>

<list>
<entry level="1" type="bullet">

<system wordnetid="104377057" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<link xlink:type="simple" xlink:href="../566/172566.xml">
Rete evaluation</link></instrumentality>
</artifact>
</system>
: with a proper logic representation (which is suitable only for crisp rules), the rules need not to be re-evaluated at every time step. Instead, a form of a cache storing the evaluation from the previous step can be used.</entry>
<entry level="1" type="bullet">

Scripting languages: Sometimes, the rules or FSMs are directly the primitives of an architecture (e.g. in <link xlink:type="simple" xlink:href="../751/729751.xml">
Soar</link>). But more often, reactive plans are programmed in a <link xlink:type="simple" xlink:href="../524/29524.xml">
scripting language</link>, where the rules are only one of the primitives (like in JAM or ABL).</entry>
</list>
</p>

</sec>
<sec>
<st>
 Steering </st>

<p>

Steering is a special reactive technique used in navigation of agents. It is based on superposition of attractive or repulsive forces that effect on the agent. Steering is based on the original work on <link xlink:type="simple" xlink:href="../015/404015.xml">
boids</link> of Craig Reynolds.  
By means of steering, one can achieve a simple form of:</p>
<p>

<list>
<entry level="1" type="bullet">

 towards a goal navigation</entry>
<entry level="1" type="bullet">

 obstacles avoidance behaviour</entry>
<entry level="1" type="bullet">

 a wall following behaviour</entry>
<entry level="1" type="bullet">

 enemy approaching</entry>
<entry level="1" type="bullet">

 predator avoidance</entry>
<entry level="1" type="bullet">

 crowd behaviour</entry>
</list>
</p>
<p>

The advantage of steering is that it is computationally very efficient. In <link xlink:type="simple" xlink:href="../363/5363.xml">
computer games</link>, hundreds of soldiers can be driven by this technique. In cases of more complicated terrain (e.g. a building), however, steering must be combined with <condition wordnetid="113920835" confidence="0.8">
<state wordnetid="100024720" confidence="0.8">
<problem wordnetid="114410605" confidence="0.8">
<difficulty wordnetid="114408086" confidence="0.8">
<link xlink:type="simple" xlink:href="../985/41985.xml">
path-finding</link></difficulty>
</problem>
</state>
</condition>
, which is a form of <link xlink:type="simple" xlink:href="../641/1505641.xml">
planning</link>.</p>

</sec>
<sec>
<st>
See also</st>
<p>

<list>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../919/3918919.xml">
Behavior based AI</link></entry>
</list>
</p>

</sec>
<sec>
<st>
 References </st>

<p>

<list>
<entry level="1" type="bullet">

 Blumberg, B.: Old Tricks, New Dogs:  Ethology and Interactive Creatures.  PhD thesis,  Massachusetts Institute of Technology (1996).</entry>
<entry level="1" type="bullet">

 Brom, C.: Hierarchical Reactive Planning: Where is its limit? In: Proceedings of MNAS workshop. Edinburgh, Scotland (2005) </entry>
<entry level="1" type="bullet">

 Bryson, J.: Intelligence by Design: Principles of Modularity and Coordination for Engineering Complex Adaptive Agents. PhD thesis, Massachusetts Institute of Technology (2001)</entry>
<entry level="1" type="bullet">

 Champandard, A. J.: AI Game Development: Synthetic Creatures with learning and Reactive Behaviors. New Riders, USA (2003)  </entry>
<entry level="1" type="bullet">

 Grand, S., Cliff, D., Malhotra, A.: Creatures: Artificial life autonomous software-agents for home entertainment. In: Johnson, W. L. (eds.): Proceedings of the First International Conference on Autonomous Agents. ACM press (1997) 22-29</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://creatures.wikia.com/wiki/Creatures_Wiki_Homepage/">
Creatures development resource</weblink></entry>
<entry level="1" type="bullet">

 Huber, M. J.: <weblink xlink:type="simple" xlink:href="http://www.marcush.net/IRS/irs_downloads.html">
JAM: A BDI-theoretic mobile agent architecture</weblink>. In: Proceedings of the Third International Conference on Autonomous Agents (Agents'99). Seatle (1999) 236-243</entry>
<entry level="1" type="bullet">

 Isla, D.: <weblink xlink:type="simple" xlink:href="http://www.gamasutra.com/gdc2005/features/20050311/isla_pfv.htm">
 Handling complexity in Halo 2</weblink>. In: Gamastura online, 03/11 (2005)</entry>
<entry level="1" type="bullet">

 Reynolds, C. W. Flocks, Herds, and Schools: A Distributed Behavioral Model. In: Computer Graphics, 21(4) (SIGGRAPH '87 Conference Proceedings) (1987) 25-34.</entry>
<entry level="1" type="bullet">

 de Sevin, E. Thalmann, D.:A motivational Model of Action Selection for Virtual Humans. In: Computer Graphics International (CGI), IEEE Computer SocietyPress, New York (2005)</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.softimage.com/">
Softimage/Behavior product</weblink>. Avid Technology Inc. </entry>
<entry level="1" type="bullet">

 Tyrrell, T.: Computational Mechanisms for Action Selection. Ph.D. Dissertation. Centre for Cognitive Science, University of Edinburgh (1993)</entry>
<entry level="1" type="bullet">

 van Waveren, J. M. P.: The Quake III Arena Bot. Master thesis. Faculty ITS, University of Technology Delft (2001)</entry>
<entry level="1" type="bullet">

 Wooldridge, M. An Introduction to MultiAgent Systems. John Wiley &amp; Sons (2002)</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://artemis.ms.mff.cuni.cz/pogamut/">
Pogamut2</weblink>. Platform for fast agent prototyping in Unreal Tournament 2004 - using POSH - reactive planner designed and developed by J.J. Bryson.</entry>
</list>

</p>
</sec>
</bdy>
</article>
