<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 17:11:40[mciao0825] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Cryptographic engineering</title>
<id>504431</id>
<revision>
<id>205619133</id>
<timestamp>2008-04-14T19:39:00Z</timestamp>
<contributor>
<username>Good Olfactory</username>
<id>6454287</id>
</contributor>
</revision>
<categories>
<category>Cryptography</category>
</categories>
</header>
<bdy>

<b><link xlink:type="simple" xlink:href="../432/18934432.xml">
Cryptographic</link> <link xlink:type="simple" xlink:href="../251/9251.xml">
engineering</link></b> is the discipline of using cryptography to solve human problems. Cryptography is typically applied when trying to ensure data <link xlink:type="simple" xlink:href="../859/353859.xml">
confidentiality</link>, to <link>
 authenticate</link> people or devices, or to verify <link xlink:type="simple" xlink:href="../995/40995.xml">
data integrity</link> in risky environments.

<sec>
<st>
Major Issues</st>

<p>

In modern practice, cryptographic engineering is deployed in <link xlink:type="simple" xlink:href="../383/506383.xml">
crypto system</link>s. Like most engineering design, these are wholly human creations. Most crypto systems are <link xlink:type="simple" xlink:href="../309/5309.xml">
computer software</link>, either embedded in <link xlink:type="simple" xlink:href="../155/41155.xml">
firmware</link> or running as ordinary executable files under an <link xlink:type="simple" xlink:href="../194/22194.xml">
operating system</link>. In some system designs, the cryptography runs under manual direction, in others, it is run automatically, often in the background. Like other software design, and unlike most other engineering, there are few external constraints.</p>

<ss1>
<st>
Active opposition</st>
<p>

In other engineering design, a successful design or implementation of one, is one which 'works'. Thus, an aircraft which actually flies without crashing due to some <link xlink:type="simple" xlink:href="../819/2819.xml">
aerodynamic</link> design blunder is a successful design. How successful is important, of course, and depends on how well it meets intended performance criteria. Continuing with the aircraft example, several WWI <link xlink:type="simple" xlink:href="../929/10929.xml">
fighter aircraft</link> designs only barely flew, while others flew well (at least one design flew well, but its wings broke off with some regularity) though with insufficient agility (turning, climbing, ..., rates) or insufficient stability (too frequent inescapeable spins and so on) to be useful or survivable. To a considerable extent, good agility in aircraft is inversely related to inadequate stability, so fighter aircraft designs are, in this respect, inevitable compromises. The same considerations have  continued in more recent times, as for instance the necessity for computer 'fly-by-wire' control in some fighters with great agility.</p>
<p>

Cryptographic designs also have performance goals (eg, unbreakability of encryption), but must perform in a more complex, and more complexly hostile, environment than merely high (but not too low) in the Earth's atmosphere under war conditions. </p>
<p>

Some aspects of the conditions under which crypto designs must work (to be successful and so worth bothering with) have been long recognized. Sensible cipher designers (of which there were fewer than their users would have wanted) attempted to find ways to prevent <link xlink:type="simple" xlink:href="../934/157934.xml">
frequency analysis</link> success, starting, it must be assumed, almost immediately after that cryptanalytic technique was first used. The most effective way to defeat frequency analysis attacks was the polyalphabetic substitution cipher, invented by <link xlink:type="simple" xlink:href="../031/18031.xml">
Alberti</link> about 1465. For the next several hundred years, other designers also tried to evade frequency analysis, usually poorly, demonstrating that few had a clear understanding of the problem. What is probably the best known (and likely the widest used) of those attempts is the (misnamed) <link>
Vigen√®re cipher</link> which is a partial implementation of Alberti's idea. <person wordnetid="100007846" confidence="0.9508927676800064">
<writer wordnetid="110794014" confidence="0.9508927676800064">
<critic wordnetid="109979321" confidence="0.9173553029164789">
<link xlink:type="simple" xlink:href="../549/9549.xml">
Edgar Allan Poe</link></critic>
</writer>
</person>
 famously, and rashly, boasted that no cipher could defeat his cryptanalytic talents (essentially frequency analysis); that he was almost entirely correct about the ciphertexts submitted to him suggests a low level of cryptographic awareness some 400 (!) years after Alberti. As this history suggests, an important part of crypto engineering is understanding the techniques the Opposition may have available. </p>
<p>

In addition, it has been explicitly realized since the mid 1800s that the Opposition must be credited with certain kinds of knowledge, lest one's design efforts address too little. <link xlink:type="simple" xlink:href="../064/53064.xml">
Kerckhoffs' Law</link> -- "The security of a cipher must reside entirely in the key", and the equivalent, and somewhat less obscure, <scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../693/5693.xml">
Shannon</link></scientist>
's Maxim -- "The enemy knows the system", put it more or less clearly. A crypto design must achieve its goals (eg, confidentiality, or message integrity -- see 'goals' in the article <link xlink:type="simple" xlink:href="../432/18934432.xml">
cryptography</link>), not only despite active intelligent Opposition, but in spite of uncomfortably well informed Opposition.</p>

</ss1>
<ss1>
<st>
Inherent zero-defect requirement</st>
<p>

Many failures in cryptographic engineering are catastrophic. That is, success in breaking one message leads to reading all messages. Most cryptographic algorithms and protocols make certain assumptions (random <link xlink:type="simple" xlink:href="../039/53039.xml">
key</link> or <link xlink:type="simple" xlink:href="../390/6988390.xml">
nonce</link> choices, for example), and when those assumptions are violated, all security is lost.</p>
<p>

Examples: Netscape random bug found at UC Berkeley, Microsoft's PPTP protocol implementation problems found by Schneier.</p>

</ss1>
<ss1>
<st>
Invisibility of most failure modes</st>
<p>

Success in cryptographic engineering is unclear at best. Not crashing is a quite prominent <it><link xlink:type="simple" xlink:href="../767/1245767.xml">
sine qua non</link></it> in aircraft design. Not allowing the Opposition access (to protected message traffic, for instance) is the design goal, but it is far less obvious when this goal has been achieved than in other engineering. Essentially no Opponents will ever make their access to message content public, and so neither designers nor implementors nor users of crypto systems will ever learn from them that their design is insecure. It is certainly irrational to count on Opponents as a quality control resource.  </p>
<p>

One tempting measure of security is 'I can't figure out how to break it, so I will assume Opponents will not be able to do so either'. This may be true, but there is no way to actually know your Opponents have the same limitations you do. In a modern environment, in which messages travel over public networks, it is not even possible to detect eavesdropping, much less to prevent it. Accordingly, most message traffic must be presumed to be entirely in an Opponent's possession.</p>
<p>

Known cryptographic failures fall into several classes. Future failures may also, or may find new categories. Examples include:</p>
<p>

Design errors:
<list>
<entry level="1" type="bullet">

cryptographic protocol errors </entry>
<entry level="1" type="bullet">

user operational procedure errors</entry>
<entry level="1" type="bullet">

algorithm implementation errors</entry>
<entry level="1" type="bullet">

associated system failures</entry>
</list>
</p>
<p>

User errors:
<list>
<entry level="1" type="bullet">

misunderstanding of correct operations</entry>
<entry level="1" type="bullet">

arbitrary user actions</entry>
</list>
</p>
<p>

Implementation errors:
<list>
<entry level="1" type="bullet">

programming errors (bugs)</entry>
<entry level="1" type="bullet">

precision arithmetic errors</entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../523/19196523.xml">
random</link> data errors</entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../421/106421.xml">
software library</link> routine errors</entry>
</list>
</p>
<p>

Environment errors:
<list>
<entry level="1" type="bullet">

operating system insecurities with effects on cryptographic software (eg, keys retained in <link xlink:type="simple" xlink:href="../193/311193.xml">
swap file</link> data)</entry>
<entry level="1" type="bullet">

operating system insecurities with regard to <link xlink:type="simple" xlink:href="../935/157935.xml">
plaintext</link> access </entry>
<entry level="1" type="bullet">

operating system vulnerabilities (<link xlink:type="simple" xlink:href="../679/19167679.xml">
viruses</link>, <link xlink:type="simple" xlink:href="../056/30056.xml">
Trojan horse</link>s, etc)</entry>
</list>
</p>
<p>

The effect of most of these will not be apparent to end users, generally not to the computer system's administrators, and often not even to the cryptographic system's designers. For instance, a <link xlink:type="simple" xlink:href="../373/4373.xml">
buffer overflow</link> vulnerability in an obligatory operating system component may not have been present in version 5.1 (used during crypto system testing), but appear only at version 5.3, available only after release of the crypto system. Or that particular vulnerability may have been removed in all operating system releases later than version 5.3, but the crytographic system is being used in this case with version 5.1.</p>
<p>

The invisibility of many such errors makes finding and removing them more difficult than in many other kinds of engineering.</p>



</ss1>
</sec>
</bdy>
</article>
