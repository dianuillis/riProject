<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 21:41:51[mciao0825] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Linear-quadratic regulator</title>
<id>5346611</id>
<revision>
<id>240891988</id>
<timestamp>2008-09-25T13:12:14Z</timestamp>
<contributor>
<username>Encyclops</username>
<id>275300</id>
</contributor>
</revision>
<categories>
<category>Optimal control</category>
</categories>
</header>
<bdy>

The theory of <link xlink:type="simple" xlink:href="../565/362565.xml">
optimal control</link> is concerned with operating a <link>
dynamic system</link> at minimum cost.  The case where  the system dynamics are described by a set of <link xlink:type="simple" xlink:href="../868/379868.xml">
linear differential equation</link>s and the cost is described by a <link xlink:type="simple" xlink:href="../157/511157.xml">
quadratic</link> <link xlink:type="simple" xlink:href="../948/1374948.xml">
functional</link> is called the LQ problem.  One of the main results in the theory is that the solution is provided by the <b>linear-quadratic regulator (LQR)</b>, a feedback controller whose equations are given below. The LQR is an important part of the solution to the <link xlink:type="simple" xlink:href="../179/5347179.xml">
LQG problem</link>. Like the LQR problem itself the LQG problem is one of the most fundamental problems in <link xlink:type="simple" xlink:href="../039/7039.xml">
control theory</link>.
<sec>
<st>
General description</st>
<p>

In layman's terms this means that the settings of a (regulating) controller governing either a machine or process (like an airplane or chemical reactor) are found by using a mathematical algorithm that minimizes a cost function with weighting factors supplied by a human (engineer). The "cost" (function) is often defined as a sum of the deviations of key measurements from their desired values. In effect this algorithm therefore finds those controller settings that minimize the undesired deviations, like deviations from desired altitude or process temperature. Often the magnitude of the control action itself is included in this sum as to keep the energy expended by the control action itself limited.</p>
<p>

In effect, the LQR algorithm takes care of the tedious work done by the control systems engineer in optimizing the controller. However, the engineer still needs to specify the weighting factors and compare the results with the specified design goals. Often this means that controller synthesis will still be an iterative process where the engineer judges the produced "optimal" controllers through simulation and then adjusts the weighting factors to get a controller more in line with the specified design goals. </p>
<p>

The LQR algorithm is, at its core, just an automated way of finding an appropriate <link xlink:type="simple" xlink:href="../156/548156.xml">
state-feedback controller</link>. And as such it is not uncommon to find that control engineers prefer alternative methods like <link xlink:type="simple" xlink:href="../217/5425217.xml">
full state feedback</link> (also known as pole placement) to find a controller over the use of the LQR algorithm. With these the engineer has a much clearer linkage between adjusted parameters and the resulting changes in controller behaviour. Difficulty in finding the right weighting factors limits the application of the LQR based controller synthesis.</p>

</sec>
<sec>
<st>
Finite-horizon, continuous-time LQR</st>

<p>

For a continuous-time linear system described by</p>
<p>

<indent level="1">

<math>\dot{x} = Ax + Bu</math>
</indent>

with a quadratic cost function defined as</p>
<p>

<indent level="1">

<math>J = \frac{1}{2} x^T(T)F(T)x(T)  + \int\limits_{0}^T \left( x^T Q x + u^T R u \right) dt</math>
</indent>

the feedback control law that minimizes the value of the cost is</p>
<p>

<indent level="1">

<math>u = -F x \,</math>
</indent>

where <math>F</math> is given by</p>
<p>

<indent level="1">

<math>F = R^{-1} B^T P \,</math>
</indent>

and <math>P</math> is found by solving the continuous time <link xlink:type="simple" xlink:href="../054/16684054.xml">
algebraic Riccati equation</link> (CARE).</p>

</sec>
<sec>
<st>
Infinite-horizon, continuous-time LQR</st>

<p>

For a continuous-time linear system described by</p>
<p>

<indent level="1">

<math>\dot{x} = Ax + Bu</math>
</indent>

with a cost functional defined as</p>
<p>

<indent level="1">

<math>J = \int\limits_{0}^\infty \left( x^T Q x + u^T R u \right) dt</math>
</indent>

the feedback control law that minimizes the value of the cost is</p>
<p>

<indent level="1">

<math>u = -F x \,</math>
</indent>

where <math>F</math> is given by</p>
<p>

<indent level="1">

<math>F = R^{-1} B^T P \,</math>
</indent>

and <math>P</math> is found by solving the continuous time <link xlink:type="simple" xlink:href="../054/16684054.xml">
algebraic Riccati equation</link></p>
<p>

<indent level="1">

<math>A^T P + P A - P B R^{-1} B^T P + Q = 0 \,</math>
</indent>

</p>
</sec>
<sec>
<st>
Infinite-horizon, discrete-time LQR</st>

<p>

For a discrete-time linear system described by</p>
<p>

<indent level="1">

<math>x_{k+1} = A x_k + B u_k \,</math>
</indent>

with a performance index defined as</p>
<p>

<indent level="1">

<math>J = \sum\limits_{k=0}^{\infty} \left( x_k^T Q x_k + u_k^T R u_k \right)</math>
</indent>

the optimal control sequence minimizing the performance index is given by</p>
<p>

<indent level="1">

<math>u_k = -F x_k \,</math>
</indent>

where</p>
<p>

<indent level="1">

<math>F = (R + B^T P B)^{-1} B^T P A \,</math>
</indent>

and <math>P</math> is the solution to the discrete time <link xlink:type="simple" xlink:href="../054/16684054.xml">
algebraic Riccati equation</link> (DARE).</p>
<p>

<math>P = Q + A^T \left( P - P B \left( R + B^T P B \right)^{-1} B^T P \right) A</math></p>

</sec>
<sec>
<st>
Bibliography</st>
<p>

<list>
<entry level="1" type="bullet">

 <cite id="Reference-Kwakernaak, Huibert and Sivan, Raphael-1972" style="font-style:normal" class="book">Kwakernaak, Huibert and Sivan, Raphael&#32;(1972). Linear Optimal Control Systems.  First Edition.&#32;Wiley-Interscience. ISBN 0-471-511102.</cite>&nbsp;</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <cite id="Reference-Sontag-1998" style="font-style:normal" class="book"><scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../520/5612520.xml">
Sontag, Eduardo</link></scientist>
&#32;(1998). Mathematical Control Theory: Deterministic Finite Dimensional Systems. Second Edition.&#32;Springer. ISBN 0-387-984895.</cite>&nbsp;</entry>
</list>
</p>

</sec>
<sec>
<st>
External links</st>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://documents.wolfram.com/applications/control/OptimalControlSystemsDesign/10.1.html">
Linear Quadratic Regulator</weblink></entry>
</list>
</p>



</sec>
</bdy>
</article>
