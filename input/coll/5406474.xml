<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 21:50:06[mciao0827] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Consensus (computer science)</title>
<id>5406474</id>
<revision>
<id>215716217</id>
<timestamp>2008-05-29T11:44:23Z</timestamp>
<contributor>
<username>DOI bot</username>
<id>6652755</id>
</contributor>
</revision>
<categories>
<category>Articles to be expanded since January 2007</category>
<category>All articles to be expanded</category>
<category>Distributed computing</category>
</categories>
</header>
<bdy>

<b>Consensus</b> is a problem in <link xlink:type="simple" xlink:href="../501/8501.xml">
distributed computing</link> that encapsulates the task of group agreement in the presence of faults.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref><p>

In particular, any <link xlink:type="simple" xlink:href="../178/45178.xml">
process</link> in the group may crash at any time. Consensus is fundamental to core techniques in <link xlink:type="simple" xlink:href="../720/2573720.xml">
fault tolerance</link>, such as <link xlink:type="simple" xlink:href="../093/5407093.xml">
state machine replication</link>.</p>

<sec>
<st>
 Problem Description </st>

<p>

A process is called "correct" if it does not fail at any point during its execution. Unlike <link xlink:type="simple" xlink:href="../961/5107961.xml">
Terminating Reliable Broadcast</link>, the typical Consensus problem does not label any single process as a "sender". Every process "proposes" a value; the goal of the protocol is for all correct processes to choose a single value from among those proposed. A process may perform many <link xlink:type="simple" xlink:href="../558/14558.xml">
I/O</link> operations during protocol execution, but must eventually "decide" a value by passing it to the application on that process that invoked the Consensus protocol.</p>
<p>

Valid consensus protocols must provide important guarantees to all processes involved. All correct processes must eventually decide the same value, for example, and that value must be one of those proposed. A correct process is therefore guaranteed that the value it decides was also decided by all other correct processes, and can act on that value accordingly.</p>
<p>

More precisely, a Consensus protocol must satisfy the four formal properties below.</p>
<p>

<list>
<entry level="1" type="bullet">

 <b>Termination</b>: every correct process decides some value.</entry>
<entry level="1" type="bullet">

 <b>Validity</b>: if all processes propose the same value <math>v</math>, then every correct process decides <math>v</math>.</entry>
<entry level="1" type="bullet">

 <b>Integrity</b>: every correct process decides at most one value, and if it decides some value <math>v</math>, then <math>v</math> must have been proposed by some process.</entry>
<entry level="1" type="bullet">

 <b>Agreement</b>: if a correct process decides <math>v</math>, then every correct process decides <math>v</math>.</entry>
</list>
</p>
<p>

The possibility of faults in the system makes these properties more difficult to satisfy. A simple but invalid Consensus protocol might have every process broadcast its proposal to all others, and have a process decide on the smallest value received. Such a protocol, as described, does not satisfy Agreement if faults can occur: if a process crashes after sending its proposal to some processes, but before sending it to others, then the two sets of processes may decide different values.</p>

</sec>
<sec>
<st>
 Impossibility </st>


<p>

<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-notice" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="36px" src="Wiki_letter_w.svg">
</image>
</p>
</col>
<col style="" class="mbox-text">
 <b>Please help <weblink xlink:type="simple" xlink:href="http://localhost:18088/wiki/index.php?title=Consensus_%28computer_science%29&amp;action=edit">
improve this section</weblink> by expanding it.</b> Further information might be found on the  or at . 
<it>(January 2007)''</it></col>
</row>
</table>

</p>
<p>

Consensus has been shown to be impossible to solve in several <link xlink:type="simple" xlink:href="../278/1773278.xml">
models</link> of distributed computing.</p>
<p>

In an asynchronous system, where processes have no common clock and run at arbitrarily varying speeds, the problem is impossible to solve if one process may <abnormality wordnetid="114501726" confidence="0.8">
<condition wordnetid="113920835" confidence="0.8">
<state wordnetid="100024720" confidence="0.8">
<physical_condition wordnetid="114034177" confidence="0.8">
<anomaly wordnetid="114505821" confidence="0.8">
<link xlink:type="simple" xlink:href="../631/279631.xml">
crash</link></anomaly>
</physical_condition>
</state>
</condition>
</abnormality>
 and processes communicate by sending messages to one another <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref>.
The technique used to prove this result is sometimes called an FLP impossibility proof, named after its creators, Michael J. Fischer, <peer wordnetid="109626238" confidence="0.8">
<physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<honoree wordnetid="110183757" confidence="0.8">
<colleague wordnetid="109935990" confidence="0.8">
<acquirer wordnetid="109764201" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<adult wordnetid="109605289" confidence="0.8">
<professional wordnetid="110480253" confidence="0.8">
<recipient wordnetid="109627906" confidence="0.8">
<educator wordnetid="110045713" confidence="0.8">
<associate wordnetid="109816771" confidence="0.8">
<laureate wordnetid="110249011" confidence="0.8">
<academician wordnetid="109759069" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../489/2387489.xml">
Nancy A. Lynch</link></causal_agent>
</academician>
</laureate>
</associate>
</educator>
</recipient>
</professional>
</adult>
</scientist>
</acquirer>
</colleague>
</honoree>
</person>
</physical_entity>
</peer>
 and Michael S. Paterson, who won the <symbol wordnetid="106806469" confidence="0.8">
<award wordnetid="106696483" confidence="0.8">
<signal wordnetid="106791372" confidence="0.8">
<link xlink:type="simple" xlink:href="../883/7350883.xml">
Dijkstra Prize</link></signal>
</award>
</symbol>
 for this result.  The technique has been widely used to prove other impossibility results.  For example, a similar proof can be used to show that consensus is also impossible in asynchronous systems where processes communicate by reading and writing shared variables if one process may crash <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%223%22])">3</ref>.</p>
<p>

The FLP result does not state that consensus can never be reached: merely that under the model's assumptions, no algorithm can always reach consensus in bounded time. There exist algorithms, even under the asynchronous model, that can reach consensus with probability one.  The FLP proof hinges on demonstrating the existence of an order of message receipts that causes the system to never reach consensus. This "bad" input however may be vanishingly unlikely in practice.  </p>
<p>

In a synchronous system, where all processes run at the same speed, consensus is impossible if processes communicate by sending messages to one another and one third of the processes can experience <system wordnetid="104377057" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<link xlink:type="simple" xlink:href="../031/970031.xml">
Byzantine failures</link></instrumentality>
</artifact>
</system>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%224%22])">4</ref>.</p>

</sec>
<sec>
<st>
 Important Consensus Protocols </st>


<p>

<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-notice" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="36px" src="Wiki_letter_w.svg">
</image>
</p>
</col>
<col style="" class="mbox-text">
 <b>Please help <weblink xlink:type="simple" xlink:href="http://localhost:18088/wiki/index.php?title=Consensus_%28computer_science%29&amp;action=edit">
improve this section</weblink> by expanding it.</b> Further information might be found on the  or at . 
<it>(January 2007)''</it></col>
</row>
</table>

</p>
<p>

Google has implemented a distributed lock service library called Chubby <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%225%22])">5</ref>. Chubby maintains locks information in small files which are stored in a replicated database to achieve high availability in the face of failures. The database is implemented on top of a fault-tolerant log layer which is based on the <link>
 Paxos consensus algorithm</link>. In this scheme, Chubby clients communicate with the Paxos <it>master</it> in order to access/update the replicated log, i.e., read/write to the files <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref>.</p>

</sec>
<sec>
<st>
 Context in Distributed Computing </st>


<p>

<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-notice" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="36px" src="Wiki_letter_w.svg">
</image>
</p>
</col>
<col style="" class="mbox-text">
 <b>Please help <weblink xlink:type="simple" xlink:href="http://localhost:18088/wiki/index.php?title=Consensus_%28computer_science%29&amp;action=edit">
improve this section</weblink> by expanding it.</b> Further information might be found on the  or at . 
<it>(January 2007)''</it></col>
</row>
</table>

</p>

</sec>
<sec>
<st>
 References </st>

<p>

<reflist>
<entry id="1">
 <cite style="font-style:normal"><scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../671/195671.xml">
Lamport, Leslie</link></scientist>
; Marshall Pease and Robert Shostak&#32;(April 1980).&#32;"<weblink xlink:type="simple" xlink:href="http://research.microsoft.com/users/lamport/pubs/reaching.pdf">
Reaching Agreement in the Presence of Faults</weblink>". <it><magazine wordnetid="106595351" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../845/2321845.xml">
Journal of the ACM</link></magazine>
</it>&#32;<b>27</b>&#32;(2): 228--234. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1145%2F322186.322188">
10.1145/322186.322188</weblink>. 10.1145/322186.322188. Retrieved on <link>
2007-07-25</link>.</cite>&nbsp;</entry>
<entry id="2">
 <cite style="font-style:normal">Fischer, Michael J.; <peer wordnetid="109626238" confidence="0.8">
<physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<honoree wordnetid="110183757" confidence="0.8">
<colleague wordnetid="109935990" confidence="0.8">
<acquirer wordnetid="109764201" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<adult wordnetid="109605289" confidence="0.8">
<professional wordnetid="110480253" confidence="0.8">
<recipient wordnetid="109627906" confidence="0.8">
<educator wordnetid="110045713" confidence="0.8">
<associate wordnetid="109816771" confidence="0.8">
<laureate wordnetid="110249011" confidence="0.8">
<academician wordnetid="109759069" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../489/2387489.xml">
Nancy A. Lynch</link></causal_agent>
</academician>
</laureate>
</associate>
</educator>
</recipient>
</professional>
</adult>
</scientist>
</acquirer>
</colleague>
</honoree>
</person>
</physical_entity>
</peer>
; Michael S. Paterson&#32;(April 1985).&#32;"<weblink xlink:type="simple" xlink:href="http://portal.acm.org/citation.cfm?doid=3149.214121">
Impossibility of Distributed Consensus with One Faulty Process</weblink>". <it><magazine wordnetid="106595351" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../845/2321845.xml">
Journal of the ACM</link></magazine>
</it>&#32;<b>32</b>&#32;(2): 374–382. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1145%2F3149.214121">
10.1145/3149.214121</weblink>. Retrieved on <link>
2007-04-29</link>.</cite>&nbsp;</entry>
<entry id="3">
 <cite id="CITEREFLouiAbu-Amara1987" style="font-style:normal">Loui, M. C.&#32;&amp;&#32;Abu-Amara, H. H.&#32;(1987),&#32;"Memory requirements for agreement among unreliable asynchronous processes", in&#32;Preparata, F. P.,&#32;<it>Advances in Computing Research</it>, <b>4</b>, Greenwich, Connecticut: JAI Press, pp. 163-183</cite>&nbsp;</entry>
<entry id="4">
 <cite style="font-style:normal">Fischer, Michael J.; <peer wordnetid="109626238" confidence="0.8">
<physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<honoree wordnetid="110183757" confidence="0.8">
<colleague wordnetid="109935990" confidence="0.8">
<acquirer wordnetid="109764201" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<adult wordnetid="109605289" confidence="0.8">
<professional wordnetid="110480253" confidence="0.8">
<recipient wordnetid="109627906" confidence="0.8">
<educator wordnetid="110045713" confidence="0.8">
<associate wordnetid="109816771" confidence="0.8">
<laureate wordnetid="110249011" confidence="0.8">
<academician wordnetid="109759069" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../489/2387489.xml">
Nancy A. Lynch</link></causal_agent>
</academician>
</laureate>
</associate>
</educator>
</recipient>
</professional>
</adult>
</scientist>
</acquirer>
</colleague>
</honoree>
</person>
</physical_entity>
</peer>
; Michael Merritt&#32;(1986).&#32;"Easy impossibility proofs for distributed consensus problems". <it>Distributed Computing</it>&#32;<b>1</b>&#32;(1): 26–39.&#32;Springer. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1007%2FBF01843568">
10.1007/BF01843568</weblink>.</cite>&nbsp;</entry>
<entry id="5">
 <cite style="font-style:normal">Burrows, M.&#32;(2006). "<weblink xlink:type="simple" xlink:href="http://labs.google.com/papers/chubby.html">
The Chubby lock service for loosely-coupled distributed systems</weblink>".: 335-350, USENIX Association Berkeley, CA, USA.</cite>&nbsp;
</entry>
<entry id="6">
 <cite style="font-style:normal">C., Tushar;&#32;Griesemer, R; Redstone J.&#32;(2007). "<weblink xlink:type="simple" xlink:href="http://delivery.acm.org/10.1145/1290000/1281103/p398-chandra.pdf?key1=1281103&amp;key2=4382532021&amp;coll=GUIDE&amp;dl=GUIDE&amp;CFID=15324100&amp;CFTOKEN=95510390">
Paxos Made Live - An Engineering Perspective</weblink>".&#32;<it>Proceedings of the twenty-sixth annual ACM symposium on Principles of distributed computing</it>: 398-407, Portland, Oregon, USA:&#32;ACM Press New York, NY, USA. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/http://doi.acm.org/10.1145/1281100.1281103">
http://doi.acm.org/10.1145/1281100.1281103</weblink>. Retrieved on <link>
2008-02-06</link>.</cite>&nbsp;</entry>
</reflist>
</p>

</sec>
</bdy>
</article>
