<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 21:50:10[mciao0827] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>State machine replication</title>
<id>5407093</id>
<revision>
<id>241770834</id>
<timestamp>2008-09-29T14:03:35Z</timestamp>
<contributor>
<username>Gnalk</username>
<id>6700526</id>
</contributor>
</revision>
<categories>
<category>All articles with dead external links</category>
<category>Articles with invalid date parameter in template</category>
<category>Articles with dead external links since May 2008</category>
<category>Distributed computing</category>
</categories>
</header>
<bdy>

<indent level="1">

<it>Introduction from Schneider's 1990 survey:</it>
</indent>
:"Distributed software is often structured in terms of clients and services. Each service comprises one or more servers and exports operations that clients invoke by making requests. Although using a single, centralized, server is the simplest way to implement a service, the resulting service can only be as fault tolerant as the processor executing that server. If this level of fault tolerance is unacceptable, then multiple servers that fail independently must be used. Usually, replicas of a single server are executed on separate processors of a distributed system, and protocols are used to coordinate client interactions with these replicas. The physical and electrical isolation of processors in a distributed system ensures that server failures are independent, as required.<p>

<indent level="1">

"The <b>state machine approach</b> is a general method for implementing a fault-tolerant service by replicating servers and coordinating client interactions with server replicas.  The approach also provides a framework for understanding and designing replication management protocols.  Many protocols that involve replication of data or software - be it for masking failures or simply to facilitate cooperation without centralized control - can be derived using the state machine approach. Although few of these protocols actually were obtained in this manner, viewing them in terms of state machines helps in understanding how and why they work." <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref>
</indent>

</p>
<sec>
<st>
Preliminaries</st>

<ss1>
<st>
State Machine Definition</st>

<p>

For the subsequent discussion a <b>State Machine</b> will be defined as the following tuple of values <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref><physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../512/331512.xml">
Mealy machine</link></causal_agent>
</worker>
</assistant>
</model>
</person>
</physical_entity>
:</p>
<p>

<list>
<entry level="1" type="bullet">

 A set of <b>States</b></entry>
<entry level="1" type="bullet">

 A set of <b>Inputs</b></entry>
<entry level="1" type="bullet">

 A set of <b>Outputs</b></entry>
<entry level="1" type="bullet">

 A transition function (Input x State -&amp;gt; State)</entry>
<entry level="1" type="bullet">

 An output function (Input x State -&amp;gt; Output)</entry>
<entry level="1" type="bullet">

 A distinguished State called Start.</entry>
</list>
</p>
<p>

A State Machine begins at the State labeled Start.  Each Input received is passed through the transition and output function to produce a new State and an Output.  The State is held stable until a new Input is received, while the Output is communicated to the appropriate receiver.</p>
<p>

It should be clear that any algorithm can be implemented using this model if driven by an appropriate Input stream.  In particular, this discussion requires a State Machine to have the following property:</p>
<p>

<indent level="1">

<b>Deterministic:</b>
</indent>
:Multiple copies of the same State Machine begun in the Start state, and receiving the same Inputs in the same order will arrive at the same State having generated the same Outputs.</p>

</ss1>
<ss1>
<st>
Fault Tolerance Explained</st>

<p>

Determinism is an ideal characteristic for providing fault-tolerance.  Intuitively, if multiple copies of a system exist, a fault in one would be noticeable as a difference in the State or Output from the others.</p>
<p>

A little deduction shows the minimum number of copies needed for fault-tolerance is three; one which has a fault, and two others to whom we compare State and Output.  Two copies is not enough; there is no way to tell which copy is the faulty one.</p>
<p>

Further deduction shows a three-copy system can support at most one failure (after which it must repair or replace the faulty copy).  If more than one of the copies were to fail, all three States and Outputs might differ, and there would be no way to choose which is the correct one.</p>
<p>

Research has shown <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%223%22])">3</ref> that in general a system which supports F failures must have 2F+1 copies (also called replicas).  The extra copies are used as evidence to decide which of the copies are correct and which are faulty.  Special cases can improve these bounds <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%224%22])">4</ref>.</p>
<p>

All of this deduction pre-supposes that replicas are experiencing only random independent faults such as memory errors or hard-drive crash.   Failures caused by replicas which attempt to lie, deceive, or collude can also be handled by the State Machine Approach, with isolated changes.</p>
<p>

All of this deduction pre-supposes that there is a single value which is the Output of each replica. Faults where a replica sends different values in different directions (for instance, the correct Output to some of its fellow replicas and incorrect Outputs to others) are called Byzantine Failures <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%225%22])">5</ref>. Both normal and Byzantine failures are supported by the State Machine Approach, with some changes, but the possibility of Byzantine failures raises the required number of replicas to 3F+1.</p>
<p>

It should be noted that failed replicas are not required to stop; they may continue operating, including generating spurious or incorrect Outputs. If all failed replicas are guaranted to stop, we only need F+1 replicas and the system is much simpler: we simply accept the first output that's calculated, since it must've been produced by a replica which hasn't stopped and therefore (by the guarantee) hasn't failed.</p>

</ss1>
</sec>
<sec>
<st>
The State Machine Approach</st>

<p>

The preceding intuitive discussion implies a simple technique for implementing a fault-tolerant service in terms of a State Machine:</p>
<p>

<list>
<entry level="1" type="number">

 Place copies of the State Machine on multiple, independent servers.</entry>
<entry level="1" type="number">

 Receive client requests, interpreted as Inputs to the State Machine.</entry>
<entry level="1" type="number">

 Choose an ordering for the Inputs.</entry>
<entry level="1" type="number">

 Execute Inputs in the chosen order on each server.</entry>
<entry level="1" type="number">

 Respond to clients with the Output from the State Machine.</entry>
<entry level="1" type="number">

 Monitor replicas for differences in State or Output.</entry>
</list>
</p>
<p>

The remainder of this article develops the details of this technique.</p>
<p>

<list>
<entry level="1" type="bullet">

 Step 1 and 2 are outside the scope of this article.</entry>
<entry level="1" type="bullet">

 Step 3 is the critical operation, see <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Ordering+Inputs%22])">
Ordering Inputs</link>.</entry>
<entry level="1" type="bullet">

 Step 4 is covered by the <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22State+Machine+Definition%22])">
State Machine Definition</link>.</entry>
<entry level="1" type="bullet">

 Step 5, see <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Sending+Outputs%22])">
Ordering Outputs</link>.</entry>
<entry level="1" type="bullet">

 Step 6, see <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Auditing+and+Failure+Detection%22])">
Auditing and Failure Detection</link>.</entry>
</list>
</p>
<p>

The appendix contains discussion on typical extensions used in real-world systems such as <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Logging%22])">
Logging</link>, <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Checkpoints%22])">
Checkpoints</link>, <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Reconfiguration%22])">
Reconfiguration</link>, and <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22State+Transfer%22])">
State Transfer</link>.</p>

<ss1>
<st>
Ordering Inputs</st>

<p>

The critical step in building a distributed system of State Machines is choosing an order for the Inputs to be processed.  Since all non-faulty replicas will arrive at the same State and Output if given the same Inputs, it is imperative that the Inputs are submitted in an equivalent order at each replica.  Many solutions have been proposed in the literature <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%227%22])">7</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%228%22])">8</ref>.</p>
<p>

A <b>Visible Channel</b> is a communication path between two entities actively participating in the system (such as clients and servers).
Example: client to server, server to server</p>
<p>

A <b>Hidden Channel</b> is a communication path which is not revealed to the system.
Example: client to client channels are usually hidden; such as users communicating over a telephone, or a process writing files to disk which are read by another process.</p>
<p>

When all communication paths are visible channels and no hidden channels exist, a partial global order (<b>Causal Order</b>) may be inferred from the pattern of communications <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%229%22])">9</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%227%22])">7</ref>.  Causal Order may be derived independently by each server.  Inputs to the State Machine may be executed in Causal Order, guaranteeing consistent State and Output for all non-faulty replicas.</p>
<p>

In open systems, hidden channels are common and a weaker form of ordering must be used.  An order of Inputs may be defined using a voting protocol whose results depend only on the visible channels.</p>
<p>

The problem of voting for a <it>single</it> value by a group of independent entities is called <link xlink:type="simple" xlink:href="../474/5406474.xml">
<b>Consensus</b></link>.  By extension, a <it>series</it> of values may be chosen by a series of consensus instances.  This problem becomes difficult when the participants or their communication medium may experience failures <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2210%22])">10</ref>.</p>
<p>

Inputs may be ordered by their position in the series of consensus instances (<b>Consensus Order</b>).  Consensus Order may be derived independently by each server.  Inputs to the State Machine may be executed in Consensus Order, guaranteeing consistent State and Output for all non-faulty replicas.</p>
<p>

<indent level="1">

<b>Optimizing Causal &amp; Consensus Ordering</b>
</indent>
:In some cases additional information is available (such as real-time clocks).  In these cases, it is possible to achieve more efficient causal or consensus ordering for the Inputs, with a reduced number of messages, fewer message rounds, or smaller message sizes.  See references for details <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2211%22])">11</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%224%22])">4</ref></p>
<p>

<indent level="1">

Further optimizations are available when the semantics of State Machine operations are accounted for (such as Read vs Write operations).  See references <system wordnetid="104377057" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link>
Generalized Paxos</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</instrumentality>
</artifact>
</system>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2212%22])">12</ref>.
</indent>

</p>
</ss1>
<ss1>
<st>
Sending Outputs</st>

<p>

Client requests are interpreted as Inputs to the State Machine, and processed into Outputs in the appropriate order.  Each replica will generate an Output independently.  Non-faulty replicas will always produce the same Output.  Before the client response can be sent, faulty Outputs must be filtered out.  Typically, a majority of the Replicas will return the same Output, and this Output is sent as the response to the client.</p>

</ss1>
<ss1>
<st>
System Failure</st>
<p>

<indent level="1">

If there is no majority of replicas with the same Output, or if less than a majority of replicas returns an Output, a system failure has occurred.  The client response must be the unique Output: FAIL.
</indent>

</p>
</ss1>
<ss1>
<st>
Auditing and Failure Detection</st>

<p>

The permanent, unplanned compromise of a replica is called a <b>Failure</b>.  Proof of failure is difficult to obtain, as the replica may simply be slow to respond <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2213%22])">13</ref>, or even lie about its status <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%225%22])">5</ref>.</p>
<p>

Non-faulty replicas will always contain the same State and produce the same Outputs.  This invariant enables failure detection by comparing States and Outputs of all replicas.  Typically, a replica with State or Output which differs from the majority of replicas is declared faulty.</p>
<p>

A common implementation is to pass checksums of the current replica State and recent Outputs among servers.  An Audit process at each server restarts the local replica if a deviation is detected <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2214%22])">14</ref>.  Cryptographic security is not required for checksums.</p>
<p>

It is possible that the local server is compromised, or that the Audit process is faulty, and the replica continues to operate incorrectly.  This case is handled safely by the Output filter described previously (see <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Sending+Outputs%22])">
Sending Outputs</link>).</p>

</ss1>
</sec>
<sec>
<st>
Appendix: Extensions</st>

<ss1>
<st>
Input Log</st>

<p>

In a system with no failures, the Inputs may be discarded after being processed by the State Machine.  Realistic deployments must compensate for transient non-failure behaviors of the system such as message loss, network partitions, and slow processors <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2214%22])">14</ref>.</p>
<p>

One technique is to store the series of Inputs in a log.  During times of transient behavior, replicas may request copies of a log entry from another replica in order to fill in missing Inputs .</p>
<p>

In general the log is not required to be persistent (it may be held in memory).  A persistent log may compensate for extended transient periods, or support additional system features such as <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Checkpoints%22])">
Checkpoints</link>, and <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Reconfiguration%22])">
Reconfiguration</link>.</p>

</ss1>
<ss1>
<st>
Checkpoints</st>

<p>

If left unchecked a log will grow until it exhausts all available storage resources.  For continued operation, it is necessary to forget log entries.  In general a log entry may be forgotten when its contents are no longer relevant (for instance if all replicas have processed an Input, the knowledge of the Input is no longer needed).</p>
<p>

A common technique to control log size is store a duplicate State (called a <b>Checkpoint</b>), then discard any log entries which contributed to the checkpoint.  This saves space when the duplicated State is smaller than the size of the log.</p>
<p>

Checkpoints may be added to any State Machine by supporting an additional Input called <b>CHECKPOINT</b>.  Each replica maintains a checkpoint in addition to the current State value.  When the log grows large, a replica submits the CHECKPOINT command just like a client request.  The system will ensure non-faulty replicas process this command in the same order, after which all log entries before the checkpoint may be discarded.</p>
<p>

In a system with checkpoints, requests for log entries occurring before the checkpoint are ignored.  Replicas which cannot locate copies of a needed log entry are faulty and must re-join the system (see <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Reconfiguration%22])">
Reconfiguration</link>).</p>

</ss1>
<ss1>
<st>
Reconfiguration</st>

<p>

Reconfiguration allows replicas to be added and removed from a system while client requests continue to be processed.  Planned maintenance and replica failure are common examples of reconfiguration.  Reconfiguration involves <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Quitting%22])">
Quitting</link> and <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Joining%22])">
Joining</link>.</p>

</ss1>
<ss1>
<st>
Quitting</st>

<p>

When a server detects its State or Output is faulty (see <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Auditing+and+Failure+Detection%22])">
Auditing and Failure Detection</link>), it may selectively exit the system.  Likewise, an administrator may manually execute a command to remove a replica for maintenance.</p>
<p>

A new Input is added to the State Machine called <b>QUIT</b><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref>.  A replica submits this command to the system just like a client request.  All non-faulty replicas remove the quitting replica from the system upon processing this Input.  During this time, the replica may ignore all protocol messages.  If a majority of non-faulty replicas remain, the quit is successful.  If not, there is a <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22System+Failure%22])">
System Failure</link>.</p>

</ss1>
<ss1>
<st>
Joining</st>

<p>

After quitting, a failed server may selectively restart or re-join the system.  Likewise, an administrator may add a new replica to the group for additional capacity.</p>
<p>

A new Input is added to the State Machine called <b>JOIN</b>.  A replica submits this command to the system just like a client request.  All non-faulty replicas add the joining node to the system upon processing this Input.  A new replica must be up-to-date on the system's State before joining (see <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22State+Transfer%22])">
State Transfer</link>).</p>

</ss1>
<ss1>
<st>
State Transfer</st>

<p>

When a new replica is made available or an old replica is restarted, it must be brought up to the current State before processing Inputs (see <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Joining%22])">
Joining</link>).  Logically, this requires applying every Input from the dawn of the system in the appropriate order.</p>
<p>

Typical deployments short-circuit the logical flow by performing a State Transfer of the most recent Checkpoint (see <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Checkpoints%22])">
Checkpoints</link>).  This involves directly copying the State of one replica to another using an out-of-band protocol.</p>
<p>

A checkpoint may be large, requiring an extended transfer period.  During this time, new Inputs may be added to the log.  If this occurs, the new replica must also receive the new Inputs and apply them after the checkpoint is received.  Typical deployments add the new replica as an observer to the ordering protocol before beginning the state transfer, allowing the new replica to collect Inputs during this period.</p>
<p>

<indent level="1">

<b>Optimizing State Transfer</b>
</indent>
:Common deployments reduce state transfer times by sending only State components which differ.  This requires knowledge of the State Machine internals.  Since state transfer is usually an out-of-band protocol, this assumption is not difficult to achieve.</p>
<p>

<indent level="1">

Compression is another feature commonly added to state transfer protocols, reducing the size of the total transfer.
</indent>

</p>
</ss1>
<ss1>
<st>
Leader Election (for Paxos)</st>

<p>

<system wordnetid="104377057" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../488/5722488.xml">
<b>Paxos</b></link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</instrumentality>
</artifact>
</system>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2215%22])">15</ref> is a protocol for solving consensus, and may be used as the protocol for implementing <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Consensus+Order%22])">
Consensus Order</link>.</p>
<p>

Paxos requires a single leader to ensure liveness <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2215%22])">15</ref>.  That is, one of the replicas must remain leader long enough to achieve consensus on the next operation of the state machine.  System behavior is unaffected if the leader changes after every instance, or if the leader changes multiple times per instance.  The only requirement is that one replica remain leader long enough to move the system forward.</p>
<p>

<indent level="1">

<b>Conflict Resolution</b>
</indent>
:In general, a leader is necessary only when there is disagreement about which operation to perform <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2211%22])">11</ref>, and if those operations conflict in some way (for instance, if they do not commute) <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2212%22])">12</ref>.</p>
<p>

<indent level="1">

When conflicting operations are proposed, the leader acts as the single authority to set the record straight, defining an order for the operations, allowing the system to make progress.
</indent>

With Paxos, multiple replicas may believe they are leaders at the same time.  This property makes Leader Election for Paxos very simple, and any algorithm which guarantees an 'eventual leader' will work.</p>

</ss1>
</sec>
<sec>
<st>
 Historical background </st>

<p>

<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../671/195671.xml">
Leslie Lamport</link></scientist>
 was the first to propose the state machine approach, in his seminal 1984 paper on <weblink xlink:type="simple" xlink:href="http://portal.acm.org/citation.cfm?id=2994&amp;dl=ACM&amp;coll=GUIDE">
"Using Time Instead of Timeout In Distributed Systems"</weblink>.  Fred Schneider later elaborated the approach in his paper <weblink xlink:type="simple" xlink:href="http://portal.acm.org/citation.cfm?id=98167">
"Implementing Fault-Tolerant Services Using the State Machine Approach: A Tutorial"</weblink>.</p>
<p>

<weblink xlink:type="simple" xlink:href="http://en.wikipedia.org/wiki/User:Ken_Birman">
'Ken Birman'</weblink> developed the <link xlink:type="simple" xlink:href="../735/11459735.xml">
virtual synchrony</link> model in a series of papers published between 1985 and 1987.  The primary reference to this work is <weblink xlink:type="simple" xlink:href="http://portal.acm.org/citation.cfm?id=37515&amp;dl=ACM&amp;coll=GUIDE">
"Exploiting Virtual Synchrony in Distributed Systems"</weblink>, which describes the Isis Toolkit, a system that  was used to build the New York and Swiss Stock Exchanges, French Air Traffic Control System, US Navy AEGIS Warship, and other applications.</p>
<p>

Recent work by Miguel Castro and <expert wordnetid="109617867" confidence="0.8">
<peer wordnetid="109626238" confidence="0.8">
<physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<interior_designer wordnetid="110210648" confidence="0.8">
<specialist wordnetid="110631941" confidence="0.8">
<intellectual wordnetid="109621545" confidence="0.8">
<colleague wordnetid="109935990" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<associate wordnetid="109816771" confidence="0.8">
<alumnus wordnetid="109786338" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<research_worker wordnetid="110523076" confidence="0.8">
<scholar wordnetid="110557854" confidence="0.8">
<link xlink:type="simple" xlink:href="../538/1507538.xml">
Barbara Liskov</link></scholar>
</research_worker>
</causal_agent>
</alumnus>
</associate>
</scientist>
</colleague>
</intellectual>
</specialist>
</interior_designer>
</person>
</physical_entity>
</peer>
</expert>
 used the state machine approach in what they call a <weblink xlink:type="simple" xlink:href="http://portal.acm.org/citation.cfm?id=296824&amp;coll=portal&amp;dl=ACM">
"Practical Byzantine fault tolerance"</weblink> architecture that replicates especially sensitive services using a version of Lamport's original state machine approach, but with optimizations that substantially improve performance.</p>
<p>

A hard real-time variant of this approach has been developed by Prof. <link>
Hermann Kopetz</link> at TU Vienna, Austria, in the <weblink xlink:type="simple" xlink:href="http://citeseer.ist.psu.edu/kopetz88timetriggered.html">
"Time-Triggered Architecture"</weblink> (<link xlink:type="simple" xlink:href="../611/5065611.xml">
TTA</link>) based on the <link xlink:type="simple" xlink:href="../996/2042996.xml">
Time-Triggered Protocol</link> (<link xlink:type="simple" xlink:href="../051/333051.xml">
TTP</link>) during the 1990s. It has been commercialized in the 2000s by <company wordnetid="108058098" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../742/10370742.xml">
TTTech Computertechnik AG</link></company>
 and deployed in various <link>
aerospace projects</link>.</p>

</sec>
<sec>
<st>
References</st>


<p>

<reflist>
<entry id="1">
 <cite style="font-style:normal">Schneider, Fred&#32;(1990).&#32;“<weblink xlink:type="simple" xlink:href="http://www.eecs.harvard.edu/cs262/DSbook.c7.pdf">
Implementing Fault-Tolerant Services Using the State Machine Approach: A Tutorial</weblink>”&#32;(&#91;&#93;). <it>ACM Computing Surveys</it>&#32;<b>22</b>: 299. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1145%2F98163.98167">
10.1145/98163.98167</weblink>.</cite>&nbsp;</entry>
<entry id="2">
 <cite style="font-style:normal">Lamport, Leslie&#32;(1978).&#32;“<weblink xlink:type="simple" xlink:href="http://research.microsoft.com/users/lamport/pubs/pubs.html#implementation">
The Implementation of Reliable Distributed Multiprocess Systems</weblink>”. <it>Computer Networks</it>&#32;<b>2</b>: 95–114. Retrieved on <link>
2008-03-13</link>.</cite>&nbsp;</entry>
<entry id="3">
Lamport, Leslie&#32;(2004).&#32;"<weblink xlink:type="simple" xlink:href="http://research.microsoft.com/users/lamport/pubs/pubs.html#lower-bound">
Lower Bounds for Asynchronous Consensus</weblink>".</entry>
<entry id="4">
 <cite style="font-style:normal">Lamport, Leslie; Mike Massa&#32;(2004).&#32;“<weblink xlink:type="simple" xlink:href="http://research.microsoft.com/users/lamport/pubs/pubs.html#web-dsn-submission">
Cheap Paxos</weblink>”. <it>Proceedings of the International Conference on Dependable Systems and Networks (DSN 2004)</it>.</cite>&nbsp;</entry>
<entry id="5">
 <cite style="font-style:normal">Lamport, Leslie; Robert Shostak, Marshall Pease&#32;(July 1982).&#32;“<weblink xlink:type="simple" xlink:href="http://research.microsoft.com/users/lamport/pubs/pubs.html#byz">
The Byzantine Generals Problem</weblink>”. <it>ACM Transactions on Programming Languages and Systems</it>&#32;<b>4</b>&#32;(3): 382–401. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1145%2F357172.357176">
10.1145/357172.357176</weblink>. Retrieved on <link>
2007-02-02</link>.</cite>&nbsp;</entry>
<entry id="6">
 <cite style="font-style:normal">Lamport, Leslie&#32;(1984).&#32;“<weblink xlink:type="simple" xlink:href="http://research.microsoft.com/users/lamport/pubs/pubs.html#using-time">
Using Time Instead of Timeout for Fault-Tolerant Distributed Systems</weblink>”. <it>ACM Transactions on Programming Languages and Systems</it>&#32;<b>6</b>&#32;(2): 254–280. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1145%2F2993.2994">
10.1145/2993.2994</weblink>. Retrieved on <link>
2008-03-13</link>.</cite>&nbsp;</entry>
<entry id="7">
 <cite style="font-style:normal">Birman, Kenneth; Thomas Joseph&#32;(1987).&#32;“<weblink xlink:type="simple" xlink:href="http://portal.acm.org/citation.cfm?id=37515&amp;dl=ACM&amp;coll=GUIDE">
Exploiting virtual synchrony in distributed systems</weblink>”. <it>Proceedings of the 11th ACM Symposium on Operating systems principles (SOSP)</it>&#32;<b>21</b>: 123. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1145%2F37499.37515">
10.1145/37499.37515</weblink>. Retrieved on <link>
2008-03-13</link>.</cite>&nbsp;</entry>
<entry id="8">
Lampson, Butler&#32;(1996).&#32;"<weblink xlink:type="simple" xlink:href="http://research.microsoft.com/lampson/58-Consensus/Abstract.html">
How to Build a Highly Available System Using Consensus</weblink>".&#32;Retrieved on <link>
2008-03-13</link>.</entry>
<entry id="9">
 <cite style="font-style:normal">Lamport, Leslie&#32;(July 1978).&#32;“<weblink xlink:type="simple" xlink:href="http://research.microsoft.com/users/lamport/pubs/pubs.html#time-clocks">
Time, Clocks and the Ordering of Events in a Distributed System</weblink>”. <it>Communications of the ACM</it>&#32;<b>21</b>&#32;(7): 558–565. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1145%2F359545.359563">
10.1145/359545.359563</weblink>. Retrieved on <link>
2007-02-02</link>.</cite>&nbsp;</entry>
<entry id="10">
Lamport, Leslie&#32;(2004).&#32;"<weblink xlink:type="simple" xlink:href="http://research.microsoft.com/users/lamport/pubs/pubs.html#lower-bound">
Lower Bounds for Asynchronous Consensus</weblink>".</entry>
<entry id="11">
Lamport, Leslie&#32;(2005).&#32;"<weblink xlink:type="simple" xlink:href="http://research.microsoft.com/users/lamport/pubs/pubs.html#fast-paxos">
Fast Paxos</weblink>".</entry>
<entry id="12">
 <cite style="font-style:normal">Lamport, Leslie&#32;(2005).&#32;“<weblink xlink:type="simple" xlink:href="http://research.microsoft.com/users/lamport/pubs/pubs.html#generalized">
Generalized Consensus and Paxos</weblink>”.</cite>&nbsp;</entry>
<entry id="13">
 <cite style="font-style:normal">Fischer, Michael&#32;(1985).&#32;“<weblink xlink:type="simple" xlink:href="http://research.microsoft.com/users/lamport/pubs/pubs.html#using-time">
Impossibility of Distributed Consensus with One Faulty
Process</weblink>”. <it>Journal of the Association for Computing Machinery</it>&#32;<b>32</b>&#32;(2): 347–382. Retrieved on <link>
2008-03-13</link>.</cite>&nbsp;</entry>
<entry id="14">
 <cite style="font-style:normal">Chandra, Tushar; Robert Griesemer, Joshua Redstone&#32;(2007).&#32;“<weblink xlink:type="simple" xlink:href="http://labs.google.com/papers/paxos_made_live.html">
Paxos Made Live – An Engineering Perspective</weblink>”. <it>PODC '07: 26th ACM Symposium on Principles of Distributed Computing</it>.</cite>&nbsp;</entry>
<entry id="15">
 <cite style="font-style:normal">Lamport, Leslie&#32;(May 1998).&#32;“<weblink xlink:type="simple" xlink:href="http://research.microsoft.com/users/lamport/pubs/pubs.html#lamport-paxos">
The Part-Time Parliament</weblink>”. <it>ACM Transactions on Computer Systems</it>&#32;<b>16</b>&#32;(2): 133–169. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1145%2F279227.279229">
10.1145/279227.279229</weblink>. Retrieved on <link>
2007-02-02</link>.</cite>&nbsp;</entry>
</reflist>
</p>

</sec>
</bdy>
</article>
