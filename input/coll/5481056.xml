<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 21:41:59[mciao0828] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<event  confidence="0.8" wordnetid="100029378">
<rule  confidence="0.8" wordnetid="105846932">
<act  confidence="0.8" wordnetid="100030358">
<psychological_feature  confidence="0.8" wordnetid="100023100">
<procedure  confidence="0.8" wordnetid="101023820">
<activity  confidence="0.8" wordnetid="100407535">
<algorithm  confidence="0.8" wordnetid="105847438">
<header>
<title>Analogical modeling</title>
<id>5481056</id>
<revision>
<id>232348350</id>
<timestamp>2008-08-16T18:06:03Z</timestamp>
<contributor>
<username>Rjwilmsi</username>
<id>203434</id>
</contributor>
</revision>
<categories>
<category>Machine learning</category>
<category>Computational linguistics</category>
<category>Classification algorithms</category>
</categories>
</header>
<bdy>

__NOTOC__<p>

<table style="float: right; border: 1px solid #8888aa; background: #f7f8ff; padding: 5px; font-size: 90%; margin: 0px 0px 15px 15px; clear:right;" cellpadding="1">
<row>
<col style="background: #ccf; text-align: center;">
 <b><link xlink:type="simple" xlink:href="../526/17526.xml">
Linguistics</link></b></col>
</row>
<row>
<col>
 <link xlink:type="simple" xlink:href="../422/55422.xml">
Theoretical linguistics</link></col>
</row>
<row>
<col style="padding-left: 1.0em;">
<link xlink:type="simple" xlink:href="../194/23194.xml">
Phonetics</link></col>
</row>
<row>
<col style="padding-left: 1.0em;">
<link xlink:type="simple" xlink:href="../247/23247.xml">
Phonology</link></col>
</row>
<row>
<col style="padding-left: 1.0em;">
<link xlink:type="simple" xlink:href="../646/20646.xml">
Morphology</link></col>
</row>
<row>
<col style="padding-left: 1.0em;">
<link xlink:type="simple" xlink:href="../860/26860.xml">
Syntax</link></col>
</row>
<row>
<col style="padding-left: 1.0em;">
<link xlink:type="simple" xlink:href="../742/3136742.xml">
Lexis</link></col>
</row>
<row>
<col style="padding-left: 1.0em;">
<link xlink:type="simple" xlink:href="../107/29107.xml">
Semantics</link></col>
</row>
<row>
<col style="padding-left: 2.0em;">
<link xlink:type="simple" xlink:href="../466/205466.xml">
Lexical semantics</link></col>
</row>
<row>
<col style="padding-left: 2.0em;">
<software wordnetid="106566077" confidence="0.8">
<application wordnetid="106570110" confidence="0.8">
<program wordnetid="106568978" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106359877" confidence="0.8">
<code wordnetid="106355894" confidence="0.8">
<coding_system wordnetid="106353757" confidence="0.8">
<link xlink:type="simple" xlink:href="../261/7271261.xml">
Statistical semantics</link></coding_system>
</code>
</writing>
</written_communication>
</program>
</application>
</software>
</col>
</row>
<row>
<col style="padding-left: 2.0em;">
<link xlink:type="simple" xlink:href="../890/7299890.xml">
Structural semantics</link></col>
</row>
<row>
<col style="padding-left: 2.0em;">
<link xlink:type="simple" xlink:href="../464/1042464.xml">
Prototype semantics</link></col>
</row>
<row>
<col style="padding-left: 1.0em;">
<link xlink:type="simple" xlink:href="../816/44816.xml">
Pragmatics</link></col>
</row>
<row>
<col style="border-bottom: 1px solid #ccc"></col>
</row>
<row>
<col>
 <link xlink:type="simple" xlink:href="../551/406551.xml">
Applied linguistics</link></col>
</row>
<row>
<col style="padding-left: 1.0em;">
<link xlink:type="simple" xlink:href="../614/18614.xml">
Language acquisition</link></col>
</row>
<row>
<col style="padding-left: 1.0em;">
<link xlink:type="simple" xlink:href="../538/160538.xml">
Psycholinguistics</link></col>
</row>
<row>
<col style="padding-left: 1.0em;">
<link xlink:type="simple" xlink:href="../842/89842.xml">
Sociolinguistics</link></col>
</row>
<row>
<col style="padding-left: 1.0em;">
<link xlink:type="simple" xlink:href="../208/166208.xml">
Linguistic anthropology</link></col>
</row>
<row>
<col style="padding-left: 1.0em;">
<link xlink:type="simple" xlink:href="../848/443848.xml">
Generative linguistics</link></col>
</row>
<row>
<col style="padding-left: 1.0em;">
<link xlink:type="simple" xlink:href="../711/72711.xml">
Cognitive linguistics</link></col>
</row>
<row>
<col style="padding-left: 1.0em;">
<link xlink:type="simple" xlink:href="../561/5561.xml">
Computational linguistics</link></col>
</row>
<row>
<col style="padding-left: 1.0em;">
<link xlink:type="simple" xlink:href="../402/55402.xml">
Descriptive linguistics</link></col>
</row>
<row>
<col style="padding-left: 1.0em;">
<link xlink:type="simple" xlink:href="../630/63630.xml">
Historical linguistics</link></col>
</row>
<row>
<col style="padding-left: 2.0em;">
<link xlink:type="simple" xlink:href="../814/931814.xml">
Comparative linguistics</link></col>
</row>
<row>
<col style="padding-left: 2.0em;">
<link xlink:type="simple" xlink:href="../207/888207.xml">
Etymology</link></col>
</row>
<row>
<col style="padding-left: 1.0em;">
<assortment wordnetid="108398773" confidence="0.8">
<collection wordnetid="107951464" confidence="0.8">
<group wordnetid="100031264" confidence="0.8">
<link xlink:type="simple" xlink:href="../445/302445.xml">
Stylistics</link></group>
</collection>
</assortment>
</col>
</row>
<row>
<col style="padding-left: 2.0em;">
<link xlink:type="simple" xlink:href="../136/229136.xml">
Prescription</link></col>
</row>
<row>
<col style="padding-left: 1.0em;">
<link xlink:type="simple" xlink:href="../277/40277.xml">
Corpus linguistics</link></col>
</row>
<row>
<col style="border-bottom: 1px solid #ccc"></col>
</row>
<row>
<col>
 <link xlink:type="simple" xlink:href="../419/55419.xml">
History of linguistics</link></col>
</row>
<row>
<col>
 <link xlink:type="simple" xlink:href="../416/55416.xml">
List of linguists</link></col>
</row>
<row>
<col>
 <link xlink:type="simple" xlink:href="../167/4847167.xml">
Unsolved problems</link></col>
</row>
</table>

<b>Analogical modeling</b> (hereafter AM) is a formal theory of <link>
exemplar-based</link> analogical reasoning, proposed by <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<good_person wordnetid="110138767" confidence="0.8">
<intellectual wordnetid="109621545" confidence="0.8">
<alumnus wordnetid="109786338" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<saint wordnetid="110546850" confidence="0.8">
<scholar wordnetid="110557854" confidence="0.8">
<link xlink:type="simple" xlink:href="../879/11679879.xml">
Royal Skousen</link></scholar>
</saint>
</causal_agent>
</alumnus>
</intellectual>
</good_person>
</person>
</physical_entity>
, professor of Linguistics and English language at <university wordnetid="108286163" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../058/82058.xml">
Brigham Young University</link></university>
 in <link xlink:type="simple" xlink:href="../131/82131.xml">
Provo</link>, Utah. It is applicable to language modeling and other categorization tasks. Analogical modeling is related to <link xlink:type="simple" xlink:href="../636/263636.xml">
connectionism</link> and <link xlink:type="simple" xlink:href="../388/1775388.xml">
nearest neighbor</link> approaches, in that it is data-based rather than abstraction-based; but it is distinguished by its ability to cope with imperfect datasets (such as caused by simulated short term memory limits) and to base predictions on all relevant segments of the dataset, whether near or far. In language modeling, AM has successfully predicted empirically valid forms for which no theoretical explanation was known (see the discussion of Finnish morphology in Skousen et al. 2002). </p>

<sec>
<st>
Implementation of the model</st>

<ss1>
<st>
Overview</st>
<p>

An exemplar-based model consists of a general-purpose modeling engine and a problem-specific dataset. Within the dataset, each exemplar (a case to be reasoned from, or an informative past experience) appears as a feature vector: a row of values for parameters that describe the problem. For example, in a spelling-to-sound task, the feature vector might consist of the letters of a word.  Each exemplar in the dataset is stored with an outcome, such as a phoneme or phone to be generated. When the model is presented with a novel situation (in the form of an outcome-less feature vector), the engine algorithmically sorts the dataset to find exemplars that helpfully resemble it, and selects one, whose outcome is the model's prediction. The particulars of this algorithm distinguish one exemplar-based modeling system from another.</p>
<p>

In AM, we think of the feature values as characterizing a context, and the outcome as a behavior that occurs within that context. Accordingly, the novel situation is known as the <it>given context.</it> Given the known features of the context, the AM engine systematically generates all contexts that include it (all of its <it>supracontexts</it>), and extracts from the dataset the exemplars that belong to each. The engine then discards those supracontexts whose outcomes are <link xlink:type="simple" xlink:href="../802/75802.xml">
inconsistent</link> (this measure of consistency will be discussed further below), leaving an <it>analogical set</it> of supracontexts, and probabilistically selects an exemplar from the analogical set with a bias toward those in large supracontexts. This multilevel search exponentially magnifies the likelihood of a behavior's being predicted as it occurs reliably in settings that specifically resemble the given context.</p>

</ss1>
<ss1>
<st>
Analogical modeling in detail</st>

<p>

AM performs the same process for each case it is asked to evaluate. The given context, consisting of n variables, is used as a template to generate two-to-the-n supracontexts. Each supracontext is a set of exemplars in which one or more variables have the same values that they do in the given context, and the other variables are ignored. In effect, each is a view of the data, created by filtering for some criteria of similarity to the given context, and the total set of supracontexts exhausts all such views. Alternatively, each supracontext is a theory of the task or a proposed rule whose predictive power needs to be evaluated. </p>
<p>

It is important to note that the supracontexts are not equal peers one with another; they are arranged by their distance from the given context, forming a hierarchy. If a supracontext specifies all of the variables that another one does and more, it is a subcontext of that other one, and it lies closer to the given context. (The hierarchy is not strictly branching; each supracontext can itself be a subcontext of several others, and can have several subcontexts.) This hierarchy becomes significant in the next step of the algorithm.</p>
<p>

The engine now chooses the analogical set from among the supracontexts. A supracontext may contain exemplars that only exhibit one behavior; it is deterministically homogeneous and is included. It is a view of the data that displays regularity, or a relevant theory that has never yet been disproven. A supracontext may exhibit several behaviors, but contain no exemplars that occur in any more specific supracontext (that is, in any of its subcontexts); in this case it is non-deterministically homogeneous and is included. Here there is no great evidence that a systematic behavior occurs, but also no counterargument. Finally, a supracontext may be heterogeneous, meaning that it exhibits behaviors that are found in a subcontext (closer to the given context), and also behaviors that are not. Where the ambiguous behavior of the nondeterministically homogeneous supracontext was accepted, this is rejected because the intervening subcontext demonstrates that there is a better theory to be found. The heterogeneous supracontext is therefore excluded. This guarantees that we see an increase in meaningfully consistent behavior in the analogical set as we approach the given context. </p>
<p>

With the analogical set chosen, each appearance of an exemplar (for a given exemplar may appear in several of the analogical supracontexts) is given a pointer to every other appearance of an exemplar within its supracontexts. One of these pointers is then selected at random and followed, and the exemplar to which it points provides the outcome. This gives each supracontext an importance proportional to the square of its size, and makes each exemplar likely to be selected in direct proportion to the sum of the sizes of all analogically consistent supracontexts in which it appears. Then, of course, the probability of predicting a particular outcome is proportional to the summed probabilities of all the exemplars that support it. </p>
<p>

(Skousen 2002, in Skousen et al. 2002, pp. 11-25, and Skousen 2003, both passim)</p>

</ss1>
<ss1>
<st>
Formulas</st>
<p>

Given a context with <math>n</math> elements:
<indent level="1">

total number of pairings: <math>n^2</math>
</indent>
:number of agreements for outcome <it>i</it>: <math>n_i^2</math>
<indent level="1">

number of disagreements for outcome <it>i</it>: <math>n_i(n - n_i)</math>
</indent>
:total number of agreements: <math>\sum{n_i^2}</math>
<indent level="1">

total number of disagreements: <math>\sum{n_i(n - n_i)} = n^2 - \sum{n_i^2}</math>
</indent>

</p>
</ss1>
<ss1>
<st>
Example</st>
<p>

This terminology is best understood through an example. In the example used in the second chapter of Skousen (1989), each context consists of three variables with potential values 0-3</p>
<p>

<indent level="1">

Variable 1: 0,1,2,3
</indent>
:Variable 2: 0,1,2,3
<indent level="1">

Variable 3: 0,1,2,3
</indent>

</p>
</ss1>
</sec>
<sec>
<st>
Historical Context</st>
<p>

Analogy has been considered useful in describing language at least since the time of <link xlink:type="simple" xlink:href="../041/11041.xml">
Saussure</link>. <person wordnetid="100007846" confidence="0.9508927676800064">
<philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../566/21566.xml">
Noam Chomsky</link></philosopher>
</person>
 and others have more recently criticized analogy as too vague to really be useful (Bańko 1991), an appeal to a <it>deus ex machina.</it> Skousen's proposal appears to address that criticism by proposing an explicit mechanism for analogy, which can be tested for psychological validity.</p>

</sec>
<sec>
<st>
Applications</st>
<p>

Analogical modeling has been employed in experiments ranging from <link xlink:type="simple" xlink:href="../247/23247.xml">
phonology</link> and <link xlink:type="simple" xlink:href="../646/20646.xml">
morphology (linguistics)</link> to <link xlink:type="simple" xlink:href="../209/22209.xml">
orthography</link> and <link xlink:type="simple" xlink:href="../860/26860.xml">
syntax</link>.</p>

</sec>
<sec>
<st>
Problems</st>
<p>

Though analogical modeling aims to create a model free from rules seen as contrived by linguists, in its current form it still requires researchers to select which variables to take into consideration. This is necessary because of the so-called "exponential explosion" of processing power requirements of the computer software used to implement analogical modeling. Recent research suggests that <link xlink:type="simple" xlink:href="../220/25220.xml">
quantum computing</link> could provide the solution to such performance bottlenecks (Skousen et al. 2002, see pp 45-47).</p>

</sec>
<sec>
<st>
References</st>
<p>

<list>
<entry level="1" type="bullet">

 <cite style="font-style:normal" class="book">Royal Skousen&#32;(1989). Analogical Modeling of Language&#32;(hardcover),&#32;Dordrecht:&#32;Kluwer Academic Publishers,&#32;xii+212pp. ISBN 0-7923-0517-5.</cite>&nbsp;</entry>
<entry level="1" type="bullet">

 <cite style="font-style:normal">Miroslaw Bańko&#32;(June 1991).&#32;"<weblink xlink:type="simple" xlink:href="http://acl.ldc.upenn.edu/J/J91/J91-2010.pdf">
Review: Analogical Modeling of Language</weblink>". <it>Computational Linguistics</it>&#32;<b>17</b>&#32;(2): 246–248.</cite>&nbsp;</entry>
<entry level="1" type="bullet">

 <cite style="font-style:normal" class="book">Royal Skousen&#32;(1992). Analogy and Structure.&#32;Dordrect:&#32;Kluwer Academic Publishers.</cite>&nbsp;</entry>
<entry level="1" type="bullet">

 <cite style="font-style:normal" class="book">&#32;(2002)&#32;in Royal Skousen, Deryle Lonsdale, Dilworth B. Parkinson: Analogical Modeling: An exemplar-based approach to language&#32;(Human Cognitive Processing vol. 10),&#32;Amsterdam/Philadelphia:&#32;John Benjamins Publishing Company,&#32;x+417pp. ISBN 1-58811-302-7.</cite>&nbsp;</entry>
<entry level="1" type="bullet">

 Skousen, Royal.  (2003). <weblink xlink:type="simple" xlink:href="http://humanities.byu.edu/am/bls_paper3.pdf">
<it>Analogical Modeling: Exemplars, Rules, and Quantum Mechanics.''</it></weblink>.  Presented at the Berkeley Linguistics Society conference.</entry>
</list>
</p>

</sec>
<sec>
<st>
See also</st>
<p>

<list>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../561/5561.xml">
Computational Linguistics</link></entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../636/263636.xml">
Connectionism</link></entry>
</list>
</p>

</sec>
<sec>
<st>
External links</st>
<p>

<list>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://humanities.byu.edu/am">
Analogical Modeling Research Group Homepage</weblink></entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://linguistlist.org/issues/14/14-110.html">
LINGUIST List Announcement</weblink> of <it>Analogical Modeling</it>, Skousen et al. (2002)</entry>
</list>
</p>

</sec>
</bdy>
</algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</article>
