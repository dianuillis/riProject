<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 17:16:53[mciao0827] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<event  confidence="0.8" wordnetid="100029378">
<rule  confidence="0.8" wordnetid="105846932">
<act  confidence="0.8" wordnetid="100030358">
<psychological_feature  confidence="0.8" wordnetid="100023100">
<procedure  confidence="0.8" wordnetid="101023820">
<activity  confidence="0.8" wordnetid="100407535">
<algorithm  confidence="0.8" wordnetid="105847438">
<header>
<title>Non-blocking synchronization</title>
<id>554867</id>
<revision>
<id>239662819</id>
<timestamp>2008-09-19T21:59:07Z</timestamp>
<contributor>
<username>Salix alba</username>
<id>212526</id>
</contributor>
</revision>
<categories>
<category>Articles to be merged&amp;#32;since May 2008</category>
<category>Concurrency control</category>
<category>Concurrent algorithms</category>
<category>Synchronization</category>
<category>Operating system technology</category>
<category>All articles to be merged</category>
</categories>
</header>
<bdy>

<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-move" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="50px" src="Mergefrom.svg">
</image>
</p>
</col>
<col style="" class="mbox-text">
 It has been suggested that  be  into this article or section. ()</col>
</row>
</table>


In <link xlink:type="simple" xlink:href="../323/5323.xml">
computer science</link>, <b>non-blocking synchronization</b> ensures that <link>
thread</link>s competing for a shared <link xlink:type="simple" xlink:href="../365/1728365.xml">
resource</link> do not have their <link xlink:type="simple" xlink:href="../206/418206.xml">
execution</link> indefinitely postponed by <link xlink:type="simple" xlink:href="../827/36827.xml">
mutual exclusion</link>. Literature up to the turn of the century used "non-blocking" synonymously with <it>lock-free</it>: an algorithm with guaranteed system-wide progress. However, since 2003,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref> the term has been weakened to only prevent progress-blocking interactions with a <link xlink:type="simple" xlink:href="../857/6857.xml">
preemptive scheduler</link>.<p>

In modern usage, therefore, an algorithm is <it>non-blocking</it> if the suspension of one or more threads will not stop the potential progress of the remaining threads. They are designed to avoid requiring a <link xlink:type="simple" xlink:href="../312/638312.xml">
critical section</link>. Often, these algorithms allow multiple processes to make progress on a problem without ever blocking each other.  For some operations, these algorithms provide an alternative to <link xlink:type="simple" xlink:href="../593/244593.xml">
locking mechanism</link>s.</p>



<sec>
<st>
 Motivation </st>

<p>

The traditional approach to multi-threaded programming is to use <link xlink:type="simple" xlink:href="../593/244593.xml">
locks</link> to synchronize access to shared resources. Synchronization primitives such as <link xlink:type="simple" xlink:href="../827/36827.xml">
mutexes</link>, semaphores, and <link xlink:type="simple" xlink:href="../312/638312.xml">
critical section</link>s are all mechanisms by which a programmer can ensure that certain sections of code do not execute concurrently if doing so would corrupt shared memory structures. If one thread attempts to acquire a lock that is already held by another thread, the thread will block until the lock is free.</p>
<p>

Blocking a thread, though, is undesirable for many reasons. An obvious reason is that while the thread is blocked, it cannot accomplish anything.  If the blocked thread is performing a high-priority or <link xlink:type="simple" xlink:href="../767/25767.xml">
real-time</link> task, it is highly undesirable to halt its progress.  Other problems are less obvious.  Certain interactions between locks can lead to error conditions such as <link xlink:type="simple" xlink:href="../181/105181.xml">
deadlock</link>, <link>
livelock</link>, and <link xlink:type="simple" xlink:href="../507/521507.xml">
priority inversion</link>.  Using locks also involves a trade-off between coarse-grained locking, which can significantly reduce opportunities for <link xlink:type="simple" xlink:href="../162/145162.xml">
parallelism</link>, and fine-grained locking, which requires more careful design, increases overhead and is more prone to bugs.</p>
<p>

Non-blocking algorithms are also safe for use in <link xlink:type="simple" xlink:href="../824/638824.xml">
interrupt handler</link>s: even though the <link xlink:type="simple" xlink:href="../566/2204566.xml">
preempted</link> thread cannot be resumed, progress is still possible without it. In contrast, global data structures protected by mutual exclusion cannot safely be accessed in a handler, as the preempted thread may be the one holding the lock.</p>
<p>

Non-blocking synchronization has the potential to prevent <link xlink:type="simple" xlink:href="../507/521507.xml">
priority inversion</link>, as no thread is forced to wait for a suspended thread to complete. However, as livelock is still possible in the modern definition, threads have to wait when they encounter contention; hence, priority inversion is still possible depending upon the contention management system used. Lock-free algorithms, below, avoid priority inversion.</p>

</sec>
<sec>
<st>
 Implementation </st>

<p>

Non-blocking algorithms use <link xlink:type="simple" xlink:href="../310/1204310.xml">
atomic</link> <link xlink:type="simple" xlink:href="../875/5587875.xml">
read-modify-write</link> primitives that the hardware must provide, the most notable of which is <link xlink:type="simple" xlink:href="../224/632224.xml">
compare and swap (CAS)</link>. Ultimately, all synchronizing algorithms must use these; however, <link xlink:type="simple" xlink:href="../312/638312.xml">
critical section</link>s are almost always implemented using standard interfaces over these primitives. Until recently, all non-blocking algorithms had to be written "natively" with the underlying primitives to achieve acceptable performance. However, the emerging field of <link xlink:type="simple" xlink:href="../707/1478707.xml">
software transactional memory</link> promises standard abstractions for writing efficient non-blocking code.</p>
<p>

Much research has also been done in providing basic <link xlink:type="simple" xlink:href="../519/8519.xml">
data structure</link>s such as <link xlink:type="simple" xlink:href="../993/273993.xml">
stacks</link>, <link xlink:type="simple" xlink:href="../265/25265.xml">
queues</link>, <link xlink:type="simple" xlink:href="../127/201127.xml">
sets</link>, and <link xlink:type="simple" xlink:href="../833/13833.xml">
hash table</link>s.  These allow programs to easily exchange data between threads asynchronously.</p>

</sec>
<sec>
<st>
 Wait-freedom </st>

<p>

Wait-freedom is the strongest non-blocking guarantee of progress, combining guaranteed system-wide throughput with <link xlink:type="simple" xlink:href="../591/501591.xml">
starvation</link>-freedom. An algorithm is wait-free if every operation has a bound on the number of steps it will take before completing.</p>
<p>

It was shown in the 1980s<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref> that all algorithms can be implemented wait-free, and many transformations from serial code, called <it>universal constructions</it>, have been demonstrated. However, the resulting performance does not in general match even naive blocking designs. It has also been shown<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%223%22])">3</ref> that the widely-available <link xlink:type="simple" xlink:href="../310/1204310.xml">
atomic</link> <it>conditional</it> primitives, <link xlink:type="simple" xlink:href="../224/632224.xml">
compare-and-swap</link> and <link xlink:type="simple" xlink:href="../985/2882985.xml">
LL/SC</link>, cannot provide starvation-free implementations of many common data structures without memory costs growing linearly in the number of threads. Wait-free algorithms are therefore rare, both in research and in practice.</p>

</sec>
<sec>
<st>
 Lock-freedom </st>

<p>

<indent level="1">

<it>Main article: <link xlink:type="simple" xlink:href="../864/554864.xml">
Lock-free and wait-free algorithms</link></it>
</indent>

Lock-freedom allows individual threads to starve but guarantees system-wide throughput. An algorithm is lock-free if every step taken achieves global progress (for some sensible definition of progress). All wait-free algorithms are lock-free.</p>
<p>

In general, a lock-free algorithm can run in four phases: completing one's own operation, assisting an obstructing operation, aborting an obstructing operation, and waiting. Completing one's own operation is complicated by the possibility of concurrent assistance and abortion, but is invariably the fastest path to completion.</p>
<p>

The decision about when to assist, abort or wait when an obstruction is met is the responsibility of a <it>contention manager</it>. This may be very simple (assist higher priority operations, abort lower priority ones), or may be more optimized to achieve better throughput, or lower the latency of prioritized operations.</p>
<p>

Correct concurrent assistance is typically the most complex part of a lock-free algorithm, and often very costly to execute: not only does the assisting thread slow down, but thanks to the mechanics of shared memory, the thread being assisted will be slowed, too, if it is still running.</p>

</sec>
<sec>
<st>
 Obstruction-freedom </st>

<p>

Obstruction-freedom is possibly the weakest natural non-blocking progress guarantee. An algorithm is obstruction-free if at any point, a single thread executed in isolation (i.e. with all obstructing threads suspended) for a bounded number of steps will complete its operation. All lock-free algorithms are obstruction-free.</p>
<p>

Obstruction-freedom demands only that any partially-completed operation can be aborted and the changes made rolled back. Dropping concurrent assistance can often result in much simpler algorithms that are easier to validate. Preventing the system from continually <link>
live-locking</link> is the task of a contention manager.</p>
<p>

Obstruction-freedom is also called <link xlink:type="simple" xlink:href="../011/233011.xml">
optimistic concurrency control</link>.</p>
<p>

Some obstruction-free algorithms use a pair of "consistency markers" in the data structure.
Processes reading the data structure first read one consistency marker, then read the relevant data into an internal buffer, then read the other marker, and then compare the markers.
When comparing the two markers, occasionally a process will notice they are different, indicating "inconsistent data".
That happens when the read was interrupted by some other process updating the data structure.
In that case the process discards the data in the internal buffer and tries again.
When comparing the two markers, typically both markers will be identical, indicating that the data is consistent.</p>
<p>

Recent research<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%224%22])">4</ref> has yielded a promising practical contention manager, whimsically named <it>Polka</it>, combining <link xlink:type="simple" xlink:href="../272/1148272.xml">
exponential backoff</link> with "priority accumulation". As an operation progresses, it gains "priority"; when an operation is obstructed by another with higher priority, it will back off, with backoff intervals increasing exponentially. Each backoff increases the operation's priority; only when its priority is greater than that of its obstructor will it abort it. Aborted operations retain their former priority, giving their next attempt a greater chance of success.</p>
<p>

Polka achieves good throughput in benchmarks because it minimizes both wasted effort, by prioritizing long transactions, and memory interconnect contention, using exponential backoff. This can inform other parallel algorithms, such as lock-free ones, to achieve greater throughput in the common case.</p>

</sec>
<sec>
<st>
See also</st>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../356/217356.xml">
Concurrency control</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../310/1204310.xml">
Linearizability</link></entry>
</list>
</p>

</sec>
<sec>
<st>
References</st>
<p>

<reflist>
<entry id="1">
M. Herlihy, V. Luchangco and M. Moir. <weblink xlink:type="simple" xlink:href="http://www.cs.brown.edu/people/mph/HerlihyLM03/main.pdf">
"Obstruction-Free Synchronization: Double-Ended Queues as an Example."</weblink> 23rd International Conference on Distributed Computing Systems, 2003, p.522.</entry>
<entry id="2">
Maurice P. Herlihy. <weblink xlink:type="simple" xlink:href="http://portal.acm.org/citation.cfm?coll=GUIDE&amp;dl=GUIDE&amp;id=62593">
"Impossibility and universality results for wait-free synchronization"</weblink> Proceedings of the seventh annual ACM Symposium on Principles of distributed computing, 1988, pp. 276 - 290.</entry>
<entry id="3">
F. Fich, D. Hendler, N. Shavit. <weblink xlink:type="simple" xlink:href="http://www.cs.tau.ac.il/~afek/Handler-conditionals.pdf">
"On the inherent weakness of conditional synchronization primitives."</weblink> 23rd Annual ACM Symposium on Principles of Distributed Computing, 2004, pp. 80-87.</entry>
<entry id="4">
W. Scherer and M. Scott. <weblink xlink:type="simple" xlink:href="http://www.cs.rochester.edu/u/scott/papers/2005_PODC_CM.pdf">
"Advanced Contention Management for Dynamic Software Transactional Memory."</weblink> 24th annual ACM SIGACT-SIGOPS Symposium on Principles of Distributed Computing, 2005, pp. 240-248.</entry>
</reflist>
</p>

</sec>
<sec>
<st>
External links</st>
<p>

<list>
<entry level="1" type="bullet">

Article "<weblink xlink:type="simple" xlink:href="http://www.research.ibm.com/people/m/michael/podc-1996.pdf">
Simple, Fast, and Practical Non-Blocking and Blocking Concurrent Queue Algorithms</weblink>" by <link>
Maged M. Michael</link> and <physical_entity wordnetid="100001930" confidence="0.8">
<peer wordnetid="109626238" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<colleague wordnetid="109935990" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<associate wordnetid="109816771" confidence="0.8">
<link xlink:type="simple" xlink:href="../547/7828547.xml">
Michael L. Scott</link></associate>
</scientist>
</causal_agent>
</colleague>
</person>
</peer>
</physical_entity>
</entry>
<entry level="1" type="bullet">

Discussion "<weblink xlink:type="simple" xlink:href="http://groups.google.com/groups?group=comp.programming.threads&amp;threadm=c2s1qn%24mrj%247%40newsserv.zdv.uni-tuebingen.de">
Communication between Threads, without blocking</weblink>"</entry>
</list>
</p>


</sec>
</bdy>
</algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</article>
