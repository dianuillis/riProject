<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 21:50:42[mciao0825] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Sensitivity and specificity</title>
<id>5599330</id>
<revision>
<id>244377928</id>
<timestamp>2008-10-10T14:39:55Z</timestamp>
<contributor>
<username>Wjastle</username>
<id>7382776</id>
</contributor>
</revision>
<categories>
<category>Articles to be merged&amp;#32;since October 2008</category>
<category>All articles to be merged</category>
<category>Statistical theory</category>
<category>Biostatistics</category>
</categories>
</header>
<bdy>

<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-move" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="150px" src="Merge-arrows.svg">
<caption>

Merge arrows
</caption>
</image>
</p>
</col>
<col style="" class="mbox-text">
 It has been suggested that this article or section be  with . ()</col>
</row>
</table>

<p>

<b>Sensitivity and specificity</b> are statistical measures of the performance of a <link xlink:type="simple" xlink:href="../393/205393.xml">
binary classification</link> <link xlink:type="simple" xlink:href="../284/30284.xml">
test</link>. The <b>sensitivity</b> or the <b>recall rate</b> measures the proportion of actual positives which are correctly identified as such (i.e. the percentage of sick people who are identified as having the condition); and the <b>specificity</b> measures the proportion of negatives which are correctly identified (i.e. the percentage of well people who are identified as not having the condition). They are closely related to the concepts of <link xlink:type="simple" xlink:href="../877/5657877.xml">
type I and type II errors</link>.</p>
<p>

For any test, there is usually a trade-off between each measure. For example in a manufacturing setting in which one is testing for faults, one may be willing to risk discarding functioning components (low specificity), in order to increase the chance of identifying nearly all faulty components (high sensitivity). This trade-off can be represented graphically using a <link xlink:type="simple" xlink:href="../505/922505.xml">
ROC curve</link>.</p>

<sec>
<st>
Definitions</st>
<p>

Imagine a scenario where people are tested for a disease. The outcome can be positive (sick) or negative (healthy).</p>

<ss1>
<st>
Sensitivity</st>
<p>

<indent level="1">

<math>{\rm sensitivity}=\frac{\rm number\ of\ True\ Positives\ called\ as\ Positives}{{\rm number\ of\ True\ Positives\ (called\ as\ Positives}+{\rm called\ as\ False\ Negatives)}}</math>
</indent>

A sensitivity of 100% means that the test recognizes all sick people as such.  Thus in a high sensitivity test, a negative result  is used to rule out the disease.</p>
<p>

Sensitivity alone does not tell us how well the test predicts other classes (that is, about the negative cases).  In the binary classification, as illustrated above, this is the corresponding <link>
 specificity</link> test, or equivalently, the sensitivity for the other classes. </p>
<p>

Sensitivity is not the same as the <link xlink:type="simple" xlink:href="../952/1556952.xml">
positive predictive value</link> (ratio of true positives to combined true and false positives), which is as much a statement about the proportion of actual positives in the population being tested as it is about the test.</p>
<p>

The calculation of sensitivity does not take into account indeterminate test results. If a test cannot be repeated, the options are to exclude indeterminate samples from analyses (but the number of exclusions should be stated when quoting sensitivity), or, alternatively, indeterminate samples can be treated as false negatives (which gives the worst-case value for sensitivity and may therefore underestimate it).</p>

</ss1>
<ss1>
<st>
Specificity</st>
<p>

<indent level="1">

<math>{\rm specificity}=\frac{\rm number\ of\ True\ Negatives\ called\ as\ Negatives}{{\rm number\ of\ True\ Negatives\ (called\ as\ Negatives}+{\rm called\ as\ False\ Positives)}}</math>
</indent>

A specificity of <b>100%</b> means that the test recognizes all healthy people as healthy.   Thus a positive result in a high specificity test is used to rule in the disease. The maximum is trivially achieved by a test that claims everybody healthy regardless of the true condition. Therefore, the specificity alone does not tell us how well the test recognizes positive cases.  We also need to know the <link xlink:type="simple" xlink:href="../330/5599330.xml">
sensitivity</link> of the test to the class, or equivalently, the specificities to the other classes.</p>
<p>

A test with a high specificity has a low <link>
 Type I error</link> rate.</p>
<p>

Specificity is sometimes confused with the <link xlink:type="simple" xlink:href="../887/14343887.xml">
precision</link> or the <link xlink:type="simple" xlink:href="../952/1556952.xml">
positive predictive value</link>, both of which refer to the fraction of returned positives that are true positives. The distinction is critical when the classes are different sizes. A test with very high specificity can have very low precision if there are far more true negatives than true positives, and vice versa.</p>

</ss1>
</sec>
<sec>
<st>
Worked example</st>

<p>

<list>
<entry level="1" type="definition">

Relationships among terms: </entry>
</list>
</p>
<p>

<table style="text-align: center; background: #FFFFFF;" align="center" border="1">
<row>


<col colspan="2" style="background: #ddffdd;">
 <b>Condition(as determined by "<link xlink:type="simple" xlink:href="../000/723000.xml">
Gold standard</link>")</b></col>
</row>
<row>


<col style="background: #ddffdd;">
<b><it>Positive</it></b></col>
<col style="background: #ddffdd;">
<b><it>Negative</it></b></col>

</row>
<row>
<col style="background: #ffdddd;" rowspan="2">
<b>Testoutcome</b></col>
<col style="background: #ffdddd;">
<b><it>Positive</it></b></col>
<col style="background: #eeeeff;">
<b>True Positive</b></col>
<col>
  <b>False Positive</b>(<link>
Type I error</link>, <link xlink:type="simple" xlink:href="../994/554994.xml">
P-value</link>)</col>
<col>
  → <process wordnetid="105701363" confidence="0.8">
<inquiry wordnetid="105797597" confidence="0.8">
<thinking wordnetid="105770926" confidence="0.8">
<problem_solving wordnetid="105796750" confidence="0.8">
<experiment wordnetid="105798043" confidence="0.8">
<trial wordnetid="105799212" confidence="0.8">
<higher_cognitive_process wordnetid="105770664" confidence="0.8">
<link xlink:type="simple" xlink:href="../952/1556952.xml">
Positive predictive value</link></higher_cognitive_process>
</trial>
</experiment>
</problem_solving>
</thinking>
</inquiry>
</process>
</col>
</row>
<row>
<col style="background: #ffdddd;">
<b><it>Negative</it></b></col>
<col style="background: #eeeeff;">
 <b>False Negative</b>(<link>
Type II error</link>)</col>
<col>
<b>True Negative</b></col>
<col>
  → <link xlink:type="simple" xlink:href="../957/1556957.xml">
Negative predictive value</link></col>
</row>
<row>


<col style="background: #eeeeff;">
  ↓<link>
Sensitivity</link></col>
<col>
  ↓<link>
Specificity</link></col>
</row>
</table>
</p>
<p>

<list>
<entry level="1" type="definition">

A worked example: the <link xlink:type="simple" xlink:href="../768/643768.xml">
Fecal occult blood</link> (FOB) screen test is used in 203 people to look for bowel cancer:</entry>
</list>
</p>
<p>

<table style="text-align: center; background: #FFFFFF;" align="center" border="1">
<row>


<col colspan="2" style="background: #ddffdd;">
 <b>Patients with <link xlink:type="simple" xlink:href="../979/206979.xml">
bowel cancer</link>(as confirmed on <link xlink:type="simple" xlink:href="../002/197002.xml">
endoscopy</link>)</b></col>
</row>
<row>


<col style="background: #ddffdd;">
<b><it>Positive</it></b></col>
<col style="background: #ddffdd;">
<b><it>Negative</it></b></col>
<col>
?</col>
</row>
<row>
<col style="background: #ffdddd;" rowspan="2">
<b>FOBtest</b></col>
<col style="background: #ffdddd;">
<b><it>Positive</it></b></col>
<col style="background: #eeeeff;">
<b>TP = 2</b></col>
<col>
<b>FP = 18</b></col>
<col>
= TP / (TP + FP)= 2 / (2 + 18)= 2 / 20 <b>≡ 10%</b></col>
</row>
<row>
<col style="background: #ffdddd;">
<b><it>Negative</it></b></col>
<col style="background: #eeeeff;">
<b>FN = 1</b></col>
<col>
<b>TN = 182</b></col>
<col>
= TN / (TN + FN)182 / (1 + 182)= 182 / 183 <b>≡ 99.5%</b></col>
</row>
<row>


<col style="background: #eeeeff;">
↓= TP / (TP + FN)= 2 / (2 + 1)= 2 / 3 <b>≡ 66.67%</b></col>
<col>
↓= TN / (FP + TN)= 182 / (18 + 182)= 182 / 200 <b>≡ 91%</b></col>
</row>
</table>
</p>
<p>

<b>Related calculations</b>
<list>
<entry level="1" type="bullet">

 False positive rate (α) = FP / (FP + TN) = 18 / (18 + 182) = 9% = 1 - specificity</entry>
<entry level="1" type="bullet">

 False negative rate (β) = FN / (TP + FN) = 1 / (2 + 1) = 33% = 1 - sensitivity</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../695/238695.xml">
Power</link> = sensitivity =  1 − β</entry>
</list>
</p>
<p>

Hence with large numbers of false positives and few false negatives, a positive FOB screen test is in itself poor at confirming cancer (PPV=10%) and further investigations must be undertaken, it will though pickup 66.7% of all cancers (the sensitivity). However as a screening test, a negative result is very good at reassuring that a patient does not have cancer (NPV=99.5%) and at this initial screen correctly identifies 91% of those who do not have cancer (the specificity).</p>

</sec>
<sec>
<st>
Terminology in information retrieval</st>
<p>
 
In <link xlink:type="simple" xlink:href="../271/15271.xml">
information retrieval</link> positive predictive value is called <b>precision</b>, and sensitivity is called <b>recall</b>.</p>
<p>

The <link>
F-measure</link> can be used as a single measure of performance of the test.  The F-measure is the <link xlink:type="simple" xlink:href="../463/14463.xml">
harmonic mean</link> of precision and recall:</p>
<p>

<indent level="1">

<math>F = 2 \times ({\rm precision} \times {\rm recall}) / ({\rm precision} + {\rm recall}).</math>
</indent>

In the traditional language of <link xlink:type="simple" xlink:href="../284/30284.xml">
statistical hypothesis testing</link>, the sensitivity of a test is called the <link xlink:type="simple" xlink:href="../695/238695.xml">
statistical power</link> of the test, although the word <it>power</it> in that context has a more general usage that is not applicable in the present context.  A sensitive test will have fewer <link>
 Type II error</link>s.</p>

</sec>
<sec>
<st>
 See also </st>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../393/205393.xml">
binary classification</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../505/922505.xml">
receiver operating characteristic</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../995/160995.xml">
statistical significance</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../877/5657877.xml">
Type I and type II errors</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../758/1094758.xml">
Selectivity</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../957/1556957.xml">
Negative predictive value</link></entry>
<entry level="1" type="bullet">

 <process wordnetid="105701363" confidence="0.8">
<inquiry wordnetid="105797597" confidence="0.8">
<thinking wordnetid="105770926" confidence="0.8">
<problem_solving wordnetid="105796750" confidence="0.8">
<experiment wordnetid="105798043" confidence="0.8">
<trial wordnetid="105799212" confidence="0.8">
<higher_cognitive_process wordnetid="105770664" confidence="0.8">
<link xlink:type="simple" xlink:href="../952/1556952.xml">
Positive predictive value</link></higher_cognitive_process>
</trial>
</experiment>
</problem_solving>
</thinking>
</inquiry>
</process>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../995/160995.xml">
statistical significance</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../544/14092544.xml">
Youden's J statistic</link></entry>
</list>
</p>

</sec>
<sec>
<st>
References</st>
<p>

<list>
<entry level="1" type="bullet">

  <cite style="font-style:normal">Altman DG, Bland JM&#32;(1994).&#32;"<weblink xlink:type="simple" xlink:href="http://www.bmj.com/cgi/content/full/308/6943/1552">
Diagnostic tests. 1: Sensitivity and specificity</weblink>". <it>BMJ</it>&#32;<b>308</b>&#32;(6943): 1552. PMID 8019315.</cite>&nbsp;</entry>
</list>
</p>

</sec>
<sec>
<st>
External links</st>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.musc.edu/dc/icrebm/sensitivity.html">
Sensitivity and Specificity</weblink> Medical University of South Carolina</entry>
<entry level="1" type="bullet">

 Calculators:</entry>
<entry level="2" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://faculty.vassar.edu/lowry/clin1.html">
Vassar College's Sensitivity/Specificity Calculator</weblink></entry>
<entry level="2" type="bullet">

 <software wordnetid="106566077" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../172/11732172.xml">
OpenEpi</link></software>
 software program</entry>
</list>
</p>


</sec>
</bdy>
</article>
