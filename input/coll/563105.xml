<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 17:18:18[mciao0826] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<algorithm  confidence="0.9511911446218017" wordnetid="105847438">
<header>
<title>Approximation algorithm</title>
<id>563105</id>
<revision>
<id>224417266</id>
<timestamp>2008-07-08T19:28:42Z</timestamp>
<contributor>
<username>SmackBot</username>
<id>433328</id>
</contributor>
</revision>
<categories>
<category>Computational complexity theory</category>
<category>Articles lacking in-text citations</category>
<category>Approximation algorithms</category>
</categories>
</header>
<bdy>

<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-style" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="50px" src="Text_document_with_red_question_mark.svg">
</image>
</p>
</col>
<col style="" class="mbox-text">
 This article or section includes a  or , but its sources remain unclear because it lacks <b>.</b>
You can  this article by introducing more precise citations .</col>
</row>
</table>

<p>

In <link xlink:type="simple" xlink:href="../323/5323.xml">
computer science</link> and <link xlink:type="simple" xlink:href="../476/43476.xml">
operations research</link>, <b>approximation algorithms</b> are <link xlink:type="simple" xlink:href="../775/775.xml">
algorithm</link>s used to find approximate solutions to <link xlink:type="simple" xlink:href="../536/1126536.xml">
optimization problem</link>s. Approximation algorithms are often associated with <class wordnetid="107997703" confidence="0.8">
<collection wordnetid="107951464" confidence="0.8">
<group wordnetid="100031264" confidence="0.8">
<link xlink:type="simple" xlink:href="../681/54681.xml">
NP-hard</link></group>
</collection>
</class>
 problems; since it is unlikely that there can ever be efficient <link xlink:type="simple" xlink:href="../576/44576.xml">
polynomial time</link> exact algorithms solving NP-hard problems, one settles for polynomial time sub-optimal solutions. Unlike <link xlink:type="simple" xlink:href="../509/846509.xml">
heuristics</link>, which usually only find reasonably good solutions reasonably fast, one wants provable solution quality and provable run time bounds. Ideally, the approximation is optimal up to a small constant factor (for instance within 5% of the optimal solution). Approximation algorithms are increasingly being used for problems where exact polynomial-time algorithms are known but are too expensive due to the input size.</p>
<p>

A typical example for an approximation algorithm is the one for <condition wordnetid="113920835" confidence="0.8">
<state wordnetid="100024720" confidence="0.8">
<problem wordnetid="114410605" confidence="0.8">
<difficulty wordnetid="114408086" confidence="0.8">
<link xlink:type="simple" xlink:href="../382/391382.xml">
vertex cover</link></difficulty>
</problem>
</state>
</condition>
 in <link xlink:type="simple" xlink:href="../806/325806.xml">
graph</link>s: find an uncovered edge and add <it>both</it> endpoints to the vertex cover, until none remain.  It is clear that the resulting cover is at most twice as large as the optimal one. This is a <link xlink:type="simple" xlink:href="../925/2018925.xml">
constant factor approximation algorithm</link> with a factor of 2.</p>
<p>

NP-hard problems vary greatly in their approximability; some, such as the <link xlink:type="simple" xlink:href="../015/287015.xml">
bin packing problem</link>, can be approximated within any factor greater than 1 (such a family of approximation algorithms is often called a <link xlink:type="simple" xlink:href="../431/666431.xml">
polynomial time approximation scheme</link> or <it>PTAS</it>). Others are impossible to approximate within any constant, or even polynomial factor unless <link xlink:type="simple" xlink:href="../115/6115.xml">
P = NP</link>, such as the <link xlink:type="simple" xlink:href="../254/249254.xml">
maximum clique problem</link>.</p>
<p>

NP-hard problems can often be expressed as <link>
integer programs</link> (IP) and solved exactly in <link xlink:type="simple" xlink:href="../581/44581.xml">
exponential time</link>. Many approximation algorithms emerge from the <link xlink:type="simple" xlink:href="../430/6368430.xml">
linear programming relaxation</link> of the integer program.</p>
<p>

Not all approximation algorithms are suitable for all practical applications. They often use IP/LP/<link xlink:type="simple" xlink:href="../539/4993539.xml">
Semidefinite</link> solvers, complex data structures or sophisticated algorithmic techniques which lead to difficult implementation problems. Also, some approximation algorithms have impractical running times even though they are polynomial time, for example O(<it>n</it>2000). Yet the study of even very expensive algorithms is not a completely theoretical pursuit as they can yield valuable insights. A classic example is the initial PTAS for <link>
Euclidean TSP</link> due to <link>
Sanjeev Arora</link> which had prohibitive running time, yet within a year, Arora refined the ideas into a linear time algorithm. Such algorithms are also worthwhile in some applications where the running times and cost can be justified e.g. computational biology, financial engineering, transportation planning, and inventory management. In such scenarios, they must compete with the corresponding direct IP formulations.</p>
<p>

Another limitation of the approach is that it applies only to optimization problems and not to "pure" <link xlink:type="simple" xlink:href="../336/8336.xml">
decision problem</link>s like <link xlink:type="simple" xlink:href="../715/4715.xml">
satisfiability</link>, although it is often possible to conceive optimization versions of such problems, such as the <link xlink:type="simple" xlink:href="../916/3351916.xml">
maximum satisfiability problem</link>.</p>
<p>

Inapproximability has been a fruitful area of research in computational complexity theory since the 1990 result of Feige, Goldwasser, Lovasz, Safra and Szegedy on the inapproximability of Independent Set.  After Arora et al. proved the <link>
PCP theorem</link> a year later, it has now been shown that Johnson's 1974 approximation algorithms for Max SAT, Set Cover, Independent Set and Coloring all achieve the optimal approximation ratio, assuming P != NP.  </p>

<sec>
<st>
 Performance guarantees </st>

<p>

For some approximation algorithms it is possible to prove certain properties about the approximation of the optimum result. For example, in the case of a <b><it>&amp;rho;</it></b><b>-approximation algorithm</b> it has been proven that the approximation <it>a</it> will not be more (or less, depending on the situation) than a factor <it>&amp;rho;</it> times the optimum solution <it>s</it>.</p>
<p>

<indent level="1">

<math>\begin{cases}s \leq a \leq \rho s,\qquad\mbox{if } \rho &amp;gt; 1; \\ \rho s \leq a \leq s,\qquad\mbox{if } \rho &amp;lt; 1.\end{cases}</math>
</indent>

The factor <it>&amp;rho;</it> is called the <it>relative performance guarantee</it>. An approximation algorithm has an <it>absolute performance guarantee</it> or <it>bounded error</it> <it>&amp;epsilon;</it>, if it has been proven that</p>
<p>

<indent level="1">

<math> (s - \epsilon) \leq a \leq (s + \epsilon).</math>
</indent>

Similarly, the <it>absolute performance ratio</it> <math>\Rho_A</math> of some approximation algorithm <math>A</math>, where <math>I</math> refers to an instance of a problem, and where <math>R_A(I)</math> is the performance guarantee of <math>A</math> on <math>I</math> (i.e. <math>\rho</math> for problem instance <math>I</math>) is:</p>
<p>

<indent level="1">

<math> \Rho_A = \inf \{ r \geq 1 | R_A(I) \leq r, \forall I \}</math>
</indent>

That is to say that <math>\Rho_A</math> is the largest bound on the approximation ratio, <math>r</math>, that one sees over all possible instances of the problem. Likewise, the <it>asymptotic performance ratio</it> <math>R_A^\infty</math> is:</p>
<p>

<indent level="1">

<math> R_A^\infty = \inf \{ r \geq 1 | \exists n \in \mathbb{Z}^+, R_A(I) \leq r, \forall I, I \geq n\} </math>
</indent>

That is to say that it is the same as the <it>absolute performance ratio</it>, with a lower bound <math>n</math> on the size of problem instances. These two types of ratios are used because there exist algorithms where the difference between these two is significant.</p>
<p>

<event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../115/3176115.xml">
Domination analysis</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
 provides an alternative way to analyze the quality of an approximation algorithm in terms of the rank of the computed solution in the sorted sequence of all possible solutions.</p>

</sec>
<sec>
<st>
References</st>
<p>

<list>
<entry level="1" type="bullet">

  <cite style="font-style:normal" class="book"><physical_entity wordnetid="100001930" confidence="0.8">
<peer wordnetid="109626238" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<colleague wordnetid="109935990" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<associate wordnetid="109816771" confidence="0.8">
<link xlink:type="simple" xlink:href="../036/3007036.xml">
Vazirani, Vijay V.</link></associate>
</causal_agent>
</colleague>
</person>
</peer>
</physical_entity>
&#32;(2003). Approximation Algorithms.&#32;Berlin:&#32;Springer. ISBN 3540653678.</cite>&nbsp;</entry>
<entry level="1" type="bullet">

 <scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../475/4108475.xml">
Thomas H. Cormen</link></scientist>
, <scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../884/1400884.xml">
Charles E. Leiserson</link></scientist>
, <link xlink:type="simple" xlink:href="../057/68057.xml">
Ronald L. Rivest</link>, and <scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../993/3489993.xml">
Clifford Stein</link></scientist>
. <it><work wordnetid="104599396" confidence="0.8">
<product wordnetid="104007894" confidence="0.8">
<creation wordnetid="103129123" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<book wordnetid="106410904" confidence="0.8">
<publication wordnetid="106589574" confidence="0.8">
<link xlink:type="simple" xlink:href="../226/3499226.xml">
Introduction to Algorithms</link></publication>
</book>
</artifact>
</creation>
</product>
</work>
</it>, Second Edition. MIT Press and McGraw-Hill, 2001. ISBN 0-262-03293-7. Chapter 35: Approximation Algorithms, pp.1022&ndash;1056.</entry>
<entry level="1" type="bullet">

 <link>
Dorit H. Hochbaum</link>, ed. <it><link>
Approximation Algorithms for NP-Hard problems</link>, PWS Publishing Company, 1997. ISBN 0-534-94968-1. Chapter 9: Various Notions of Approximations: Good, Better, Best, and More</it></entry>
</list>
</p>

</sec>
<sec>
<st>
External links</st>
<p>

<list>
<entry level="1" type="bullet">

Pierluigi Crescenzi, Viggo Kann, Magnús Halldórsson, <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<mathematician wordnetid="110301261" confidence="0.8">
<link xlink:type="simple" xlink:href="../042/2994042.xml">
Marek Karpinski</link></mathematician>
</scientist>
</causal_agent>
</person>
</physical_entity>
 and Gerhard Woeginger, <weblink xlink:type="simple" xlink:href="http://www.nada.kth.se/~viggo/wwwcompendium/">
<it>A compendium of NP optimization problems''</it></weblink>.</entry>
</list>
</p>


</sec>
</bdy>
</algorithm>
</article>
