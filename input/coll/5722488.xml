<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 21:55:52[mciao0825] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<system  confidence="0.8" wordnetid="104377057">
<artifact  confidence="0.8" wordnetid="100021939">
<instrumentality  confidence="0.8" wordnetid="103575240">
<event  confidence="0.8" wordnetid="100029378">
<rule  confidence="0.8" wordnetid="105846932">
<act  confidence="0.8" wordnetid="100030358">
<psychological_feature  confidence="0.8" wordnetid="100023100">
<procedure  confidence="0.8" wordnetid="101023820">
<activity  confidence="0.8" wordnetid="100407535">
<algorithm  confidence="0.8" wordnetid="105847438">
<header>
<title>Paxos algorithm</title>
<id>5722488</id>
<revision>
<id>244647458</id>
<timestamp>2008-10-11T21:28:34Z</timestamp>
<contributor>
<username>Jsnx</username>
<id>433286</id>
</contributor>
</revision>
<categories>
<category>All articles with dead external links</category>
<category>Distributed systems</category>
<category>Distributed algorithms</category>
<category>Articles with dead external links </category>
</categories>
</header>
<bdy>

<b>Paxos</b> is a family of protocols for solving <link>
consensus</link> in a network of unreliable processors.
<b>Consensus</b> is the process of agreeing on one result among a group of participants.  This problem becomes difficult when the participants or their communication medium may experience failures.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref><p>

Consensus protocols are the basis for the <link>
state machine approach</link> to distributed computing, as suggested by <scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../671/195671.xml">
Leslie Lamport</link></scientist>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref> and surveyed by Fred Schneider<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref>.</p>
<p>

The <b>state machine approach</b> is a technique for converting an algorithm into a fault-tolerant, distributed implementation.  Ad-hoc techniques may leave important cases of failures unresolved.  The principled approach proposed by Lamport et al. ensures all cases are handled safely.</p>
<p>

The Paxos family of protocols includes a spectrum of tradeoffs between the number of processors, number of message delays before learning the agreed value, the activity level of individual participants, number of messages sent, and types of failures.  The convergent property of the Paxos family is their safety from inconsistency.
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%223%22])">3</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%224%22])">4</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%225%22])">5</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%227%22])">7</ref></p>

<sec>
<st>
Safety properties</st>

<p>

In order to guarantee safety, Paxos defines three safety properties and ensures they are always held, regardless of the pattern of failures:</p>

<ss1>
<st>
Nontriviality</st>
<p>

<indent level="1">

Only proposed values can be learned. <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%225%22])">5</ref>
</indent>

</p>
</ss1>
<ss1>
<st>
Consistency</st>
<p>

<indent level="1">

At most one value can be learned (Two different learners cannot learn different values). <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%225%22])">5</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref>
</indent>

</p>
</ss1>
<ss1>
<st>
Liveness(C;L)</st>
<p>

<indent level="1">

If value C has been proposed, then eventually learner L will learn some value (if sufficient processors remain non-faulty). <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref>
</indent>

</p>
</ss1>
</sec>
<sec>
<st>
Preliminaries</st>

<p>

In order to simplify the presentation of Paxos, the following assumptions and definitions are made explicit.  Techniques to broaden the applicability are known in the literature, and are not covered in this article; please see references for further reading.</p>

<ss1>
<st>
Processors</st>

<p>

<list>
<entry level="1" type="bullet">

 Processors operate at arbitrary speed.</entry>
<entry level="1" type="bullet">

 Processors may experience failures.</entry>
<entry level="1" type="bullet">

 Processors with stable storage may re-join the protocol after failures.</entry>
<entry level="1" type="bullet">

 Processors do not collude, lie, or otherwise attempt to divert the protocol.  (See <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Byzantine+Paxos%22])">
Byzantine Paxos</link> for a solution which tolerates arbitrary failures)</entry>
</list>
</p>

</ss1>
<ss1>
<st>
Network</st>

<p>

<list>
<entry level="1" type="bullet">

 Processors can send messages to any other processor.</entry>
<entry level="1" type="bullet">

 Messages are sent asynchronously and may take arbitrarily long to deliver.</entry>
<entry level="1" type="bullet">

 Messages may be lost, reordered, or duplicated.</entry>
<entry level="1" type="bullet">

 Messages are delivered without corruption. (See <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Byzantine+Paxos%22])">
Byzantine Paxos</link> for a solution which tolerates arbitrary failures)</entry>
</list>
</p>

</ss1>
<ss1>
<st>
Number of processors</st>

<p>

<indent level="1">

In general, a consensus algorithm can make progress using 2F+1 processors despite the simultaneous failure of any F processors<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%228%22])">8</ref>.  However, using reconfiguration, a protocol may be employed which survives more total failures if they do not occur too rapidly:
</indent>

<indent level="2">

"For example, it takes seven servers to tolerate three [ed: simultaneous] failures. In many systems, the best way to achieve the desired degree of fault tolerance is to reconfigure the system to replace failed servers by spares. With reconfiguration, a system that uses three active servers and two spares can tolerate a total of three failures, if a failed server can be replaced by a spare before another failure occurs. Reconfiguration therefore allows fewer processors to tolerate the same total number of failures, though not the same number of simultaneous failures. (In most systems, simultaneous failures are much less likely than successive ones.)"  <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%224%22])">4</ref>
</indent>

</p>
</ss1>
<ss1>
<st>
Roles</st>

<p>

Paxos describes the actions of the processes by their roles in the protocol; Client, Acceptor, Proposer, Learner, and Leader.  In typical implementations, a single processor may play one or more roles at the same time.  This does not affect the correctness of the protocol – it is usual to coalesce roles to improve the latency and/or number of messages in the protocol.</p>

<ss2>
<st>
Client</st>
<p>

The Client issues a <it>request</it> to the distributed system, and waits for a <it>response</it>.  For instance a "write" request on a file in a distributed file server.</p>

</ss2>
<ss2>
<st>
Acceptor</st>
<p>

The Acceptors act as the fault-tolerant "memory" of the protocol. Acceptors are collected into groups called Quorums.  Any message sent to an Acceptor must be sent to a Quorum of Acceptors, any message received from an Acceptor is ignored unless a copy is received from each Acceptor in a Quorum.</p>

</ss2>
<ss2>
<st>
Proposer</st>
<p>

A Proposer advocates a client request, attempting to convince the Acceptors to agree on it, and acting as a coordinator to move the protocol forward when conflicts occur.</p>

</ss2>
<ss2>
<st>
Learner</st>
<p>

Learners act as the replication factor for the protocol.  Once a Client request has been agreed on by the Acceptors, the Learner may take action (ie: execute the request and send a response to the client).  To improve availability of processing, additional Learners can be added.</p>

</ss2>
<ss2>
<st>
Leader</st>
<p>

Paxos requires a distinguished Proposer (called the leader) to make progress.  Many processes may believe they are leaders, but the protocol only guarantees progress if one of them is eventually chosen.  If two processes believe they are leaders, it is possible to stall the protocol by continuously proposing conflicting updates.  The safety properties are preserved regardless.</p>

</ss2>
</ss1>
<ss1>
<st>
Quorums</st>
<p>

<indent level="1">

Quorums express the safety properties of Paxos by ensuring at least some surviving processor retains knowledge of the results.
</indent>

<indent level="1">

Typically, a Quorum is any majority of participating Acceptors.  ie: given the set of Acceptors {A,B,C,D}, a majority Quorum would be any three Acceptors:  {A,B,C}, {A,C,D}, {A,B,D}, {B,C,D}.
</indent>

</p>
</ss1>
<ss1>
<st>
Choice</st>
<p>

<indent level="1">

In Paxos, the leader sometimes has to choose among a set of conflicting values.  If a set of values is in conflict, the leader must choose one of the values from the most recent round.  The protocol does not specify which value must be chosen, and correctness is guaranteed regardless of the choice.  However, it is possible for the choice to impede progress.
</indent>

<indent level="1">

A typical Choice function is to select the majority value from the highest round.
</indent>

</p>
</ss1>
</sec>
<sec>
<st>
Typical deployment</st>

<p>

In most deployments of Paxos, each participating process acts in three roles; Proposer, Acceptor and Learner <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%229%22])">9</ref>.  This reduces the message complexity significantly, without sacrificing correctness:</p>
<p>

<indent level="2">

"In Paxos, clients send commands to a leader. During normal operation, the leader receives a client's command, assigns it a new command number i, and then begins the ith  instance of the consensus algorithm by sending messages to a set of acceptor processes." <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref>
</indent>

By merging roles the protocol "collapses" into an efficient client-master-replica style deployment typical of the database community.  The benefit of the Paxos family (including implementations with merged roles) is the guarantee of its <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Satety+Properties%22])">
Safety Properties</link>.</p>
<p>

A typical implementation's message flow is covered in <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Typical+Multi-Paxos+Deployment%22])">
Typical Multi-Paxos Deployment</link>.</p>

</sec>
<sec>
<st>
Basic Paxos</st>

<p>

This protocol is the most basic of the Paxos family; it is not the protocol which is typically implemented in a deployment (see <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Multi-Paxos%22])">
Multi-Paxos</link>).</p>
<p>

Each instance of the Basic Paxos protocol decides on a single output value.  The protocol proceeds over several rounds, a successful round has two phases:</p>

<ss1>
<st>
Phase 1a: <it>Prepare''</it></st>
<p>

<indent level="1">

A <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Proposer%22])">
Proposer</link> (the <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Leader%22])">
leader</link>) selects a proposal number N and sends a <it>Prepare</it> message to a <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Quorums%22])">
Quorum</link> of <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Acceptor%22])">
Acceptors</link>.
</indent>

</p>
</ss1>
<ss1>
<st>
Phase 1b: <it>Promise''</it></st>
<p>

<indent level="1">

If the proposal number N is larger than any previous proposal, then each Acceptor promises not to accept proposals less than N, and sends the value it last accepted for this instance to the Proposer (the leader).
</indent>

<indent level="1">

Otherwise a denial is sent (<it>Nack</it>).
</indent>

</p>
</ss1>
<ss1>
<st>
Phase 2a: <it>Accept!''</it></st>
<p>

<indent level="1">

If the Proposer receives responses from a Quorum of Acceptors, it may now <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Choice%22])">
Choose</link> a value to be agreed upon.  If any of the Acceptors have already accepted a value, the leader must Choose a value from this set.  Otherwise, the Proposer is free to choose any value.
</indent>

<indent level="1">

The Proposer sends an <it>Accept!</it> message to a Quorum of Acceptors with the Chosen value.
</indent>

</p>
</ss1>
<ss1>
<st>
Phase 2b: <it>Accepted''</it></st>
<p>

<indent level="1">

If the Acceptor receives an Accept! message for a proposal it has promised, then it Accepts the value.
</indent>

<indent level="1">

Each Acceptor sends an <it>Accepted</it> message to the Proposer and every Learner.
</indent>

Rounds fail when multiple Proposers send conflicting <it>Prepare</it> messages, or when the Proposer does not receive a Quorum of responses (<it>Promise</it> or <it>Accepted</it>).  In these cases, another round must be started with a higher proposal number.</p>
<p>

Here is a graphic representation of the Basic Paxos protocol.  Note that the values returned in the <it>Promise</it> message (Va, Vb, Vc) are typically null for the first round of each instance, they are shown below for completeness.</p>

</ss1>
<ss1>
<st>
Message flow: Basic Paxos</st>
<p>

(one instance, one successful round)

 Client   Proposer      Acceptor     Learner
   |         |          |  |  |       |  |
   X--------&amp;gt;|          |  |  |       |  |  Request
   |         X---------&amp;gt;|-&amp;gt;|-&amp;gt;|       |  |  Prepare(N)
   |         |&amp;lt;---------X--X--X       |  |  Promise(N,{Va,Vb,Vc})
   |         X---------&amp;gt;|-&amp;gt;|-&amp;gt;|       |  |  Accept!(N,Vn)
   |         |&amp;lt;---------X--X--X------&amp;gt;|-&amp;gt;|  Accepted(N,Vn)
   |&amp;lt;---------------------------------X--X  Response
   |         |          |  |  |       |  |
</p>

</ss1>
<ss1>
<st>
Error cases in basic Paxos</st>

<p>

The simplest error cases are the failure of a redundant Learner, or failure of an Acceptor when a Quorum of Acceptors remains live.  In these cases, the protocol requires no recovery.  No additional rounds or messages are required, as shown below:</p>

</ss1>
<ss1>
<st>
Message flow: Basic Paxos, failure of Acceptor</st>
<p>

(Quorum size = 2 Acceptors)

 Client   Proposer      Acceptor     Learner
   |         |          |  |  |       |  |
   X--------&amp;gt;|          |  |  |       |  |  Request
   |         X---------&amp;gt;|-&amp;gt;|-&amp;gt;|       |  |  Prepare(N)
   |         |          |  |  !       |  |  !! FAIL !!
   |         |&amp;lt;---------X--X          |  |  Promise(N,{Va,Vb,Vc})
   |         X---------&amp;gt;|-&amp;gt;|          |  |  Accept!(N,Vn)
   |         |&amp;lt;---------X--X---------&amp;gt;|-&amp;gt;|  Accepted(N,Vn)
   |&amp;lt;---------------------------------X--X  Response
   |         |          |  |          |  |
</p>

</ss1>
<ss1>
<st>
Message flow: Basic Paxos, failure of redundant Learner</st>
<p>


 Client   Proposer      Acceptor     Learner
   |         |          |  |  |       |  |
   X--------&amp;gt;|          |  |  |       |  |  Request
   |         X---------&amp;gt;|-&amp;gt;|-&amp;gt;|       |  |  Prepare(N)
   |         |&amp;lt;---------X--X--X       |  |  Promise(N,{Va,Vb,Vc})
   |         X---------&amp;gt;|-&amp;gt;|-&amp;gt;|       |  |  Accept!(N,Vn)
   |         |&amp;lt;---------X--X--X------&amp;gt;|-&amp;gt;|  Accepted(N,Vn)
   |         |          |  |  |       |  !  !! FAIL !!
   |&amp;lt;---------------------------------X     Response
   |         |          |  |  |       |
</p>
<p>

The next failure case is when a Proposer fails after proposing a value, but before agreement is reached.  Ignoring Leader election, an example message flow is as follows:</p>

</ss1>
<ss1>
<st>
Message flow: Basic Paxos, failure of Proposer</st>
<p>

(re-election not shown, one instance, two rounds)

Client  Leader         Acceptor     Learner
   |      |             |  |  |       |  |
   X-----&amp;gt;|             |  |  |       |  |  Request
   |      X------------&amp;gt;|-&amp;gt;|-&amp;gt;|       |  |  Prepare(N)
   |      |&amp;lt;------------X--X--X       |  |  Promise(N,{Va,Vb,Vc})
   |      |             |  |  |       |  |
   |      |             |  |  |       |  |  !! Leader fails during broadcast !!
   |      X------------&amp;gt;|  |  |       |  |  Accept!(N,Vn)
   |      !             |  |  |       |  |
   |         |          |  |  |       |  |  !! NEW LEADER !!
   |         X---------&amp;gt;|-&amp;gt;|-&amp;gt;|       |  |  Prepare(N+1)
   |         |&amp;lt;---------X--X--X       |  |  Promise(N+1,{Vn})
   |         X---------&amp;gt;|-&amp;gt;|-&amp;gt;|       |  |  Accept!(N+1,Vn)
   |         |&amp;lt;---------X--X--X------&amp;gt;|-&amp;gt;|  Accepted(N+1,Vn)
   |&amp;lt;---------------------------------X--X  Response
   |         |          |  |  |       |  |
</p>
<p>

The most complex case is when multiple Proposers believe themselves to be Leaders.  For instance the current leader may fail and later recover, but the other Proposers have already re-elected a new leader.  The recovered leader has not learned this yet and attempts to begin a round in conflict with the current leader.</p>

</ss1>
<ss1>
<st>
Message flow: Basic Paxos, dueling Proposers</st>
<p>

(one instance, four unsuccessful rounds)

Client   Proposer      Acceptor     Learner
   |      |             |  |  |       |  |
   X-----&amp;gt;|             |  |  |       |  |  Request
   |      X------------&amp;gt;|-&amp;gt;|-&amp;gt;|       |  |  Prepare(N)
   |      |&amp;lt;------------X--X--X       |  |  Promise(N,{Va,Vb,Vc})
   |      !             |  |  |       |  |  !! LEADER FAILS
   |         |          |  |  |       |  |  !! NEW LEADER (knows N)
   |         X---------&amp;gt;|-&amp;gt;|-&amp;gt;|       |  |  Prepare(N+1)
   |         |&amp;lt;---------X--X--X       |  |  Promise(N+1,{Va,Vb,Vc})
   |      |  |          |  |  |       |  |  !! OLD LEADER recovers
   |      |  |          |  |  |       |  |  !! OLD LEADER tries N+1, denied
   |      X------------&amp;gt;|-&amp;gt;|-&amp;gt;|       |  |  Prepare(N+1)
   |      |&amp;lt;------------X--X--X       |  |  Nack(N+1)
   |      |  |          |  |  |       |  |  !! OLD LEADER tries N+2
   |      X------------&amp;gt;|-&amp;gt;|-&amp;gt;|       |  |  Prepare(N+2)
   |      |&amp;lt;------------X--X--X       |  |  Promise(N+2,{Va,Vb,Vc})
   |      |  |          |  |  |       |  |  !! NEW LEADER proposes, denied
   |      |  X---------&amp;gt;|-&amp;gt;|-&amp;gt;|       |  |  Accept!(N+1,Vn)
   |      |  |&amp;lt;---------X--X--X       |  |  Nack(N+2)
   |      |  |          |  |  |       |  |  !! NEW LEADER tries N+3
   |      |  X---------&amp;gt;|-&amp;gt;|-&amp;gt;|       |  |  Prepare(N+3)
   |      |  |&amp;lt;---------X--X--X       |  |  Promise(N+3,{Va,Vb,Vc})
   |      |  |          |  |  |       |  |  !! OLD LEADER proposes, denied
   |      X------------&amp;gt;|-&amp;gt;|-&amp;gt;|       |  |  Accept!(N+2,Vn)
   |      |&amp;lt;------------X--X--X       |  |  Nack(N+3)
   |      |  |          |  |  |       |  |  ... and so on ...
</p>

</ss1>
</sec>
<sec>
<st>
Multi-Paxos</st>

<p>

A typical deployment of Paxos requires a continuous stream of agreed values acting as commands to a distributed state machine.  If each command is the result of a single instance of the <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Basic+Paxos%22])">
Basic Paxos</link> protocol, a significant amount of overhead would result.</p>
<p>

If the leader is relatively stable, phase 1 becomes unnecessary. Thus, it is possible to skip phase 1 for future instances of the protocol with the same leader.</p>
<p>

To achieve this, the instance number is included along with each value.  Multi-Paxos reduces the failure-free message delay (proposal to learning) from 4 delays to 2 delays.</p>

<ss1>
<st>
Message flow: Multi-Paxos, start</st>
<p>

( first instance with new leader)

 Client   Proposer      Acceptor     Learner
   |         |          |  |  |       |  | --- First Request ---
   X--------&amp;gt;|          |  |  |       |  |  Request
   |         X---------&amp;gt;|-&amp;gt;|-&amp;gt;|       |  |  Prepare(N)
   |         |&amp;lt;---------X--X--X       |  |  Promise(N,I,{Va,Vb,Vc})
   |         X---------&amp;gt;|-&amp;gt;|-&amp;gt;|       |  |  Accept!(N,I,Vn)
   |         |&amp;lt;---------X--X--X------&amp;gt;|-&amp;gt;|  Accepted(N,I,Vn)
   |&amp;lt;---------------------------------X--X  Response
   |         |          |  |  |       |  |
</p>

</ss1>
<ss1>
<st>
Message flow: Multi-Paxos, steady-state</st>
<p>

(subsequent instances with same leader)

Client   Proposer      Acceptor     Learner
   |         |          |  |  |       |  |  --- Following Requests ---
   X--------&amp;gt;|          |  |  |       |  |  Request
   |         X---------&amp;gt;|-&amp;gt;|-&amp;gt;|       |  |  Accept!(N,I+1,W)
   |         |&amp;lt;---------X--X--X------&amp;gt;|-&amp;gt;|  Accepted(N,I+1,W)
   |&amp;lt;---------------------------------X--X  Response
   |         |          |  |  |       |  |
</p>

</ss1>
<ss1>
<st>
Typical Multi-Paxos deployment</st>

<p>

The most common deployment of the Paxos family is Multi-Paxos <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%229%22])">9</ref>, specialized for participating processors to each be Proposers, Acceptors and Learners.  The message flow may be optimized as depicted here:</p>

</ss1>
<ss1>
<st>
Message flow: Collapsed Multi-Paxos, start</st>
<p>

(first instance with new leader)

 Client      Servers
   |         |  |  | --- First Request ---
   X--------&amp;gt;|  |  |  Request
   |         X-&amp;gt;|-&amp;gt;|  Prepare(N)
   |         |&amp;lt;-X--X  Promise(N,I,{Va,Vb,Vc})
   |         X-&amp;gt;|-&amp;gt;|  Accept!(N,I,Vn)
   |         |&amp;lt;-X--X  Accepted(N,I)
   |&amp;lt;--------X  |  |  Response
   |         |  |  |
</p>

</ss1>
<ss1>
<st>
Message flow: Collapsed Multi-Paxos, steady state</st>
<p>

(subsequent instances with same leader)

 Client      Servers
   X--------&amp;gt;|  |  |  Request
   |         X-&amp;gt;|-&amp;gt;|  Accept!(N,I+1,W)
   |         |&amp;lt;-X--X  Accepted(N)
   |&amp;lt;--------X  |  |  Response
   |         |  |  |
</p>

</ss1>
</sec>
<sec>
<st>
Optimizations</st>

<p>

A number of optimizations reduce message complexity and size.  These optimizations are summarized below:</p>
<p>

<indent level="2">

 "We can save messages at the cost of an extra message delay by having a single distinguished learner that informs the other learners when it finds out that a value has been chosen. Acceptors then send <it>Accepted</it> messages only to the distinguished learner.  In most applications, the roles of leader and distinguished learner are performed by the same processor.
</indent>

<indent level="2">

"A leader can send its <it>Prepare</it> and <it>Accept!</it> messages just to a quorum of acceptors. As long as all acceptors in that quorum are working and can communicate with the leader and the learners, there is no need for acceptors not in the quorum to do anything.
</indent>

<indent level="2">

 "Acceptors do not care what value is chosen. They simply respond to <it>Prepare</it> and <it>Accept!</it> messages to ensure that, despite failures, only a single value can be chosen. However, if an acceptor does learn what value has been chosen, it can store the value in stable storage and erase any other information it has saved there. If the acceptor later receives a <it>Prepare</it> or <it>Accept!</it> message, instead of performing its Phase1b or Phase2b action, it can simply inform the leader of the chosen value.
</indent>

<indent level="2">

"Instead of sending the value v, the leader can send a hash of v to some acceptors in its <it>Accept!</it> messages. A learner will learn that v is chosen if it receives <it>Accepted</it> messages for either v or its hash from a quorum of acceptors, and at least one of those messages contains v rather than its hash. However, a leader could receive <it>Promise</it> messages that tell it the hash of a value v that it must use in its Phase2a action without telling it the actual value of v. If that happens, the leader cannot execute its Phase2a action until it communicates with some process that knows v."  <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%224%22])">4</ref>
</indent>

<indent level="2">

"A proposer can send its proposal only to the leader rather than to all coordinators. However, this requires that the result of the leader-selection algorithm be broadcast to the proposers, which might be expensive. So, it might be better to let the proposer send its proposal to all coordinators. (In that case, only the coordinators themselves need to know who the leader is.)
</indent>

<indent level="2">

"Instead of each acceptor sending <it>Accepted</it> messages to each learner, acceptors can send their <it>Accepted</it> messages to the leader and the leader can inform the learners when a value has been chosen. However, this adds an extra message delay.
</indent>

<indent level="2">

"Finally, observe that phase 1 is unnecessary for round 1 .. The leader of round 1 can begin the round by sending an <it>Accept!</it> message with any proposed value." <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%225%22])">5</ref>
</indent>

</p>
</sec>
<sec>
<st>
Cheap Paxos</st>

<p>

Cheap Paxos extends <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Basic+Paxos%22])">
Basic Paxos</link> to tolerate F failures with F+1 main processors and F auxiliary processors by dynamically reconfiguring after each failure.</p>
<p>

This reduction in processor requirements comes at the expense of liveness; if too many main processors fail in a short time, the system must halt until the auxiliary processors can reconfigure the system.  During stable periods, the auxiliary processors take no part in the protocol.</p>
<p>

<indent level="2">

"With only two processors p and q, one processor cannot distinguish failure of the other processor from failure of the communication medium. A third processor is needed. However, that third processor does not have to participate in choosing the sequence of commands. It must take action only in case p or q fails, after which it does nothing while either p or q continues to operate the system by itself. The third processor can therefore be a small/slow/cheap one, or a processor primarily devoted to other tasks." <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%224%22])">4</ref>
</indent>

</p>
<ss1>
<st>
Message flow: Cheap Multi-Paxos</st>
<p>

3 main Acceptors, 1 Auxiliary Acceptor, Quorum size = 3, showing failure of one main processor and subsequent reconfiguration

            {  Acceptors   }
Proposer     Main       Aux    Learner
|            |  |  |     |       |  -- Phase 2 --
X-----------&amp;gt;|-&amp;gt;|-&amp;gt;|     |       |  Accept!(N,I,V)
|            |  |  !     |       |  --- FAIL! ---
|&amp;lt;-----------X--X---------------&amp;gt;|  Accepted(N,I,V)
|            |  |        |       |  -- Failure detected (only 2 accepted) --
X-----------&amp;gt;|-&amp;gt;|-------&amp;gt;|       |  Accept!(N,I,V)  (re-transmit, include Aux)
|&amp;lt;-----------X--X--------X------&amp;gt;|  Accepted(N,I,V)
|            |  |        |       |  -- Reconfigure : Quorum = 2 --
X-----------&amp;gt;|-&amp;gt;|        |       |  Accept!(N,I+1,W) (Aux not participating)
|&amp;lt;-----------X--X---------------&amp;gt;|  Accepted(N,I+1,W)
|            |  |        |       |
</p>

</ss1>
</sec>
<sec>
<st>
Fast Paxos</st>

<p>

Fast Paxos generalizes <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22Basic+Paxos%22])">
Basic Paxos</link> to reduce end-to-end message delays.  In Basic Paxos, the message delay from client request to learning is 3 message delays.  Fast Paxos allows 2 message delays, but requires the Client to send its request to multiple destinations.</p>
<p>

Intuitively, if the leader has no value to propose, then a client could send an <it>Accept!</it> message to the Acceptors directly.  The Acceptors would respond as in Basic Paxos, sending <it>Accepted</it> messages to the leader and every Learner achieving two message delays from Client to Learner.</p>
<p>

If the leader detects a collision, it resolves the collision by sending <it>Accept!</it> messages for a new round which are <it>Accepted</it> as usual.  This coordinated recovery technique requires four message delays from Client to Learner.</p>
<p>

The final optimization occurs when the leader specifies a recovery technique in advance, allowing the Acceptors to perform the collision recovery themselves.  Thus, uncoordinated collision recovery can occur in three message delays (and only two message delays if all Learners are also Acceptors).</p>

<ss1>
<st>
Message flow: Fast Paxos, non-conflicting</st>
<p>


Client    Leader         Acceptor      Learner
   |         |          |  |  |  |       |  |
   |         X---------&amp;gt;|-&amp;gt;|-&amp;gt;|-&amp;gt;|       |  |  Any(N,I,Recovery)
   |         |          |  |  |  |       |  |
   X-------------------&amp;gt;|-&amp;gt;|-&amp;gt;|-&amp;gt;|       |  |  Accept!(N,I,W)
   |         |&amp;lt;---------X--X--X--X------&amp;gt;|-&amp;gt;|  Accepted(N,I,W)
   |&amp;lt;------------------------------------X--X  Response(W)
   |         |          |  |  |  |       |  |
</p>

</ss1>
<ss1>
<st>
Message flow: Fast Paxos, conflicting proposals</st>
<p>

Conflicting proposals with uncoordinated recovery.  Note: the protocol does not specify how to handle the dropped client request.</p>
<p>


Client   Leader      Acceptor     Learner
 |  |      |        |  |  |  |      |  |
 |  |      X-------&amp;gt;|-&amp;gt;|-&amp;gt;|-&amp;gt;|      |  |  Any(N,I,Recovery)
 |  |      |        |  |  |  |      |  |
 |  |      |        |  |  |  |      |  |  !! Concurrent conflicting proposals
 |  |      |        |  |  |  |      |  |  !!   received in different order
 |  |      |        |  |  |  |      |  |  !!   by the Acceptors
 |  X--------------?|-?|-?|-?|      |  |  Accept!(N,I,V)
 X-----------------?|-?|-?|-?|      |  |  Accept!(N,I,W)
 |  |      |        |  |  |  |      |  |
 |  |      |        |  |  |  |      |  |  !! Acceptors disagree on value
 |  |      |&amp;lt;-------X--X-&amp;gt;|-&amp;gt;|-----&amp;gt;|-&amp;gt;|  Accepted(N,I,V)
 |  |      |&amp;lt;-------|&amp;lt;-|&amp;lt;-X--X-----&amp;gt;|-&amp;gt;|  Accepted(N,I,W)
 |  |      |        |  |  |  |      |  |
 |  |      |        |  |  |  |      |  |  !! Detect collision &amp; recover
 |  |      |&amp;lt;-------X--X--X--X-----&amp;gt;|-&amp;gt;|  Accepted(N+1,I,W)
 |&amp;lt;---------------------------------X--X  Response(W)
 |  |      |        |  |  |  |      |  |
</p>

</ss1>
<ss1>
<st>
Message flow: Fast Paxos, collapsed roles</st>
<p>

(merged Acceptor/Learner roles)

Client         Servers
 |  |         |  |  |  |
 |  |         X-&amp;gt;|-&amp;gt;|-&amp;gt;|  Any(N,I,Recovery)
 |  |         |  |  |  |
 |  |         |  |  |  |  !! Concurrent conflicting proposals
 |  |         |  |  |  |  !!   received in different order
 |  |         |  |  |  |  !!   by the Servers
 |  X--------?|-?|-?|-?|  Accept!(N,I,V)
 X-----------?|-?|-?|-?|  Accept!(N,I,W)
 |  |         |  |  |  |
 |  |         |  |  |  |  !! Servers disagree on value
 |  |         X--X-&amp;gt;|-&amp;gt;|  Accepted(N,I,V)
 |  |         |&amp;lt;-|&amp;lt;-X--X  Accepted(N,I,W)
 |  |         |  |  |  |
 |  |         |  |  |  |  !! Detect collision &amp; recover
 |&amp;lt;-----------X--X--X--X  Response(W)
 |  |         |  |  |  |
</p>

</ss1>
</sec>
<sec>
<st>
Generalized Paxos</st>

<p>

Generalized consensus explores the relationship between the operations of a distributed state machine and the consensus protocol used to maintain consistency of that state machine.  The main discovery involves optimizations of the consensus protocol when conflicting proposals could be applied to the state machine in any order.  ie: The operations proposed by the conflicting proposals are <link xlink:type="simple" xlink:href="../390/294390.xml">
commutative operations</link> of the state machine.</p>
<p>

In such cases, the conflicting operations can both be accepted, avoiding the delays required for resolving conflicts and re-proposing the rejected operation.</p>
<p>

This concept is further generalized into ever-growing sets of commutative operations, some of which are known to be stable (and thus may be executed).  The protocol tracks these sets of operations, ensuring that all proposed commutative operations of one set are stabilized before allowing any non-commuting operation to become stable.</p>

<ss1>
<st>
Example</st>
<p>

<indent level="1">

In order to illustrate Generalized Paxos, this example shows a message flow between two concurrently executing clients and a distributed state machine performing the operations of a read/write register with 2 independent register addresses (A and B).
</indent>

<indent level="1">

Commutativity Table; marked cells denote interference:
</indent>

	         Read(A) Write(A) Read(B) Write(B)
	Read(A) |       |    X   |       |        |
	Write(A)|   X   |    X   |       |        |
	Read(B) |       |        |       |    X   |
	Write(B)|       |        |   X   |    X   |
</p>
<p>

<indent level="1">

Proposed Series of operations (global order):
</indent>

	1:Read(A)
	2:Read(B)
	3:Write(B)
	4:Read(B)
	5:Read(A)
	6:Write(A)
	7:Read(A)

<indent level="1">

One possible permutation allowed by commutes:
</indent>

	{ 1:Read(A),  2:Read(B), 5:Read(A) }
	{ 3:Write(B), 6:Write(A) }
	{ 4:Read(B),  7:Read(A)  }

<indent level="1">

Observations:
</indent>
* 5:Read(A) may commute in front of 3:Write(B)/4:Read(B) pair.
<list>
<entry level="1" type="bullet">

 4:Read(B) may commute behind the 3:Write(B)/6:Write(A) pair.</entry>
<entry level="1" type="bullet">

 In practice, a commute occurs only when operations are proposed concurrently.</entry>
</list>
</p>

</ss1>
<ss1>
<st>
 Message flow: Generalized Paxos (example)</st>
<p>

Responses not shown. Note: message abbreviations differ from previous message flows due to specifics of the protocol, see <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref> for a full discussion.

           {    Acceptors   }
Client      Leader  Acceptor     Learner
 |  |         |      |  |  |         |  |  !! New Leader Begins Round
 |  |         X-----&amp;gt;|-&amp;gt;|-&amp;gt;|         |  |  Prepare(N)
 |  |         |&amp;lt;-----X--X--X         |  |  Promise(N,null)
 |  |         X-----&amp;gt;|-&amp;gt;|-&amp;gt;|         |  |  Phase2Start(N,null)
 |  |         |      |  |  |         |  |
 |  |         |      |  |  |         |  |  !! Concurrent commuting proposals
 |  X--------?|-----?|-?|-?|         |  |  Propose(ReadA)
 X-----------?|-----?|-?|-?|         |  |  Propose(ReadB)
 |  |         X------X--------------&amp;gt;|-&amp;gt;|  Accepted(N,&amp;lt;ReadA,ReadB&amp;gt;)
 |  |         |&amp;lt;--------X--X--------&amp;gt;|-&amp;gt;|  Accepted(N,&amp;lt;ReadB,ReadA&amp;gt;)
 |  |         |      |  |  |         |  |
 |  |         |      |  |  |         |  |  !! No Conflict, both accepted
 |  |         |      |  |  |         |  |  Stable = &amp;lt;ReadA, ReadB&amp;gt;
 |  |         |      |  |  |         |  |
 |  |         |      |  |  |         |  |  !! Concurrent conflicting proposals
 X-----------?|-----?|-?|-?|         |  |  Propose(&amp;lt;WriteB,ReadA&amp;gt;)
 |  X--------?|-----?|-?|-?|         |  |  Propose(ReadB)
 |  |         |      |  |  |         |  |
 |  |         X------X--------------&amp;gt;|-&amp;gt;|  Accepted(N,&amp;lt;WriteB,ReadA&amp;gt; . &amp;lt;ReadB&amp;gt;)
 |  |         |&amp;lt;--------X--X--------&amp;gt;|-&amp;gt;|  Accepted(N,&amp;lt;ReadB&amp;gt; . &amp;lt;WriteB,ReadA&amp;gt;)
 |  |         |      |  |  |         |  |
 |  |         |      |  |  |         |  | !! Conflict detected, leader chooses
 |  |         |      |  |  |         |  |    commutative order:
 |  |         |      |  |  |         |  |    V = &amp;lt;ReadA, WriteB, ReadB&amp;gt;
 |  |         |      |  |  |         |  |
 |  |         X-----&amp;gt;|-&amp;gt;|-&amp;gt;|         |  |  Phase2Start(N+1,V)
 |  |         |&amp;lt;-----X--X--X--------&amp;gt;|-&amp;gt;|  Accepted(N+1,V)
 |  |         |      |  |  |         |  |  Stable = &amp;lt;ReadA, ReadB&amp;gt; .
 |  |         |      |  |  |         |  |           &amp;lt;ReadA, WriteB, ReadB&amp;gt;
 |  |         |      |  |  |         |  |
 |  |         |      |  |  |         |  |  !! More conflicting proposals
 X-----------?|-----?|-?|-?|         |  |  Propose(WriteA)
 |  X--------?|-----?|-?|-?|         |  |  Propose(ReadA)
 |  |         |      |  |  |         |  |
 |  |         X------X--------------&amp;gt;|-&amp;gt;|  Accepted(N+2,&amp;lt;WriteA&amp;gt; . &amp;lt;ReadA&amp;gt;)
 |  |         |&amp;lt;--------X--X--------&amp;gt;|-&amp;gt;|  Accepted(N+2,&amp;lt;ReadA&amp;gt; . &amp;lt;WriteA&amp;gt;)
 |  |         |      |  |  |         |  |  
 |  |         |      |  |  |         |  |  !! Leader chooses order W
 |  |         X-----&amp;gt;|-&amp;gt;|-&amp;gt;|         |  |  Phase2Start(N+2,W)
 |  |         |&amp;lt;-----X--X--X--------&amp;gt;|-&amp;gt;|  Accepted(N+2,W)
 |  |         |      |  |  |         |  |  Stable = &amp;lt;ReadA, ReadB&amp;gt; .
 |  |         |      |  |  |         |  |           &amp;lt;ReadA, WriteB, ReadB&amp;gt; .
 |  |         |      |  |  |         |  |           &amp;lt;WriteA, ReadA&amp;gt;
 |  |         |      |  |  |         |  |
</p>

</ss1>
<ss1>
<st>
Generalized Paxos vs. Fast Multi-Paxos</st>

<p>

<indent level="1">

The message flow above shows Generalized Paxos performing agreement on seven values in (nominally) 10 message delays.  Fast Multi-Paxos would require 15-17 delays for the same sequence (3 delays for each of  the three concurrent proposals with uncoordinated recovery, plus at least 2 delays for the eventual re-submission of the three rejected proposals, concurrent re-proposals may add two additional delays).
</indent>

</p>
</ss1>
</sec>
<sec>
<st>
Byzantine Paxos</st>

<p>

Paxos may also be extended to support arbitrary failures of the participants, including lying, fabrication of messages, collusion with other participants, selective non-participation, etc.  These types of failures are called Byzantine Failures, after the solution popularized by Lamport. <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2210%22])">10</ref></p>
<p>

Byzantine Paxos <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%227%22])">7</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%225%22])">5</ref> adds an extra message (Verify) which acts to distribute knowledge and verify the actions of the other processors:</p>

<ss1>
<st>
Message flow: Byzantine Multi-Paxos, steady state</st>
<p>


Client   Proposer      Acceptor     Learner
   |         |          |  |  |       |  |
   X--------&amp;gt;|          |  |  |       |  |  Request
   |         X---------&amp;gt;|-&amp;gt;|-&amp;gt;|       |  |  Accept!(N,I,V)
   |         |          X&amp;lt;&amp;gt;X&amp;lt;&amp;gt;X       |  |  Verify(N,I,V) - BROADCAST
   |         |&amp;lt;---------X--X--X------&amp;gt;|-&amp;gt;|  Accepted(N,V)
   |&amp;lt;---------------------------------X--X  Response(V)
   |         |          |  |  |       |  |

Fast Byzantine Paxos removes this extra delay, since the client sends commands directly to the Acceptors <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%225%22])">5</ref>.</p>
<p>

Note the <it>Accepted</it> message in Fast Byzantine Paxos is sent to all Acceptors and all Learners, while Fast Paxos sends <it>Accepted</it> messages only to Learners):</p>

</ss1>
<ss1>
<st>
Message flow: Fast Byzantine Multi-Paxos, steady state</st>
<p>


Client    Acceptor     Learner
   |      |  |  |       |  |
   X-----&amp;gt;|-&amp;gt;|-&amp;gt;|       |  |  Accept!(N,I,V)
   |      X&amp;lt;&amp;gt;X&amp;lt;&amp;gt;X------&amp;gt;|-&amp;gt;|  Accepted(N,I,V) - BROADCAST
   |&amp;lt;-------------------X--X  Response(V)
   |      |  |  |       |  |
</p>
<p>

The failure scenario is the same for both protocols;  Each Learner waits to receive F+1 identical messages from different Acceptors.  If this does not occur, the Acceptors themselves will also be aware of it (since they exchanged each other's messages in the broadcast round), and correct Acceptors will re-broadcast the agreed value:</p>

</ss1>
<ss1>
<st>
Message flow: Fast Byzantine Multi-Paxos, failure</st>
<p>


Client    Acceptor     Learner
   |      |  |  !       |  |  !! One Acceptor is faulty
   X-----&amp;gt;|-&amp;gt;|-&amp;gt;!       |  |  Accept!(N,I,V)
   |      X&amp;lt;&amp;gt;X&amp;lt;&amp;gt;X------&amp;gt;|-&amp;gt;|  Accepted(N,I,{V,W}) - BROADCAST
   |      |  |  !       |  |  !! Learners receive 2 different commands
   |      |  |  !       |  |  !! Correct Acceptors notice error and choose
   |      X&amp;lt;&amp;gt;X&amp;lt;&amp;gt;X------&amp;gt;|-&amp;gt;|  Accepted(N,I,V) - BROADCAST
   |&amp;lt;-------------------X--X  Response(V)
   |      |  |  !       |  |
</p>

</ss1>
</sec>
<sec>
<st>
 Production use of Paxos </st>

<p>

<list>
<entry level="1" type="bullet">

 Google uses the Paxos algorithm in their <link>
Chubby</link> distributed lock service in order to keep replicas consistent in case of failure.  Chubby is used by <link xlink:type="simple" xlink:href="../973/5919973.xml">
Bigtable</link> which is now in production in Google Analytics and other products.</entry>
<entry level="1" type="bullet">

 IBM uses the Paxos algorithm in their <artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<device wordnetid="103183080" confidence="0.8">
<link xlink:type="simple" xlink:href="../933/3342933.xml">
IBM SAN Volume Controller</link></device>
</instrumentality>
</artifact>
 product to implement a general purpose fault-tolerant virtual machine used to run the configuration and control components of the storage virtualization services offered by the cluster.  This implementation features: dynamic quorum (which considers power domains and extends the Paxos protocol to an optional quorum disk to maintain fault-tolerance down to clusters as small as two nodes); concurrent ballots of batched requests broadcast and collated using an overlay binary tree network for efficiency; automatic reintegration of restarted nodes without stalling the cluster (by state delta transfer using an overlay hypercube network followed by catch-up of ballots committed during the state transfer) and an underlying view management algorithm used to select a leader and gracefully handle asymmetric network partitions.</entry>
<entry level="1" type="bullet">

 Microsoft uses Paxos in the <weblink xlink:type="simple" xlink:href="http://research.microsoft.com/users/misard/abstracts/osr2007.html">
Autopilot cluster management service</weblink> from Live Search</entry>
</list>
</p>

</sec>
<sec>
<st>
 References </st>

<p>

<reflist>
<entry id="1">
 <cite style="font-style:normal">Schneider, Fred&#32;(1990).&#32;“<weblink xlink:type="simple" xlink:href="http://www.eecs.harvard.edu/cs262/DSbook.c7.pdf">
Implementing Fault-Tolerant Services Using the State Machine Approach: A Tutorial</weblink>”&#32;(&#91;&#93;). <it>ACM Computing Surveys</it>&#32;<b>22</b>: 299. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1145%2F98163.98167">
10.1145/98163.98167</weblink>.</cite>&nbsp;</entry>
<entry id="2">
 <cite style="font-style:normal">Lamport, Leslie&#32;(July 1978).&#32;“<weblink xlink:type="simple" xlink:href="http://research.microsoft.com/users/lamport/pubs/pubs.html#time-clocks">
Time, Clocks and the Ordering of Events in a Distributed System</weblink>”. <it>Communications of the ACM</it>&#32;<b>21</b>&#32;(7): 558–565. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1145%2F359545.359563">
10.1145/359545.359563</weblink>. Retrieved on <link>
2007-02-02</link>.</cite>&nbsp;</entry>
<entry id="3">
 <cite style="font-style:normal">Lamport, Leslie&#32;(May 1998).&#32;“<weblink xlink:type="simple" xlink:href="http://research.microsoft.com/users/lamport/pubs/pubs.html#lamport-paxos">
The Part-Time Parliament</weblink>”. <it>ACM Transactions on Computer Systems</it>&#32;<b>16</b>&#32;(2): 133–169. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1145%2F279227.279229">
10.1145/279227.279229</weblink>. Retrieved on <link>
2007-02-02</link>.</cite>&nbsp;</entry>
<entry id="4">
 <cite style="font-style:normal">Lamport, Leslie; Mike Massa&#32;(2004).&#32;“<weblink xlink:type="simple" xlink:href="http://research.microsoft.com/users/lamport/pubs/pubs.html#web-dsn-submission">
Cheap Paxos</weblink>”. <it>Proceedings of the International Conference on Dependable Systems and Networks (DSN 2004)</it>.</cite>&nbsp;</entry>
<entry id="5">
Lamport, Leslie&#32;(2005).&#32;"<weblink xlink:type="simple" xlink:href="http://research.microsoft.com/users/lamport/pubs/pubs.html#fast-paxos">
Fast Paxos</weblink>".</entry>
<entry id="6">
 <cite style="font-style:normal">Lamport, Leslie&#32;(2005).&#32;“<weblink xlink:type="simple" xlink:href="http://research.microsoft.com/users/lamport/pubs/pubs.html#generalized">
Generalized Consensus and Paxos</weblink>”.</cite>&nbsp;</entry>
<entry id="7">
Castro, Miguel&#32;(2001).&#32;"<weblink xlink:type="simple" xlink:href="http://citeseer.ist.psu.edu/castro01practical.html">
Practical Byzantine Fault Tolerance</weblink>".</entry>
<entry id="8">
Lamport, Leslie&#32;(2004).&#32;"<weblink xlink:type="simple" xlink:href="http://research.microsoft.com/users/lamport/pubs/pubs.html#lower-bound">
Lower Bounds for Asynchronous Consensus</weblink>".</entry>
<entry id="9">
 <cite style="font-style:normal">Chandra, Tushar; Robert Griesemer, Joshua Redstone&#32;(2007).&#32;“<weblink xlink:type="simple" xlink:href="http://labs.google.com/papers/paxos_made_live.html">
Paxos Made Live – An Engineering Perspective</weblink>”. <it>PODC '07: 26th ACM Symposium on Principles of Distributed Computing</it>.</cite>&nbsp;</entry>
<entry id="10">
 <cite style="font-style:normal">Lamport, Leslie; Robert Shostak, Marshall Pease&#32;(July 1982).&#32;“<weblink xlink:type="simple" xlink:href="http://research.microsoft.com/users/lamport/pubs/pubs.html#byz">
The Byzantine Generals Problem</weblink>”. <it>ACM Transactions on Programming Languages and Systems</it>&#32;<b>4</b>&#32;(3): 382–401. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1145%2F357172.357176">
10.1145/357172.357176</weblink>. Retrieved on <link>
2007-02-02</link>.</cite>&nbsp;</entry>
</reflist>
</p>

</sec>
<sec>
<st>
See also</st>

<p>

<list>
<entry level="1" type="bullet">

 <link>
Chandra-Toueg consensus algorithm</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../931/10931.xml">
State machine</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../735/11459735.xml">
Virtual synchrony</link></entry>
</list>
</p>

</sec>
<sec>
<st>
 External links </st>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.lamport.org/">
Leslie Lamport's home page</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://research.microsoft.com/users/lamport/pubs/pubs.html#paxos-simple">
Paxos Made Simple</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://citeseer.ist.psu.edu/deprisco97revisiting.html">
Revisiting the Paxos Algorithm</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://research.microsoft.com/users/lamport/pubs/pubs.html#paxos-commit">
Paxos Commit</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://pine.cs.yale.edu/pinewiki/Paxos">
Yale University's Wiki article</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://research.microsoft.com/users/lamport/pubs/pubs.html#lamport-paxos">
Leslie Lamport's history of the paper</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://labs.google.com/papers/chubby.html">
Google Whitepaper: Chubby Distributed Lock Service</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://labs.google.com/papers/bigtable.html">
Google Whitepaper: Bigtable A Distributed Storage System for Structured Data</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://brturn.googlepages.com/paxosfamily">
Survey of Paxos Algorithms (2007)</weblink></entry>
</list>
</p>

</sec>
</bdy>
</algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</instrumentality>
</artifact>
</system>
</article>
