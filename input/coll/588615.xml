<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 17:22:35[mciao0828] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<event  confidence="0.8" wordnetid="100029378">
<rule  confidence="0.8" wordnetid="105846932">
<act  confidence="0.8" wordnetid="100030358">
<psychological_feature  confidence="0.8" wordnetid="100023100">
<procedure  confidence="0.8" wordnetid="101023820">
<activity  confidence="0.8" wordnetid="100407535">
<algorithm  confidence="0.8" wordnetid="105847438">
<header>
<title>Ant colony optimization</title>
<id>588615</id>
<revision>
<id>240391496</id>
<timestamp>2008-09-23T07:59:19Z</timestamp>
<contributor>
<username>VolkovBot</username>
<id>3035831</id>
</contributor>
</revision>
<categories>
<category>Optimization algorithms</category>
</categories>
</header>
<bdy>

The <b>ant colony optimization</b> <link xlink:type="simple" xlink:href="../775/775.xml">
algorithm</link> (ACO), introduced by <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<academician wordnetid="109759069" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<adult wordnetid="109605289" confidence="0.8">
<professional wordnetid="110480253" confidence="0.8">
<educator wordnetid="110045713" confidence="0.8">
<link xlink:type="simple" xlink:href="../360/1183360.xml">
Marco Dorigo</link></educator>
</professional>
</adult>
</scientist>
</academician>
</causal_agent>
</person>
</physical_entity>
 in 1992 in his PhD thesis, is a <link xlink:type="simple" xlink:href="../934/22934.xml">
probabilistic</link> technique for solving computational problems which can be reduced to finding good paths through <link xlink:type="simple" xlink:href="../806/325806.xml">
graph</link>s.  They are inspired by the behavior of <link xlink:type="simple" xlink:href="../594/2594.xml">
ant</link>s in finding paths from the <link xlink:type="simple" xlink:href="../536/1056536.xml">
colony</link> to food.
<sec>
<st>
Overview</st>
<p>

In the real world, ants (initially) wander <link xlink:type="simple" xlink:href="../523/19196523.xml">
random</link>ly, and upon finding food return to their colony while laying down <link xlink:type="simple" xlink:href="../390/105390.xml">
pheromone</link> trails. If other ants find such a path, they are likely not to keep traveling at <link xlink:type="simple" xlink:href="../523/19196523.xml">
random</link>, but to instead follow the trail, returning and reinforcing it if they eventually find food (see <link xlink:type="simple" xlink:href="../594/2594.xml#xpointer(//*[./st=%22Communication%22])">
Ant communication</link>).</p>
<p>

Over time, however, the pheromone trail starts to evaporate, thus reducing its attractive strength. The more time it takes for an ant to travel down the path and back again, the more time the pheromones have to evaporate. A short path, by comparison, gets marched over faster, and thus the pheromone density remains high as it is laid on the path as fast as it can evaporate. Pheromone evaporation has also the advantage of avoiding the convergence to a locally optimal solution. If there were no evaporation at all, the paths chosen by the first ants would tend to be excessively attractive to the following ones. In that case, the exploration of the solution space would be constrained.</p>
<p>

Thus, when one ant finds a good (i.e. short) path from the colony to a food source, other ants are more likely to follow that path, and <link xlink:type="simple" xlink:href="../354/213354.xml">
positive feedback</link> eventually leads all the ants following a single path. The idea of the ant colony algorithm is to mimic this behavior with "simulated ants" walking around the graph representing the problem to solve.</p>
<p>

Ant colony optimization algorithms have been used to produce near-optimal solutions to the <link xlink:type="simple" xlink:href="../248/31248.xml#xpointer(//*[./st=%22Ant_colony_optimization%22])">
traveling salesman problem</link>.  They have an advantage over <link xlink:type="simple" xlink:href="../244/172244.xml">
simulated annealing</link> and <link xlink:type="simple" xlink:href="../254/40254.xml">
genetic algorithm</link> approaches when the graph may change dynamically; the ant colony algorithm can be run continuously and adapt to changes in real time.  This is of interest in <link xlink:type="simple" xlink:href="../750/25750.xml">
network routing</link> and urban transportation systems.</p>

</sec>
<sec>
<st>
Pseudo-code &amp; Formulas</st>

<p>

procedure ACO_MetaHeuristic
while(not_termination)
generateSolutions()
pheromoneUpdate()
daemonActions()
end while
end procedure</p>
<p>

<b>Arc Selection:</b></p>
<p>

An ant will move from node <math>i</math> to node <math>j</math> with probability</p>
<p>

<math>
p_{i,j} = 
\frac
{ (\tau_{i,j}^{\alpha}) (\eta_{i,j}^{\beta}) }
{ \sum (\tau_{i,j}^{\alpha}) (\eta_{i,j}^{\beta}) }
</math></p>
<p>

where, </p>
<p>

<math>\tau_{i,j}</math> is the amount of pheromone on arc <math>i,j</math></p>
<p>

<math>\alpha</math> is a parameter to control the influence of <math>\tau_{i,j}</math></p>
<p>

<math>\eta_{i,j}</math> is the desirability of arc <math>i,j</math> (a priori knowledge, typically <math>1/d_{i,j}</math>)</p>
<p>

<math>\beta</math> is a parameter to control the influence of <math>\eta_{i,j}</math></p>
<p>

<b>Pheromone Update</b></p>
<p>

<math>
\tau_{i,j} = 
\rho\tau_{i,j} + \Delta \tau_{i,j}
</math></p>
<p>

where, </p>
<p>

<math>\tau_{i,j}</math> is the amount of pheromone on a given arc <math>i,j</math></p>
<p>

<math>\rho</math> is the rate of pheromone evaporation</p>
<p>

and <math>\Delta \tau_{i,j}</math> is the amount of pheromone deposited, typically given by</p>
<p>

<math>
\Delta \tau^{k}_{i,j} = 
\begin{cases}
1/L_k &amp; \mbox{if ant }k\mbox{ travels on arc }i,j \\
0 &amp; \mbox{otherwise}
\end{cases}
</math></p>
<p>

where <math>L_k</math> is the cost of the <math>k</math>th ant's tour (typically length).</p>

</sec>
<sec>
<st>
Common Extensions </st>
<p>

<list>
<entry level="1" type="number">

Elitist Ant System</entry>
<entry level="2" type="bullet">

The global best solution deposits pheromone on every iteration along with all the other ants</entry>
<entry level="1" type="number">

Max-Min Ant System (MMAS)</entry>
<entry level="2" type="bullet">

Added Maximum and Minimum pheromone amounts [τmax,τmin]</entry>
<entry level="2" type="bullet">

Only global best or iteration best tour deposited pheromone</entry>
<entry level="2" type="bullet">

All edges are initialized to τmax and reinitialized to τmax when nearing stagnation.</entry>
<entry level="1" type="number">

Rank-Based Ant System (ASrank)</entry>
<entry level="2" type="bullet">

All solutions are ranked according to their fitness. The amount of pheromone deposited is then weighted for each solution, such that the more optimal solutions deposit more pheromone than the less optimal solutions</entry>
</list>
</p>

</sec>
<sec>
<st>
Related methods </st>

<p>

<link xlink:type="simple" xlink:href="../254/40254.xml">
Genetic Algorithms</link> (GA) maintain a pool of solutions rather than just one. The process of finding superior solutions mimics that of evolution, with solutions being combined or mutated to alter the pool of solutions, with solutions of inferior quality being discarded. This form of algorithm is superior.</p>
<p>

<link xlink:type="simple" xlink:href="../244/172244.xml">
Simulated Annealing</link> (SA) is a related global optimization technique which traverses the search space by generating neighboring solutions of the current solution. A superior neighbor is always accepted. An inferior neighbor is accepted probabilistically based on the difference in quality and a temperature parameter. The temperature parameter is modified as the algorithm progresses to alter the nature of the search.</p>
<p>

<event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../937/381937.xml">
Tabu search</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
 (TS) is similar to Simulated Annealing, in that both traverse the solution space by testing mutations of an individual solution. While simulated annealing generates only one mutated solution, tabu search generates many mutated solutions and moves to the solution with the lowest fitness of those generated. In order to prevent cycling and encourage greater movement through the solution space, a tabu list is maintained of partial or complete solutions. It is forbidden to move to a solution that contains elements of the tabu list, which is updated as the solution traverses the solution space. </p>
<p>

<event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../902/9485902.xml">
Harmony search</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
 (HS) is an algorithm based on the analogy between music improvisation and optimization. Each musician (variable) together seeks better harmonies (vectors).</p>
<p>

<link>
Artificial Immune Systems</link> (AIS) algorithms that are modeled on vertebrate immune systems.</p>

</sec>
<sec>
<st>
See also</st>
<p>

<list>
<entry level="1" type="bullet">

<event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../083/337083.xml">
Particle swarm optimization</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../913/60913.xml">
Stigmergy</link></entry>
<entry level="1" type="bullet">

<system wordnetid="104377057" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../988/762988.xml">
Swarm Intelligence</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</instrumentality>
</artifact>
</system>
</entry>
</list>
</p>

</sec>
<sec>
<st>
Publications (selected)</st>
<p>

<list>
<entry level="1" type="bullet">

 <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<academician wordnetid="109759069" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<adult wordnetid="109605289" confidence="0.8">
<professional wordnetid="110480253" confidence="0.8">
<educator wordnetid="110045713" confidence="0.8">
<link xlink:type="simple" xlink:href="../360/1183360.xml">
M. Dorigo</link></educator>
</professional>
</adult>
</scientist>
</academician>
</causal_agent>
</person>
</physical_entity>
, 1992. <it>Optimization, Learning and Natural Algorithms</it>, PhD thesis, Politecnico di Milano, Italy.</entry>
<entry level="1" type="bullet">

 M. Dorigo, V. Maniezzo &amp; A. Colorni, 1996. "Ant System: Optimization by a Colony of Cooperating Agents", IEEE Transactions on Systems, Man, and Cybernetics–Part B, 26 (1): 29–41. </entry>
<entry level="1" type="bullet">

 M. Dorigo &amp; <person wordnetid="100007846" confidence="0.9638700866880419">
<link xlink:type="simple" xlink:href="../883/4103883.xml">
L. M. Gambardella</link></person>
, 1997. "Ant Colony System: A Cooperative Learning Approach to the Traveling Salesman Problem". IEEE Transactions on Evolutionary Computation, 1 (1): 53–66.</entry>
<entry level="1" type="bullet">

 M. Dorigo, G. Di Caro &amp; L. M. Gambardella, 1999. "Ant Algorithms for Discrete Optimization". Artificial Life, 5 (2): 137–172. </entry>
<entry level="1" type="bullet">

 E. Bonabeau, M. Dorigo et G. Theraulaz, 1999. <it>Swarm Intelligence: From Natural to Artificial Systems</it>, Oxford University Press. ISBN 0-19-513159-2</entry>
<entry level="1" type="bullet">

 M. Dorigo &amp; T. Stützle, 2004. <it>Ant Colony Optimization</it>, MIT Press. ISBN 0-262-04219-3</entry>
<entry level="1" type="bullet">

 M. Dorigo, 2007. <weblink xlink:type="simple" xlink:href="http://www.scholarpedia.org/article/Ant_Colony_Optimization">
 "Ant Colony Optimization"</weblink>. Scholarpedia.</entry>
<entry level="1" type="bullet">

 C. Blum, 2005 "ant colony optimization:introduction and recent trends" physics of life review(2) 353-373</entry>
</list>
</p>

</sec>
<sec>
<st>
 External links </st>
<p>

<list>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.aco-metaheuristic.org/">
Ant Colony Optimization Home Page</weblink></entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.ict.swin.edu.au/personal/dangus/dissertations.htm">
A list of dissertations related to the field of Ant Colony Optimization</weblink></entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.visualbots.com/index.htm">
VisualBots</weblink> - Freeware multi-agent simulator in Microsoft Excel. Sample programs include genetic algorithm, ACO, and simulated annealing solutions to TSP.</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.not-equal.eu/myrmedrome">
Myrmedrome</weblink> A visual simulation of Ant Colony Optimization with artificial ants. (Windows and Linux Application)</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.nightlab.ch/antsim">
AntSim v1.0</weblink> A visual simulation of Ant Colony Optimization with artificial ants. (Windows Application)</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.geocities.com/chamonate/hormigas/antfarm">
Ant Farm Simulator</weblink> A simulation of ants food-gathering behaviour (Windows Application and source code available)</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://djoh.net/blog/?toute-l-histoire-des-fourmis">
ANT Colony Algorithm</weblink> A Java Simulation of the Path Optimisation, on a changing ground. Presentation and source code available.</entry>
</list>
</p>




</sec>
</bdy>
</algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</article>
