<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 15:45:30[mciao0825] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<idea  confidence="0.8" wordnetid="105833840">
<concept  confidence="0.8" wordnetid="105835747">
<header>
<title>Statistical ensemble (mathematical physics)</title>
<id>59052</id>
<revision>
<id>242484142</id>
<timestamp>2008-10-02T12:46:59Z</timestamp>
<contributor>
<username>A.Cython</username>
<id>6463349</id>
</contributor>
</revision>
<categories>
<category>Statistical mechanics</category>
<category>Philosophy of thermal and statistical physics</category>
<category>Fundamental physics concepts</category>
</categories>
</header>
<bdy>

In <link xlink:type="simple" xlink:href="../416/173416.xml">
mathematical physics</link>, especially as introduced into <link xlink:type="simple" xlink:href="../481/28481.xml">
statistical mechanics</link> and <link xlink:type="simple" xlink:href="../952/29952.xml">
thermodynamics</link> by <link xlink:type="simple" xlink:href="../332/37332.xml">
J. Willard Gibbs</link> in 1878, an <b>ensemble</b> (also <b>statistical ensemble</b> or <b>thermodynamic ensemble</b>)<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref> is an idealization consisting of a large number of mental copies (sometimes infinitely many) of a <link xlink:type="simple" xlink:href="../675/8286675.xml">
system</link>, considered all at once, each of which represents a possible state that the real system might be in. This article treats the notion of ensembles in a mathematically rigorous fashion, although relevant physical aspects will be mentioned.
<sec>
<st>
 Physical considerations </st>

<p>

The ensemble formalises the notion that a physicist repeating an experiment again and again under the same macroscopic conditions, but unable to control the microscopic details, may expect to observe a range of different outcomes.  </p>
<p>

The notional size of the mental ensembles in thermodynamics, statistical mechanics and <link xlink:type="simple" xlink:href="../450/712450.xml">
quantum statistical mechanics</link> can be very large indeed, to include every possible <link xlink:type="simple" xlink:href="../350/3066350.xml">
microscopic state</link> the system could be in, consistent with its observed <link xlink:type="simple" xlink:href="../187/382187.xml">
macroscopic</link> properties.  But for important physical cases it can be possible to calculate averages directly over the whole of the thermodynamic ensemble, to obtain explicit formulas for many of the thermodynamic quantities of interest, often in terms of the appropriate partition function (see below). Some of these results are presented in the article <link xlink:type="simple" xlink:href="../481/28481.xml">
Statistical mechanics</link>. </p>

<ss2>
<st>
 Note on terminology </st>

<p>

<list>
<entry level="1" type="bullet">

The word ensemble is also sometimes used for smaller sets of possibilities, <link xlink:type="simple" xlink:href="../586/27586.xml">
sampled</link> from the full set of possible states.  Thus for example, an ensemble of walkers in a <know-how wordnetid="105616786" confidence="0.8">
<method wordnetid="105660268" confidence="0.8">
<link xlink:type="simple" xlink:href="../801/236801.xml">
Markov chain Monte Carlo</link></method>
</know-how>
 iteration.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

The word ensemble is particularly used in thermodynamics; by some physicists working in <representation wordnetid="105926676" confidence="0.8">
<interpretation wordnetid="105928513" confidence="0.8">
<link xlink:type="simple" xlink:href="../890/4890.xml">
Bayesian probability</link></interpretation>
</representation>
 theory; and by mathematicians whose work in probability theory is heavily influenced by physicists, especially those working on <link xlink:type="simple" xlink:href="../765/1648765.xml">
random matrices</link>.  Most "pure" mathematicians working in <link xlink:type="simple" xlink:href="../542/23542.xml">
probability theory</link> do not use the term, preferring to use the terminology of <link xlink:type="simple" xlink:href="../325/43325.xml">
probability space</link>s.</entry>
</list>
</p>

</ss2>
</sec>
<sec>
<st>
 Ensembles of classical mechanical systems </st>

<p>

For an ensemble of a <idea wordnetid="105833840" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<link xlink:type="simple" xlink:href="../319/198319.xml">
classical mechanical system</link></concept>
</idea>
, one considers the phase space of the given system. A collection of elements from the ensemble can be viewed as a swarm of representative points in the phase space. The statistical properties of the ensemble then depend on a chosen <link>
probability measure</link> on the phase space. If a region <it>A</it> of the phase space has larger measure than region B, then a system chosen at random from the ensemble is more likely to be in a microstate belonging to <it>A</it> than <it>B</it>. The choice of this measure is dictated by the specific details of the system and the assumptions one makes about the ensemble in general. For example, the phase space measure of the <link xlink:type="simple" xlink:href="../447/1136447.xml">
microcanonical ensemble</link> (see below) is different from that of the <link xlink:type="simple" xlink:href="../672/1137672.xml">
canonical ensemble</link>. The normalizing factor of the probability measure is referred to as the <link xlink:type="simple" xlink:href="../266/54266.xml">
partition function</link> of the ensemble. Physically, the partition function encodes the underlying physical structure of the system. </p>
<p>

When the measure is time-independent, the ensemble is said to be <it>stationary</it>.</p>

<ss1>
<st>
 Principal ensembles of statistical thermodynamics </st>

<p>

Different macroscopic environmental constraints lead to different types of ensembles, with particular statistical characteristics.  The following are the most important:</p>
<p>

<list>
<entry level="1" type="bullet">

  <link xlink:type="simple" xlink:href="../447/1136447.xml">
Microcanonical ensemble</link> or NVE ensemble -- an ensemble of systems, each of which is required to have the same total energy (i.e. thermally isolated).</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

  <link xlink:type="simple" xlink:href="../672/1137672.xml">
Canonical ensemble</link> or NVT ensemble -- an ensemble of systems, each of which can share its energy with a large heat reservoir or heat bath. The system is allowed to exchange energy with the reservoir, and the heat capacity of the reservoir is assumed to be so large as to maintain a fixed temperature for the coupled system.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

  <link xlink:type="simple" xlink:href="../074/1129074.xml">
Grand canonical ensemble</link> -- an ensemble of systems, each of which is again in thermal contact with a reservoir. But now in addition to energy, there is also exchange of particles. The temperature is still assumed to be fixed.</entry>
</list>
</p>
<p>

The calculations that can be made over each of these ensembles are explored further in the article <link xlink:type="simple" xlink:href="../481/28481.xml">
Statistical mechanics</link>. The main result for each ensemble however, is its characteristic state function:</p>
<p>

Microcanonical: <math>\; \Omega(U,V,N) = e^{\beta TS} </math></p>
<p>

Canonical: <math>\; Z(T,V,N) = e^{- \beta A} </math></p>
<p>

Grand canonical:  <math>\; \Xi(T,V,\mu) = e^{\beta P V} </math></p>
<p>

For these ensembles, the choice for the appropriate probability measure is dictated by the expressions above. </p>
<p>

Other thermodynamic ensembles can be also defined, corresponding to different physical requirements, for which analogous formulae can often similarly be derived.</p>

</ss1>
<ss1>
<st>
 Properties of "good" ensembles </st>

<p>

The following properties are considered desirable for a classical mechanical ensemble.</p>
<p>

<list>
<entry level="1" type="bullet">

  Representativeness</entry>
</list>
</p>
<p>

The chosen probability measure on the phase space should be a <link xlink:type="simple" xlink:href="../205/3045205.xml">
Gibbs state</link> of the ensemble, i.e. it should be invariant under time evolution. A standard example of this is the natural measure (locally, it is just the Lebesgue measure) on a constant energy surface for a classical mechanical system. <link xlink:type="simple" xlink:href="../815/72815.xml">
Liouville's theorem</link> states this measure is invariant under the <link xlink:type="simple" xlink:href="../270/1818270.xml">
Hamiltonian flow</link>.</p>
<p>

<list>
<entry level="1" type="bullet">

  Ergodicity </entry>
</list>
</p>
<p>

Once a probability measure μ on the phase space <math>\Lambda</math> is specified, one can define the <it>ensemble average</it> of an observable, i.e. real-valued function <it>f</it> defined on <math>\Lambda</math> via this measure by</p>
<p>

<indent level="1">

<math>\langle f \rangle = \int _{\Lambda} f d \mu</math>,
</indent>

where we have restricted to those observables which are μ-integrable.</p>
<p>

On the other hand, let <math>\; x(0)</math> denote a representative point in the phase space, and <math>\; x(t)</math> be its image under the flow, specified by the system in question, at time <it>t</it>. The <it>time average</it> of <it>f</it> is defined to be</p>
<p>

<indent level="1">

<math>\lim _{T \rightarrow \infty}\frac{1}{T} \int _0 ^T f(x(t)) d t,</math> 
</indent>

provided that this limit exists μ-almost everywhere and is independent of <math>\; x(0)</math>.</p>
<p>

The <link xlink:type="simple" xlink:href="../986/258986.xml">
ergodicity</link> requirement is that the ensemble average coincide with the time average. A sufficient condition for ergodicity is that the time evolution of the system is a <link xlink:type="simple" xlink:href="../444/546444.xml">
mixing</link>. (See also <link xlink:type="simple" xlink:href="../980/258980.xml">
ergodic hypothesis</link>.) Not all systems are ergodic. For instance, it is unknown at this time whether classical mechanical flows on a constant energy surface are ergodic in general. Physically, when a system fails to be ergodic, we may infer that there is more macroscopically discoverable information available about the microscopic state of the system than what we first thought. In turn this may be used to create a better-<link xlink:type="simple" xlink:href="../791/5791.xml">
conditioned</link> ensemble.</p>

</ss1>
</sec>
<sec>
<st>
 Ensembles in quantum statistical mechanics </st>
<p>

<indent level="1">

</indent>
:<it>Main article: <link xlink:type="simple" xlink:href="../450/712450.xml">
Quantum statistical mechanics</link></it></p>
<p>

Putting aside for the moment the question of how statistical ensembles are generated <link xlink:type="simple" xlink:href="../692/65692.xml">
operationally</link>, we should be able to perform the following two operations on ensembles <it>A</it>, <it>B</it> of the same system:</p>
<p>

<list>
<entry level="1" type="bullet">

 Test whether  <it>A</it>, <it>B</it> are statistically equivalent.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 If <it>p</it> is a real number such that 0  <it>p</it>  1, then produce a new ensemble by probabilistic sampling from  <it>A</it> with probability <it>p</it> and from <it>B</it> with probability <it>1 – p</it>. </entry>
</list>
</p>
<p>

Under certain conditions therefore, <link xlink:type="simple" xlink:href="../260/9260.xml">
equivalence class</link>es of statistical ensembles have the structure of a convex set.  In quantum physics, a general <link xlink:type="simple" xlink:href="../795/3224795.xml">
model</link> for this convex set is the set of <link xlink:type="simple" xlink:href="../844/62844.xml">
density operators</link> on a <link xlink:type="simple" xlink:href="../167/18994167.xml">
Hilbert space</link>. Accordingly, there are two types of ensembles:</p>
<p>

<list>
<entry level="1" type="bullet">

<it>Pure ensembles</it>  cannot be decomposed as a convex combination of different ensembles. In quantum mechanics, a pure density matrix is one of the form <math> |\phi \rangle \langle \phi| </math>.  Accordingly, a ray in a <link xlink:type="simple" xlink:href="../167/18994167.xml">
Hilbert space</link> can be used to represent such an ensemble in quantum mechanics. A pure ensemble corresponds to having many copies of the same (up to a global phase) quantum state.</entry>
<entry level="1" type="bullet">

<it>Mixed ensembles</it> are decomposable into a convex combination of different ensembles. In general, an infinite number of distinct decompositions will be possible.</entry>
</list>
</p>
<p>

Thus a quantum mechanical ensemble is specified by a mixed state in general. For example, one can specify the density operators describing microcanonical, canonical, and grand canonical ensembles of quantum mechanical systems, in a mathematically rigorous fashion.</p>
<p>

The normalization factor required for the density operator to have trace 1 is the quantum mechanical version of the partition function.</p>
<p>

We note here that ensembles of quantum mechanical system are sometimes treated by physicists in a <it>semi-classical</it> fashion. Namely, one considers the phase space of the corresponding classical system (e.g. for an ensemble of quantum harmonic oscillators, the phase space of a classical harmonic oscillator is considered). Then, using physical arguments, one derives a suitable "fundamental volume" for the particular system to reflect the fact that quantum mechanical microstates are discretely distributed on the phase space. From the uncertainly principle, it is expected this fundamental volume to be related to the Planck constant, <math>\hbar</math>, in some way.</p>

</sec>
<sec>
<st>
 Ensembles in statistics </st>
<p>

<indent level="1">

</indent>
:<it>Main articles: <link xlink:type="simple" xlink:href="../718/201718.xml">
Principle of maximum entropy</link>&#32;and&#32;<link xlink:type="simple" xlink:href="../985/1323985.xml">
Markov random field</link></it>
The formulation of statistical ensembles used in physics has now been widely adopted in other fields, in part because it has been recognized that the <link xlink:type="simple" xlink:href="../107/4107.xml">
Boltzmann distribution</link> or <link xlink:type="simple" xlink:href="../914/3085914.xml">
Gibbs measure</link> serves to maximize the entropy of a system, subject to a set of constraints: this is the <link xlink:type="simple" xlink:href="../718/201718.xml">
principle of maximum entropy</link>. This principle has now been widely applied to problems in <link xlink:type="simple" xlink:href="../526/17526.xml">
linguistics</link>, <link xlink:type="simple" xlink:href="../673/46673.xml">
robotics</link>, and the like.</p>
<p>

In addition, statistical ensembles in physics are often built on a <link xlink:type="simple" xlink:href="../118/427118.xml">
principle of locality</link>: that all interactions are only between neighboring atoms or nearby molecules. Thus, for example, <link xlink:type="simple" xlink:href="../472/291472.xml">
lattice models</link>, such as the <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../744/292744.xml">
Ising model</link></causal_agent>
</worker>
</assistant>
</model>
</person>
</physical_entity>
, model <link xlink:type="simple" xlink:href="../807/11807.xml">
ferromagnetic</link> materials by means of nearest-neighbor interactions between spins.  The statistical formulation of the principle of locality is now seen to be a form of the <link xlink:type="simple" xlink:href="../422/306422.xml">
Markov property</link> in the broad sense; nearest neighbors are now <system wordnetid="108435388" confidence="0.8">
<group wordnetid="100031264" confidence="0.8">
<network wordnetid="108434259" confidence="0.8">
<link xlink:type="simple" xlink:href="../984/1169984.xml">
Markov blanket</link></network>
</group>
</system>
s. Thus, the general notion of a statistical ensemble with nearest-neighbor interactions leads to <link xlink:type="simple" xlink:href="../985/1323985.xml">
Markov random field</link>s, which again find broad applicability; for example in <link xlink:type="simple" xlink:href="../097/1170097.xml">
Hopfield network</link>s.</p>

</sec>
<sec>
<st>
 Operational interpretation </st>

<p>

In the discussion given so far, while rigorous, we have taken for granted that the notion of an ensemble is valid a priori, as is commonly done in physical context. What has not been shown is that the ensemble <it>itself</it> (not the consequent results) is a precisely defined object mathematically. For instance, </p>
<p>

<list>
<entry level="1" type="bullet">

 It is not clear where this <it>very large set of systems</it> exists (for example, is it a <link xlink:type="simple" xlink:href="../316/1389316.xml">
<it>gas</it> of particles inside a container</link>?)</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 It is not clear how to physically generate an ensemble. </entry>
</list>
</p>
<p>

In this section we attempt to partially answer this question.  </p>
<p>

Suppose we have a <it>preparation procedure</it> for a system in a physics
lab: For example, the procedure might involve a physical apparatus and
some protocols for manipulating the apparatus.  As a result of this preparation procedure some system
is produced and maintained in isolation for some small period of time.
By repeating this laboratory preparation procedure we obtain a
sequence of systems <it>X</it>1, <it>X</it>2,
....,<it>Xk</it>, which in our mathematical idealization, we assume is an <link xlink:type="simple" xlink:href="../455/15455.xml">
infinite</link> sequence of systems. The systems are similar in that they were all produced in the same way.  This infinite sequence is an ensemble.</p>
<p>

In a laboratory setting, each one of these prepped systems might be used as input
for <it>one</it> subsequent <it>testing procedure</it>. Again, the testing procedure
involves a physical apparatus and some protocols;  as a result of the
testing procedure we obtain a <it>yes</it> or <it>no</it> answer. 
Given a testing procedure <it>E</it> applied to each prepared system, we obtain a sequence of values
Meas (<it>E</it>, <it>X</it>1), Meas (<it>E</it>, <it>X</it>2),
...., Meas (<it>E</it>, <it>Xk</it>).  Each one of these values is a 0 (or no) or a 1 (yes).</p>
<p>

Assume the following time average exists:
<indent level="1">

<math> \sigma(E) = \lim_{N \rightarrow \infty} \frac{1}{N} \sum_{k=1}^N \operatorname{Meas}(E, X_k) </math>
</indent>
For quantum mechanical systems, an important assumption made in the
<link xlink:type="simple" xlink:href="../426/663426.xml">
quantum logic</link> approach to quantum mechanics is the identification of <it>yes-no</it> questions to the
lattice of closed subspaces of a Hilbert space. With some additional
technical assumptions one can then infer that states are given by
density operators <it>S</it> so that:
<indent level="1">

<math> \sigma(E) = \operatorname{Tr}(E S). </math>
</indent>

We see this reflects the definition of quantum states in general: A quantum state is a mapping from the observables to their expectation values.</p>

</sec>
<sec>
<st>
See also</st>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../844/62844.xml">
density matrix</link></entry>
<entry level="1" type="bullet">

 <idea wordnetid="105833840" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<link xlink:type="simple" xlink:href="../252/312252.xml">
Partition function (statistical mechanics)</link></concept>
</idea>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../849/16846849.xml">
Partition function (mathematics)</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../038/3521038.xml">
isothermal-isobaric ensemble</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../101/191101.xml">
phase space</link></entry>
<entry level="1" type="bullet">

 <statement wordnetid="106722453" confidence="0.8">
<message wordnetid="106598915" confidence="0.8">
<idea wordnetid="105833840" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<theorem wordnetid="106752293" confidence="0.8">
<proposition wordnetid="106750804" confidence="0.8">
<link xlink:type="simple" xlink:href="../301/312301.xml">
Liouville's theorem (Hamiltonian)</link></proposition>
</theorem>
</concept>
</idea>
</message>
</statement>
</entry>
</list>
</p>

</sec>
<sec>
<st>
References</st>
<p>

<reflist>
<entry id="1">
 <cite id="Reference-Kittel-1980" style="font-style:normal" class="book"><person wordnetid="100007846" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../250/13033250.xml">
Kittel, Charles</link></person>
;&#32;Herbert Kroemer&#32;(1980). Thermal Physics, Second Edition.&#32;San Francisco:&#32;W.H. Freeman and Company,&#32;31 ff. ISBN 0716710889.</cite>&nbsp;</entry>
<entry id="2">
 <cite id="Reference-Landau-1980" style="font-style:normal" class="book"><person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../322/80322.xml">
Landau, L.D.</link></scientist>
</person>
;&#32;Lifshitz, E.M.&#32;(1980). Statistical Physics.&#32;Pergamon Press,&#32;9 ff. ISBN 0080230385.</cite>&nbsp;</entry>
</reflist>
</p>


</sec>
</bdy>
</concept>
</idea>
</article>
