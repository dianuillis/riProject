<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 17:22:51[mciao0825] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<event  confidence="0.8" wordnetid="100029378">
<rule  confidence="0.8" wordnetid="105846932">
<act  confidence="0.8" wordnetid="100030358">
<psychological_feature  confidence="0.8" wordnetid="100023100">
<procedure  confidence="0.8" wordnetid="101023820">
<activity  confidence="0.8" wordnetid="100407535">
<algorithm  confidence="0.8" wordnetid="105847438">
<header>
<title>Apriori algorithm</title>
<id>608194</id>
<revision>
<id>239010186</id>
<timestamp>2008-09-17T12:31:40Z</timestamp>
<contributor>
<username>VolkovBot</username>
<id>3035831</id>
</contributor>
</revision>
<categories>
<category>Search algorithms</category>
<category>Data mining</category>
<category>Wikipedia articles needing clarification</category>
</categories>
</header>
<bdy>

<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-style" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="40px" src="Ambox_?.svg">
</image>
</p>
</col>
<col style="" class="mbox-text">
 <b>All or part of this article may be .</b>
Please help . Suggestions may be on the . <it>(December 2006)</it></col>
</row>
</table>



<p>

In <link xlink:type="simple" xlink:href="../323/5323.xml">
computer science</link> and <link xlink:type="simple" xlink:href="../253/42253.xml">
data mining</link>, <b>Apriori</b> is a classic algorithm for learning <link xlink:type="simple" xlink:href="../053/577053.xml">
association rule</link>s. Apriori is designed to operate on <link xlink:type="simple" xlink:href="../377/8377.xml">
database</link>s containing transactions (for example, collections of items bought by customers, or details of a website frequentation). Other algorithms are designed for finding association rules in data having no transactions (Winepi and Minepi), or having no timestamps (DNA sequencing).</p>
<p>

As is common in <link xlink:type="simple" xlink:href="../053/577053.xml">
association rule mining</link>, given a set of <it>itemsets</it> (for instance, sets of retail transactions, each listing individual items purchased), the algorithm attempts to find subsets which are common to at least a minimum number C (the cutoff, or confidence threshold) of the itemsets.  Apriori uses a "bottom up" approach, where frequent subsets are extended one item at a time (a step known as <it>candidate generation</it>), and groups of candidates are tested against the data.  The algorithm terminates when no further successful extensions are found.</p>
<p>

Apriori uses <link xlink:type="simple" xlink:href="../026/97026.xml">
breadth-first search</link> and a <link xlink:type="simple" xlink:href="../806/30806.xml">
tree</link> structure to count candidate item sets efficiently. It generates candidate item sets of length <math>k</math> from item sets of length <math>k-1</math>.  Then it prunes the candidates which have an infrequent sub pattern.  According to the <link>
downward closure lemma</link>, the candidate set contains all frequent <math>k</math>-length item sets. After that, it scans the transaction database to determine frequent item sets among the candidates. </p>
<p>

Apriori, while historically significant, suffers from a number of inefficiencies or trade-offs, which have spawned other algorithms.  Candidate generation generates large numbers of subsets (the algorithm attempts to load up the candidate set with as many as possible before each scan).  Bottom-up subset exploration (essentially a breadth-first traversal of the subset lattice)  finds any maximal subset S only after all <math>2^{|S|}-1</math> of its proper subsets.  </p>

<sec>
<st>
 Example </st>

<p>

This example suggests the process of selecting or generating a list of likely ordered serial candidate item sets.
The technique's goal is to construct a set of <math>k</math> node ordered serial item sets from <math>k-1</math> length item sets.
For example, with <math>k = 4</math>, suppose there are two such sets of length <math>k-1</math>...
<indent level="1">

<math>A \rightarrow B \rightarrow C</math>, 
</indent>
and 
<indent level="1">

<math>A \rightarrow B \rightarrow D</math>, 
</indent>
two candidate item sets are generated, namely 
<indent level="1">

<math>A \rightarrow B \rightarrow C \rightarrow D</math>
</indent>
and 
<indent level="1">

<math>A \rightarrow B \rightarrow D \rightarrow C</math>.
</indent>

</p>
</sec>
<sec>
<st>
 Algorithm </st>
<p>

Association rule mining is to find out association rules that satisfy the predefined
minimum support and confidence from a given database. The problem is usually
decomposed into two subproblems. One is to find those itemsets whose occurrences
exceed a predefined threshold in the database; those itemsets are called frequent or
large itemsets. The second problem is to generate association rules from those large
itemsets with the constraints of minimal confidence. Suppose one of the large itemsets
is Lk, Lk = {I1, I2, … , Ik}, association rules with this itemsets are generated in the
following way: the first rule is {I1, I2, … , Ik-1}⇒ {Ik}, by checking the confidence
this rule can be determined as interesting or not. Then other rule are generated by
deleting the last items in the antecedent and inserting it to the consequent, further the
confidences of the new rules are checked to determine the interestingness of them.
Those processes iterated until the antecedent becomes empty. Since the second subproblem
is quite straight forward, most of the researches focus on the first subproblem.
The Apriori algorithm finds the frequent sets <math>L</math> In Database <math>D</math>.</p>
<p>

<list>
<entry level="1" type="bullet">

 Find frequent set <math>L_{k-1}</math>.</entry>
<entry level="1" type="bullet">

 Join Step.</entry>
<entry level="2" type="bullet">

   <math>C_k</math> is generated by joining <math>L_{k-1}</math>with itself</entry>
<entry level="1" type="bullet">

 Prune Step.</entry>
<entry level="2" type="bullet">

 Any <math>(k-1)</math> -itemset that is not frequent cannot be a subset of a frequent <math>k</math> -itemset, hence should be removed.</entry>
</list>
</p>
<p>

where
<list>
<entry level="1" type="bullet">

 (<math>C_k</math>: Candidate itemset of size <math>k</math>)</entry>
<entry level="1" type="bullet">

 (<math>L_k</math>: frequent itemset of size <math>k</math>)</entry>
</list>
</p>

<ss1>
<st>
 Apriori Pseudocode </st>

<p>

<it>Apriori</it> <math>(T,\varepsilon)</math>
<indent level="1">

 <math>L_1 \gets \{ </math> <it>large 1-itemsets that appear in more than <math>\varepsilon</math> transactions</it> <math> \}</math>
</indent>
: <math>k \gets 2</math>
<indent level="2">

 <it>while</it> <math> L_{k-1} \neq \varnothing </math>
</indent>
::: <math>C_k \gets </math><it>Generate</it><math>(L_{k-1})</math>
<indent level="3">

 <it>for transactions</it> <math>t \in T</math>
</indent>
:::: <math>C_t \gets </math>Subset<math>(C_k,t)</math>
<indent level="4">

 <it>for candidates</it> <math>c \in C_t</math>
</indent>
::::: <math>\mathrm{count}[c] \gets \mathrm{count}[c]+1</math>
<indent level="3">

 <math>L_k \gets \{ c \in C_k | ~ \mathrm{count}[c] \geq \varepsilon \}</math>
</indent>
::: <math>k \gets k+1 </math>
<indent level="1">

 <it>return</it> <math>\bigcup_k L_k</math>
</indent>

</p>
</ss1>
</sec>
<sec>
<st>
 References </st>

<p>

<list>
<entry level="1" type="bullet">

 Agrawal R, Imielinski T, Swami AN. "Mining Association Rules between Sets of Items in Large Databases." <it><link xlink:type="simple" xlink:href="../519/5897519.xml">
SIGMOD</link></it>. June 1993, <b>22</b>(2):207-16, <weblink xlink:type="simple" xlink:href="http://portal.acm.org/ft_gateway.cfm?id=170072&amp;type=pdf&amp;coll=GUIDE&amp;dl=portal,ACM&amp;CFID=11111111&amp;CFTOKEN=2222222">
pdf</weblink>.</entry>
<entry level="1" type="bullet">

 Agrawal R, Srikant R. "Fast Algorithms for Mining Association Rules", <it><link xlink:type="simple" xlink:href="../577/2425577.xml">
VLDB</link></it>. Sep 12-15 1994, Chile, 487-99, <weblink xlink:type="simple" xlink:href="http://www.acm.org/sigmod/vldb/conf/1994/P487.PDF">
pdf</weblink>, ISBN 1-55860-153-8.</entry>
<entry level="1" type="bullet">

 Mannila H, Toivonen H, Verkamo AI. "Efficient algorithms for discovering association rules." <it><link>
AAAI</link> Workshop on Knowledge Discovery in Databases (<link xlink:type="simple" xlink:href="../528/5856528.xml">
SIGKDD</link>)</it>. July 1994, Seattle, 181-92, <weblink xlink:type="simple" xlink:href="http://www.softlab.ntua.gr/facilities/public/AD/DM/Efficient_Algorithms_for_Discovering_Association_Rules.ps">
ps</weblink>.</entry>
<entry level="1" type="bullet">

 S. Kotsiantis, D. Kanellopoulos, Association Rules Mining: A Recent Overview, GESTS International Transactions on Computer Science and Engineering, Vol.32 (1), 2006, pp. 71-82 (http://www.math.upatras.gr/~esdlab/en/members/kotsiantis/association%20rules%20kotsiantis.pdf)</entry>
</list>
</p>


</sec>
</bdy>
</algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</article>
