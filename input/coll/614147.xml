<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 17:25:01[mciao0828] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<system  confidence="0.8" wordnetid="104377057">
<artifact  confidence="0.8" wordnetid="100021939">
<instrumentality  confidence="0.8" wordnetid="103575240">
<language  confidence="0.8" wordnetid="106282651">
<header>
<title>Knuth-Bendix completion algorithm</title>
<id>614147</id>
<revision>
<id>204293085</id>
<timestamp>2008-04-08T20:27:36Z</timestamp>
<contributor>
<username>Linas</username>
<id>159886</id>
</contributor>
</revision>
<categories>
<category>Donald Knuth</category>
<category>Reduction systems</category>
<category>Computational group theory</category>
<category>Formal languages</category>
</categories>
</header>
<bdy>

The <b>Knuth-Bendix completion algorithm</b> is an <link xlink:type="simple" xlink:href="../775/775.xml">
algorithm</link> for transforming a set of <link xlink:type="simple" xlink:href="../284/9284.xml">
equation</link>s (over <link xlink:type="simple" xlink:href="../184/180184.xml">
terms</link>) into a <system wordnetid="104377057" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<link xlink:type="simple" xlink:href="../377/3755377.xml">
confluent</link></instrumentality>
</artifact>
</system>
 <link xlink:type="simple" xlink:href="../847/415847.xml">
term rewriting system</link>.  When the algorithm succeeds, it has effectively solved the <link xlink:type="simple" xlink:href="../079/3852079.xml">
word problem</link> for the specified <link xlink:type="simple" xlink:href="../923/18716923.xml">
algebra</link>.  <p>

An important case in <link xlink:type="simple" xlink:href="../584/618584.xml">
computational group theory</link> are string rewriting systems which can be used to give canonical labels to elements or cosets of a finitely presented group as products of the generators.  This special case is the current focus of this article.</p>

<sec>
<st>
 Motivation in group theory </st>
<p>

The <link xlink:type="simple" xlink:href="../947/5017947.xml">
critical pair lemma</link> states that a term rewriting system is <link xlink:type="simple" xlink:href="../377/3755377.xml">
weakly confluent</link> if and only if the critical pairs are convergent. Furthermore, we have <system wordnetid="104377057" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<link xlink:type="simple" xlink:href="../529/6038529.xml">
Newman's lemma</link></instrumentality>
</artifact>
</system>
 which states that if an (abstract) rewriting system is <link xlink:type="simple" xlink:href="../531/5085531.xml">
strongly normalizing</link> and weakly confluent, then the rewriting system is confluent. So, if we can add rules to the term rewriting system in order to force all critical pairs to be convergent while maintaining the strong normalizing property, then this will force the resultant rewriting system to be confluent.</p>
<p>

Consider a <link xlink:type="simple" xlink:href="../652/19652.xml">
finitely presented monoid</link> <math>M = &amp;lt; X | R &amp;gt;</math> where X is a finite set of generators and R is a set of defining relations on X.  Let X* be the set of all words in X (i.e. the free monoid generated by X).  Since the relations R define an equivalence relation on X*, one can consider elements of M to be the equivalence classes of X* under R.  For each class <it>{w1, w2, ... }</it> it is desirable to choose a standard representative <it>wk</it>.  This representative is called the <b>canonical</b> or <b>normal form</b> for each word <it>wk</it> in the class.  If there is a computable method to determine for each <it>wk</it> its normal form <it>wi</it> then the word problem is easily solved.  A confluent rewriting system allows one to do precisely this.</p>
<p>

Although the choice of a canonical form can theoretically be made in an arbitrary fashion this approach is generally not computable.  (Consider that an equivalence relation on a language can produce an infinite number of infinite classes.)  If the language is <link xlink:type="simple" xlink:href="../456/33456.xml">
well-ordered</link> then the order  gives a consistent method for defining minimal representatives, however computing these representatives may still not be possible.  In particular, if a rewriting system is used to calculate minimal representatives then the order  should also have the property:</p>
<p>

<indent level="1">

 A  B -&amp;gt; XAY  XBY for all words A,B,X,Y
</indent>

This property is called <b>translation invariance</b>.  An order that is both translation-invariant and a well-order is called a <b>reduction order</b>.</p>
<p>

From the presentation of the monoid it is possible to define a rewriting system given by the relations R.  If A x B is in R then either A  B in which case B -&amp;gt; A is a rule in the rewriting system, otherwise A &amp;gt; B and A -&amp;gt; B.  Since  is a reduction order a given word W can be reduced W &amp;gt; W_1 &amp;gt; ... &amp;gt; W_n where W_n is irreducible under the rewriting system.  However, depending on the rules that are applied at each Wi -&amp;gt; Wi+1 it is possible to end up with two different irreducible reductions Wn <math>\ne</math> W'm of W.  However, if the rewriting system given by the relations is converted to a confluent rewriting system via the Knuth-Bendix algorithm, then all reductions are guaranteed to produce the same irreducible word, namely the normal form for that word.</p>

</sec>
<sec>
<st>
Description of the algorithm for finitely presented monoids</st>

<p>

Suppose we are given a <link xlink:type="simple" xlink:href="../494/99494.xml">
presentation</link> <math> \langle X \mid R \rangle </math>, where <math> X </math> is a set of <link xlink:type="simple" xlink:href="../945/99945.xml">
generator</link>s and <math> R </math> is a set of <link xlink:type="simple" xlink:href="../509/19509.xml">
relations</link> giving the rewriting system.  Suppose further that we have a reduction ordering <math> &amp;lt; </math> among the words generated by <math> X </math>.  For each relation <math> P_i = Q_i </math> in <math> R </math>, suppose <math> Q_i &amp;lt; P_i </math>.  Thus we begin with the set of reductions <math> P_i \rightarrow Q_i </math>.</p>
<p>

First, if any relation <math> P_i = Q_i </math> can be reduced, replace <math> P_i </math> and <math> Q_i </math> with the reductions.</p>
<p>

Next, we add more reductions (that is, rewriting rules) to eliminate possible exceptions of confluence.  Suppose that <math> P_i </math> and <math> P_j </math>, where <math> i \neq j </math>, overlap.  That is, either the prefix of <math> P_i</math> equals the suffix of <math> P_j </math>, or vice versa.  In the former case, we can write <math> P_i = BC, P_j = AB </math>; in the latter case, <math> P_i = AB, P_j = BC </math>.</p>
<p>

Reduce the word <math> ABC </math> using <math> P_i </math> first, then using <math> P_j </math> first.  Call the results <math> r_1, r_2 </math>, respectively.  If <math> r_1 \neq r_2 </math>, then we have an instance where confluence could fail.  Hence, add the reduction <math> \max r_1, r_2 \rightarrow \min r_1, r_2 </math> to <math> R </math>.</p>
<p>

After adding a rule to <math> R </math>, remove any rules in <math> R </math> that might have reducible left sides.</p>
<p>

Repeat the procedure until all overlapping left sides have been checked.</p>

</sec>
<sec>
<st>
Example</st>

<p>

Consider the presentation <math> \{ x, y \mid x^3 = y^3 = (xy)^3 = 1 \} </math>.  We use the <link xlink:type="simple" xlink:href="../383/2660383.xml">
shortlex order</link>.  In fact, this is an infinite group.  Nevertheless, the Knuth-Bendix algorithm is able to solve the word problem.</p>
<p>

Our beginning three reductions are therefore (1) <math> x^3 \rightarrow 1 </math>, (2) <math> y^3 \rightarrow 1 </math>, and (3) <math> (xy)^3 \rightarrow 1 </math>.</p>
<p>

First, we see an overlap of <math> x </math> in (1) and (3).  Consider the word <math> x^3yxyxy </math>.  Reducing using (1), we get <math> yxyxy </math>.  Reducing using (3), we get <math> x^2 </math>.  Hence, we get <math> yxyxy = x^2 </math>, giving the reduction rule (4) <math> yxyxy \rightarrow x^2 </math>.</p>
<p>

Similarly, using the overlap of <math> y </math> in (2) and (3), we get the reduction (5) <math> xyxyx \rightarrow y^2 </math>.</p>
<p>

Both of these rules obsolete (3), so we remove it.</p>
<p>

Next, consider the overlap of <math> x </math> of (1) and (5).  Considering <math> x^3yxyx </math> we get <math> yxyx = x^2y^2 </math>, so we add the rule (6) <math> yxyx \rightarrow x^2y^2</math>.  This obsoletes rules (4) and (5), so we remove them.  Considering <math> xyxyx^3 </math>, we get <math> xyxy = y^2x^2 </math>, so we add the rule (7) <math> y^2x^2 \rightarrow xyxy </math>.</p>
<p>

Now, we are left with the rewriting system
<list>
<entry level="1" type="bullet">

 (1) <math> x^3 \rightarrow 1 </math></entry>
<entry level="1" type="bullet">

 (2) <math> y^3 \rightarrow 1 </math></entry>
<entry level="1" type="bullet">

 (6) <math> yxyx \rightarrow x^2y^2 </math></entry>
<entry level="1" type="bullet">

 (7) <math> y^2 x^2 \rightarrow xyxy </math></entry>
</list>

Checking the overlaps of these rules, we find no potential failures of confluence.  Therefore, we have a confluent rewriting system, and the algorithm terminates successfully.</p>

</sec>
<sec>
<st>
Generalizations</st>

<p>

If Knuth-Bendix does not succeed, it will either run forever, or fail when it encounters an unorientable equation (i.e. an equation that it cannot turn into a rewrite rule). The enhanced <link>
completion without failure</link> will not fail on unorientable equations and provides a <link>
semi-decision procedure</link> for the word problem.</p>

</sec>
<sec>
<st>
References</st>

<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../095/8095.xml">
D. Knuth</link> and P. Bendix. "Simple word problems in universal algebras." <it>Computational Problems in Abstract Algebra</it> (Ed. J. Leech) pages 263--297, 1970.</entry>
<entry level="1" type="bullet">

 C. Sims. 'Computations with finitely presented groups.' Cambridge, 1994.</entry>
</list>
</p>

</sec>
<sec>
<st>
External links</st>
<p>

<list>
<entry level="1" type="bullet">

  <cite id="Reference-Mathworld-Knuth-Bendix Completion Algorithm"><physical_entity wordnetid="100001930" confidence="0.8">
<communicator wordnetid="109610660" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<intellectual wordnetid="109621545" confidence="0.8">
<encyclopedist wordnetid="110055566" confidence="0.8">
<compiler wordnetid="109946957" confidence="0.8">
<alumnus wordnetid="109786338" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<writer wordnetid="110794014" confidence="0.8">
<mathematician wordnetid="110301261" confidence="0.8">
<scholar wordnetid="110557854" confidence="0.8">
<link xlink:type="simple" xlink:href="../189/836189.xml">
Eric W. Weisstein</link></scholar>
</mathematician>
</writer>
</scientist>
</causal_agent>
</alumnus>
</compiler>
</encyclopedist>
</intellectual>
</person>
</communicator>
</physical_entity>
, <it><weblink xlink:type="simple" xlink:href="http://mathworld.wolfram.com/Knuth-BendixCompletionAlgorithm.html">
Knuth-Bendix Completion Algorithm</weblink></it> at <computer wordnetid="103082979" confidence="0.8">
<work wordnetid="104599396" confidence="0.8">
<creation wordnetid="103129123" confidence="0.8">
<machine wordnetid="103699975" confidence="0.8">
<reference_book wordnetid="106417598" confidence="0.8">
<publication wordnetid="106589574" confidence="0.8">
<encyclopedia wordnetid="106427387" confidence="0.8">
<product wordnetid="104007894" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<book wordnetid="106410904" confidence="0.8">
<device wordnetid="103183080" confidence="0.8">
<web_site wordnetid="106359193" confidence="0.8">
<link xlink:type="simple" xlink:href="../235/374235.xml">
MathWorld</link></web_site>
</device>
</book>
</instrumentality>
</artifact>
</product>
</encyclopedia>
</publication>
</reference_book>
</machine>
</creation>
</work>
</computer>
.</cite></entry>
</list>
</p>


</sec>
</bdy>
</language>
</instrumentality>
</artifact>
</system>
</article>
