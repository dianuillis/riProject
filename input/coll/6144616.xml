<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 22:12:10[mciao0825] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<physical_entity  confidence="0.8" wordnetid="100001930">
<person  confidence="0.8" wordnetid="100007846">
<model  confidence="0.8" wordnetid="110324560">
<assistant  confidence="0.8" wordnetid="109815790">
<worker  confidence="0.8" wordnetid="109632518">
<causal_agent  confidence="0.8" wordnetid="100007347">
<header>
<title>Pointer machine</title>
<id>6144616</id>
<revision>
<id>218200758</id>
<timestamp>2008-06-09T16:37:04Z</timestamp>
<contributor>
<username>Xpapillon</username>
<id>1876937</id>
</contributor>
</revision>
<categories>
<category>Computational models</category>
</categories>
</header>
<bdy>

For  <link xlink:type="simple" xlink:href="../783/5783.xml">
computer program</link>s that deal with <link xlink:type="simple" xlink:href="../519/8519.xml">
data structure</link> problems (e.g. <link xlink:type="simple" xlink:href="../986/19721986.xml">
directed graph</link>s) , see <link>
 pointer algorithm </link>.<p>

In <link xlink:type="simple" xlink:href="../392/323392.xml">
theoretical computer science</link> a <b>pointer machine</b> is an "atomistic" <it>abstract computational machine</it> model akin to the <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../227/544227.xml">
Random access machine</link></causal_agent>
</worker>
</assistant>
</model>
</person>
</physical_entity>
.</p>
<p>

Depending on the type, a pointer machine may be called a linking automaton, a KU-machine, an SMM, an atomistic LISP machine, a tree-pointer machine, etc. (cf Ben-Amram 1995). At least three major varieties exist in the literature -- the Kolmogorov-Uspenskii model (KUM, KU-machine), the Knuth linking automaton, and the Schönhage Storage Modification Machine model (SMM). The SMM seems to be the most common.</p>
<p>

From its "read-only tape" (or equivalent) a pointer machine receives <it>input</it> -- bounded symbol-sequences ("words") made of at least two symbols e.g. { 0 , 1 } -- and it writes <it>output</it> symbol-sequences on an output "write-only" tape (or equivalent). To transform a symbol-sequence (input word) to an output symbol-sequence the machine is equipped with a "program" -- a finite-state machine (memory and list of instructions). Via its state machine the program <it>reads</it> the input symbols, <it>operates</it> on its <it>storage structure</it> -- a collection of "nodes" (registers) interconnected by "edges" (pointers labelled with the symbols e.g. { 0, 1 }), and <it>writes</it> symbols on the output tape.</p>
<p>

Pointer machines cannot do arithmetic. Computation proceeds only by reading input symbols, modifying and doing various tests on its storage structure -- the pattern of nodes and pointers, and outputting symbols based on the tests. "Information" is in the storage <it>structure</it>.</p>

<sec>
<st>
 Types of "Pointer Machines" </st>

<p>

Both Gurevich and Ben-Amram list a number of very similar "atomistic" models" of  "abstract machines"; Ben-Amram believes that the 6 "atomistic models" must be distinguished from "High-level" models. This article will discuss the following 3 atomistic models in particular: </p>
<p>

<list>
<entry level="1" type="bullet">

 Schönhage's Storage Modification Machines (SMM), </entry>
<entry level="1" type="bullet">

 Kolmogorov-Uspenskii Machines (KUM or KU-Machines), </entry>
<entry level="1" type="bullet">

 Knuth's "Linking Automaton"</entry>
</list>
</p>
<p>

But Ben-Amram add more:
<list>
<entry level="1" type="bullet">

 Atomistic Pure-LISP Machine (APLM)</entry>
<entry level="1" type="bullet">

 Atomistic Full-LISP machine (AFLM), </entry>
<entry level="1" type="bullet">

 General atomistic Pointer Machines,</entry>
<entry level="1" type="bullet">

 Jone's I Language (two types)</entry>
</list>
</p>

</sec>
<sec>
<st>
 Problems with the pointer machine model </st>
<p>

<b>Use of the model in complexity theory</b>:
van Emde Boas (1990) expresses concern that this form of abstract model is:
<indent level="1">

"an interesting theoretical model, but ... its attractiveness as a fundamental model for complexity theory is questionable. Its time measure is based on uniform time in a context where this measure is known to underestimate the true time complexity. The same observation holds for the space measure for the machine" (van Emde Boas (1990) p. 35)
</indent>

Gurevich 1988 also expresses concern:
<indent level="1">

"Pragmatically speaking, the Schönhage model provides a good measure of time complexity at the current state of the art (though I would prefer something along the lines of the random access computers of Angluin and Valiant)" (Gurevich (1988) p. 6 with reference to Angluin D. and Valiant L. G., <it>Fast Probabilistic Algorithms for Hamiltonian Circuits and Matchings", Journal of Computer and System Sciences 18 (1979) 155-193.)
</it></indent>

The fact that, in |3 and |4 (pp. 494-497), Schönhage himself (1980) demonstrates the real-time equivalences of his two <link xlink:type="simple" xlink:href="../227/544227.xml">
Random Access Machine</link> models "RAM0" and "RAM1" leads one to question the necessity of the SMM for complexity studies.</p>
<p>

<b>Potential uses for the model</b>: However, Schönhage (1980) demonstrates in his |6, <it>Integer-multiplication in linear time</it>. And Gurevich wonders whether or not the "parallel KU machine" "resembles somewhat the human brain" (Gurevich (1988) p. 5)</p>

</sec>
<sec>
<st>
 Schönhage's Storage Modification Machine (SMM) model </st>
<p>

Outline: work in progress (follows van Emde Boas 1990 rather than Schonhage which is marred with virtually no examples). Seems to be the most common and accepted model:</p>
<p>

&amp;gt; unlike <link xlink:type="simple" xlink:href="../218/505218.xml">
register machine</link> model. More difficult to understand quite unlike a "computer" -- abstract or otherwise. </p>
<p>

&amp;gt; Attempt here to give an understanding from a more basic-concept level.  </p>
<p>

<list>
<entry level="1" type="bullet">

 directed "graph" (a drawing that looks virtually identical to a <link xlink:type="simple" xlink:href="../337/187337.xml">
state diagram</link>) of circles called <b>nodes</b> and labelled arrows called <b>edges</b>. </entry>
</list>
</p>
<p>

<b>Alphabet k </b> = list of symbols input to the machine. k=2 is the minimum number of edges/sumbols. Typical is the binary alphabet { 0, 1 }. A ternary set might be { a, b, c } etc.</p>
<p>

<b>Word</b> = a string of symbols, e.g. 101101, input to the machine. A machine will "accept" a subset of all the possible strings U that can be generated by all SUM0 to n( 2(n*k) ) (  ) possible combinations of the symbols 
<indent level="1">

 U = { 0, 1, 00, 01, 10, 11, 100, 101, 110, 111, 1000, 1001, 1011, 1100, 1101, 1110, 1111, 11110, etc }
</indent>

<b>Node</b>: Each node is distinguishable and unique and labelled with a symbol inside it (e.g. with a number or a letter). From each node emerges k arrows (e.g. 2 arrows for the binary set of symbols { 0 , 1 }). A node is created by the <b>new w</b> instruction. </p>
<p>

<b>Edge</b>: From each node emerges as many "arrows" as there are symbols in the alphabet; The arrow's head indicates the "next" node, and each arrow is labelled with a symbol. Example: for a binary alphabet, e.g. { 0, 1 }, two arrows will emerge from every node; one of the two arrows will be labelled with "0", the other with "1". for a ternary alphabet, e.g. { a, b, c }, three symbols will emerge, each will bear the (unique) symbol "a", "b", or "c". The <b>set w to v</b> instruction redirects an edge to different node. Here <it>w</it> and <it>v</it> represent <it>words</it>. The word <it>v</it> is a <it>former</it> word -- i.e. a previously-created string of symbols -- so that the redirected edge will point "backwards" to an old node that "culminates/results" in that string.  </p>
<p>

<b>Path</b>: A path along nodes and arrows represents every word (string of symbols e.g. 101101) "the machine" can accept. A path will be determined in part by the history of how it was created.   </p>
<p>

<image width="500px" src="Pointer-machine_2_.JPG" type="thumbnail">
<caption>

The steps in the creation of a new "node" in a 2-symbol {0,1} machine: When confronted with a novel word (here: "11"), the machine is responsible for (i) creating new node 3 and pointing the appropriate 1-edge at it, then (ii) creating two new pointers (a 0-"edge" and a 1-"edge") both of which point back to the former node (here: node 2).
</caption>
</image>
 </p>
<p>

(1) <b>new</b> <it>w</it>: creates a new node. <it>w</it> represents the new <it>word</it> that creates the new node. As the The machine reads the word <it>w</it> it follows the path represented by the word <it>w</it> until the machine comes to the last (extra, additional, concatenated) symbol. The additional symbol forces the last state to "flip" its arrow from backward-pointing to forward-pointing, to create a new node, and to point to the node.  The new node in turn points both its edges back to the old last-state, where they just "rest" until redirected by <b>new</b> or <b>set</b>.</p>
<p>

<list>
<entry level="2" type="bullet">

 "w" is the (new) word that "leads to" such as the 5-to-6 expansion: 10110[1] </entry>
<entry level="2" type="bullet">

old edge: points toward new node, example 10110[1], the 5th node's 1-edge now points to the 6th node</entry>
<entry level="2" type="bullet">

new edges: both new edges point "backward" to the previous node. In a sense they are "sleeping", waiting for an assignment. In the case of the starting or center node both edges point back to itself (the starting node).</entry>
</list>
</p>
<p>

(2)<b>Set</b> <it>w</it> <b>to</b> <it>v</it>: redirects (moves) an edge (arrow) from the path represented by word <it>w</it> to a former node that represents word <it>v</it></p>
<p>

(3)<b>If</b> <it>v = w</it> <b>then</b> instruction <b>z</b> : Conditional instruction that compares two paths represented by words <it>w</it> and <it>v</it> to see if they end at the same node; if so jump to instruction <b>z</b> else continue.</p>
<p>

<image width="500px" src="Pointer-machine_1_.JPG" type="thumbnail">
<caption>

The steps in the creation of new "nodes" in a 2-symbol {0,1} machine. As words -- strings of symbols 0 and 1 -- come into the machine, the machine creates the graph. As shown here, after the 5th step two words -- "111" and "10" -- both point to node 4. At this time, if the machine were to do the <b>if</b> 10=111 <b>then</b> xxx, then the test would be successful and the machine would indeed jump to xxx.
</caption>
</image>
</p>

</sec>
<sec>
<st>
 Knuth's "Linking Automaton" model </st>

</sec>
<sec>
<st>
 Kolmogorov-Uspenskii Machine (KU-machine) model </st>

<p>

KUM differs from SMM in allowing only invertible pointers: for every pointer from a node x to a node y, an inverse pointer from y to x must be present. Since outgoing pointers must be labeled by distinct symbols of the alphabet, both KUM and SMM graphs have O(1) outdegree. However, KUM pointers' invertibility restricts the in-degree to O(1), as well. This addresses some concerns for physical (as opposite to purely informational) realism, like those in the above van Emde Boas quote.</p>

</sec>
<sec>
<st>
 See also </st>
<p>

<physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../218/505218.xml">
Register machine</link></causal_agent>
</worker>
</assistant>
</model>
</person>
</physical_entity>
 -- generic register-based <link xlink:type="simple" xlink:href="../492/60492.xml">
abstract machine</link> computational model
<list>
<entry level="1" type="bullet">

<physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../543/7583543.xml">
Counter machine</link></causal_agent>
</worker>
</assistant>
</model>
</person>
</physical_entity>
 -- most primitive machine, base models' instruction-sets are used throughout the class of register machines</entry>
<entry level="1" type="bullet">

<physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../227/544227.xml">
Random access machine</link></causal_agent>
</worker>
</assistant>
</model>
</person>
</physical_entity>
 -- RAM: counter machine with added indirect addressing capability</entry>
<entry level="1" type="bullet">

<physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../421/7179421.xml">
Random access stored program machine</link></causal_agent>
</worker>
</assistant>
</model>
</person>
</physical_entity>
 -- RASP: counter-based or RAM-based machine with a "program of instructions" to be found in the registers themselves in the matter of a <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<device wordnetid="103183080" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<machine wordnetid="103699975" confidence="0.8">
<link xlink:type="simple" xlink:href="../435/71435.xml">
Universal Turing machine</link></machine>
</causal_agent>
</worker>
</device>
</assistant>
</instrumentality>
</artifact>
</model>
</person>
</physical_entity>
 i.e. the <link xlink:type="simple" xlink:href="../091/478091.xml">
von Neumann architecture</link>.</entry>
</list>

<invention wordnetid="105633385" confidence="0.8">
<know-how wordnetid="105616786" confidence="0.8">
<method wordnetid="105660268" confidence="0.8">
<link xlink:type="simple" xlink:href="../403/30403.xml">
Turing machine</link></method>
</know-how>
</invention>
 -- generic tape-based <link xlink:type="simple" xlink:href="../492/60492.xml">
abstract machine</link> computational model
<list>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../147/3688147.xml">
Post-Turing machine</link> -- minimalist one-tape, two-direction, 1 symbol { blank, mark } Turing-like machine but with default sequential instruction execution in a manner similar to the basic 3-instruction counter machines.</entry>
</list>
</p>

</sec>
<sec>
<st>
 References </st>
<p>

Most references and a bibliography are to be found at the article <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../218/505218.xml">
Register machine</link></causal_agent>
</worker>
</assistant>
</model>
</person>
</physical_entity>
. The following are particular to this article:</p>
<p>

<list>
<entry level="1" type="bullet">

 <link>
Amir Ben-Amram</link> (1995), <it>What is a "Pointer machine</it>?, SIGACTN: SIGACT News (ACM Special Interest Group on Automata and Computability Theory)", volume 26, 1995. also: DIKU, Department of Computer Science, University of Copenhagen, amirben@diku.dk. Wherein Ben-Amram describes the types and subtypes: (type 1a) Abstract Machines: Atomistic models including Kolmogorov-Uspenskii Machines (KUM), Schönhage's Storage Modification Machines (SMM), Knuth's "Linking Automaton", APLM and AFLM (Atomistic Pure-LISP Machine) and (Atomistic Full-LISP machine), General atomistic Pointer Machines, Jone's I Language; (type 1b) Abstract Machines: High-level models, (type 2) Pointer algorithms.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

Andrey <link xlink:type="simple" xlink:href="../161/91161.xml">
Kolmogorov</link> and V. <link>
Uspenskii</link>, <it>On the definition of an algorithm,</it> Uspehi Mat. Nauk. 13 (1958), 3-28. English translation in American Mathematical Society Translations, Series II, Volume 29 (1963), pp. 217-245.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

<physical_entity wordnetid="100001930" confidence="0.8">
<peer wordnetid="109626238" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<colleague wordnetid="109935990" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<employee wordnetid="110053808" confidence="0.8">
<associate wordnetid="109816771" confidence="0.8">
<link xlink:type="simple" xlink:href="../014/16488014.xml">
Yuri Gurevich</link></associate>
</employee>
</scientist>
</causal_agent>
</colleague>
</worker>
</person>
</peer>
</physical_entity>
 (2000), <it>Sequential Abstract State Machines Capture Sequential Algorithms</it>, ACM Transactions on Computational Logic, vol. 1, no. 1, (July 2000), pages 77-111. In a single sentence Gurevich compares the Schönhage [1980] "storage modification machines" to Knuth's "pointer machines." For more, similar models such as "random access machines" Gurevich references:</entry>
</list>
</p>
<p>

<list>
<entry level="2" type="bullet">

<link>
J. E. Savage</link> (1998), <it>Models of Computation: Exploring the Power of Computing</it>. Addison Wesley Longman.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

<physical_entity wordnetid="100001930" confidence="0.8">
<peer wordnetid="109626238" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<colleague wordnetid="109935990" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<employee wordnetid="110053808" confidence="0.8">
<associate wordnetid="109816771" confidence="0.8">
<link xlink:type="simple" xlink:href="../014/16488014.xml">
Yuri Gurevich</link></associate>
</employee>
</scientist>
</causal_agent>
</colleague>
</worker>
</person>
</peer>
</physical_entity>
 (1988), <it>On Kolmogorov Machines and Related Issues</it>, the column on "Logic in Computer Science", Bulletin of European Association for Theoretical Computer Science, Number 35, June 1988, 71-82. </entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

A. <link>
Schōnhage</link> (1980), <it>Storage Modification Machines</it>, Society for Industrial and Applied Mathematics, SIAM J. Comput. Vol. 9, No. 3, August 1980. Wherein Schōnhage shows the equivalence of his SMM with the "successor RAM" (Random Access Machine), etc. He refers to an earlier paper where he introduces the SMM:</entry>
</list>
</p>
<p>

<list>
<entry level="2" type="bullet">

<link>
A. Schōnhage</link> (1970), <it>Universelle Turing Speicherung</it>, Automatentheorie und Formale Sprachen, Dōrr, Hotz, eds. Bibliogr. Institut, Mannheim, 1970, pp. 69-383.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

<link>
Peter van Emde Boas</link>, <it>Machine Models and Simulations</it> pp.3-66, appearing in:</entry>
<entry level="2" type="indent">

<link>
Jan Van Leeuwen</link>, ed. "Handbbook of Theoretical Computer Science. Volumne A: Algorithms and Complexity<it>, The MIT PRESS/Elsevier, 1990. ISBN 0-444-88071-2 (volume A). QA 76.H279 1990. </it></entry>
<entry level="1" type="indent">

van Emde Boas' treatment of SMMs appears on pp. 32-35. This treatment clarifies Schōnhage 1980 -- it closely follows but expands slightly the Schōnhage treatment. Both references may be needed for effective understanding.</entry>
</list>
</p>


</sec>
</bdy>
</causal_agent>
</worker>
</assistant>
</model>
</person>
</physical_entity>
</article>
