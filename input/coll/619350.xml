<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 17:23:52[mciao0827] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<know-how  confidence="0.8" wordnetid="105616786">
<method  confidence="0.8" wordnetid="105660268">
<header>
<title>Program evaluation</title>
<id>619350</id>
<revision>
<id>238758866</id>
<timestamp>2008-09-16T06:59:56Z</timestamp>
<contributor>
<username>Piano non troppo</username>
<id>7723863</id>
</contributor>
</revision>
<categories>
<category>Evaluation</category>
<category>Wikipedia articles needing style editing from December 2007</category>
<category>Evaluation methods</category>
<category>Articles lacking in-text citations</category>
<category>Social sciences methodology</category>
<category>All articles needing style editing</category>
<category>Philosophy of science</category>
<category>Impact assessment</category>
<category>Educational assessment and evaluation</category>
</categories>
</header>
<bdy>

<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-style" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="50px" src="Text_document_with_red_question_mark.svg">
</image>
</p>
</col>
<col style="" class="mbox-text">
 This article or section includes a  or , but its sources remain unclear because it lacks <b>.</b>
You can  this article by introducing more precise citations . <it>(February 2008)''</it></col>
</row>
</table>

<p>

<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-style" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="40x40px" src="Ambox_style.png">
</image>
</p>
</col>
<col style="" class="mbox-text">
 <b>The  or style of this article or section may not be appropriate for Wikipedia.</b>
Specific concerns may be found on the . See Wikipedia's for suggestions. <it>(December 2007)''</it></col>
</row>
</table>

</p>
<p>

<b>Program evaluation</b> is a formalized approach to studying the goals, processes, and impacts of projects, policies and <link xlink:type="simple" xlink:href="../626/282626.xml">
programs</link>.  Program evaluation is used in the public and private sector and is taught in numerous universities.  Evaluation became particularly relevant in the U.S. in the 1960s during the period of the <idea wordnetid="105833840" confidence="0.8">
<plan wordnetid="105898568" confidence="0.8">
<link xlink:type="simple" xlink:href="../792/55792.xml">
Great Society</link></plan>
</idea>
 social programs associated with the <president wordnetid="110468559" confidence="0.9508927676800064">
<person wordnetid="100007846" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../376/5119376.xml">
Kennedy</link></person>
</president>
 and <link xlink:type="simple" xlink:href="../533/54533.xml">
Johnson</link> administrations. Extraordinary sums were invested in social programs, but the impacts of these investments were largely unknown.</p>
<p>

Program evaluations can involve <link xlink:type="simple" xlink:href="../564/389564.xml">
quantitative method</link>s of <link xlink:type="simple" xlink:href="../212/373212.xml">
social research</link> or <link xlink:type="simple" xlink:href="../299/371299.xml">
qualitative method</link>s  or both. People who do program evaluation come from many different backgrounds: <link xlink:type="simple" xlink:href="../981/18717981.xml">
sociology</link>, <link xlink:type="simple" xlink:href="../921/22921.xml">
psychology</link>, <link xlink:type="simple" xlink:href="../223/9223.xml">
economics</link>, <link xlink:type="simple" xlink:href="../717/146717.xml">
social work</link>. Some graduate schools also have specific training programs for program evaluation. </p>

<sec>
<st>
 Dimensions of Program Evaluation </st>

<p>

Program evaluators may assess programs on several dimensions to determine whether the program works. Rossi et al. (2004) divide these dimensions into 5 main categories: needs assessment, program theory, process analysis, impact analysis, and cost-benefit &amp; cost-effectiveness analysis.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref></p>
<p>

A needs assessment examines the nature of the problem that the program is meant to address. This includes evaluating who is affected by the problem, how wide-spread the problem is, and what effects stem from the problem. For example, for a housing program aimed at mitigating homelessness, a program evaluator may want to find out how many people are homeless in a given geographic area and what their demographics are.</p>
<p>

The program theory is the formal description of the program's concept and design. This is also called a <link xlink:type="simple" xlink:href="../305/8599305.xml">
logic model</link> or impact pathways. The program theory breaks down the components of the program and shows anticipated short- and long-term effects.  An analysis of the program theory examines how the program is organized and how that organization will lead to desired outcomes. It will also reveal unintended or unforeseen consequences of a program, both positive and negative. The program theory drives the hypotheses to test for impact evaluation.  Developing a logic model can also build common understanding amongst program staff and stakeholders (see <link xlink:type="simple" xlink:href="../799/13076799.xml">
Participatory Impact Pathways Analysis</link>).  </p>
<p>

Process analysis looks beyond the theory of what the program is supposed to do and instead evaluates how the program is being implemented. The evaluation determines whether target populations are being reached, people are receiving the intended services, staff are adequately qualified, etc.</p>
<p>

The impact evaluation determines the causal effects of the program. More information about impact evaluation is found under the heading 'Determining Causation'.</p>
<p>

Finally, cost-benefit or cost-effectiveness analysis assesses the efficiency of a program. Evaluators outline the benefits and cost of the program for comparison. An efficient program has a lower cost-benefit ratio.</p>

</sec>
<sec>
<st>
 Determining Causation </st>

<p>

Perhaps the most difficult part of evaluation is determining whether the program itself is causing observed impacts. Events or processes outside of the program may be the real cause of the observed outcome (or the real prevention of the anticipated outcome). </p>
<p>

Causation is difficult to determine. One main reason for this is <link xlink:type="simple" xlink:href="../154/292154.xml">
self selection</link> bias. People select themselves to participate in a program. For example, in a job training program, some people decide to participate and others do not. Those who do participate may differ from those who do not in important ways. They may be more determined to find a job or have better support resources. These characteristics may actually be causing the observed outcome of increased employment, not the job training program.</p>
<p>

If programs could use random assignment, then they could determine <link xlink:type="simple" xlink:href="../196/37196.xml">
causation</link>. A program could randomly assign people to participate or to not participate in the program, eliminating self-selection bias. Thus, the group of people who participate would be the same as the group who did not participate.</p>
<p>

However, since most programs cannot use random assignment, causation cannot be determined. Impact analysis can still provide useful information. For example, the outcomes of the program can be described. Thus the evaluation can describe that people who participated in the program were more likely to experience a given outcome than people who did not participate.</p>
<p>

If the program is fairly large, and there is enough data, statistical analysis can be used to make a reasonable case for the program by showing, for example, that other causes are unlikely.</p>

</sec>
<sec>
<st>
 Types of Program Evaluation </st>

<p>

Program evaluation is often divided into types of evaluation.  </p>
<p>

<b>Formative Evaluation</b> occurs early in the program.  The results are used to decide how the program is delivered, or what form the program will take.  For example, an exercise program for elderly adults would seek to learn what activities are motivating and interesting to this group.  These activities would then be included in the program. </p>
<p>

<b>Process Evaluation</b> is concerned with how the program is delivered.  It deals with things such as when the program activities occur, where they occur, and who delivers them.  In other words, it asks the question: Is the program being delivered as intended?  An effective program may not yield desired results if it is not delivered properly.  </p>
<p>

<b>Outcome Evaluation</b> addresses the question of what are the results.  It is common to speak of short-term outcomes and long-term outcomes.  For example, in an exercise program, a short-term outcome could be a change knowledge about the health effects of exercise, or it could be a change in exercise behavior.  A long-term outcome could be less likelihood of dying from heart disease.</p>

</sec>
<sec>
<st>
 CDC framework </st>
<p>
 
In 1999, the <link xlink:type="simple" xlink:href="../C$1$1/Freescale_68H$C$11.xml">
Centers for Disease Control and Prevention</link> (CDC) published a six-step framework for conducting evaluation of public health programs. The publication of the framework is a result of the increased emphasis on program evaluation of government programs in the US.  The six steps are: 
<list>
<entry level="1" type="number">

 Engage <link xlink:type="simple" xlink:href="../723/17243723.xml">
stakeholders</link></entry>
<entry level="1" type="number">

 Describe the program.</entry>
<entry level="1" type="number">

 Focus the evaluation.</entry>
<entry level="1" type="number">

 Gather credible evidence.</entry>
<entry level="1" type="number">

 Justify conclusions. </entry>
<entry level="1" type="number">

 Ensure use and share lessons learned.</entry>
</list>
</p>

</sec>
<sec>
<st>
 See also</st>
<p>

<list>
<entry level="1" type="bullet">

 <know-how wordnetid="105616786" confidence="0.8">
<method wordnetid="105660268" confidence="0.8">
<link xlink:type="simple" xlink:href="../646/17575646.xml">
Impact assessment</link></method>
</know-how>
</entry>
<entry level="1" type="bullet">

 <know-how wordnetid="105616786" confidence="0.8">
<method wordnetid="105660268" confidence="0.8">
<link xlink:type="simple" xlink:href="../946/15092946.xml">
Impact evaluation</link></method>
</know-how>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../200/810200.xml#xpointer(//*[./st=%22Program+evaluation%22])">
Important publications in program evaluation</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../799/13076799.xml">
Participatory Impact Pathways Analysis</link></entry>
<entry level="1" type="bullet">

 <occupation wordnetid="100582388" confidence="0.8">
<know-how wordnetid="105616786" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<method wordnetid="105660268" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<link xlink:type="simple" xlink:href="../389/639389.xml">
Policy analysis</link></activity>
</psychological_feature>
</act>
</method>
</event>
</know-how>
</occupation>
</entry>
<entry level="1" type="bullet">

 <politics wordnetid="113840719" confidence="0.8">
<social_relation wordnetid="100032823" confidence="0.8">
<link xlink:type="simple" xlink:href="../265/10412265.xml">
Policy studies</link></social_relation>
</politics>
</entry>
</list>
</p>

</sec>
<sec>
<st>
 External links </st>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.eval.org/">
American Evaluation Association</weblink>Includes a link to <weblink xlink:type="simple" xlink:href="http://www.eval.org/EvaluationLinks/default.htm">
Evaluation resources</weblink> such as organizations, links sites, email discussion lists, consultants and more</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.evaluationcanada.ca/">
Canadian Evaluation Society</weblink> Includes a link to <weblink xlink:type="simple" xlink:href="http://evaluationcanada.ca/site.cgi?section=1&amp;ssection=1&amp;_lang=an">
Evaluation information</weblink> such as services, professional development, resources, organizations, regional chapters</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.cdc.gov/mmwr/preview/mmwrhtml/rr4811a1.htm">
CDC six-step framework.</weblink></entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.evaluationwiki.org">
The EvaluationWiki</weblink> - The mission of EvaluationWiki is to make freely available a compendium of up-to-date information and resources to everyone involved in the science and practice of evaluation. The EvaluationWiki is presented by the non-profit <weblink xlink:type="simple" xlink:href="http://www.evaluationwiki.org/wiki/index.php/Evaluation_Resource_Institute">
Evaluation Resource Institute</weblink>.</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.internationalevaluation.com/">
International Organization for Cooperation in Evaluation</weblink> </entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.innonet.org">
Innovation Network</weblink> Innovation Network is a nonprofit organization working to share planning and evaluation tools and know-how. The organization provides online tools, consulting, and training, for nonprofits and funders.</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.education.purdue.edu/AssessmentCouncil/Links/Index.htm">
Links to Assessment and Evaluation Resources</weblink> List of links to resources on several topics, including: Centers; Community building; Education and training in evaluation; Foundations; Indiana government &amp; organizations; Links collected by...; Logic models; Performance assessment &amp; electronic portfolios; Political &amp; private groups or companies; Professional assns, orgs &amp; pubs; Purdue University; United States Government; Web searches for publications by author &amp; topic; and Vivisimo topical meta searches.</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.maine.gov/legis/opega/">
Maine Legislature's Office of Program Evaluation &amp; Government Accountability</weblink> An excellent example of a governmental Program Evaluation office with links to several detailed reports which include methodology, evaluations results, recommendations and action plans.</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.ncsl.org/nlpes/">
National Legislative Program Evaluation Society</weblink>Includes links to state offices of program evaluation and/or performance auditing in the USA </entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.upjohninstitute.org/">
W.E. Upjohn Institute for Employment Research</weblink></entry>
</list>
</p>

</sec>
<sec>
<st>
 References </st>
<p>

<reflist>
<entry id="1">
Rossi, P.H., Lipsey, M.W. &amp; Freeman, H.E. (2004) <it>Evaluation: A Systematic Approach</it>. </entry>
</reflist>
</p>


</sec>
</bdy>
</method>
</know-how>
</article>
