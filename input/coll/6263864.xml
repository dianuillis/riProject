<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 22:10:45[mciao0828] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<physical_entity  confidence="0.8" wordnetid="100001930">
<person  confidence="0.8" wordnetid="100007846">
<model  confidence="0.8" wordnetid="110324560">
<assistant  confidence="0.8" wordnetid="109815790">
<worker  confidence="0.8" wordnetid="109632518">
<causal_agent  confidence="0.8" wordnetid="100007347">
<header>
<title>Turing machine equivalents</title>
<id>6263864</id>
<revision>
<id>184896000</id>
<timestamp>2008-01-17T03:22:19Z</timestamp>
<contributor>
<username>Gene Nygaard</username>
<id>146986</id>
</contributor>
</revision>
<categories>
<category>Computational models</category>
<category>Theory of computation</category>
</categories>
</header>
<bdy>

The following article is a referral from the article <invention wordnetid="105633385" confidence="0.8">
<know-how wordnetid="105616786" confidence="0.8">
<method wordnetid="105660268" confidence="0.8">
<link xlink:type="simple" xlink:href="../403/30403.xml">
Turing machine</link></method>
</know-how>
</invention>
. Many of the machines described here have articles that offer much more information.
<sec>
<st>
 Machines equivalent to the Turing machine model </st>

<p>

<b>Turing equivalence</b>:</p>
<p>

Many machines that might be thought to have more computational capability than a simple universal Turing machine can be shown to have no more power  (Hopcroft and Ullman p. 159,  cf  Minsky). They might compute faster, perhaps, or use less memory, or their instruction set might be smaller, but they cannot compute more powerfully (i.e. more mathematical functions). (Recall that the <link xlink:type="simple" xlink:href="../854/6854.xml">
Church-Turing thesis</link> <it>hypothesizes</it> this to be true: that anything that can be “computed” can be computed by some Turing machine.)</p>
<p>

While none of the following models have been shown to have more power than the single-tape, one-way infinite, multi-symbol Turing-machine model, their authors defined and used them to investigate questions and solve problems more easily than they could have if they had stayed with Turing's <it>a</it>-machine model.</p>
<p>

<b>The sequential-machine models</b>:</p>
<p>

All of the following are called "sequential machine models" to distinguish them from "parallel machine models" (van Emde Boas (1990) p. 18).</p>

</sec>
<sec>
<st>
 Tape-based Turing machines </st>
<p>

<indent level="1">

<it>For more return to the article <invention wordnetid="105633385" confidence="0.8">
<know-how wordnetid="105616786" confidence="0.8">
<method wordnetid="105660268" confidence="0.8">
<link xlink:type="simple" xlink:href="../403/30403.xml">
Turing machine</link></method>
</know-how>
</invention>
</it>
</indent>

<b>Turing's <it>a</it></b><b>-machine model</b>: Turing's (1936) a-machine (his name) was left-ended, right-end-infinite. He provided symbols <b>əə</b> to mark the left end. Any of finite number of tape symbols were permitted. The instructions (if a universal machine), and the "input" and "out" were written on only on "F-squares", and markers were to appear on "E-squares". In essence he divided his machine into two tapes that always moved together. The instructions appeared in a tabular form called "5-tuples" and were not executed sequentially. </p>

<ss1>
<st>
 Single-tape machines with restricted symbols and/or restricted instructions </st>
<p>

The following models are single tape Turing machines but restricted with (i) restricted tape symbols { mark, blank }, and/or (ii) sequential, computer-like instructions, and/or (iii) machine-actions fully-atomized.</p>

<ss2>
<st>
 Post's "Formulation 1" model of computation </st>
<p>

<indent level="1">

<it>For more see the article <link xlink:type="simple" xlink:href="../147/3688147.xml">
Post-Turing machine</link></it>
</indent>

<link xlink:type="simple" xlink:href="../382/362382.xml">
Emil Post</link> (1936) in an independent description of a computational process, reduced the symbols allowed to the equivalent binary set of marks on the tape { "mark", "blank"=not_mark }. He changed the notion of "tape" from 1-way infinite to the right to an infinite set of rooms each with a sheet of paper in both directions. He atomized the Turing 5-tuples into 4-tuples -- motion instructions separate from print/erase instructions. Although his (1936) model is ambiguous about this, Post's (1947) model did not require sequential instruction execution.</p>
<p>

His extremely simple model can emulate any Turing machine, and although his 1936 <it>Formulation 1</it> does not use the word "program" or "machine", it is effectively a formulation of a very primitive programmable computer and associated <link xlink:type="simple" xlink:href="../015/23015.xml">
programming language</link>, with the boxes acting as an unbounded bitstring memory, and the set of instructions constituting a program.</p>

</ss2>
<ss2>
<st>
 Wang machines </st>

<p>

<indent level="1">

<it>For more details on this topic, see <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<know-how wordnetid="105616786" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<method wordnetid="105660268" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../489/6640489.xml">
Wang B-machine</link></causal_agent>
</method>
</worker>
</know-how>
</assistant>
</model>
</person>
</physical_entity>
.</it>
</indent>

In an influential paper, <scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../047/1056047.xml">
Hao Wang</link></scientist>
 (1954, 1957) reduced Post's "" to machines that still use a two-way infinite binary tape, but whose instructions are simpler — being the "atomic" components of Post's instructions — and are by default executed sequentially (like a "computer program").  His stated principal purpose was to offer, as an alternative to Turing's theory, one that "is more economical in the basic operations".  His results were "program formulations" of a variety of such machines, including the 5-instruction Wang <b>W-machine</b> with the instruction-set  </p>
<p>

<indent level="1">

 { SHIFT-LEFT, SHIFT-RIGHT, MARK-SQUARE, ERASE-SQUARE, JUMP-IF-SQUARE-MARKED-to xxx }
</indent>

and his most-severely reduced 4-instruction <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<know-how wordnetid="105616786" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<method wordnetid="105660268" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../489/6640489.xml">
Wang B-machine</link></causal_agent>
</method>
</worker>
</know-how>
</assistant>
</model>
</person>
</physical_entity>
 ("B" for "basic") with the instruction-set</p>
<p>

<indent level="1">

 { SHIFT-LEFT, SHIFT-RIGHT, MARK-SQUARE, JUMP-IF-SQUARE-MARKED-to xxx }
</indent>

which has not even an ERASE-SQUARE instruction.</p>
<p>

Many authors later introduced variants of the machines discussed by Wang: </p>
<p>

Minsky (1961) evolved Wang's notion with his version of the (multi-tape) "counter machine" model that allowed SHIFT-LEFT and SHIFT-RIGHT motion of the separate heads but no printing at all. In this case the tapes would be left-ended, each end marked with a single "mark" to indicate the end. He was able to reduce this to a single tape, but at the expense of introducing multi-tape-square motion equivalent to multiplication and division rather than the much simpler { SHIFT-LEFT = DECREMENT, SHIFT-RIGHT = INCREMENT }.</p>
<p>

Davis, adding an explicit HALT instruction to one of the machines discussed by Wang, used a model with the instruction-set</p>
<p>

<indent level="1">

 { SHIFT-LEFT, SHIFT-RIGHT, ERASE, MARK, JUMP-IF-SQUARE-MARKED-to xxx, JUMP-to xxx, HALT }
</indent>

and also considered versions with tape-alphabets of size larger than 2.</p>

</ss2>
<ss2>
<st>
  Böhm's theoretical machine language P" </st>
<p>
  
<indent level="1">

<it>For  details see the article </it>'<link>
P%22</link></indent>
In keeping with Wang's project to seek a Turing-equivalent theory "economical in the basic operations", and wishing to avoid unconditional jumps, a notable theoretical language is the 4-instruction language <link>
P%22</link> introduced by <link>
Corrado Böhm</link> in 1964 — the first "GOTO-less" imperative "<link xlink:type="simple" xlink:href="../695/27695.xml">
structured programming</link>" language to be proved <link xlink:type="simple" xlink:href="../621/30621.xml">
Turing-complete</link>.</p>

</ss2>
<ss2>
<st>
 Finite State Machine Model  </st>
<p>

<indent level="1">

<it>For more see the article <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../401/12302401.xml">
Read only right moving Turing Machines</link></causal_agent>
</worker>
</assistant>
</model>
</person>
</physical_entity>
</it>
</indent>

There is an equivalence between the set of <invention wordnetid="105633385" confidence="0.8">
<know-how wordnetid="105616786" confidence="0.8">
<method wordnetid="105660268" confidence="0.8">
<link xlink:type="simple" xlink:href="../403/30403.xml">
Turing machine</link></method>
</know-how>
</invention>
 with only the  and <link>
Determinstic Finite State Machines</link>.
<indent level="1">

 { LEFT, RIGHT, HALT }
</indent>

</p>
</ss2>
</ss1>
<ss1>
<st>
 Multi-tape Turing machines </st>
<p>

<indent level="1">

<it>For more see the article <link xlink:type="simple" xlink:href="../403/30403.xml">
Multi-tape Turing machine</link></it>
</indent>

In practical analysis, various types of <b>multi-tape Turing machines</b> are often used.  Multi-tape machines are similar to single-tape machines, but there is some constant <it>k</it> number of independent tapes. </p>
<p>

The TABLE has full independent control over all the heads, any of all of which move and print/erase their own tapes (cf Aho-Hopcroft-Ullman 1974 p. 26). Most models have tapes with left ends, right ends unbounded.</p>
<p>

This model intuitively seems much more powerful than the single-tape model, but any multi-tape machine, no matter how large the <it>k</it>, can be simulated by a single-tape machine using only quadratically more computation time (Papadimitriou 1994, Thrm 2.1).  Thus, multi-tape machines cannot calculate any more functions than single-tape machines, and none of the robust complexity classes (such as <class wordnetid="107997703" confidence="0.8">
<collection wordnetid="107951464" confidence="0.8">
<group wordnetid="100031264" confidence="0.8">
<link xlink:type="simple" xlink:href="../550/658550.xml">
polynomial time</link></group>
</collection>
</class>
) are affected by a change between single-tape and multi-tape machines.</p>

<ss2>
<st>
 Two-stack Turing machine </st>
<p>

Two-stack Turing machines have a read-only input and two storage tapes. If a head moves left on either tape a blank is printed on that tape, but one symbol from a “library” can be printed.</p>

</ss2>
<ss2>
<st>
 Formal definition: multi-tape Turing machine </st>
<p>

A k-tape Turing machine can be described as a 6-tuple <math>M=\langle Q, \Gamma, s, b, F, \delta \rangle</math> where</p>
<p>

<list>
<entry level="1" type="bullet">

<math>Q</math> is a finite set of states</entry>
<entry level="1" type="bullet">

<math>\Gamma</math> is a finite set of the tape alphabet</entry>
<entry level="1" type="bullet">

<math>s \in Q</math> is the initial state</entry>
<entry level="1" type="bullet">

<math>b \in \Gamma</math> is the blank symbol</entry>
<entry level="1" type="bullet">

<math>F \subseteq Q</math> is the set of final or accepting states</entry>
<entry level="1" type="bullet">

<math>\delta: Q \times \Gamma^k \rightarrow Q \times (\Gamma \times \{L,R,S\})^k</math> is a partial function called the transition function, where L is left shift, R is right shift, S is no shift.</entry>
</list>
</p>

</ss2>
</ss1>
<ss1>
<st>
 Deterministic and non-deterministic Turing machines  </st>
<p>

<indent level="1">

<it>For more see the article <link xlink:type="simple" xlink:href="../935/21935.xml">
non-deterministic Turing machine</link>.</it>
</indent>

If the action table has at most one entry for each combination of symbol and state then the machine is a "deterministic Turing machine" (DTM).  If the action table contains multiple entries for a combination of symbol and state then the machine is a "non-deterministic Turing machine" (NDTM). The two are computationally equivalent, that is, it is possible to turn any NDTM into a DTM (and <it>vice versa</it>).</p>

</ss1>
</sec>
<sec>
<st>
 Register machine models </st>
<p>

<indent level="2">

<it>For more see the article <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../218/505218.xml">
Register machine</link></causal_agent>
</worker>
</assistant>
</model>
</person>
</physical_entity>
.</it>
</indent>

van Emde Boas (1990) includes all machines of this type in one category (group, class, collection) -- "the register machine". However, historically the literature has also called the most primitive member of this group i.e. "the counter machine" -- "the register machine". And the most primitive embodiment of a "counter machine" is sometimes called the "Minsky machine".</p>

<ss1>
<st>
 The "counter machine", also called a "register machine" model </st>
<p>

<indent level="1">

<it>For more see the article <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../543/7583543.xml">
Counter machine</link></causal_agent>
</worker>
</assistant>
</model>
</person>
</physical_entity>
.</it>
</indent>

The primitive model register machine is, in effect, a multitape 2-symbol Post-Turing machine with its behavior restricted so its tapes act like simple "counters". </p>
<p>

By the time of Melzak, Lambek, and Minsky (all 1961) the notion of a "computer program" produced a different type of simple machine with many left-ended tapes cut from a Post-Turing tape. In all cases the models permit only two tape symbols { mark, blank }. </p>
<p>

Some versions represent the positive integers as only a strings/stack of marks allowed in a "register" (i.e. left-ended tape), and a blank tape represented by the count "0". Minsky (1961) eliminated the PRINT instruction at the expense of providing his model with a mandatory single mark at the left-end of each tape.   </p>
<p>

In this model the single-ended tapes-as-registers are thought of as "counters", their instructions restricted to only two (or three if the TEST/DECREMENT instruction is atomized). Two common instruction sets are the following:
<indent level="1">

(1): { INC ( r ), DEC ( r ), JZ ( r,z ) }, i.e.
</indent>
::{ INCrement contents of register #r; DECrement contents of register #r; IF contents of #r=Zero THEN Jump-to Instruction #z}
<indent level="1">

(2): { CLR ( r ); INC ( r ); JE ( ri, rj, z ) }, i.e.
</indent>
::{ CLeaR contents of register r; INCrement contents of r; compare contents of ri to rj and if Equal then Jump to instruction z} </p>
<p>

Although his model is more complicated than this simple description, the Melzak "pebble" model extended this notion of "counter" to permit multi-
pebble adds and subtracts. </p>

</ss1>
<ss1>
<st>
 The Random Access Machine (RAM) model </st>
<p>

<indent level="1">

<it>For more see the article <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../227/544227.xml">
Random access machine</link></causal_agent>
</worker>
</assistant>
</model>
</person>
</physical_entity>
</it>.
</indent>

Melzak (1961) recognized a couple serious defects in his register/counter-machine model: (i) Without a form of indirect addressing he would be not be able to "easily" show the model is <link xlink:type="simple" xlink:href="../406/3246406.xml">
Turing equivalent</link>, (ii) The program and registers were in different "spaces", so self-modifying programs would not be easy. When Melzak added indirect addressing to his model he created a random access machine model. </p>
<p>

(However, with <link>
Gödel numbering</link> of the instructions Minsky (1961) offered a proof that with such numbering the general <link xlink:type="simple" xlink:href="../264/5987264.xml">
recursive function</link>s were indeed possible; in Minsky (1967) he offers proof that <link>
μ recursion</link> is indeed possible). </p>
<p>

Unlike the RASP model, the RAM model does not allow the machine's actions to modify its instructions. Sometimes the model works only register-to-register with no accumulator, but most models seem to include an accumulator. </p>
<p>

van Emde Boas (1990) divides the various RAM models into a number of sub-types:
<list>
<entry level="1" type="bullet">

 SRAM, the "successor RAM" with only one arithmetic instruction, the successor (INCREMENT h). The others include "CLEAR h", and an IF equality-between-register THEN jump-to xxx.</entry>
<entry level="1" type="bullet">

 RAM: the standard model with addition and subtraction</entry>
<entry level="1" type="bullet">

 MRAM: the RAM agumented with multiplication and division</entry>
<entry level="1" type="bullet">

 BRAM, MBRAM: Bitwise Boolean versions of the RAM  and MRAM</entry>
<entry level="1" type="bullet">

 N****: Non-deterministic versions of any of the above with an N before the name</entry>
</list>
</p>

</ss1>
<ss1>
<st>
 The Random Access Stored Program (RASP) machine model </st>
<p>

<indent level="1">

<it>For more see the article <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../421/7179421.xml">
Random access stored program machine</link></causal_agent>
</worker>
</assistant>
</model>
</person>
</physical_entity>
.</it>
</indent>

The RASP is a RAM with the instructions stored together with their data in the same 'space' -- i.e. sequence of registers. The notion of a RASP was described at least as early as Kiphengst (1959). His model had a "mill" -- an accumulator, but now the instructions were in the registers with the data -- the so-called <link xlink:type="simple" xlink:href="../091/478091.xml">
von Neumann architecture</link>. When the RASP has alternating even and odd registers -- the even holding the "operation code" (instruction) and the odd holding its "operand" (parameter), then indirect addressing is achieved by simply modifying an instruction's operand (cf Cook and Reckhow 1973).  </p>
<p>

The original RASP model of Elgot and Robinson (1964) had only three instructions in the fashion of the register-machine model, but they placed them in the register space together with their data. (Here COPY takes the place of CLEAR when one register e.g. "z" or "0" starts with and always contains 0. This trick is not unusual. The unit 1 in register "unit" or "1" is also useful.) 
<indent level="1">

 { INC ( r ), COPY ( ri, rj ),  JE ( ri, ri, z ) }    
</indent>

The RASP models allow indirect as well as direct-addressing; some allow "immediate" instructions too, e.g. "Load accumulator with the constant 3". The instructions may be of a highly-restricted set such as the following 16 instructions of Hartmanis (1971). This model uses an accumulator A. The mnemonics are those that the authors used (their CLA is "load accumulator" with constant or from register; STO is "store accumulator"). Their syntax is the following, excepting the jumps: "n, , &amp;gt;" for "immediate", "direct" and "indirect"). Jumps are via two "Transfer instructions" TRA -- unconditional jump by directly "n" or indirectly " n &amp;gt;" jamming contents of register n into the instruction counter, TRZ (conditional jump if Accumulator is zero in the same manner as TRA): 
<indent level="1">

{ ADD n , ADD  n &amp;gt;, ADD  n &amp;gt;&amp;gt;, SUB n, SUB  n &amp;gt;, SUB  n &amp;gt;&amp;gt;, CLA n, CLA  n &amp;gt;, CLA  n &amp;gt;&amp;gt;, STO  n &amp;gt;, STO  n &amp;gt;&amp;gt;, TRA n, TRA  n &amp;gt;, TRZ n, TRA  n &amp;gt;, HALT }
</indent>

</p>
</ss1>
<ss1>
<st>
 The Pointer machine model </st>
<p>

<indent level="1">

<it>For more see the article <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../616/6144616.xml">
Pointer machine</link></causal_agent>
</worker>
</assistant>
</model>
</person>
</physical_entity>
.</it>
</indent>

A relative late-comer is Schönage's Storage Modification Machine (1970) or <link xlink:type="simple" xlink:href="../616/6144616.xml">
pointer machine</link>. Another version is the Kolmogorov-Uspensii machine, and the Knuth "linking automaton" proposal. (For references see <link xlink:type="simple" xlink:href="../616/6144616.xml">
pointer machine</link>). Like a state-machine diagram, a node emits at least two labelled "edges" (arrows) that point to another node or nodes which in turn point to other nodes, etc. The outside world points at the center node.</p>

</ss1>
</sec>
<sec>
<st>
 Machines with input and output</st>
<p>

Any of the above tape-based machines can be equipped with input and output tapes; any of the above register-based machines can be equipped with dedicated input and output registers. For example, the Schönhage pointer-machine model has two instructions called "<it>input</it> λ0,λ1" and "<it>output</it> β" (Schönhage 1990 p. 493)</p>
<p>

It is difficult to study <link xlink:type="simple" xlink:href="../541/1750541.xml">
sublinear</link> <link>
space complexity</link> on multi-tape machines with the traditional model, because an input of size <it>n</it> already takes up space <it>n</it>.  Thus, to study small <assets wordnetid="113329641" confidence="0.8">
<possession wordnetid="100032613" confidence="0.8">
<resource wordnetid="113331778" confidence="0.8">
<link xlink:type="simple" xlink:href="../520/658520.xml">
DSPACE</link></resource>
</possession>
</assets>
 classes, we must use a different model.  In some sense, if we never "write to" the input tape, we don't want to charge ourself for this space.  And if we never "read from" our output tape, we don't want to charge ourself for this space.</p>
<p>

We solve this problem by introducing a <b><it>k</it></b><b>-string Turing machine with input and output</b>.  This is the same as an ordinary <it>k</it>-string Turing machine, except that the transition function <math>\delta</math> is restricted so that the input tape can never be changed, and so that the output head can never move left.  This model allows us to define deterministic space classes smaller than linear.  Turing machines with input-and-output also have the same time complexity as other Turing machines; in the words of Papaditriou 1994 Prop 2.2:</p>
<p>

<indent level="1">

For any <it>k</it>-string Turing machine <it>M</it> operating within time bound <it>f(n))</it> there is a <it>(k+2)</it>-string Turing machine <it>M</it>’ with input and output, which operates within time bound <it>O(f(n))</it>.
</indent>

<it>k</it>-string Turing machines with input and output are used in the formal definition of the complexity resource <assets wordnetid="113329641" confidence="0.8">
<possession wordnetid="100032613" confidence="0.8">
<resource wordnetid="113331778" confidence="0.8">
<link xlink:type="simple" xlink:href="../520/658520.xml">
DSPACE</link></resource>
</possession>
</assets>
 in, for example, Papadimitriou 1994 (Def. 2.6).</p>

</sec>
<sec>
<st>
 Other equivalent machines and methods </st>

<p>

<list>
<entry level="1" type="bullet">

 Multidimensional Turing machine: For example, a model by Schonhage (1990) uses the four head-movement commands { <b>N</b>orth, <b>S</b>outh, <b>E</b>ast, <b>W</b>est }.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 Single-tape, multi-head Turing machine: In an undecidability proof of the "problem of tag", Minsky 1961 and Shepherdson and Sturgis (1963) described machines with a single tape that could write along the tape with one head and read further along the tape with another.  </entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 Markov's (1954) <link>
Normal Algorithm</link> is another remarkably simple computational model equivalent to the Turing machines.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<know-how wordnetid="105616786" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<method wordnetid="105660268" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../203/18203.xml">
Lambda calculus</link></causal_agent>
</method>
</worker>
</know-how>
</assistant>
</model>
</person>
</physical_entity>
</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../258/14098258.xml">
Queue machine</link></entry>
</list>
</p>

</sec>
<sec>
<st>
 References </st>

<p>

<list>
<entry level="1" type="bullet">

 For more references see the following, or return to the article <invention wordnetid="105633385" confidence="0.8">
<know-how wordnetid="105616786" confidence="0.8">
<method wordnetid="105660268" confidence="0.8">
<link xlink:type="simple" xlink:href="../403/30403.xml">
Turing machine</link></method>
</know-how>
</invention>
:</entry>
<entry level="2" type="bullet">

 <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../218/505218.xml">
Register machine</link></causal_agent>
</worker>
</assistant>
</model>
</person>
</physical_entity>
</entry>
<entry level="2" type="bullet">

 <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../227/544227.xml">
Random access machine</link></causal_agent>
</worker>
</assistant>
</model>
</person>
</physical_entity>
</entry>
<entry level="2" type="bullet">

 <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../421/7179421.xml">
Random access stored program machine</link></causal_agent>
</worker>
</assistant>
</model>
</person>
</physical_entity>
 </entry>
<entry level="2" type="bullet">

 <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../616/6144616.xml">
Pointer machine</link></causal_agent>
</worker>
</assistant>
</model>
</person>
</physical_entity>
</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

<link>
Peter van Emde Boas</link>, <it>Machine Models and Simulations</it>, pp. 3-66, located in:</entry>
<entry level="2" type="bullet">

<link>
Jan van Leeuwen</link>, ed. <it>Handbook of Theoretical Computer Science. Volume A: Algorithms and Complexity</it>, The MIT Press/Elsevier, 1990. ISBN 0-262-72014-0 (volume A). QA76.H279 1990.</entry>
<entry level="3" type="bullet">

 A thorough and helpful survey with respect to machine models and complexity theory, with definitions of e.g. M-LOGSPACE, etc., and a categorization of "sequential machine" models. With 141 references (!)</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../915/915.xml">
A. A. Markov</link> (1954) <it>Theory of algorithms</it>. [Translated by Jacques J. Schorr-Kon and PST staff] Imprint Moscow, Academy of Sciences of the USSR, 1954 [i.e. Jerusalem, Israel Program for Scientific Translations, 1961; available from the Office of Technical Services, U.S. Dept. of Commerce, Washington] Description 444 p. 28 cm. Added t.p. in Russian Translation of Works of the Mathematical Institute, Academy of Sciences of the USSR, v. 42. Original title: Teoriya algerifmov. [QA248.M2943 Dartmouth College library. U.S. Dept. of Commerce, Office of Technical Services, number OTS 60-51085.]</entry>
</list>
</p>

</sec>
</bdy>
</causal_agent>
</worker>
</assistant>
</model>
</person>
</physical_entity>
</article>
