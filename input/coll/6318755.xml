<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 22:22:42[mciao0827] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Lock convoy</title>
<id>6318755</id>
<revision>
<id>170327497</id>
<timestamp>2007-11-09T14:16:57Z</timestamp>
<contributor>
<username>Tomaxer</username>
<id>3686472</id>
</contributor>
</revision>
<categories>
<category>Concurrency control</category>
</categories>
</header>
<bdy>

In <link xlink:type="simple" xlink:href="../323/5323.xml">
computer science</link>, a <b>lock convoy</b> is a performance problem that can occur when using <link xlink:type="simple" xlink:href="../593/244593.xml">
locks</link> for <link xlink:type="simple" xlink:href="../356/217356.xml">
concurrency control</link> in a <link xlink:type="simple" xlink:href="../679/10520679.xml">
multithreaded</link> application.  <p>

A lock convoy occurs when multiple <link xlink:type="simple" xlink:href="../303/45303.xml">
threads</link> of equal priority contend repeatedly for the same lock. Unlike <link xlink:type="simple" xlink:href="../181/105181.xml">
deadlock</link> and <link xlink:type="simple" xlink:href="../181/105181.xml#xpointer(//*[./st=%22Livelock%22])">
livelock</link> situations, the threads in a lock convoy do progress; however, each time a thread attempts to acquire the lock and fails, it relinquishes the remainder of its scheduling quantum and forcing a context switch.  The overhead of repeated context switches and underutilization of scheduling quanta degrade overall performance.</p>
<p>

Lock convoys often occur when concurrency control primitives such as <link xlink:type="simple" xlink:href="../312/638312.xml">
critical sections</link> serialize access to a commonly used resource, such as a <link xlink:type="simple" xlink:href="../117/547117.xml">
memory heap</link> or a <link xlink:type="simple" xlink:href="../016/764016.xml">
thread pool</link>.  They can sometimes be addressed by using non-locking alternatives such as <link xlink:type="simple" xlink:href="../864/554864.xml">
lock-free algorithms</link> or by altering the relative priorities of the contending threads.</p>

<sec>
<st>
Example</st>

<p>

Critical sections as implemented in <link xlink:type="simple" xlink:href="../890/18890.xml">
Microsoft Windows</link> operating systems provide a good example of how lock convoys can occur.  In Windows, critical sections use a combination of a spinlock and a kernel synchronization object called an "event" to ensure <link xlink:type="simple" xlink:href="../827/36827.xml">
mutual exclusion</link>.  For low-contention critical sections, the spinlock will provide mutual exclusion most of the time, falling back on the event only when a thread fails to acquire the spinlock within a certain amount of time.  When contention is high, however, it is possible for many threads to fail to acquire the spinlock and enter a waiting state, all waiting on the same event.</p>
<p>

When the event is signalled, all threads that are waiting on the event are woken, but only one will be allowed to acquire the critical section and continue execution; the remaining threads will each block again.</p>
<p>

As of Windows 2003, a thread waiting on an event is boosted to 1 priority level more than the thread which "set" (ie: signaled) the event associated to the critical section (aka, the thread releasing the critical section, which notifies other waiters by signaling the event). On the other hand, the setting thread will also lose the boost it may have requested while calling the "Set Event" API, which takes such a boost as a parameter.</p>
<p>

These two improvements help against a lock convoy, because now, each waiting thread should be able to run its full quantum, while the thread releasing the lock will probably have to wait more before being able to acquire the resource again.</p>

</sec>
</bdy>
</article>
