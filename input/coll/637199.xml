<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 17:27:44[mciao0828] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Automatic summarization</title>
<id>637199</id>
<revision>
<id>239083733</id>
<timestamp>2008-09-17T19:04:43Z</timestamp>
<contributor>
<username>Maghnus</username>
<id>3103609</id>
</contributor>
</revision>
<categories>
<category>Natural language processing</category>
<category>Computational linguistics</category>
</categories>
</header>
<bdy>

<b>Automatic summarization</b> is the creation of a shortened version of a <link xlink:type="simple" xlink:href="../977/32977.xml">
text</link> by a <link xlink:type="simple" xlink:href="../783/5783.xml">
computer program</link>. The product of this procedure still contains the most important points of the original text.<p>

The phenomenon of <link xlink:type="simple" xlink:href="../664/495664.xml">
information overload</link> has meant that access to <link xlink:type="simple" xlink:href="../984/2585984.xml">
coherent</link> and correctly-developed <link xlink:type="simple" xlink:href="../970/4168970.xml">
summaries</link> is vital. As access to data has increased so has interest in automatic summarization. An example of the use of summarization technology is <link xlink:type="simple" xlink:href="../023/4059023.xml">
search engine</link>s such as <company wordnetid="108058098" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../923/1092923.xml">
Google</link></company>
.</p>
<p>

<link xlink:type="simple" xlink:href="../816/29816.xml">
Technologies</link> that can make a <link xlink:type="simple" xlink:href="../984/2585984.xml">
coherent</link> summary, of any kind of text, need to take into account several <link xlink:type="simple" xlink:href="../818/32818.xml">
variable</link>s such as length, writing-style and <link xlink:type="simple" xlink:href="../860/26860.xml">
syntax</link> to make a useful summary.</p>

<sec>
<st>
Extraction and abstraction</st>
<p>

Broadly, one distinguishes two approaches:  and <it><link xlink:type="simple" xlink:href="../400/556400.xml">
abstraction</link></it>.</p>
<p>

Extraction techniques merely copy the information deemed most important by the system to the summary (for example, key clauses, sentences or paragraphs), while abstraction involves paraphrasing sections of the <link xlink:type="simple" xlink:href="../367/2377367.xml">
source document</link>. In general, abstraction can condense a text more strongly than extraction, but the programs that can do this are harder to develop as they require the use of <link xlink:type="simple" xlink:href="../999/301999.xml">
natural language generation</link> technology, which itself is a growing field.</p>

</sec>
<sec>
<st>
Types of summaries</st>

<p>

There are different types of summaries depending what the summarization program focuses on to make the summary of the text, for example <it>generic summaries</it> or <it>query relevant summaries</it> (sometimes called <it>query-biased summaries</it>). </p>
<p>

Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs. Summarization of <link xlink:type="simple" xlink:href="../420/20420.xml">
multimedia</link> documents, e.g. pictures or movies are also possible.</p>
<p>

Some systems will generate a summary based on a single source document, while others can use multiple source documents (for example, a <link xlink:type="simple" xlink:href="../675/669675.xml">
cluster</link> of news stories on the same topic). These systems are known as <it><link xlink:type="simple" xlink:href="../342/6870342.xml">
multi-document summarization</link></it> systems.</p>


</sec>
<sec>
<st>
Aided summarization</st>
<p>

<link xlink:type="simple" xlink:href="../488/233488.xml">
Machine learning</link> techniques from closely related fields such as <link xlink:type="simple" xlink:href="../271/15271.xml">
information retrieval</link> or <link xlink:type="simple" xlink:href="../439/318439.xml">
text mining</link> have been successfully adapted to help automatic summarization.</p>
<p>

Apart from Fully Automated Summarizers (FAS), there are systems that aid users with the task of summarization (MAHS = Machine Aided Human Summarization), for example by highlighting candidate passages to be included in the summary, and there are systems that depend on post-processing by a human (HAMS = Human Aided Machine Summarization).</p>

</sec>
<sec>
<st>
Evaluation</st>
<p>

An ongoing issue in this field is that of evaluation. Human judgement often has wide variance on what is considered a "good" summary, which means that making the evaluation process automatic is particularly difficult. Manual evaluation can be used, but this is both time and labor intensive as it requires humans to read not only the summaries but also the source documents. Other issues are those concerning <link xlink:type="simple" xlink:href="../984/2585984.xml">
coherence</link> and <link xlink:type="simple" xlink:href="../005/527005.xml">
coverage</link>.</p>
<p>

One of the metrics used in <link xlink:type="simple" xlink:href="../888/21888.xml">
NIST</link>'s annual Document Understanding Conferences, in which research groups submit their systems for both summarization and translation tasks, is the ROUGE metric (Recall-Oriented Understudy for Gisting Evaluation <weblink xlink:type="simple" xlink:href="http://haydn.isi.edu/ROUGE/">
http://haydn.isi.edu/ROUGE/</weblink>). It essentially calculates <link xlink:type="simple" xlink:href="../182/986182.xml">
n-gram</link> overlaps between automatically generated summaries and previously-written human summaries. A high level of overlap should indicate a high level of shared concepts between the two summaries. Note that overlap metrics like this are unable to provide any feedback on a summary's coherence. <link xlink:type="simple" xlink:href="../799/1276799.xml">
Anaphor resolution</link> remains another problem yet to be fully solved.</p>

</sec>
<sec>
<st>
 Further reading </st>
<p>

<list>
<entry level="1" type="bullet">

 Endres-Niggemeyer, Brigitte (1998):  Summarizing Information (ISBN 3-540-63735-4)</entry>
<entry level="1" type="bullet">

 Marcu, Daniel (2000): The Theory and Practice of Discourse Parsing and Summarization (ISBN 0-262-13372-5)</entry>
<entry level="1" type="bullet">

 Mani, Inderjeet (2001): Automatic Summarization (ISBN 1-58811-060-5)</entry>
</list>
</p>

</sec>
<sec>
<st>
See also</st>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../096/996096.xml">
Sentence extraction</link></entry>
<entry level="1" type="bullet">

 <software wordnetid="106566077" confidence="0.8">
<application wordnetid="106570110" confidence="0.8">
<program wordnetid="106568978" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106359877" confidence="0.8">
<code wordnetid="106355894" confidence="0.8">
<coding_system wordnetid="106353757" confidence="0.8">
<link xlink:type="simple" xlink:href="../439/318439.xml">
Text mining</link></coding_system>
</code>
</writing>
</written_communication>
</program>
</application>
</software>
</entry>
</list>
</p>

</sec>
<sec>
<st>
External links</st>

<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.acm.org/sigir/">
ACM Special Interest Group on Information Retrieval</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://duc.nist.gov/">
Document Understanding Conference</weblink> 	</entry>
</list>
</p>



</sec>
</bdy>
</article>
