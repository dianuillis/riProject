<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 22:21:59[mciao0826] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<event  confidence="0.8" wordnetid="100029378">
<rule  confidence="0.8" wordnetid="105846932">
<act  confidence="0.8" wordnetid="100030358">
<psychological_feature  confidence="0.8" wordnetid="100023100">
<procedure  confidence="0.8" wordnetid="101023820">
<activity  confidence="0.8" wordnetid="100407535">
<algorithm  confidence="0.8" wordnetid="105847438">
<header>
<title>K-medoids</title>
<id>6406095</id>
<revision>
<id>242029171</id>
<timestamp>2008-09-30T16:27:03Z</timestamp>
<contributor>
<username>Cvene64</username>
<id>477314</id>
</contributor>
</revision>
<categories>
<category>Statistical algorithms</category>
<category>Wikipedia articles needing clarification</category>
<category>Machine learning</category>
<category>Data analysis</category>
</categories>
</header>
<bdy>

<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-style" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="40px" src="Ambox_?.svg">
</image>
</p>
</col>
<col style="" class="mbox-text">
 <b>All or part of this article may be .</b>
Please help . Suggestions may be on the . <it>(December 2006)</it></col>
</row>
</table>


<p>

The <b>K-medoids algorithm</b> is a <link xlink:type="simple" xlink:href="../675/669675.xml">
clustering</link> <link xlink:type="simple" xlink:href="../775/775.xml">
algorithm</link> related to the <link xlink:type="simple" xlink:href="../407/1860407.xml">
K-means</link> algorithm and the medoidshift algorithm. Both the K-means and K-medoids algorithms are partitional (breaking the dataset up into groups) and both attempt to minimize <link xlink:type="simple" xlink:href="../816/201816.xml">
squared error</link>, the distance between points labeled to be in a cluster and a point designated as the center of that cluster. In contrast to the K-means algorithm K-medoids chooses datapoints as centers (medoids or exemplars).</p>

<p>

<link xlink:type="simple" xlink:href="../095/6406095.xml">
k-medoid</link> is a classical partitioning technique of clustering  that clusters the data set of n objects into k clusters  known apriori.</p>
<p>

It is more robust to noise and outliers as compared to <link xlink:type="simple" xlink:href="../407/1860407.xml">
k-means</link></p>
<p>

A <link xlink:type="simple" xlink:href="../175/2421175.xml">
medoid</link> can be defined as that object of a cluster, whose average dissimilarity to all the objects in the cluster is minimal i.e. it is a most centrally located  point  in the given data set.</p>
<p>

<link xlink:type="simple" xlink:href="../095/6406095.xml">
K-medoid</link> clustering algorithm is as follows</p>
<p>

1) The algorithm  begins with arbitrary selection of the k objects as medoid points out of n data points (n&amp;gt;k)</p>
<p>

2) After selection of the k medoid points, associate each data object in the given data set to most similar  medoid. The similarity here is defined using distance measure that can be <link xlink:type="simple" xlink:href="../932/53932.xml">
euclidean distance</link>, <link xlink:type="simple" xlink:href="../354/408354.xml">
manhattan distance</link> or <link>
minkowski distance</link></p>
<p>

3) Randomly select nonmedoid object O’ </p>
<p>

4) compute total cost , S  of swapping  initial <link xlink:type="simple" xlink:href="../175/2421175.xml">
medoid</link> object to O’</p>
<p>

5) If  S0, then swap initial medoid with the new one ( if S0 then there will be new set of medoids)</p>
<p>

6) repeat steps 2 to 5 until there is no change in the medoid.</p>

<sec>
<st>
Demonstration of algorithm</st>

<p>

Cluster the following data set of 10 objects into 2 clusters i.e k=2.</p>
<p>

Consider data set  of 10  data set of objects as follows:</p>
<p>

<image width="150px" src="kmedoidt1.jpg">
<caption>

kmedoidt1.jpg
</caption>
</image>
</p>
<p>

<image width="150px" src="kmedoid1.jpg">
<caption>

Figure 1.1 distribution of the data
</caption>
</image>

Figure 1.1 distribution of the data</p>
<p>

Step 1:</p>
<p>

Initialize k centre  
Let us assume C1=(3,4) and C2=(7,4)
So here C1 and C2 are selected as medoid.
Calculating distance so as to associate each data object to its nearest medoid. Cost is calculated using Minkowski distance metric with r = 1.</p>
<p>

<image width="150px" src="kmedoidt2.jpg">
<caption>

kmedoidt2.jpg
</caption>
</image>
</p>
<p>

So the clusters become:</p>
<p>

Cluster1={(3,4)(2,6)(3,8)(4,7)}
Cluster2={(7,4)(6,2)(6,4)(7,3)(8,5)(7,6)}</p>
<p>

Since the points (2,6) ( 3,8) and (4,7)  are close to c1 hence they form one cluster while   
remaining points form another cluster.</p>
<p>

So the total cost involved is  20.</p>
<p>

Where cost between any 2 points is found using formula 
<image width="150px" src="kmedoideq.png">
<caption>

kmedoideq.png
</caption>
</image>
</p>
<p>

where x is any data object, c is the medoid, and d is the dimension of the object which in this case is 2.</p>
<p>

Total cost  is summation of the cost of data object from its medoid  in its cluster so here</p>
<p>

Total cost= {cost((3,4),(2,6))+ cost((3,4),(3,8))+ cost((3,4),(4,7))} + {cost((7,4),(6,2))+            cost((7,4),(6,4)) + cost((7,4),(7,3)) + cost((7,4),(8,5)) + cost((7,4),(7,6)) }</p>
<p>

=3+4+4+3+1+1+2+2
=20</p>
<p>

<image width="150px" src="kmedoid2.jpg">
<caption>

kmedoid2.jpg
</caption>
</image>

Figure 1.2   clusters after step 1</p>
<p>

Step 2:
Selection of  nonmedoid O’ randomly
Let us assume O’=(7,3)</p>
<p>

So now the medoids are c1(3,4) and  O’(7,3)
If c1 and O’ are new medoids, calculate the total cost involved
By using the formula in the step 1</p>
<p>

<image width="150px" src="kmedoidt3.jpg">
<caption>

kmedoidt3.jpg
</caption>
</image>
</p>
<p>

<image width="150px" src="kmedoid3.jpg">
<caption>

kmedoid3.jpg
</caption>
</image>

Figure 1.3  clusters after step 2</p>
<p>

Total cost = 3+4+4+2+2+1+3+3 =22</p>
<p>

So cost of swapping medoid from c2 to O’ is </p>
<p>

S=Current total cost – past total cost 
= 22-20
= 2&amp;gt;0</p>
<p>

So moving to O’ would be bad idea,so the previous choice was good and algorithm terminates here(i.e there is no change in the medoids).</p>
<p>

It may happen some data points may shift from one cluster to another cluster depending upon their closeness to medoid.</p>


</sec>
</bdy>
</algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</article>
