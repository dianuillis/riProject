<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 22:24:02[mciao0826] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<event  confidence="0.8" wordnetid="100029378">
<rule  confidence="0.8" wordnetid="105846932">
<act  confidence="0.8" wordnetid="100030358">
<psychological_feature  confidence="0.8" wordnetid="100023100">
<procedure  confidence="0.8" wordnetid="101023820">
<activity  confidence="0.8" wordnetid="100407535">
<algorithm  confidence="0.8" wordnetid="105847438">
<header>
<title>Incompressible string</title>
<id>6495416</id>
<revision>
<id>185697529</id>
<timestamp>2008-01-20T20:05:42Z</timestamp>
<contributor>
<username>Andreas Kaufmann</username>
<id>72502</id>
</contributor>
</revision>
<categories>
<category>Lossless compression algorithms</category>
</categories>
</header>
<bdy>

An <b>incompressible <idea wordnetid="105833840" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<category wordnetid="105838765" confidence="0.8">
<language wordnetid="106282651" confidence="0.8">
<type wordnetid="105840188" confidence="0.8">
<kind wordnetid="105839024" confidence="0.8">
<link xlink:type="simple" xlink:href="../701/27701.xml">
string</link></kind>
</type>
</language>
</category>
</concept>
</idea>
</b> is one that cannot be compressed because it lacks sufficient repeating sequences.  Whether a string is compressible will often depend on the <link xlink:type="simple" xlink:href="../775/775.xml">
algorithm</link> being used.  Some examples may illuminate this.<p>

Suppose we have the string 12349999123499991234, and we are using a <link xlink:type="simple" xlink:href="../808/38808.xml">
compression</link> method that works by putting a special character into the string (say '@') followed by a value that points to an entry in a <link xlink:type="simple" xlink:href="../457/356457.xml">
lookup table</link> (or dictionary) of repeating values.  Let's imagine we have an algorithm that examines the string in 4 character chunks.  Looking at our string, our algorithm might pick out the values 1234 and 9999 to place into its dictionary.  Let's say 1234 is entry 0 and 9999 is entry 1. Now the string can become:</p>
<p>

@0@1@0@1</p>
<p>

Obviously, this is much shorter, although storing the dictionary itself will cost some space.  However, the more repeats there are in the string, the better the compression will be.</p>
<p>

Our algorithm can do better though, if it can view the string in chunks larger than 4 characters.  Then it can put 12349999 and 1234 into the dictionary, giving us:</p>
<p>

@0@0@1</p>
<p>

Even shorter!  Now let's consider another string:</p>
<p>

1234999988884321</p>
<p>

This string is incompressible by our algorithm. The only repeats that occur, are 88 and 99.  If we were to store 88 and 99 in our dictionary, we would produce:</p>
<p>

1234@1@1@0@04321</p>
<p>

Unfortunately this is just as long as the original string, because our placeholders for items in the dictionary are 2 bytes long, and the items they replace are the same length.</p>
<p>

Hence, this string is incompressible by our algorithm.</p>

</bdy>
</algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</article>
