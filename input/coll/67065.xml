<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 15:49:51[mciao0827] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Word sense disambiguation</title>
<id>67065</id>
<revision>
<id>241813730</id>
<timestamp>2008-09-29T17:37:25Z</timestamp>
<contributor>
<username>Funandtrvl</username>
<id>2966869</id>
</contributor>
</revision>
<categories>
<category>Natural language processing</category>
<category>Computational linguistics</category>
<category>Semantics</category>
</categories>
</header>
<bdy>

"WSD" redirects here. For the design school, see <link xlink:type="simple" xlink:href="../679/6034679.xml">
Wanganui School of Design</link>.
"Disambiguation" redirects here. For the Wikipedia guideline about disambiguation, see <p>

In <link xlink:type="simple" xlink:href="../561/5561.xml">
computational linguistics</link>, <b>word sense disambiguation</b> (WSD) is the process of identifying which <link xlink:type="simple" xlink:href="../695/3063695.xml">
sense</link> of a <link xlink:type="simple" xlink:href="../866/1449866.xml">
word</link> is used in any given <unit_of_measurement wordnetid="113583724" confidence="0.8">
<definite_quantity wordnetid="113576101" confidence="0.8">
<link xlink:type="simple" xlink:href="../352/870352.xml">
sentence</link></definite_quantity>
</unit_of_measurement>
, when the word has a number of distinct senses. </p>
<p>

For example, consider two examples of the distinct senses that exist for the word <it>bass</it>:
<list>
<entry level="1" type="number">

a type of fish</entry>
<entry level="1" type="number">

tones of low frequency</entry>
</list>

and the sentences: 
<list>
<entry level="1" type="number">

<it>I went fishing for some sea bass</it> </entry>
<entry level="1" type="number">

<it>The bass line of the song is very moving</it> </entry>
</list>
</p>
<p>

To a human, it is obvious that the first sentence is using the word <it>bass</it>, as in the former sense above and in the second sentence, the word <it>bass</it> is being used as in the latter sense below. Developing <link xlink:type="simple" xlink:href="../775/775.xml">
algorithm</link>s to replicate this human ability can often be a difficult task.</p>

<sec>
<st>
Difficulties</st>
<p>

One problem with word sense disambiguation is deciding what the senses are. In cases like the word <it>bass</it> above, at least some senses are obviously different. In other cases, however, the different senses can be closely related (one meaning being a <link xlink:type="simple" xlink:href="../518/20518.xml">
metaphor</link>ical or <link xlink:type="simple" xlink:href="../715/72715.xml">
metonymic</link> extension of another), and in such cases division of words into senses becomes much more difficult. Different dictionaries will provide different divisions of words into senses. One solution some researchers have used is to choose a particular dictionary, and just use its set of senses. Generally, however, research results using broad distinctions in senses have been much better than those using narrow, so most researchers ignore the fine-grained distinctions in their work.</p>
<p>

Another problem is inter-judge <link xlink:type="simple" xlink:href="../344/32344.xml">
variance</link>. WSD systems are normally tested by having their results on a task compared against those of a human. However, humans do not agree on the task at hand — give a list of senses and sentences, and humans will not always agree on which word belongs in which sense. A computer cannot be expected to give better performance on such a task than a human (indeed, since the human serves as the standard, the computer being better than the human is incoherent), so the human performance serves as an upper bound. Human performance, however, is much better on coarse-grained than fine-grained distinctions, so this again is why research on coarse-grained distinctions is most useful.</p>

</sec>
<sec>
<st>
Approaches</st>
<p>

As in all <link xlink:type="simple" xlink:href="../652/21652.xml">
natural language processing</link>, there are two main approaches to WSD — deep approaches and shallow approaches.</p>
<p>

Deep approaches presume access to a comprehensive body of <link xlink:type="simple" xlink:href="../339/2239339.xml">
world knowledge</link>. Knowledge, such as "you can go fishing for a type of fish, but not for low frequency sounds" and "songs have low frequency sounds as parts, but not types of fish", is then used to determine in which sense the word is used. These approaches are not very successful in practice, mainly because such a body of knowledge does not exist in a computer-readable format, outside of very limited domains. However, if such knowledge did exist, then deep approaches would be much more accurate than the shallow approaches. Also, there is a long tradition in <link xlink:type="simple" xlink:href="../561/5561.xml">
computational linguistics</link>, of trying such approaches in terms of coded knowledge and in some cases, it is hard to say clearly whether the knowledge involved is linguistic or world knowledge. The first attempt was that by Margaret Masterman and her colleagues, at the Cambridge Language Research Unit in England, in the 1950s. This attempt used as data a punched-card version of Roget's Thesaurus and its numbered "heads", as an indicator of topics and looked for repetitions in text, using a set intersection algorithm. It was not very successful, as is described in some detail in (Wilks, Y. et al., 1996), but had strong relationships to later work, especially Yarowsky's machine learning optimisation of a thesaurus method in the 1990s.</p>
<p>

Shallow approaches don't try to understand the text. They just consider the surrounding words, using information such as "if <it>bass</it> has words <it>sea</it> or <it>fishing</it> nearby, it probably is in the fish sense; if <it>bass</it> has the words <it>music</it> or <it>song</it> nearby, it is probably in the music sense." These rules can be automatically derived by the computer, using a training corpus of words tagged with their word senses. This approach, while theoretically not as powerful as deep approaches, gives superior results in practice, due to the computer's limited world knowledge. Though, it can be confused by sentences, like <it>The dogs bark at the tree</it>, which contains the word <it>bark</it> near both  <it>tree</it> and <it>dogs</it>.</p>
<p>

These approaches normally work by defining a window of <it>N</it> content words around each word to be disambiguated in the corpus, and statistically analyzing those <it>N</it> surrounding words. Two shallow approaches used to train and then disambiguate are <it><event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../339/87339.xml">
Naïve Bayes classifier</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
s</it> and <it><link xlink:type="simple" xlink:href="../602/232602.xml">
decision tree</link>s</it>. In recent research, kernel based methods such as <link xlink:type="simple" xlink:href="../309/65309.xml">
support vector machine</link>s have shown superior performance in <link xlink:type="simple" xlink:href="../926/20926.xml">
supervised learning</link>. But over the last few years, there hasn't been any major improvement in performance of any of these methods.</p>
<p>

It is instructive to compare the word sense disambiguation problem with the problem of <link xlink:type="simple" xlink:href="../912/746912.xml">
part-of-speech tagging</link>. Both involve disambiguating or tagging with words, be it with senses or parts of speech. However, algorithms used for one do not tend to work well for the other, mainly because the part of speech of a word is primarily determined by the immediately adjacent one to three words, whereas the sense of a word may be determined by words further away. The success rate for part-of-speech tagging algorithms is at present much higher than that for WSD, state-of-the art being around 95% accuracy or better, as compared to less than 75% accuracy in word sense disambiguation with supervised learning. These figures are typical for English, and may be very different from those for other languages.</p>
<p>

Another aspect of word sense disambiguation that differentiates it from part-of-speech tagging is the availability of training data.  While it is relatively easy to assign parts of speech to text, training people to tag senses is far more difficult <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref>.  While users can memorize all of the possible parts of speech a word can take, it is impossible for individuals to memorize all of the senses a word can take.  Thus, many word sense disambiguation algorithms use <link xlink:type="simple" xlink:href="../632/2829632.xml">
semi-supervised learning</link>, which allows both labeled and unlabeled data.  The Yarowsky algorithm was an early example of such an algorithm.</p>
<p>

Yarowsky’s <link xlink:type="simple" xlink:href="../497/233497.xml">
unsupervised algorithm</link> uses the ‘One sense per collocation’ and the ‘One sense per discourse’ properties of human languages for word sense disambiguation. From observation, words tend to exhibit only one sense in most given discourse and in a given collocation. The corpus is initially untagged.</p>
<p>

The algorithm starts with a large corpus, in which it identifies examples of the given polysemous word, and stores all the relevant sentences as lines. For instance, Yarowsky uses the word ‘plant’ in his 1995 paper to demonstrate the algorithm. Assume that there are two possible senses of the word, the next step is to identify a small number of seed collocations representative of each sense, give each sense a label, i.e. sense A and B, then assign the appropriate label to all training examples containing the seed collocations. In this case, the words ‘life’ and ‘manufacturing’ are chosen as initial seed collocations for sense A and B respectively. The residual examples (85% - 98% according to Yarowsky) remain untagged.</p>
<p>

The algorithm should initially choose seed collocations representative that will distinguish sense A and B accurately and productively. This can be done by selecting seed words from a dictionary’s entry for that sense. The collocations tend to have stronger effect if they are adjacent to the target word, the effect weakens with distance. According to the criteria given in Yarowsky (1993), seed words that appear in the most reliable collocational relationships with the target word will be selected. The effect is much stronger for words in a predicate-argument relationship than for arbitrary associations at the same distance to the target word, and is much stronger for collocations with content words than with function words. Having said this, a collocation word can have several collocational relationships with the target word throughout the corpus. This could give the word different rankings or even different classifications. Alternatively, it can be done by identifying a single defining collocate for each class, and using for seeds only those contexts containing one of these defining words. A publicly available database called WordNet can be used as an automatic source for such defining terms. In addition, words that occur near the target word in great frequency can be selected as seed collocations representative. This approach is not fully automatic, a human judge must decide which word will be selected for each target word’s sense, the outputs will be reliable indicators of the senses.</p>
<p>

A decision-list algorithm is then used to identify other reliable collocations. This training algorithm calculates the probability P(Sense | Collocation), and the decision list is ranked by the log-likelihood ratio:</p>
<p>

<b>Log(  P(SenseA | Collocationi)  /  P(SenseB | Collocationi) )</b></p>
<p>

A <link xlink:type="simple" xlink:href="../662/4155662.xml">
smoothing</link> algorithm will then be used to avoid 0 values. The decision-list algorithm resolves many problems in a large set of non-independent evidence source by using only the most reliable piece of evidence rather than the whole matching collocation set.</p>
<p>

The new resulting classifier will then be applied to the whole sample set. Add those examples in the residual that are tagged as A or B with probability above a reasonable threshold to the seed sets.  Apply the decision-list algorithm and the above adding step iteratively. As more newly-learned collocations are added to the seed sets, the sense A or sense B set will grow, and the original residual will shrink. However, these collocations stay in the seed sets only if their probability of classification remains above the threshold, otherwise they are returned to the residual for later classification. At the end of each iteration, the ‘One sense per discourse’ property can be used to help preventing initially mistagged collocates and hence improving the purity of the seed sets. </p>
<p>

In order to avoid strong collocates becoming indicators for the wrong class, the class-inclusion threshold needs to be randomly altered. For the same purpose, after intermediate convergence the algorithm will also need to increase the width of the context window.</p>
<p>

The algorithm will continue to iterate until no more reliable collocations are found. The ‘One sense per discourse’ property can be used here for error correction. For a target word that has a binary sense partition, if the occurrences of the majority sense A exceed that of the minor sense B by a certain threshold, the minority ones will be relabeled as A. According to Yarowsky, for any sense to be clearly dominant, the occurrences of the target word should not be less than 4.</p>
<p>

When the algorithm converges on a stable residual set, a final decision list of the target word is obtained. The most reliable collocations are at the top of the new list instead of the original seed words. The original untagged corpus is then tagged with sense labels and probabilities. The final decision list may now be applied to new data, the collocation with the highest rank in the list is used to classify the new data. For example, if the highest ranking collocation of the target word in the new data set is of sense A, then the target word is classified as sense A.</p>

</sec>
<sec>
<st>
 See also </st>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../677/677.xml">
Ambiguity</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../275/13477275.xml">
Lesk algorithm</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../912/746912.xml">
Part-of-speech tagging</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../327/155327.xml">
Polysemy</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../040/154040.xml">
Syntactic ambiguity</link></entry>
</list>
</p>

</sec>
<sec>
<st>
 Notes </st>
<p>

<reflist>
<entry id="1">
<physical_entity wordnetid="100001930" confidence="0.8">
<communicator wordnetid="109610660" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<compiler wordnetid="109946957" confidence="0.8">
<lexicographer wordnetid="110256080" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<writer wordnetid="110794014" confidence="0.8">
<linguist wordnetid="110264437" confidence="0.8">
<link xlink:type="simple" xlink:href="../570/7970570.xml">
Fellbaum, Christiane</link></linguist>
</writer>
</scientist>
</causal_agent>
</lexicographer>
</compiler>
</person>
</communicator>
</physical_entity>
 1997. Analysis of a handtagging task. Proceedings of ANLP-97 Workshop on Tagging Text with Lexical Semantics: Why, What, and How? Washington D.C., USA.</entry>
</reflist>
</p>

</sec>
<sec>
<st>
References</st>
<p>

<list>
<entry level="1" type="bullet">

 Wilks, Y., Slator, B., Guthrie, L. (1996) Electric Words: dictionaries, computers and meanings. Cambridge, MA: MIT Press.</entry>
<entry level="1" type="bullet">

 X.Y.Chou, (2007), Yarowsky’s unsupervised algorithm, Oxford Computing Lab.</entry>
</list>
</p>

</sec>
<sec>
<st>
 External links </st>

<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.scholarpedia.org/article/Word_sense_disambiguation">
<it>Word Sense Disambiguation''</it></weblink> as defined in Scholarpedia</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.senseval.org">
http://www.senseval.org</weblink> <it>(Evaluation Exercises for Word Sense Disambiguation)</it> The de-facto standard benchmarks for WSD systems.</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.aclweb.org/anthology-new/J/J98/">
Computational Linguistics Special Issue on Word Sense Disambiguation</weblink> (1998)</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.up.univ-mrs.fr/~veronis/pdf/1998wsd.pdf">
<it>Word Sense Disambiguation: The State of the Art</it></weblink> (PDF) <it> A comprehensive overview By Prof. Nancy Ide &amp; Jean Véronis (1998).</it></entry>
<entry level="1" type="bullet">

 A <weblink xlink:type="simple" xlink:href="http://www.d.umn.edu/~tpederse/WSDTutorial.html">
Word Sense Disambiguation Tutorial</weblink>, by Rada Mihalcea and Ted Pedersen.</entry>
<entry level="1" type="bullet">

Rada Mihalcea.&#32;"<weblink xlink:type="simple" xlink:href="http://www.cs.unt.edu/~rada/papers/mihalcea.naacl07.pdf">
Using Wikipedia for Automatic Word Sense Disambiguation</weblink>"&#32;(<message wordnetid="106598915" confidence="0.8">
<information wordnetid="106634376" confidence="0.8">
<language wordnetid="106282651" confidence="0.8">
<format wordnetid="106636806" confidence="0.8">
<link xlink:type="simple" xlink:href="../077/24077.xml">
PDF</link></format>
</language>
</information>
</message>
).&#32;  Department of Computer Science, <university wordnetid="108286163" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../976/179976.xml">
University of North Texas</link></university>
.&#32;Retrieved on <link>
2008-07-13</link>.</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.wsdbook.org">
www.wsdbook.org</weblink> Companion website for the book <it>Word Sense Disambiguation: Algorithms and Applications</it>, edited by Agirre and Edmonds (2006). Covers the entire field with chapters contributed by leading researchers.</entry>
</list>
</p>



</sec>
</bdy>
</article>
