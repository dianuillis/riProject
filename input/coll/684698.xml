<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 17:31:10[mciao0825] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<event  confidence="0.8" wordnetid="100029378">
<rule  confidence="0.8" wordnetid="105846932">
<act  confidence="0.8" wordnetid="100030358">
<psychological_feature  confidence="0.8" wordnetid="100023100">
<procedure  confidence="0.8" wordnetid="101023820">
<activity  confidence="0.8" wordnetid="100407535">
<algorithm  confidence="0.8" wordnetid="105847438">
<header>
<title>Rabin-Karp string search algorithm</title>
<id>684698</id>
<revision>
<id>237495118</id>
<timestamp>2008-09-10T13:37:43Z</timestamp>
<contributor>
<username>Robertgreer</username>
<id>2742851</id>
</contributor>
</revision>
<categories>
<category>Search algorithms</category>
<category>Hashing</category>
<category>Algorithms on strings</category>
</categories>
</header>
<bdy>

The <b>Rabin-Karp algorithm</b> is a <link xlink:type="simple" xlink:href="../648/28648.xml">
string searching algorithm</link> created by <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../404/298404.xml">
Michael O. Rabin</link></scientist>
</person>
 and <link>
Richard M. Karp</link> in <link xlink:type="simple" xlink:href="../760/34760.xml">
1987</link> that uses <link xlink:type="simple" xlink:href="../679/684679.xml">
hashing</link> to find a substring in a text. It is used for multiple pattern matching rather than single pattern matching. For text of length <it>n</it> and pattern of length <it>m</it>, its average and best case running time is <link xlink:type="simple" xlink:href="../578/44578.xml">
O</link>(<it>n</it>), but the worst case performance of O(<it>nm</it>) is a reason why it is not widely used. However, it has the unique advantage of being able to find any one of <it>k</it> strings or less in O(<it>n</it>) time on average, regardless of the magnitude of <it>k</it>.<p>

A practical application of Rabin-Karp is detecting <link xlink:type="simple" xlink:href="../210/18960210.xml">
plagiarism</link>. Given source material, Rabin-Karp can rapidly search through a paper for instances of sentences from the source material, ignoring details such as case and punctuation. Because of the abundance of the sought strings, single-string searching algorithms are impractical.</p>

<sec>
<st>
 Shifting substrings search and competing algorithms </st>
<p>

A simple substring search algorithm checks all possible positions:</p>
<p>

<b>1</b> <b>function</b> NaiveSearch(<it>string</it> s[1..n], <it>string</it> sub[1..m])
<b>2</b>     <b>for</b> i <b>from</b> 1 <b>to</b> n-m+1
<b>3</b>         <b>for</b> j <b>from</b> 1 <b>to</b> m
<b>4</b>             <b>if</b> s[i+j-1] &amp;ne; sub[j]
<b>5</b>                 jump to next iteration of outer loop
<b>6</b>         <b>return</b> i
<b>7</b>     <b>return</b> not found</p>
<p>

This algorithm works well in many practical cases, but can exhibit relatively long running times on certain examples, such as searching for a string of 10,000 "a"s followed by a "b" in a string of 10 million "a"s, in which case it exhibits its worst-case <link xlink:type="simple" xlink:href="../578/44578.xml">
&amp;Theta;</link>(<it>mn</it>) time.</p>
<p>

The <link xlink:type="simple" xlink:href="../227/253227.xml">
Knuth-Morris-Pratt algorithm</link> reduces this to &amp;Theta;(<it>n</it>) time using precomputation to examine each text character only once; the <link xlink:type="simple" xlink:href="../709/684709.xml">
Boyer-Moore algorithm</link> skips forward not by 1 character, but by as many as possible for the search to succeed, effectively decreasing the number of times we iterate through the outer loop, so that the number of characters examined can be as small as <it>n/m</it> in the best case.  The Rabin-Karp algorithm focuses instead on speeding up lines 3-6.</p>

</sec>
<sec>
<st>
 Use of hashing for shifting substring search </st>
<p>

Rather than pursuing more sophisticated skipping, the Rabin-Karp algorithm seeks to speed up the testing of equality of the pattern to the substrings in the text by using a <link xlink:type="simple" xlink:href="../790/13790.xml">
hash function</link>. A hash function is a function which converts every string into a numeric value, called its <it>hash value</it>; for example, we might have hash("hello")=5. Rabin-Karp exploits the fact that if two strings are equal, their hash values are also equal. Thus, it would seem all we have to do is compute the hash value of the substring we're searching for, and then look for a substring with the same hash value.</p>
<p>

However, there are two problems with this. First, because there are so many different strings, to keep the hash values small we have to assign some strings the same number. This means that if the hash values match, the strings might not match; we have to verify that they do, which can take a long time for long substrings. Luckily, a good hash function promises us that on most reasonable inputs, this won't happen too often, which keeps the average search time good.</p>
<p>

The algorithm is as shown:</p>
<p>

<b>1</b> <b>function</b> RabinKarp(<it>string</it> s[1..n], <it>string</it> sub[1..m])
<b>2</b>     hsub := hash(sub[1..m]);  hs := hash(s[1..m])     
<b>3</b>     <b>for</b> i <b>from</b> 1 <b>to</b> n-m+1
<b>4</b>         <b>if</b> hs = hsub
<b>5</b>             <b>if</b> s[i..i+m-1] = sub
<b>6</b>                 <b>return</b> i
<b>7</b>         hs := hash(s[i+1..i+m])
<b>8</b>     <b>return</b> not found</p>
<p>

Lines 2, 5, and 7 each require <link xlink:type="simple" xlink:href="../578/44578.xml">
&amp;Theta;</link>(m) time. However, line 2 is only executed once, and line 5 is only executed if the hash values match, which is unlikely to happen more than a few times. Line 4 is executed <it>n</it> times, but only requires constant time. So the only problem is line 7.</p>
<p>

If we naively recompute the hash value for the substring s[i+1..i+m], this would require <link xlink:type="simple" xlink:href="../578/44578.xml">
&amp;Theta;</link>(<it>m</it>) time, and since this is done on each loop, the algorithm would require &amp;Omega;(mn) time, the same as the most naive algorithms. The trick to solving this is to note that the variable hs already contains the hash value of s[i..i+m-1]. If we can use this to compute the next hash value in constant time, then our problem will be solved.</p>
<p>

We do this using what is called a <link xlink:type="simple" xlink:href="../549/4071549.xml">
rolling hash</link>. A rolling hash is a hash function specially designed to enable this operation. One simple example is adding up the values of each character in the substring. Then, we can use this formula to compute the next hash value in constant time:
s[i+1..i+m] = s[i..i+m-1] - s[i] + s[i+m]
This simple function works, but will result in statement 5 being executed more often than other more sophisticated rolling hash functions such as those discussed in the next section.</p>
<p>

Notice that if we're very unlucky, or have a very bad hash function such as a constant function, line 5 might very well be executed <it>n</it> times, on every iteration of the loop. Because it requires &amp;Theta;(m) time, the whole algorithm then takes a worst-case &amp;Theta;(mn) time.</p>

</sec>
<sec>
<st>
 Hash function used </st>
<p>

The key to Rabin-Karp performance is the efficient computation of <link xlink:type="simple" xlink:href="../790/13790.xml">
hash value</link>s of the successive substrings of the text. One popular and effective rolling hash function treats every substring as a number in some base, the base being usually a large <link xlink:type="simple" xlink:href="../666/23666.xml">
prime</link>. For example, if the substring is "hi" and the base is 101, the hash value would be 104 &amp;times; 1011 + 105 &amp;times; 1010 = 10609 (<message wordnetid="106598915" confidence="0.8">
<protocol wordnetid="106665108" confidence="0.8">
<representation wordnetid="105926676" confidence="0.8">
<direction wordnetid="106786629" confidence="0.8">
<rule wordnetid="106652242" confidence="0.8">
<link xlink:type="simple" xlink:href="../586/586.xml">
ASCII</link></rule>
</direction>
</representation>
</protocol>
</message>
 of 'h' is 104 and of 'i' is 105).</p>
<p>

Technically, this algorithm is only similar to the true number in a non-decimal system representation, since for example we could have the "base" less than one of the "digits". See <link xlink:type="simple" xlink:href="../790/13790.xml">
hash function</link> for a much more detailed discussion. The essential benefit achieved by such representation is that it is possible to compute the hash value of the next substring from the previous one by doing only a constant number of operations, independent of the substrings' lengths.</p>
<p>

For example, if we have text "abracadabra" and we are searching for a pattern of length 3, we can compute the hash of "bra" from the hash for "abr" (the previous substring) by subtracting the number added for the first 'a' of "abr", i.e.  97 &amp;times; 1012 (97 is ASCII for 'a' and 101 is the base we are using), multiplying by the base and adding for the last a of "bra", i.e. 97 &amp;times; 1010 = 97. If the substrings in question are long, this algorithm achieves great savings compared with many other hashing schemes.</p>
<p>

Theoretically, there exist other algorithms that could provide convenient recomputation, e.g. multiplying together ASCII values of all characters so that shifting substring would only entail dividing by the first character and multiplying by the last. The limitation, however, is the limited size of the integer <link xlink:type="simple" xlink:href="../817/93817.xml">
data type</link> and the necessity of using <link xlink:type="simple" xlink:href="../087/20087.xml">
modular arithmetic</link> to scale down the hash results, for which see <link xlink:type="simple" xlink:href="../790/13790.xml">
hash function</link> article; meanwhile, those naive hash functions that would not produce large numbers quickly, like just adding ASCII values, are likely to cause many <link xlink:type="simple" xlink:href="../344/45344.xml">
hash collision</link>s and hence slow down the algorithm. Hence the described hash function is typically the preferred one in Rabin-Karp.</p>

</sec>
<sec>
<st>
 Rabin-Karp and multiple pattern search </st>
<p>

Rabin-Karp is inferior for single pattern searching to <link xlink:type="simple" xlink:href="../227/253227.xml">
Knuth-Morris-Pratt algorithm</link>, <link xlink:type="simple" xlink:href="../709/684709.xml">
Boyer-Moore string searching algorithm</link> and other faster single pattern <link xlink:type="simple" xlink:href="../648/28648.xml">
string searching algorithm</link>s because of its slow worst case behavior. However, Rabin-Karp is an algorithm of choice for multiple pattern search.</p>
<p>

That is, if we want to find any of a large number, say <it>k</it>, fixed length patterns in a text, we can create a simple variant of Rabin-Karp that uses a <link xlink:type="simple" xlink:href="../211/602211.xml">
Bloom filter</link> or a <link xlink:type="simple" xlink:href="../127/201127.xml">
set data structure</link> to check whether the hash of a given string belongs to a set of hash values of patterns we are looking for:</p>
<p>

<b>function</b> RabinKarpSet(<it>string</it> s[1..n], <it>set</it> of <it>string</it> subs, m) {
<it>set</it> hsubs := emptySet
<b>for each</b> sub <b>in</b> subs
insert hash(sub[1..m]) into hsubs
hs := hash(s[1..m])
<b>for</b> i <b>from</b> 1 <b>to</b> n-m+1
<b>if</b> hs &amp;isin; hsubs
<b>if</b> s[i..i+m-1] = a substring with hash hs
<b>return</b> i
hs := hash(s[i+1..i+m])
<b>return</b> not found
}</p>
<p>

Here we assume all the substrings have a fixed length <it>m</it>, but this assumption can be eliminated. We simply compare the current hash value against the hash values of all the substrings simultaneously using a quick lookup in our set data structure, and then verify any match we find against all substrings with that hash value.</p>
<p>

Other algorithms can search for a single pattern in O(<it>n</it>) time, and hence they can be used to search for <it>k</it> patterns in O(<it>n</it> <it>k</it>) time. In contrast, the variant Rabin-Karp above can find all <it>k</it> patterns in O(<it>n</it>+<it>k</it>) time in expectation, because a hash table checks whether a substring hash equals any of the pattern hashes in O(1) time.</p>

</sec>
<sec>
<st>
References</st>

<p>

<list>
<entry level="1" type="bullet">

 Karp and Rabin's original paper: Karp, Richard M.; Rabin, Michael O. (March 1987). "<weblink xlink:type="simple" xlink:href="http://www.research.ibm.com/journal/rd/312/ibmrd3102P.pdf">
Efficient randomized pattern-matching algorithms</weblink>". <it>IBM Journal of Research and Development</it> <b>31</b> (2), 249-260.</entry>
<entry level="1" type="bullet">

 <scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../475/4108475.xml">
Thomas H. Cormen</link></scientist>
, <scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../884/1400884.xml">
Charles E. Leiserson</link></scientist>
, <link xlink:type="simple" xlink:href="../057/68057.xml">
Ronald L. Rivest</link>, and <scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../993/3489993.xml">
Clifford Stein</link></scientist>
. <it><work wordnetid="104599396" confidence="0.8">
<product wordnetid="104007894" confidence="0.8">
<creation wordnetid="103129123" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<book wordnetid="106410904" confidence="0.8">
<publication wordnetid="106589574" confidence="0.8">
<link xlink:type="simple" xlink:href="../226/3499226.xml">
Introduction to Algorithms</link></publication>
</book>
</artifact>
</creation>
</product>
</work>
</it>, Second Edition. MIT Press and McGraw-Hill, 2001. ISBN 0-262-03293-7. Section 32.2: The Rabin-Karp algorithm, pp.911&ndash;916.</entry>
</list>
</p>


</sec>
</bdy>
</algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</article>
