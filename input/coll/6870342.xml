<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 22:36:10[mciao0826] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Multi-document summarization</title>
<id>6870342</id>
<revision>
<id>239466610</id>
<timestamp>2008-09-19T04:14:34Z</timestamp>
<contributor>
<username>Silent SAM</username>
<id>565844</id>
</contributor>
</revision>
<categories>
<category>Information retrieval</category>
<category>Natural language processing</category>
</categories>
</header>
<bdy>

<b>Multi-document summarization</b> is an automatic procedure aimed at extraction of information from multiple texts written about the same topic. Resulting summary report allows individual users, so as professional information consumers, to quickly familiarize themselves with information contained in a large cluster of documents. In such a way, multi-document summarization systems are complementing the <link xlink:type="simple" xlink:href="../677/2351677.xml">
news aggregators</link> performing the next step down the road of coping with <link xlink:type="simple" xlink:href="../664/495664.xml">
information overload</link>. 
<sec>
<st>
Key benefits</st>
<p>

Multi-document summarization creates information reports that are both concise and comprehensive.
With different opinions being put together &amp; outlined, every topic is described from multiple perspectives within a single document. 
While the goal of a brief summary is to simplify information search and cut the time by pointing to the most relevant source documents, comprehensive multi-document summary should itself contain the required information, hence limiting the need for accessing original files to cases when refinement is required. 
Automatic summaries present information extracted from multiple sources algorithmically, without any editorial touch or subjective human intervention, thus making it completely unbiased. </p>

</sec>
<sec>
<st>
Technology challenges</st>
<p>

The multi-document summarization task has turned out to be much more complex than <link xlink:type="simple" xlink:href="../199/637199.xml">
summarizing a single document</link>, even a very large one. This difficulty arises from inevitable thematic diversity within a large set of documents. A good summarization technology aims to combine the main themes with completeness, readability, and conciseness. <weblink xlink:type="simple" xlink:href="http://www-nlpir.nist.gov/projects/duc/index.html">
Document Understanding Conferences</weblink>, conducted annually by <link xlink:type="simple" xlink:href="../888/21888.xml">
NIST</link>, have developed sophisticated evaluation criteria for techniques accepting the multi-document summarization challenge. </p>
<p>

An ideal multi-document summarization system does not simply shorten the source texts but presents information organized around the key aspects to represent a wider diversity of views on the topic. When such quality is achieved, an automatic multi-document summary is perceived more like an overview of a given topic. The latter implies that such text compilations should also meet other basic requirements for an overview text compiled by a human.</p>
<p>

The multi-document summary quality criteria are as follows:
<list>
<entry level="1" type="bullet">

clear structure, including an outline of the main content, from which it is easy to navigate to the full text sections</entry>
<entry level="1" type="bullet">

text within sections is divided into meaningful paragraphs</entry>
<entry level="1" type="bullet">

gradual transition from more general to more specific thematic aspects</entry>
<entry level="1" type="bullet">

good readability</entry>
</list>
</p>
<p>

The latter point deserves additional note - special care is taken in order to ensure that the automatic overview shows:
<list>
<entry level="1" type="bullet">

no paper-unrelated "information noise" from the respective documents (e.g., web pages)</entry>
<entry level="1" type="bullet">

no dangling references to what is not mentioned or explained in the overview</entry>
<entry level="1" type="bullet">

no text breaks across a sentence</entry>
<entry level="1" type="bullet">

no semantic redundancy.</entry>
</list>
</p>

</sec>
<sec>
<st>
Real-life systems</st>
<p>

The multi-document summarization technology is now coming of age - a view supported by a choice of advanced web-based systems that are currently available. </p>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://ultimate-research-assistant.com/">
Ultimate Research Assistant</weblink> - The Ultimate Research Assistant performs text mining on Internet search results to help summarize and organize them and make it easier for the user to perform online research. Specific text mining techniques used by the tool include concept extraction, text summarization, hierarchical concept clustering (e.g., automated taxonomy generation), and various visualization techniques, including tag clouds and mind maps. To use this tool, the user types in the name of a topic, and the tool will search the web for highly relevant resources, and organize the search results into a rich, easy-to-understand research report.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.iresearch-reporter.com/">
iResearch Reporter</weblink> - Commercial Text Extraction and Text Summarization system, free demo site accepts user-entered query, passes it on to Google search engine, retrieves multiple relevant documents, produces categorized, easily-readable natural language summary reports covering multiple documents in retrieved set, all extracts linked to original documents on the Web, post-processing, entity extraction, event and relationship extraction, text extraction, extract clustering, linguistic analysis, multi-document, full text, natural language processing, categorization rules, clustering, linguistic analysis, text summary construction tool set.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www1.cs.columbia.edu/nlp/projects.html">
Newsblaster</weblink> is a system that helps users find the news that is of the most interest to them. The system automatically collects, clusters, categorizes, and summarizes news from several sites on the web (<channel wordnetid="106259898" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../028/62028.xml">
CNN</link></channel>
, <company wordnetid="108058098" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../750/18998750.xml">
Reuters</link></company>
, <link xlink:type="simple" xlink:href="../121/11121.xml">
Fox News</link>, etc.) on a daily basis, and it provides users a user-friendly interface to browse the results. </entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://lada.si.umich.edu:8080/clair/nie1/nie.cgi">
NewsInEssence</weblink> may be used to retrieve and summarize a cluster of articles from the web. It can start from a <link xlink:type="simple" xlink:href="../277/32277.xml">
URL</link> and retrieve documents that are similar, or it can retrieve documents that match a given set of keywords. NewsInEssence also downloads hundreds of news articles daily and produces news clusters from them. </entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://newsfeedresearcher.com">
NewsFeed Researcher</weblink> is a news portal performing continuous <link xlink:type="simple" xlink:href="../199/637199.xml">
automatic summarization</link> of documents initially clustered by the <link xlink:type="simple" xlink:href="../677/2351677.xml">
news aggregators</link> (e.g., <web_site wordnetid="106359193" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../299/466299.xml">
Google News</link></web_site>
). NewsFeed Researcher is backed by the free online engine covering major events related to business, technology, U.S. and international news. This tool is also available in the on-demand mode allowing a user to build a summary on any selected topic. </entry>
</list>
</p>
<p>

As the quality multi-document summaries are becoming to resemble the overviews written by a human, one cannot exclude that their use of extracted text snippets can one day face some <link xlink:type="simple" xlink:href="../278/5278.xml">
copyright</link> issues. This potential case should be regarded from the point of the <link xlink:type="simple" xlink:href="../772/10772.xml">
fair use</link> copyright concept.</p>

</sec>
<sec>
<st>
Bibliography</st>
<p>

<list>
<entry level="1" type="bullet">

 C.-Y. Lin, E. Hovy, "From single to multi-document summarization: A prototype system and its evaluation", In "Proceedings of the ACL", pp. 457–464, 2002</entry>
<entry level="1" type="bullet">

Kathleen McKeown, Rebecca J. Passonneau, David K. Elson, Ani Nenkova, Julia Hirschberg, "Do Summaries Help? A Task-Based Evaluation of Multi-Document Summarization", SIGIR’05, Salvador, Brazil, August 15–19, 2005 <weblink xlink:type="simple" xlink:href="http://www.cs.columbia.edu/~ani/papers/f98-mckeown.pdf">
http://www.cs.columbia.edu/~ani/papers/f98-mckeown.pdf</weblink></entry>
<entry level="1" type="bullet">

R. Barzilay, N. Elhadad, K. R. McKeown, "Inferring strategies for sentence ordering in multidocument news summarization", Journal of Artificial Intelligence Research, v. 17, pp. 35-55, 2002</entry>
<entry level="1" type="bullet">

M. Soubbotin, S. Soubbotin, "Trade-Off Between Factors Influencing Quality of the Summary", Document Understanding Workshop (DUC), Vancouver, B.C., Canada, October 9-10, 2005 <weblink xlink:type="simple" xlink:href="http://duc.nist.gov/pubs/2005papers/freetext.sergei.pdf">
http://duc.nist.gov/pubs/2005papers/freetext.sergei.pdf</weblink></entry>
</list>
</p>

</sec>
<sec>
<st>
See also</st>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../199/637199.xml">
Automatic summarization</link></entry>
<entry level="1" type="bullet">

 <software wordnetid="106566077" confidence="0.8">
<application wordnetid="106570110" confidence="0.8">
<program wordnetid="106568978" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106359877" confidence="0.8">
<code wordnetid="106355894" confidence="0.8">
<coding_system wordnetid="106353757" confidence="0.8">
<link xlink:type="simple" xlink:href="../439/318439.xml">
Text mining</link></coding_system>
</code>
</writing>
</written_communication>
</program>
</application>
</software>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../677/2351677.xml">
News aggregators</link></entry>
</list>
</p>

</sec>
<sec>
<st>
External links</st>

<p>

<list>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www-nlpir.nist.gov/projects/duc/index.html">
Document Understanding Conferences</weblink></entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www1.cs.columbia.edu/nlp/projects.html">
Columbia NLP Projects</weblink></entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://lada.si.umich.edu:8080/clair/nie1/nie.cgi">
NewsInEssence: Web-based News Summarization</weblink></entry>
</list>
</p>

</sec>
</bdy>
</article>
