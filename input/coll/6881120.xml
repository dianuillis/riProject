<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 22:35:07[mciao0825] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Prior knowledge for pattern recognition</title>
<id>6881120</id>
<revision>
<id>237397333</id>
<timestamp>2008-09-10T00:14:44Z</timestamp>
<contributor>
<username>J.delanoy</username>
<id>2372780</id>
</contributor>
</revision>
<categories>
<category>Statistical classification</category>
<category>Orphaned articles from November 2006</category>
<category>Machine learning</category>
<category>All orphaned articles</category>
</categories>
</header>
<bdy>
<p>

<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-style" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="44px" src="Wiki_letter_w.svg">
</image>
</p>
</col>
<col style="" class="mbox-text">
 <b>This article is  as few or no other articles <weblink xlink:type="simple" xlink:href="http://localhost:18088/wiki/index.php?title=Special:Whatlinkshere&amp;target=Prior_knowledge_for_pattern_recognition&amp;namespace=0">
link to it</weblink>.</b>
Please help  in articles on <weblink xlink:type="simple" xlink:href="http://www.google.com/search?hl=en&amp;as_qdr=all&amp;q=+site%3Aen.wikipedia.org+%22Prior+knowledge+for+pattern+recognition%22">
related topics</weblink>. <it>(November 2006)''</it></col>
</row>
</table>
</p>
<p>

 
<event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../706/126706.xml">
Pattern recognition</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
 is a very active field of research intimately bound to <link xlink:type="simple" xlink:href="../488/233488.xml">
machine learning</link>. Also known as classification or <link xlink:type="simple" xlink:href="../244/1579244.xml">
statistical classification</link>, pattern recognition aims at building a <link xlink:type="simple" xlink:href="../543/1508543.xml">
classifier</link> that can determine the class of an input pattern. This procedure, known as training, corresponds to learning an unknown decision function based only on a set of input-output pairs <math>(\boldsymbol{x}_i,y_i)</math> that form the training data (or training set). Nonetheless, in real world applications such as <link xlink:type="simple" xlink:href="../091/49091.xml">
character recognition</link>, a certain amount of information on the problem is usually known beforehand. The incorporation of this prior knowledge into the training is the key element that will allow an increase of performance in many applications.</p>

<sec>
<st>
 Definition </st>

<p>

Prior knowledge, as defined in [Scholkopf02], refers to all information about the problem available in addition to the training data. However, in this most general form, determining a <link xlink:type="simple" xlink:href="../795/3224795.xml">
model</link> from a finite set of samples without prior knowledge is an <link xlink:type="simple" xlink:href="../673/176673.xml">
ill-posed</link> problem, in the sense that a unique model may not exist. Many classifiers incorporate the general smoothness assumption that a test pattern similar to one of the training samples tends to be assigned to the same class. </p>
<p>

The importance of prior knowledge in machine learning is suggested by its role in search and optimization. Loosely, the <link xlink:type="simple" xlink:href="../402/1297402.xml">
no free lunch theorem</link> states that all search algorithms have the same average performance over all problems, and thus implies that to gain in performance on a certain application one must use a specialized algorithm that includes some prior knowledge about the problem. </p>
<p>

The different types of prior knowledge encountered in pattern recognition are now regrouped under two main categories: class-invariance and knowledge on the data.</p>

</sec>
<sec>
<st>
 Class-invariance </st>

<p>

A very common type of prior knowledge in pattern recognition is the invariance of the class (or the output of the classifier) to a <link xlink:type="simple" xlink:href="../783/30783.xml">
transformation</link> of the input pattern. This type of knowledge is referred to as <b>transformation-invariance</b>. The mostly used transformations used in image recognition are:</p>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../637/18630637.xml">
translation</link>;</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../789/39789.xml">
rotation</link>;</entry>
<entry level="1" type="bullet">

 <link>
skewing</link>;</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../962/584962.xml">
scaling</link>.</entry>
</list>
</p>
<p>

Incorporating the invariance to a transformation <math>T_{\theta}: \boldsymbol{x} \mapsto T_{\theta}\boldsymbol{x}</math> parametrized in <math>\theta</math>  into a classifier of output <math>f(\boldsymbol{x})</math> for an input pattern <math>\boldsymbol{x}</math> corresponds to enforce the equality</p>
<p>

<math>
f(\boldsymbol{x}) = f(T_{\theta}\boldsymbol{x}), \quad \forall \boldsymbol{x}, \theta
</math></p>
<p>

Local invariance can also be considered for a transformation centered at <math>\theta=0</math>, so that <math>T_0\boldsymbol{x} = \boldsymbol{x}</math>, by the constraint</p>
<p>

<math>
  \left.\frac{\partial}{\partial \theta}\right|_{\theta=0} f(T_{\theta} \boldsymbol{x}) = 0
</math></p>
<p>

It must be noted that <math>f</math> in these Equations can be either the decision function of the classifier or its real-valued output.</p>
<p>

Another approach is to consider the class-invariance with respect to a "domain of the input space" instead of a transformation. In this case, the problem becomes finding <math>f</math> so that </p>
<p>

<math>
	f(\boldsymbol{x}) = y_{\mathcal{P}},\ \forall \boldsymbol{x}\in \mathcal{P}
</math></p>
<p>

where <math>y_{\mathcal{P}}</math> is the membership class of the region <math>\mathcal{P}</math> of the input space.</p>
<p>

A different type of class-invariance found in pattern recognition is the <b>permutation-invariance</b>, i.e. invariance of the class to a permutation of elements in a structured input. A typical application of this type of prior knowledge is a classifier invariant to permutations of rows in matrix inputs.</p>

</sec>
<sec>
<st>
 Knowledge on the data </st>

<p>

Other forms of prior knowledge than class-invariance concern the data more specifically and are thus of particular interest for real-world applications. The three particular cases that most often occur when gathering data are:
<list>
<entry level="1" type="bullet">

 <b>Unlabeled samples</b> are available with supposed class-memberships;</entry>
<entry level="1" type="bullet">

 <b>Imbalance</b> of the training set due to a high proportion of samples of a class;</entry>
<entry level="1" type="bullet">

 <b>Quality of the data</b> may vary from a sample to another. </entry>
</list>
</p>
<p>

Prior knowledge on these can enhance the quality of the recognition if included in the learning. Moreover, not taking into account the poor quality of some data or a large imbalance between the classes can mislead the decision of a classifier.</p>

</sec>
<sec>
<st>
 References </st>

<p>

<list>
<entry level="1" type="bullet">

 [Scholkopf02], B. Scholkopf and A. Smola, "Learning with Kernels", MIT Press 2002.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 [Krupka07], E. Krupka and N. Tishby, "Incorporating Prior Knowledge on Features into Learning", Eleventh International Conference on Artificial Intelligence and Statistics (AISTATS 07)</entry>
</list>
</p>

</sec>
</bdy>
</article>
