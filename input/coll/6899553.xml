<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 22:37:13[mciao0826] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Dynamic game balancing</title>
<id>6899553</id>
<revision>
<id>243540527</id>
<timestamp>2008-10-06T23:18:13Z</timestamp>
<contributor>
<username>Holek</username>
<id>191019</id>
</contributor>
</revision>
<categories>
<category>Video game gameplay</category>
<category>Orphaned articles from September 2006</category>
<category>All orphaned articles</category>
</categories>
</header>
<bdy>
<p>

<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-style" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="44px" src="Wiki_letter_w.svg">
</image>
</p>
</col>
<col style="" class="mbox-text">
 <b>This article is  as few or no other articles <weblink xlink:type="simple" xlink:href="http://localhost:18088/wiki/index.php?title=Special:Whatlinkshere&amp;target=Dynamic_game_balancing&amp;namespace=0">
link to it</weblink>.</b>
Please help  in articles on <weblink xlink:type="simple" xlink:href="http://www.google.com/search?hl=en&amp;as_qdr=all&amp;q=+site%3Aen.wikipedia.org+%22Dynamic+game+balancing%22">
related topics</weblink>. <it>(September 2006)''</it></col>
</row>
</table>
</p>
<p>

 
<b>Dynamic game balancing</b> (DGB) is the process of automatically changing parameters, scenarios and behaviors in a <link xlink:type="simple" xlink:href="../363/5363.xml">
video game</link> in order to avoid a player becoming bored or frustrated with the game.  In one extreme, the player may become bored because the game is too easy.  In the other, the player may become frustrated because it is too hard. The goals of DGB is to keep the user interested from the beginning to the end and to provide a good level of challenge for the user. As the users' skills improve through time (as they make progress via learning), the level of the challenges should also continually increase.</p>

<sec>
<st>
 Approaches </st>

<p>

Different approaches are found in the literature to address DGB. In all cases, it is necessary to measure, implicitly or explicitly, the difficulty the user is facing at a given moment. This measure can be performed by a <link xlink:type="simple" xlink:href="../452/63452.xml">
heuristic</link> function, which some authors call "challenge function". This function maps a given game state into a value that specifies how easy or difficult the game feels to the user at a specific moment. Examples of heuristics used are:
<list>
<entry level="1" type="bullet">

The rate of successful shots or hits</entry>
<entry level="1" type="bullet">

The numbers of won and lost pieces</entry>
<entry level="1" type="bullet">

Life points</entry>
<entry level="1" type="bullet">

Evolution</entry>
<entry level="1" type="bullet">

Time to complete some task</entry>
</list>
</p>
<p>

... or any metric used to calculate a game score.</p>
<p>

Hunicke and Chapman’s approach 
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref> controls the game environment settings in order to make challenges easier or harder. For example, if the game is too hard, the player gets more weapons, recover life points faster or face fewer opponents. Although this approach may be effective, its application can result in implausible situations. A straightforward approach is to combine such "parameters manipulation" to some mechanisms to modify the behavior of the <link xlink:type="simple" xlink:href="../668/21668.xml">
non-player character</link>s (NPCs) (characters controlled by the computer and usually modeled as <link xlink:type="simple" xlink:href="../769/1654769.xml">
intelligent</link> agents). </p>
<p>

A traditional implementation of such an agent’s intelligence is to use behavior rules, defined during <link xlink:type="simple" xlink:href="../265/700265.xml">
game development</link>. A typical rule in a <link xlink:type="simple" xlink:href="../398/32398.xml">
fighting game</link> would state "punch opponent if he is reachable, chase him, otherwise". Extending such approach to include opponent modeling can be made through Spronck <it>et al.</it>'s dynamic <link xlink:type="simple" xlink:href="../524/29524.xml">
scripting</link>,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%223%22])">3</ref> which assigns to each rule a <link xlink:type="simple" xlink:href="../934/22934.xml">
probability</link> of being picked. Rule weights can be dynamically updated throughout the game, accordingly to the opponent skills, leading to adaptation to the specific user. With a simple mechanism, rules can be picked that generate tactics that are neither too strong nor too weak for the current player.</p>
<p>

Andrade <it>et al.</it>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%224%22])">4</ref> divides the DGB problem into two dimensions: competence (learn as well as possible) and performance (act just as well as necessary). This dichotomy between competence and performance is well known and studied in <link xlink:type="simple" xlink:href="../526/17526.xml">
linguistics</link>, as proposed by <person wordnetid="100007846" confidence="0.9508927676800064">
<philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../566/21566.xml">
Noam Chomsky</link></philosopher>
</person>
. Their approach faces both dimensions with <link xlink:type="simple" xlink:href="../294/66294.xml">
reinforcement learning</link> (RL). Offline training is used to bootstrap the learning process. This can be done by letting the agent play against itself (selflearning), other pre-programmed agents, or human players. Then, online learning is used to adapt continually this initially built-in intelligence to each specific human opponent, in order to discover the most suitable strategy to play against him or her. Concerning performance their idea is to find an adequate policy for choosing actions that provide a good game balance, i.e., actions that keep both agent and human player at approximately the same performance level. According to the difficulty the player is facing, the agent chooses actions with high or low expected performance. For a given situation, if the game level is too hard, the agent does not choose the optimal action (provided by the RL framework), but chooses progressively less and less suboptimal actions until its performance is as good as the player’s. Similarly, if the game level becomes too easy, it will choose actions whose values are higher, possibly until it reaches the optimal performance. </p>
<p>

Demasi and Cruz
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%225%22])">5</ref> built intelligent agents employing <link xlink:type="simple" xlink:href="../254/40254.xml">
genetic algorithm</link>s techniques to keep alive agents that best fit the user level. Online coevolution is used in order to speed up the learning process. Online coevolution uses pre-defined models (agents with good genetic features) as parents in the genetic operations, so that the evolution is biased by them. These models are constructed by offline training or by hand, when the agent genetic encoding is simple enough. </p>
<p>

Other work in the field of DGB is based on the hypothesis that the player-opponent interaction — rather than the audiovisual features, the context or the genre of the game — is the property that contributes the majority of the quality features of entertainment in a computer game.
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref> Based on this fundamental assumption, a metric for measuring the real time entertainment value of predator/prey games was introduced, and established as efficient and reliable by validation against human judgment. </p>
<p>

Further studies by Yannakakis and Hallam<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%227%22])">7</ref> have shown that <link xlink:type="simple" xlink:href="../523/21523.xml">
artificial neural network</link>s (ANN) and <link>
fuzzy neural network</link>s can extract a better estimator of player satisfaction than a human-designed one, given appropriate estimators of the <b>challenge and curiosity</b> (intrinsic qualitative factors for engaging gameplay according to Malone)<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%228%22])">8</ref> of the game and data on human players' preferences. The approach of constructing user models of the player of a game that can predict the answers to which variants of the game are more or less <it>fun</it> is defined as <it>Entertainment Modeling</it>. The model is usually constructed using <link xlink:type="simple" xlink:href="../488/233488.xml">
machine learning</link> techniques applied to game parameters derived from player-game interaction and/or statistical features of player's <link>
physiological signal</link>s recorded during play. This basic approach is applicable to a variety of games, both computer<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%227%22])">7</ref> and physical.</p>

</sec>
<sec>
<st>
 See also </st>
<p>
  	
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../143/1088143.xml">
Game balance</link></entry>
</list>
</p>

</sec>
<sec>
<st>
 References </st>

<p>

<reflist>
<entry id="1">
 <cite id="Reference-R. Hunicke, V. Chapman-2004" style="font-style:normal" class="book">R. Hunicke, V. Chapman&#32;(2004).&#32;"AI for Dynamic Difficulty Adjustment in Games", Challenges in Game Artificial Intelligence AAAI Workshop,&#32;91-96.</cite>&nbsp;</entry>
<entry id="2">
<weblink xlink:type="simple" xlink:href="http://www.cs.unimaas.nl/p.spronck/">
Pieter Spronck</weblink> from Institute for Knowledge and Agent Technology (IKAT)</entry>
<entry id="3">
 <cite id="Reference-P. Spronck, I. Sprinkhuizen-Kuyper, E. Postma-2004" style="font-style:normal" class="book">P. Spronck, I. Sprinkhuizen-Kuyper, E. Postma&#32;(2004).&#32;"Difficulty Scaling of Game AI", Proceedings of the 5th International Conference on Intelligent Games and Simulation,&#32;33-37.</cite>&nbsp;</entry>
<entry id="4">
 <cite id="Reference-G. Andrade, G. Ramalho, H. Santana, V. Corruble-2005" style="font-style:normal" class="book">G. Andrade, G. Ramalho, H. Santana, V. Corruble&#32;(2005).&#32;"Challenge-Sensitive Action Selection: an Application to Game Balancing", Proceedings of the IEEE/WIC/ACM International Conference on Intelligent Agent Technology (IAT-05).&#32;Compiègne, France:&#32;IEEE Computer Society,&#32;194-200.</cite>&nbsp;</entry>
<entry id="5">
 <cite id="Reference-P. Demasi, A. Cruz-2002" style="font-style:normal" class="book">P. Demasi, A. Cruz&#32;(2002).&#32;"Online Coevolution for Action Games", Proceedings of The 3rd International Conference on Intelligent Games And Simulation,&#32;113-120.</cite>&nbsp;</entry>
<entry id="6">
 <cite style="font-style:normal" class="book">G. N. Yannakakis, J. Hallam&#32;(2004-7-(13-17)).&#32;"Evolving Opponents for Interesting Interactive Computer Games", Proceedings of the 8th International Conference on the Simulation of Adaptive Behavior (SAB'04); From Animals to Animats 8.&#32;Los Angeles, California, United States:&#32;The MIT Press,&#32;499-508.</cite>&nbsp;</entry>
<entry id="7">
 <cite style="font-style:normal" class="book">G. N. Yannakakis, J. Hallam&#32;(2006-5-(18-20)).&#32;"Towards Capturing and Enhancing Entertainment in Computer Games", Proceedings of the 4th Hellenic Conference on Artificial Intelligence, Lecture Notes in Artificial Intelligence.&#32;Heraklion, Crete, Greece:&#32;Springer-Verlag,&#32;432-442.</cite>&nbsp;</entry>
<entry id="8">
 <cite style="font-style:normal">Malone, T. W.&#32;(1981).&#32;"What makes computer games fun?". <it>Byte</it>&#32;<b>6</b>: 258–277.</cite>&nbsp;</entry>
</reflist>
</p>

</sec>
<sec>
<st>
 External links </st>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.cin.ufpe.br/~gda/gamebalancing">
Dynamic Game Balancing</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.mip.sdu.dk/~georgios/">
Entertainment Modeling and Augmentation</weblink></entry>
</list>
</p>

</sec>
</bdy>
</article>
