<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 15:23:38[mciao0826] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<technique  confidence="0.8" wordnetid="105665146">
<know-how  confidence="0.8" wordnetid="105616786">
<method  confidence="0.8" wordnetid="105660268">
<header>
<title>Computer music</title>
<id>6974</id>
<revision>
<id>243100280</id>
<timestamp>2008-10-05T04:09:14Z</timestamp>
<contributor>
<username>Lightbot</username>
<id>7178666</id>
</contributor>
</revision>
<categories>
<category>Musical techniques</category>
<category>Articles lacking reliable references from April 2008</category>
<category>Articles that may contain original research since May 2008</category>
</categories>
</header>
<bdy>

<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-content" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="40x40px" src="Ambox_content.png">
</image>
</p>
</col>
<col style="" class="mbox-text">
 <p>

This article or section has multiple issues. Please help <b><weblink xlink:type="simple" xlink:href="http://localhost:18088/wiki/index.php?title=Computer_music&amp;action=edit">
improve the article</weblink></b> or discuss these issues on the .
<list>
<entry level="1" type="bullet">

 It needs <b>additional  for .</b> Tagged since April 2008.</entry>
<entry level="1" type="bullet">

 It may contain  or . Tagged since April 2008.</entry>
</list>
</p>
</col>
</row>
</table>

<p>

<b>Computer music</b> is a term that was originally used within academia to describe a field of study relating to the applications of <link xlink:type="simple" xlink:href="../213/5213.xml">
computing technology</link> in music composition; particularly that stemming from the <link xlink:type="simple" xlink:href="../778/6668778.xml">
Western art music</link> tradition. It includes the theory and application of new and existing technologies in music, such as <link xlink:type="simple" xlink:href="../344/975344.xml">
sound synthesis</link>, <link xlink:type="simple" xlink:href="../TN$$/HT$C$_T$yT$N$.xml">
digital signal processing</link>, <link xlink:type="simple" xlink:href="../401/488401.xml">
sound design</link>, sonic diffusion, <link xlink:type="simple" xlink:href="../198/1198.xml">
acoustics</link>, and <link xlink:type="simple" xlink:href="../448/24448.xml">
psychoacoustics</link>. The field of computer music can trace its roots back to the origin of <link xlink:type="simple" xlink:href="../510/9510.xml">
electronic music</link>, and the very first experiments and innovations with electronic instruments at the turn of the 20th century. More recently, with the advent of <link xlink:type="simple" xlink:href="../137/18457137.xml">
personal computing</link>, and the growth of <link xlink:type="simple" xlink:href="../121/2458121.xml">
home recording</link>, the term computer music is now sometimes used to describe any <link xlink:type="simple" xlink:href="../839/18839.xml">
music</link> that has been created using computing technology.</p>

<sec>
<st>
History</st>

<p>

<indent level="1">

<it>See also: <link xlink:type="simple" xlink:href="../389/910389.xml">
Computer music programming languages</link></it>
</indent>
Much of the work on computer music has drawn on the relationship between <link xlink:type="simple" xlink:href="../783/54783.xml">
music theory</link> and <link xlink:type="simple" xlink:href="../831/18831.xml">
mathematics</link>. 
The world's first computer to play music was <computer wordnetid="103082979" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<device wordnetid="103183080" confidence="0.8">
<machine wordnetid="103699975" confidence="0.8">
<link xlink:type="simple" xlink:href="../746/284746.xml">
CSIRAC</link></machine>
</device>
</instrumentality>
</artifact>
</computer>
 which was designed and built by <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<link xlink:type="simple" xlink:href="../327/13123327.xml">
Trevor Pearcey</link></scientist>
</causal_agent>
</person>
</physical_entity>
 and Maston Beard. Mathematician Geoff Hill programmed the CSIRAC to play popular musical melodies from the very early 1950s. In 1951 it publicly played the <song wordnetid="107048000" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../021/62021.xml">
Colonel Bogey March</link></song>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref> of which no known recordings exist. 
However, <computer wordnetid="103082979" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<device wordnetid="103183080" confidence="0.8">
<machine wordnetid="103699975" confidence="0.8">
<link xlink:type="simple" xlink:href="../746/284746.xml">
CSIRAC</link></machine>
</device>
</instrumentality>
</artifact>
</computer>
 played standard repertoire and was not used to extend musical thinking or composition practice which is current computer music practice. </p>
<p>

The oldest known recordings of computer generated music were played by the <computer wordnetid="103082979" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<device wordnetid="103183080" confidence="0.8">
<machine wordnetid="103699975" confidence="0.8">
<link xlink:type="simple" xlink:href="../886/571886.xml">
Ferranti Mark I</link></machine>
</device>
</instrumentality>
</artifact>
</computer>
 computer, a commercial version of the <computer wordnetid="103082979" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<device wordnetid="103183080" confidence="0.8">
<machine wordnetid="103699975" confidence="0.8">
<link xlink:type="simple" xlink:href="../686/531686.xml">
Baby</link></machine>
</device>
</instrumentality>
</artifact>
</computer>
 Machine from the <body wordnetid="107965085" confidence="0.8">
<university wordnetid="108286163" confidence="0.8">
<social_group wordnetid="107950920" confidence="0.8">
<educational_institution wordnetid="108276342" confidence="0.8">
<group wordnetid="100031264" confidence="0.8">
<institution wordnetid="108053576" confidence="0.8">
<link xlink:type="simple" xlink:href="../250/83250.xml">
University of Manchester</link></institution>
</group>
</educational_institution>
</social_group>
</university>
</body>
 in the autumn of 1951. The music program was written by <scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../784/932784.xml">
Christopher Strachey</link></scientist>
. During a session recorded by the <network wordnetid="108434259" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../654/19344654.xml">
BBC</link></network>
, the machine managed to work its way through Baa Baa Black Sheep, God Save the King and part of In the Mood<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref>. Subsequently, <physical_entity wordnetid="100001930" confidence="0.8">
<composer wordnetid="109947232" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<musician wordnetid="110339966" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<artist wordnetid="109812338" confidence="0.8">
<creator wordnetid="109614315" confidence="0.8">
<link xlink:type="simple" xlink:href="../838/421838.xml">
Lejaren Hiller</link></creator>
</artist>
</causal_agent>
</musician>
</person>
</composer>
</physical_entity>
 (e.g., the Illiac Suite) used a computer in the mid 1950s to compose works that were then played by conventional musicians. Later developments included the work of <physical_entity wordnetid="100001930" confidence="0.8">
<peer wordnetid="109626238" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<engineer wordnetid="109615807" confidence="0.8">
<colleague wordnetid="109935990" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<associate wordnetid="109816771" confidence="0.8">
<link xlink:type="simple" xlink:href="../801/479801.xml">
Max Mathews</link></associate>
</scientist>
</causal_agent>
</colleague>
</engineer>
</person>
</peer>
</physical_entity>
 at Bell Laboratories, who developed the influential <link xlink:type="simple" xlink:href="../761/479761.xml">
MUSIC I</link> program.  <link xlink:type="simple" xlink:href="../678/32678.xml">
Vocoder</link> technology was also a major development in this early era. </p>
<p>

Early computer music programs typically did not run in <link xlink:type="simple" xlink:href="../767/25767.xml">
real-time</link>. Programs would run for hours or days, on multi-million dollar computers, in order to generate a few minutes of music. <physical_entity wordnetid="100001930" confidence="0.8">
<composer wordnetid="109947232" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<intellectual wordnetid="109621545" confidence="0.8">
<alumnus wordnetid="109786338" confidence="0.8">
<musician wordnetid="110339966" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<artist wordnetid="109812338" confidence="0.8">
<scholar wordnetid="110557854" confidence="0.8">
<creator wordnetid="109614315" confidence="0.8">
<link xlink:type="simple" xlink:href="../729/2897729.xml">
John Chowning</link></creator>
</scholar>
</artist>
</causal_agent>
</musician>
</alumnus>
</intellectual>
</person>
</composer>
</physical_entity>
's work on FM synthesis, in the early 70s, and the advent of inexpensive digital chips and microcomputers opened the door to real-time generation of computer music. By the early 90s, the performance of microprocessor-based computers reached the point that real-time generation of computer music using more general programs and algorithms became possible.</p>

</sec>
<sec>
<st>
Advances</st>
<p>

Advances in computing power have dramatically affected the way computer music is generated and performed. Current-generation micro-computers are powerful enough to perform very sophisticated audio synthesis using a wide variety of algorithms and approaches. Computer music systems and approaches are now ubiquitous, and so firmly embedded in the process of creating music that we hardly give them a second thought: computer-based synthesizers, digital mixers,  and effects units have become so commonplace that use of digital rather than analog technology to create and record music is the norm, rather than the exception. </p>

</sec>
<sec>
<st>
Research</st>
<p>

Despite the ubiquity of computer music in contemporary culture, there is considerable activity in the field of computer music, as researchers continue to pursue new and interesting computer-based synthesis, composition, and performance approaches.Throughout the world there are many organizations and institutions dedicated to the area of computer and electronic music study and research, including the <link xlink:type="simple" xlink:href="../500/9875500.xml">
ICMA</link> (International Computer Music Association), <institute wordnetid="108407330" confidence="0.8">
<association wordnetid="108049401" confidence="0.8">
<link xlink:type="simple" xlink:href="../022/259022.xml">
IRCAM</link></association>
</institute>
, <link xlink:type="simple" xlink:href="../756/479756.xml">
Princeton Sound Lab</link>, GRAME, <link xlink:type="simple" xlink:href="../384/2254384.xml">
SEAMUS</link> (Society for Electro Acoustic Music in the United States), and a great number of institutions of higher learning around the world.</p>

</sec>
<sec>
<st>
Computer Generated music</st>
<p>

Computer-generated music is music <link xlink:type="simple" xlink:href="../962/47962.xml">
composed</link> by, or with the extensive aid of, a computer. Although any music which uses computers in its composition or realisation is computer-generated to some extent, the use of computers is now so widespread (in the editing of pop songs, for instance) that the phrase computer-generated music is generally used to mean a kind of music which could not have been created <it>without</it> the use of computers.</p>
<p>

We can distinguish two groups of computer-generated music: music in which a computer generated the score, which could be performed by humans, and music which is both composed and performed by computers.</p>

<ss1>
<st>
Computer-generated scores for performance by human players</st>
<p>

Many systems for generating musical scores actually existed well before the time of computers. One of these was <link>
Musikalisches Würfelspiel</link>, a system which used throws of the dice to randomly select measures from a large collection of small phrases. When patched together, these phrases combined to create musical pieces which could be performed by human players. Although these works were not actually composed with a computer in the modern sense, it uses a rudimentary form of the random combinatorial techniques sometimes used in computer-generated composition.</p>
<p>

The world's first digital computer music was generated in Australia by programmer Geoff Hill on the <computer wordnetid="103082979" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<device wordnetid="103183080" confidence="0.8">
<machine wordnetid="103699975" confidence="0.8">
<link xlink:type="simple" xlink:href="../746/284746.xml">
CSIRAC</link></machine>
</device>
</instrumentality>
</artifact>
</computer>
 computer which was designed and built by Trevor Pearcey and Maston Beard, although it was only used to play standard tunes of the day. Subsequently, one of the first composers to write music with a computer was <person wordnetid="100007846" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../366/158366.xml">
Iannis Xenakis</link></person>
. He wrote programs in the <link xlink:type="simple" xlink:href="../168/11168.xml">
FORTRAN</link> language that generated numeric data that he transcribed into scores to be played by traditional <link xlink:type="simple" xlink:href="../017/19017.xml">
musical instrument</link>s. An example is <it>ST/48</it> of 1962. Although Xenakis could well have composed this music by hand, the intensity of the calculations needed to transform probabilistic mathematics into musical notation was best left to the number-crunching power of the computer.</p>
<p>

Computers have also been used in an attempt to imitate the music of great composers of the past, such as <person wordnetid="100007846" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../163/33163.xml">
Mozart</link></person>
. A present exponent of this technique is <physical_entity wordnetid="100001930" confidence="0.8">
<composer wordnetid="109947232" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<musician wordnetid="110339966" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<artist wordnetid="109812338" confidence="0.8">
<research_worker wordnetid="110523076" confidence="0.8">
<creator wordnetid="109614315" confidence="0.8">
<link xlink:type="simple" xlink:href="../323/734323.xml">
David Cope</link></creator>
</research_worker>
</artist>
</scientist>
</causal_agent>
</musician>
</person>
</composer>
</physical_entity>
. He wrote computer programs that analyse works of other composers to produce new works in a similar style. He has used this program to great effect with composers such as Bach and Mozart (his program <it>Experiments in Musical Intelligence</it> is famous for creating "Mozart's 42nd Symphony"), and also within his own pieces, combining his own creations with that of the computer.</p>

</ss1>
<ss1>
<st>
Music composed and performed by computers</st>

<p>

<indent level="1">

<it>See also: <technique wordnetid="105665146" confidence="0.8">
<know-how wordnetid="105616786" confidence="0.8">
<method wordnetid="105660268" confidence="0.8">
<link xlink:type="simple" xlink:href="../884/543884.xml">
Generative music</link></method>
</know-how>
</technique>
, <link xlink:type="simple" xlink:href="../980/7682980.xml">
Evolutionary music</link>,&nbsp;and <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../254/40254.xml">
Genetic algorithm</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</it>
</indent>
Later, composers such as <physical_entity wordnetid="100001930" confidence="0.8">
<composer wordnetid="109947232" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<musician wordnetid="110339966" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<artist wordnetid="109812338" confidence="0.8">
<creator wordnetid="109614315" confidence="0.8">
<link xlink:type="simple" xlink:href="../696/2581696.xml">
Gottfried Michael Koenig</link></creator>
</artist>
</causal_agent>
</musician>
</person>
</composer>
</physical_entity>
 had computers generate the sounds of the composition as well as the score. Koenig produced <link xlink:type="simple" xlink:href="../884/479884.xml">
algorithmic composition</link> programs which were a generalisation of his own <link xlink:type="simple" xlink:href="../764/98764.xml">
serial composition</link> practice.  This is not exactly similar to Xenakis' work as he used mathematical abstractions and examined how far he could explore these musically.  Koenig's software translated the calculation of mathematical equations into codes which represented musical notation.  This could be converted into musical notation by hand and then performed by human players. His programs Project 1 and Project 2 are examples of this kind of software. Later, he extended the same kind of principles into the realm of synthesis, enabling the computer to produce the sound directly. SSP is an example of a program which performs this kind of function. All of these programs were produced by Koenig at the Institute of Sonology in <village wordnetid="108672738" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../333/50333.xml">
Utrecht, Holland</link></village>
 in the 1970s.</p>
<p>

Procedures such as those used by Koenig and Xenakis are still in use today. Since the invention of the <link xlink:type="simple" xlink:href="../461/1692461.xml">
MIDI</link> system in the early 1980s, for example, some people have worked on programs which map MIDI notes to an algorithm and then can either output sounds or music through the computer's <link xlink:type="simple" xlink:href="../184/28184.xml">
sound card</link> or write an <link xlink:type="simple" xlink:href="../ury/24th_century.xml">
audio file</link> for other programs to play. </p>
<p>

Some of these simple programs are based on <link xlink:type="simple" xlink:href="../913/10913.xml">
fractal geometry</link>, and can map midi notes to specific <link xlink:type="simple" xlink:href="../913/10913.xml">
fractal</link>s, or fractal equations. Although such programs are widely available and are sometimes seen as clever toys for the non-musician, some professional musicians have given them attention also. The resulting 'music' can be more like noise, or can sound quite familiar and pleasant. As with much algorithmic music, and <link xlink:type="simple" xlink:href="../340/4878340.xml">
algorithmic art</link> in general, more depends on the way in which the parameters are mapped to aspects of these equations than on the equations themselves. Thus, for example, the same equation can be made to produce both a lyrical and melodic piece of music in the style of the mid-nineteenth century, and a fantastically dissonant <link xlink:type="simple" xlink:href="../887/2267887.xml">
cacophony</link> more reminiscent of the avant-garde music of the 1950's and 1960's. </p>
<p>

Other programs can map mathematical formulae and constants to produce sequences of notes. In this manner, an <link xlink:type="simple" xlink:href="../804/19724804.xml">
irrational number</link> can give an infinite sequence of notes where each note is a digit in the decimal expression of that number. This sequence can in turn be a composition in itself, or simply the basis for further elaboration.</p>
<p>

Operations such as these, and even more elaborate operations can also be performed in computer music programming languages such as  <link xlink:type="simple" xlink:href="../795/479795.xml">
Max/MSP</link>, <physical_entity wordnetid="100001930" confidence="0.8">
<structure wordnetid="104341686" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<building wordnetid="102913152" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<intellectual wordnetid="109621545" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<architecture wordnetid="102734725" confidence="0.8">
<synthesist wordnetid="110687231" confidence="0.8">
<link xlink:type="simple" xlink:href="../978/346978.xml">
SuperCollider</link></synthesist>
</architecture>
</causal_agent>
</intellectual>
</artifact>
</building>
</person>
</structure>
</physical_entity>
, <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<intellectual wordnetid="109621545" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<synthesist wordnetid="110687231" confidence="0.8">
<link xlink:type="simple" xlink:href="../998/149998.xml">
Csound</link></synthesist>
</causal_agent>
</intellectual>
</person>
</physical_entity>
, <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<intellectual wordnetid="109621545" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<synthesist wordnetid="110687231" confidence="0.8">
<link xlink:type="simple" xlink:href="../378/480378.xml">
Pure Data</link></synthesist>
</causal_agent>
</intellectual>
</person>
</physical_entity>
 (Pd), <software wordnetid="106566077" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../243/8241243.xml">
Keykit</link></software>
, and <link xlink:type="simple" xlink:href="../750/478750.xml">
ChucK</link>. These programs now easily run on most personal computers, and are often capable of more complex functions than those which would have necessitated the most powerful mainframe computers several decades ago.
<image location="right" width="150px" src="GenSystemVenn.png" type="thumb">
<caption>

Diagram illustrating the position of CAAC in relation to other <technique wordnetid="105665146" confidence="0.8">
<know-how wordnetid="105616786" confidence="0.8">
<method wordnetid="105660268" confidence="0.8">
<link xlink:type="simple" xlink:href="../884/543884.xml">
Generative music</link></method>
</know-how>
</technique>
 Systems
</caption>
</image>

There exist programs that generate "human-sounding" melodies by using a vast database of phrases. One example is <link xlink:type="simple" xlink:href="../688/2887688.xml">
Band-in-a-Box</link>, which is capable of creating <link xlink:type="simple" xlink:href="../613/15613.xml">
jazz</link>, <link xlink:type="simple" xlink:href="../352/3352.xml">
blues</link> and <link xlink:type="simple" xlink:href="../423/25423.xml">
rock</link> instrumental solos with almost no user interaction. Another is <software wordnetid="106566077" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../981/12702981.xml">
Impro-Visor</link></software>
, which uses a <link xlink:type="simple" xlink:href="../329/299329.xml">
stochastic context-free grammar</link> to generate phrases and complete solos.</p>
<p>

Another 'cybernetic' approach to computer composition uses specialized hardware to detect external stimuli which are then mapped by the computer to realize the performance.  Examples of this style of <link xlink:type="simple" xlink:href="../974/6974.xml">
computer music</link> can be found in the middle-80's work of <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<artist wordnetid="109812338" confidence="0.8">
<creator wordnetid="109614315" confidence="0.8">
<link xlink:type="simple" xlink:href="../639/1238639.xml">
David Rokeby</link></creator>
</artist>
</causal_agent>
</person>
</physical_entity>
 (Very Nervous System) where audience/performer motions are 'translated' to MIDI segments. Computer controlled music is also found in the performance pieces by the Canadian composer <physical_entity wordnetid="100001930" confidence="0.8">
<composer wordnetid="109947232" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<traveler wordnetid="109629752" confidence="0.8">
<musician wordnetid="110339966" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<exile wordnetid="110071332" confidence="0.8">
<artist wordnetid="109812338" confidence="0.8">
<absentee wordnetid="109757653" confidence="0.8">
<creator wordnetid="109614315" confidence="0.8">
<link xlink:type="simple" xlink:href="../782/1787782.xml">
Udo Kasemets</link></creator>
</absentee>
</artist>
</exile>
</causal_agent>
</musician>
</traveler>
</person>
</composer>
</physical_entity>
 (1919-) such as the Marce(ntennia)l Circus C(ag)elebrating Duchamp (1987), a realization of the <artist wordnetid="109812338" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../650/42650.xml">
Marcel Duchamp</link></artist>
 process piece Music Errata using an electric model train to collect a hopper-car of stones to be deposited on a drum wired to an Analog:Digital converter, mapping the stone impacts to a score display (performed in Toronto by pianist Gordon Monahan during the 1987 Duchamp Centennial), or his installations and performance works (eg Spectrascapes) based on his Geo(sono)scope (1986) 15x4-channel computer-controlled audio mixer. In these latter works, the computer generates sound-scapes from tape-loop sound samples, live shortwave or sine-wave generators.</p>

</ss1>
<ss1>
<st>
Computer-Aided Algorithmic Composition</st>
<p>

Computer-Aided Algorithmic Composition (CAAC, pronounced "sea-ack") is the implementation and use of <link xlink:type="simple" xlink:href="../884/479884.xml">
algorithmic composition</link> techniques in software. This label is derived from the combination of two labels, each too vague for continued use. The label "computer-aided composition" lacks the specificity of using generative algorithms. Music produced with notation or sequencing software could easily be considered computer-aided composition. The label "algorithmic composition" is likewise too broad, particularly in that it does not specify the use of a computer. The term <link xlink:type="simple" xlink:href="../818/4390818.xml">
computer-aided</link>, rather than computer-assisted, is used in the same manner as <link xlink:type="simple" xlink:href="../315/37315.xml">
Computer-Aided Design</link></p>

</ss1>
</sec>
<sec>
<st>
Machine Improvisation</st>

<p>

<indent level="1">

<it>See also: <link xlink:type="simple" xlink:href="../488/233488.xml">
Machine learning</link>, <link xlink:type="simple" xlink:href="../280/17458280.xml">
Machine listening</link>, <link xlink:type="simple" xlink:href="../164/1164.xml">
Artificial intelligence</link>,&nbsp;and <link>
Neural networks</link></it>
</indent>
Machine Improvisation uses computer algorithms to create <link xlink:type="simple" xlink:href="../772/88772.xml">
improvisation</link> on existing music materials. This is usually done by sophisticated recombination of musical phrases extracted from existing music, either live or pre-recorded. In order to achieve credible improvisation in particular style, machine improvisation uses <link xlink:type="simple" xlink:href="../488/233488.xml">
machine learning</link> and <link xlink:type="simple" xlink:href="../688/279688.xml">
pattern matching</link> algorithms to analyze existing musical examples. The resulting patterns are then used to create new variations "in the style" of the original music, developing a notion of stylistic reinjection. 
This is different from other improvisation methods with computers that use <link xlink:type="simple" xlink:href="../884/479884.xml">
algorithmic composition</link> to generate new music without performing analysis of existing music examples. </p>

<ss2>
<st>
Statistical style modeling</st>
<p>

Style modeling implies building a computational representation of the musical surface that captures important stylistic features from data.  Statistical approaches are used to capture the redundancies in terms of pattern dictionaries or repetitions, which are later recombined to generate new musical data. Style mixing can be realized by analysis of a database containing multiple musical examples in different styles.  Machine Improvisation builds upon a long musical tradition of statistical modeling that began with Hiller and Isaacson’s Illiac Suite in the 1950s and Xenakis’ uses of <link xlink:type="simple" xlink:href="../876/60876.xml">
Markov chains</link> and <link xlink:type="simple" xlink:href="../895/47895.xml">
stochastic processes</link>.  Modern methods include the use of <link xlink:type="simple" xlink:href="../209/18209.xml">
lossless data compression</link> for incremental parsing,  <link xlink:type="simple" xlink:href="../449/17905449.xml">
Prediction Suffix Tree</link> and <link xlink:type="simple" xlink:href="../648/28648.xml">
string searching</link> by factor oracle algorithm</p>

</ss2>
<ss2>
<st>
Uses of Machine Improvisation</st>
<p>

Machine Improvisation encourages musical creativity by providing automatic modeling and transformation structures for existing music. This creates a natural interface with the musician without need for coding musical algorithms. In live performance, the system re-injects  the musician's material in several different ways the, allowing a semantics-level representation of the session and a smart recombination and transformation of this material in real-time. In offline version, Machine Improvisation can be used to achieve style mixing, an approach inspired by Vannevar Bush's <link xlink:type="simple" xlink:href="../636/20636.xml">
memex</link> imaginary machine.</p>

</ss2>
<ss2>
<st>
Implementations</st>
<p>

Matlab implementation of the Factor Oracle machine improvisation can be found as part of <link xlink:type="simple" xlink:href="../113/9536113.xml">
Computer Audition</link> toolbox.</p>
<p>

OMax is a software environment developed in IRCAM. OMax uses OpenMusic and Max. It is based on researches on stylistic modeling carried out by Gerard Assayag and Shlomo Dubnov and on researches on improvisation with the computer by G. Assayag, M. Chemillier and G. Bloch (Aka the OMax Brothers) in the Ircam Music Representations group.</p>

</ss2>
<ss2>
<st>
Musicians working with machine improvisation</st>
<p>

Gerard Assayag (IRCAM, France),
Tim Blackwell (Goldsmiths College, Great Brittan),
George Bloch (Composer, France),
Marc Chemiller (IRCAM/CNRS, France),
Shlomo Dubnov (Composer, Israel / USA),
Mari Kimura (Julliard, New York City),
George Lewis (Columbia University, New York City), 
Bernard Lubat (Pianist, France), 
Joel Ryan (Institute of Sonology, Netherlands),
Michel Waisvisz (STEIM, Netherlands),
David Wessel (CNMAT, California),
Michael Young (Goldsmiths College, Great Brittan)</p>

</ss2>
</sec>
<sec>
<st>
Live coding</st>

<p>

<indent level="1">

<it>See also: <paradigm wordnetid="113804375" confidence="0.8">
<linguistic_relation wordnetid="113797142" confidence="0.8">
<inflection wordnetid="113803782" confidence="0.8">
<grammatical_relation wordnetid="113796779" confidence="0.8">
<link xlink:type="simple" xlink:href="../983/1699983.xml">
Interactive programming</link></grammatical_relation>
</inflection>
</linguistic_relation>
</paradigm>
</it>
</indent>
Live coding (sometimes known as 'interactive programming', 'on-the-fly programming', 'just in time programming') is the name given to the process of writing <link xlink:type="simple" xlink:href="../309/5309.xml">
software</link> in realtime as part of a <link xlink:type="simple" xlink:href="../515/224515.xml">
performance</link>. Historically, this technique has been around since <link xlink:type="simple" xlink:href="../457/7878457.xml">
computers</link> were used to produce early <link xlink:type="simple" xlink:href="../880/353880.xml">
computer art</link>, but recently it has been explored as a more rigorous alternative to laptop DJs who, live coders often feel, lack the charisma and pizzazz of <link xlink:type="simple" xlink:href="../284/38284.xml">
musicians</link> performing live.</p>
<p>

Generally, this practise stages a more general approach: one of interactive programming, of writing (parts of) programs while they run. Traditionally most computer music programs have tended toward the old write/compile/run model which evolved when computers were much less powerful. This approach has locked out code-level innovation by people whose programming skills are more modest. Some programs have gradually integrated real-time controllers and gesturing (for example, <link xlink:type="simple" xlink:href="../461/1692461.xml">
MIDI</link>-driven software synthesis and parameter control). Until recently, however, the musician/composer rarely had the capability of real-time modification of program code itself. This legacy distinction is somewhat erased by languages such as <link xlink:type="simple" xlink:href="../750/478750.xml">
ChucK</link>, <physical_entity wordnetid="100001930" confidence="0.8">
<structure wordnetid="104341686" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<building wordnetid="102913152" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<intellectual wordnetid="109621545" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<architecture wordnetid="102734725" confidence="0.8">
<synthesist wordnetid="110687231" confidence="0.8">
<link xlink:type="simple" xlink:href="../978/346978.xml">
SuperCollider</link></synthesist>
</architecture>
</causal_agent>
</intellectual>
</artifact>
</building>
</person>
</structure>
</physical_entity>
, and impromptu. </p>
<p>

<message wordnetid="106598915" confidence="0.8">
<information wordnetid="106634376" confidence="0.8">
<electronic_database wordnetid="106588511" confidence="0.8">
<lexical_database wordnetid="106638868" confidence="0.8">
<wordnet wordnetid="106639428" confidence="0.8">
<database wordnetid="106637824" confidence="0.8">
<link xlink:type="simple" xlink:href="../535/1290535.xml">
TOPLAP</link></database>
</wordnet>
</lexical_database>
</electronic_database>
</information>
</message>
, an ad-hoc conglomerate of artists interested in live coding was set up in 2003, and promotes the use, proliferation and exploration of a range of software, languages and techniques to implement live coding. This is a parallel and collaborative effort e.g. with research at the <link xlink:type="simple" xlink:href="../756/479756.xml">
Princeton Sound Lab</link>, the  <university wordnetid="108286163" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../754/42754.xml">
University of Cologne</link></university>
, and  Computational Arts Research Group at <university wordnetid="108286163" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../332/198332.xml">
Queensland University of Technology</link></university>
.</p>

</sec>
<sec>
<st>
 See also </st>

<p>

<table style="background:transparent; width:40%;" cellpadding="0" class=" multicol" cellspacing="0">
<row>
<col align="left" width="50%" valign="top">
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../906/1918906.xml">
Acousmatic art</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../463/83463.xml">
Chiptune</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../029/9530029.xml">
Comparison of audio synthesis environments</link></entry>
<entry level="1" type="bullet">

 <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<intellectual wordnetid="109621545" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<synthesist wordnetid="110687231" confidence="0.8">
<link xlink:type="simple" xlink:href="../998/149998.xml">
Csound</link></synthesist>
</causal_agent>
</intellectual>
</person>
</physical_entity>
</entry>
<entry level="1" type="bullet">

 <computer wordnetid="103082979" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<device wordnetid="103183080" confidence="0.8">
<machine wordnetid="103699975" confidence="0.8">
<digital_computer wordnetid="103196324" confidence="0.8">
<workstation wordnetid="104603399" confidence="0.8">
<link xlink:type="simple" xlink:href="../270/431270.xml">
Digital audio workstation</link></workstation>
</digital_computer>
</machine>
</device>
</instrumentality>
</artifact>
</computer>
</entry>
<entry level="1" type="bullet">

 <artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<device wordnetid="103183080" confidence="0.8">
<instrument wordnetid="103574816" confidence="0.8">
<link xlink:type="simple" xlink:href="../247/8247.xml">
Digital synthesizer</link></instrument>
</device>
</instrumentality>
</artifact>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../510/9510.xml">
Electronic music</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../512/11512.xml">
Fast Fourier Transform</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../516/13516.xml">
Human-computer interaction</link></entry>
<entry level="1" type="bullet">

 <technique wordnetid="105665146" confidence="0.8">
<know-how wordnetid="105616786" confidence="0.8">
<method wordnetid="105660268" confidence="0.8">
<link xlink:type="simple" xlink:href="../099/889099.xml">
Interactive music</link></method>
</know-how>
</technique>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../193/261193.xml">
Music information retrieval</link></entry>
</list>
</col>
<col align="left" width="50%" valign="top">
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../910/15736910.xml">
Music Macro Language</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../522/428522.xml">
Music notation software</link></entry>
<entry level="1" type="bullet">

 <faculty wordnetid="105650329" confidence="0.8">
<link xlink:type="simple" xlink:href="../510/127510.xml">
Music sequencer</link></faculty>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../374/2127374.xml">
New interfaces for musical expression</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../441/42441.xml">
Physical modeling</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../758/18935758.xml">
Sampling (music)</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../344/975344.xml">
sound synthesis</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../428/172428.xml">
Tracker</link></entry>
</list>
</col>
</row>
</table>
</p>

</sec>
<sec>
<st>
 References </st>
<p>

<reflist>
<entry id="1">
 <cite style="font-style:normal">Doornbusch, Paul.&#32;"<weblink xlink:type="simple" xlink:href="http://www.csse.unimelb.edu.au/dept/about/csirac/music/introduction.html">
The Music of CSIRAC</weblink>". <it>Melbourne School of Engineering, Department of Computer Science and Software Engineering</it>.</cite>&nbsp;</entry>
<entry id="2">
 <cite style="font-style:normal">Fildes, Jonathan&#32;(June 2008).&#32;"<weblink xlink:type="simple" xlink:href="http://news.bbc.co.uk/2/hi/technology/7458479.stm">
'Oldest' computer music unveiled</weblink>". <it>news.bbc.co.uk</it>. Retrieved on <link>
2008-06-17</link>.</cite>&nbsp;</entry>
</reflist>
</p>

</sec>
<sec>
<st>
 Further reading </st>

<p>

<list>
<entry level="1" type="bullet">

 Ariza, C. 2005. "Navigating the Landscape of Computer-Aided Algorithmic Composition Systems: A Definition, Seven Descriptors, and a Lexicon of Systems and Research." In <it>Proceedings of the International Computer Music Conference</it>. San Francisco: International Computer Music Association. 765-772. Internet: http://www.flexatone.net/docs/nlcaacs.pdf</entry>
<entry level="1" type="bullet">

 Ariza, C. 2005. <it>An Open Design for Computer-Aided Algorithmic Music Composition: athenaCL</it>. Ph.D. Dissertation, New York University. Internet: http://www.dissertation.com/book.php?method=ISBN&amp;book=1581122926</entry>
<entry level="1" type="bullet">

 Berg, P. 1996. "Abstracting the future: The Search for Musical Constructs" <it>Computer Music Journal</it> 20(3): 24-27.</entry>
<entry level="1" type="bullet">

 Supper, M. 2001. "A Few Remarks on Algorithmic Composition." <it>Computer Music Journal</it> 25(1): 48-53.</entry>
</list>
</p>

</sec>
<sec>
<st>
 External links </st>


<ss2>
<st>
Software environments</st>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.koncon.nl/downloads/ACToolbox/">
AC Toolbox</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://bolprocessor.sourceforge.net/">
Bol Processor</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://chuck.cs.princeton.edu/">
ChucK</weblink>, a strongly-timed, concurrent, and on-the-fly language</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.csounds.com/">
Csound</weblink> </entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.pawfal.org/fluxus/">
fluxus</weblink> livecoding and playing/learning environment for 3D graphics and games based on <programming_language wordnetid="106898352" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../119/28119.xml">
Scheme</link></programming_language>
</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://impromptu.moso.com.au/">
impromptu</weblink> a live-programming environment based on <programming_language wordnetid="106898352" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../119/28119.xml">
Scheme</link></programming_language>
</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.meapsoft.org/">
MEAPsoft</weblink> descriptor based audio segmentation and re-arrangement</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.nosuch.com/keykit">
KeyKit</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://recherche.ircam.fr/equipes/repmus/OMax/">
 OMax software</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.puredata.info/">
Pd</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://processing.org/">
Processing</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://supercollider.sourceforge.net/">
SuperCollider</weblink></entry>
</list>
</p>

</ss2>
<ss2>
<st>
Articles</st>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://home.comcast.net/~chtongyu/Thesis.html">
Computer Generated Music Composition</weblink> thesis by Chong Yu (MIT 1996)</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.essl.at/bibliogr/cac.html">
Computer-aided Composition</weblink> article by Karlheinz Essl (1991)</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://mediatheque.ircam.fr/articles/textes/Assayag04a/">
G. Assayag, S. Dubnov « Using Factor Oracles for machine Improvisation », Soft Computing, vol. 8, n° 9, Septembre, 2004</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1236474">
S. Dubnov et al. Using machine-learning methods for musical style modeling,  IEEE Computer, Oct. 2003</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://muse.jhu.edu/demo/leonardo_music_journal/v010/10.1lewis.html">
G. Lewis, Too Many Notes: Computers, Complexity and Culture in Voyager, Leonardo Music Journal 10 (2000) 33-39</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://journals.cambridge.org/action/displayIssue?jid=OSO&amp;volumeId=4&amp;issueId=02#">
S. Dubnov, Stylistic randomness: about composing NTrope Suite, Organised Sound, Volume 4 ,  Issue 2  (June 1999)</weblink></entry>
</list>
</p>

</ss2>
<ss2>
<st>
Archives</st>
<p>

<list>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.algorithmic.net">
algorithmic.net</weblink> - a lexicon of systems and research in computer aided algorithmic composition</entry>
</list>
</p>

</ss2>
<ss2>
<st>
Works composed by computers for human performance</st>
<p>

<list>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://emfinstitute.emf.org/exhibits/illiacsuite.html">
Illiac Suite</weblink> for string quartet, by Lejaren A. Hiller (1957)</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.koenigproject.nl">
Übung, 3 Asko Pieces, Beitrag</weblink> (amongst others) by G.M. Koenig</entry>
</list>
</p>

</ss2>
<ss2>
<st>
Computer-generated compositions performed by computers</st>
<p>

<list>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.essl.at/works/Lexikon-Sonate.html">
Lexikon-Sonate:</weblink> Karlheinz Essl's algorithmic composition environment</entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://us.metamath.org/mpegif/mmmusic.html">
Metamath Music</weblink> Music generated from mathematical proofs</entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.codesounding.org/indexeng.html">
CodeSounding</weblink>  Sonification of java source code structures, obtained by post-processing the source files. Runtime sounds are a function of how was structured the source code of the running program</entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.lvbsx.com">
Virtual Music Composer</weblink> This software works as a composer, not as a tool for composing</entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.robertinventor.com/software/tunesmithy/tune_smithying.htm">
Fractal Tune Smithy</weblink> Computer generated music based on a similar idea to the <curve wordnetid="113867641" confidence="0.8">
<line wordnetid="113863771" confidence="0.8">
<shape wordnetid="100027807" confidence="0.8">
<link xlink:type="simple" xlink:href="../959/46959.xml">
Koch snowflake</link></shape>
</line>
</curve>
, with many examples of tunes you can make</entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.brandmaier.de/alice/">
ALICE</weblink> A software that can improvise in real-time with a human player using an <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link>
Artificial_neural_network</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.ubu.com/sound/nechvatal.html">
"viral symphOny"</weblink> created using computer virus software by <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<intellectual wordnetid="109621545" confidence="0.8">
<traveler wordnetid="109629752" confidence="0.8">
<adult wordnetid="109605289" confidence="0.8">
<exile wordnetid="110071332" confidence="0.8">
<professional wordnetid="110480253" confidence="0.8">
<absentee wordnetid="109757653" confidence="0.8">
<educator wordnetid="110045713" confidence="0.8">
<creator wordnetid="109614315" confidence="0.8">
<composer wordnetid="109947232" confidence="0.8">
<theorist wordnetid="110706812" confidence="0.8">
<performer wordnetid="110415638" confidence="0.8">
<academician wordnetid="109759069" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<musician wordnetid="110339966" confidence="0.8">
<musician wordnetid="110340312" confidence="0.8">
<painter wordnetid="110391653" confidence="0.8">
<artist wordnetid="109812338" confidence="0.8">
<printmaker wordnetid="110475687" confidence="0.8">
<entertainer wordnetid="109616922" confidence="0.8">
<link xlink:type="simple" xlink:href="../404/5999404.xml">
Joseph Nechvatal</link></entertainer>
</printmaker>
</artist>
</painter>
</musician>
</musician>
</causal_agent>
</academician>
</performer>
</theorist>
</composer>
</creator>
</educator>
</absentee>
</professional>
</exile>
</adult>
</traveler>
</intellectual>
</person>
</physical_entity>
</entry>
</list>
</p>


</ss2>
</sec>
</bdy>
</method>
</know-how>
</technique>
</article>
