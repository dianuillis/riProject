<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 22:32:53[mciao0828] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<know-how  confidence="0.8" wordnetid="105616786">
<event  confidence="0.8" wordnetid="100029378">
<rule  confidence="0.8" wordnetid="105846932">
<method  confidence="0.8" wordnetid="105660268">
<act  confidence="0.8" wordnetid="100030358">
<psychological_feature  confidence="0.8" wordnetid="100023100">
<procedure  confidence="0.8" wordnetid="101023820">
<activity  confidence="0.8" wordnetid="100407535">
<algorithm  confidence="0.8" wordnetid="105847438">
<header>
<title>Conceptual clustering</title>
<id>6979740</id>
<revision>
<id>216252318</id>
<timestamp>2008-05-31T20:29:55Z</timestamp>
<contributor>
<username>DOI bot</username>
<id>6652755</id>
</contributor>
</revision>
<categories>
<category>Learning methods </category>
<category>Machine learning</category>
<category>Classification algorithms</category>
</categories>
</header>
<bdy>

<b>Conceptual clustering</b> is a <link xlink:type="simple" xlink:href="../488/233488.xml">
machine learning</link> paradigm for <link xlink:type="simple" xlink:href="../497/233497.xml">
unsupervised classification</link> developed mainly during the 1980s.  It is distinguished from ordinary <link xlink:type="simple" xlink:href="../675/669675.xml">
data clustering</link> by generating a <b>concept description</b> for each generated class.  Most conceptual clustering methods are capable of generating hierarchical category structures;  see <link xlink:type="simple" xlink:href="../717/72717.xml">
Categorization</link> for more information on hierarchy.  Conceptual clustering is closely related to <link xlink:type="simple" xlink:href="../845/313845.xml">
formal concept analysis</link> (FCA), <link xlink:type="simple" xlink:href="../602/232602.xml">
decision tree</link> learning, and <link xlink:type="simple" xlink:href="../681/871681.xml">
mixture model</link> learning.

<sec>
<st>
 Conceptual clustering vs. data clustering </st>
<p>

Conceptual clustering is obviously closely related to data clustering; however, in conceptual clustering it is not only the inherent structure of the data that drives cluster formation, but also the <link xlink:type="simple" xlink:href="../412/4005412.xml">
description language</link> which is available to the learner.  Thus, a statistically strong grouping in the data may fail to be extracted by the learner if the prevailing concept description language is incapable of describing that particular <it>regularity</it>.  In most implementations, the description language has been limited to feature <link xlink:type="simple" xlink:href="../959/74959.xml">
conjunction</link>, although in COBWEB (see "" below), the feature language is <link xlink:type="simple" xlink:href="../934/22934.xml">
probabilistic</link>.</p>

</sec>
<sec>
<st>
 List of published algorithms </st>
<p>

A fair number of algorithms have been proposed for conceptual clustering. Some examples are given below:</p>
<p>

<list>
<entry level="1" type="bullet">

 CLUSTER/2 (Michalski &amp; Stepp 1983)</entry>
<entry level="1" type="bullet">

 COBWEB (Fisher 1987)</entry>
<entry level="1" type="bullet">

 CYRUS (Kolodner 1983)</entry>
<entry level="1" type="bullet">

 GALOIS (Carpineto &amp; Romano 1993), </entry>
<entry level="1" type="bullet">

 GCF (Talavera &amp; BÃ©jar 2001)</entry>
<entry level="1" type="bullet">

 INC (Hadzikadic &amp; Yun 1989)</entry>
<entry level="1" type="bullet">

 ITERATE (Biswas, Weinberg &amp; Fisher 1998), </entry>
<entry level="1" type="bullet">

 LABYRINTH (Thompson &amp; Langley 1989)</entry>
<entry level="1" type="bullet">

 SUBDUE (Jonyer, Cook &amp; Holder 2001). </entry>
<entry level="1" type="bullet">

 UNIMEM (Lebowitz 1987)</entry>
<entry level="1" type="bullet">

 WITT (Hanson &amp; Bauer 1989), </entry>
</list>
</p>
<p>

More general discussions and reviews of conceptual clustering can be found in the following publications:</p>
<p>

<list>
<entry level="1" type="bullet">

 Michalski (1980)</entry>
<entry level="1" type="bullet">

 Gennari, Langley, &amp; Fisher (1989)</entry>
<entry level="1" type="bullet">

 Fisher &amp; Pazzani (1991)</entry>
<entry level="1" type="bullet">

 Fisher &amp; Langley (1986)</entry>
<entry level="1" type="bullet">

 Stepp &amp; Michalski (1986)</entry>
</list>
</p>

</sec>
<sec>
<st>
 Example: A basic conceptual clustering algorithm</st>
<p>

This section discusses the rudiments of the conceptual clustering algorithm COBWEB.  There are many other algorithms using different heuristics and "<link xlink:type="simple" xlink:href="../665/8964665.xml">
category goodness</link>" or category evaluation criteria, but COBWEB is one of the best known.  The reader is referred to the <link xlink:type="simple" xlink:href="#xpointer(//*[./st=%22References%22])">
bibliography</link> for other methods.</p>

<ss1>
<st>
Knowledge representation</st>
<p>

The COBWEB data structure is a hierarchy (tree) wherein each node represents a given <it>concept</it>.  Each concept represents a set (actually, a <link xlink:type="simple" xlink:href="../303/305303.xml">
multiset</link> or bag) of  objects, each object being represented as a binary-valued property list. The data associated with each tree node (i.e., concept) are the integer property counts for the objects in that concept.  For example (see figure), let a concept <math>C_1</math> contain the following four objects (repeated objects being permitted). 
<image width="450 px" src="Concept_tree.png" type="thumb">
<caption>

Sample COBWEB knowledge representation,  probabilistic concept hierarchy.  Blue boxes list actual objects, purple boxes list attribute counts.  See text for details. <b>Note</b>: The diagram is intended to be illustrative only of COBWEB's data structure; it does not necessarily represent a "good" concept tree, or one  that COBWEB would actually construct from real data.
</caption>
</image>

<list>
<entry level="1" type="number">

[1 0 1]</entry>
<entry level="1" type="number">

[0 1 1]</entry>
<entry level="1" type="number">

[0 1 0]</entry>
<entry level="1" type="number">

[0 1 1]</entry>
</list>

The three properties might be, for example, [is_male, has_wings, is_nocturnal].  Then what is stored at this concept node is the property count [1 3 3], indicating that 1 of the objects in the concept is male, 3 of the objects have wings, and 3 of the objects are nocturnal.  The concept <it>description</it> is the category-conditional probability (likelihood) of the properties at the node.  Thus, given that an object is a member of category (concept) <math>C_1</math>, the likelihood that it is male is <math>1/4 = 0.25</math>.  Likewise, the likelihood that the object has wings and  likelihood that the object is nocturnal  are both <math> 3/4 = 0.75</math>.  The concept description can therefore simply be given as [.25 .75 .75], which corresponds to the <math>C_1</math>-conditional feature likelihood, i.e., <math>p(x|C_1) = (0.25, 0.75, 0.75)</math>.</p>
<p>

The figure to the right shows a concept tree with five concepts.  <math>C_0</math>  is the root concept, which contains all ten objects in the data set.  Concepts <math>C_1</math> and <math>C_2</math> are the children of <math>C_0</math>, the former containing four objects, and the later containing six objects.  Concept <math>C_2</math> is also the parent of concepts <math>C_3</math>, <math>C_4</math>, and <math>C_5</math>, which contain three, two, and one object, respectively.  Note that each parent node (relative superordinate concept) contains all the objects contained by its child nodes (relative subordinate concepts).  In Fisher's (1987) description of COBWEB, he indicates that only the total attribute counts (not conditional probabilities, and not object lists) are stored at the nodes.  Any probabilities are computed from the attribute counts as needed.</p>

<ss2>
<st>
The COBWEB language</st>
<p>

The description language of COBWEB is a "language" only in a loose sense, because being fully probabilistic it is capable of describing any concept.  However, if constraints are placed on the probability ranges which concepts may represent, then a stronger language is obtained.  For example,  we might permit only concepts wherein at least one probability differs from 0.5 by more than <math>\alpha</math>.  Under this constraint, with <math>\alpha=0.3</math>, a concept such as [.6 .5 .7] could not be constructed by the learner;  however a concept such as [.6 .5 .9] would be accessible because at least one probability differs from 0.5 by more than <math>\alpha</math>.  Thus, under constraints such as these, we obtain something like a traditional concept language.  In the limiting case where <math>\alpha=0.5</math> for every feature, and thus every probability in a concept must be 0 or 1, the result is a feature language base on conjunction; that is, every concept that can be represented can then be described as a conjunction of features (and their negations), and concepts that cannot be described in this way cannot be represented.</p>

</ss2>
</ss1>
<ss1>
<st>
Evaluation criterion</st>
<p>

In Fisher's (1987) description of COBWEB, the measure he uses to evaluate the quality of the hierarchy is Gluck and Corter's (1985) <link xlink:type="simple" xlink:href="../665/8964665.xml">
category utility</link> (CU) measure, which he re-derives in his paper.   The motivation for the measure is highly similar to the "<link xlink:type="simple" xlink:href="../527/467527.xml">
information gain</link>" measure introduced by Quinlan for decision tree learning.  It has previously been shown that the CU for feature-based classification  is the same as the <link xlink:type="simple" xlink:href="../282/427282.xml">
mutual information</link>  between the feature variables and the class variable (Gluck &amp; Corter, 1985; Corter &amp; Gluck, 1992), and since this measure is much better know, we proceed here with mutual information as the measure of category "goodness".</p>
<p>

What we wish to evaluate is the overall utility of grouping the objects into a particular hierarchical categorization structure.  Given a set of possible classification structures, we need to determine whether one is better than another.</p>

</ss1>
<ss1>
<st>
Incremental structure learning</st>

</ss1>
<ss1>
<st>
Order dependence</st>


</ss1>
</sec>
<sec>
<st>
External links</st>
<p>

<list>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www-lsi.upc.es/~talavera/conceptual-clustering.html">
Bibliography of conceptual clustering</weblink></entry>
</list>
</p>

</sec>
<sec>
<st>
 References </st>


<p>

<list>
<entry level="1" type="bullet">

 <cite style="font-style:normal">Biswas, G.; Weinberg, J. B.; Fisher, Douglas H.&#32;(1998).&#32;"Iterate: A conceptual clustering algorithm for data mining". <it>IEEE Transactions on Systems, Man, and Cybernetics, Part C: Applications and Reviews</it>&#32;<b>28</b>: 100â111.</cite>&nbsp;</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <cite style="font-style:normal">Carpineto, C.; Romano, G.&#32;(1993). "Galois: An order-theoretic approach to conceptual clustering".&#32;<it>Proceedings of 10th International Conference on Machine Learning, Amherst</it>: 33â40.</cite>&nbsp;</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <cite style="font-style:normal">Fisher, Douglas H.&#32;(1987).&#32;"Knowledge acquisition via incremental conceptual clustering". <it>Machine Learning</it>&#32;<b>2</b>: 139â172. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1007%2FBF00114265">
10.1007/BF00114265</weblink>.</cite>&nbsp;</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <cite style="font-style:normal">Fisher, Douglas H.; Langley, Patrick W.&#32;(1986). "Conceptual clustering and its relation to numerical taxonomy".&#32;Gale, W. A. (Ed.)&#32;<it>Artificial Intelligence and Statistics</it>: 77â116, Reading, MA:&#32;Addison-Wesley.</cite>&nbsp;</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <cite style="font-style:normal">Fisher, Douglas H.; Pazzani, Michael J.&#32;(1991). "Computational models of concept learning".&#32;Fisher, D. H.; Pazzani, M. J.; Langley, P. (Eds.)&#32;<it>Concept Formation: Knowledge and Experience in Unsupervised Learning</it>: 3â43, San Mateo, CA:&#32;Morgan Kaufmann.</cite>&nbsp;</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <cite style="font-style:normal">Gennari, John H.; Langley, Patrick W.; Fisher, Douglas H.&#32;(1989).&#32;"Models of incremental concept formation". <it>Artificial Intelligence</it>&#32;<b>40</b>: 11â61. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1016%2F0004-3702%2889%2990046-5">
10.1016/0004-3702(89)90046-5</weblink>.</cite>&nbsp;</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <cite style="font-style:normal">Hanson, S. J.; Bauer, M.&#32;(1989).&#32;"Conceptual clustering, categorization, and polymorphy". <it>Machine Learning</it>&#32;<b>3</b>: 343â372. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1007%2FBF00116838">
10.1007/BF00116838</weblink>.</cite>&nbsp;</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <cite style="font-style:normal">Jonyer, I.; Cook, D. J.; Holder, L. B.&#32;(2001).&#32;"Graph-based hierarchical conceptual clustering". <it>Journal of Machine Learning Research</it>&#32;<b>2</b>: 19â43. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1162%2F153244302760185234">
10.1162/153244302760185234</weblink>.</cite>&nbsp;</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <cite style="font-style:normal">Lebowitz, M.&#32;(1987).&#32;"Experiments with incremental concept formation". <it>Machine Learning</it>&#32;<b>2</b>: 103â138. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1007%2FBF00114264">
10.1007/BF00114264</weblink>.</cite>&nbsp;</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <cite style="font-style:normal">Michalski, R. S.&#32;(1980).&#32;"Knowledge acquisition through conceptual clustering: A theoretical framework and an algorithm for partitioning data into conjunctive concepts". <it>International Journal of Policy Analysis and Information Systems</it>&#32;<b>4</b>: 219â244.</cite>&nbsp;</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <cite style="font-style:normal">Michalski, R. S.; Stepp, R. E.&#32;(1983). "Learning from observation: Conceptual clustering".&#32;Michalski, R. S.; Carbonell, J. G.; Mitchell, T. M. (Eds.)&#32;<it>Machine Learning: An Artificial Intelligence Approach</it>: 331â363, Palo Alto, CA:&#32;Tioga.</cite>&nbsp;</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <cite style="font-style:normal">Stepp, R. E.; Michalski, R. S.&#32;(1986). "Conceptual clustering: Inventing goal-oriented classifications of structured objects".&#32;Michalski, R. S.; Carbonell, J. G.; Mitchell, T. M. (Eds.)&#32;<it>Machine Learning: An Artificial Intelligence Approach</it>: 471â498, Los Altos, CA:&#32;Morgan Kaufmann.</cite>&nbsp;</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <cite style="font-style:normal">Talavera, L.; BÃ©jar, J.&#32;(2001).&#32;"Generality-based conceptual clustering with probabilistic concepts". <it>IEEE Transactions on Pattern Analysis and Machine Intelligence</it>&#32;<b>23</b>: 196â206. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1109%2F34.908969">
10.1109/34.908969</weblink>.</cite>&nbsp;</entry>
</list>
</p>



</sec>
</bdy>
</algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</method>
</rule>
</event>
</know-how>
</article>
