<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 22:38:14[mciao0825] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<work  confidence="0.8" wordnetid="104599396">
<product  confidence="0.8" wordnetid="104007894">
<creation  confidence="0.8" wordnetid="103129123">
<artifact  confidence="0.8" wordnetid="100021939">
<book  confidence="0.8" wordnetid="106410904">
<publication  confidence="0.8" wordnetid="106589574">
<header>
<title>The Nature of Rationality</title>
<id>6980744</id>
<revision>
<id>226438448</id>
<timestamp>2008-07-18T12:53:42Z</timestamp>
<contributor>
<username>Edward</username>
<id>4261</id>
</contributor>
</revision>
<categories>
<category>Philosophy of Robert Nozick</category>
<category>Philosophy books</category>
<category>1993 books</category>
</categories>
</header>
<bdy>

<b><it>The Nature of Rationality</it></b> is an exploration of practical rationality written by <philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../275/26275.xml">
Robert Nozick</link></philosopher>
 and published in 1993. It views human rationality as an evolutionary adaptation. Its delimited purpose and function may be responsible for biases and blind spots, possibly accounting for instance for philosophy's difficulty with the perennial questions, so remote from the exigencies that drive natural selection. He offers a reformulation of the decision theory that was developed in the twentieth century to explain rational action. It should include the symbolic meaning of actions as well as a new rule of rational decision that maximizes decision value. These have implications for long-standing issues such as the Prisoner's Dilemma and for Newcomb's Problem. His proposal about rational belief has an internalist element of support by reasons that make the belief credible, and an exernalist element of generation by a process that reliably produces true beliefs. Rational belief has an intellectual component, for one should not believe any statement less credible than some incompatible alternative. But also it has a practical component, for one should believe a statement only if the expected utility (or decision value) of doing so is greater than that of not believing it.  
<sec>
<st>
 How to Do Things with Principles </st>

<ss1>
<st>
 Intellectual Functions </st>
<p>

Principles and other general theories have an interpersonal intellectual function of <it>justification to another</it>, both because of the face appeal of the principle and because the principle recruits other accepted cases covered by the principle to support a proposed position in the case at hand. Principles also guide one's self to correct judgment in a particular case and to control for personal bias. 
</p>
</ss1>
<ss1>
<st>
Interpersonal Functions </st>
<p>

A person's principles reassure others that he will usually get past temptations, and they help one's self to overcome them. With people close to us we can rely on their affection, but with others more distant we rely on their principled behavior. Principles constitute a form of binding, including reputation effects that occur from announcing principles, and either adhering to them or not. What's most reassuring to others is the subject's believing that the principle is correct, not just seeming so. This kind of commitment to principles makes possible an expanded range of interactions with others and cooperative activities.
</p>
</ss1>
<ss1>
<st>
 Personal Functions </st>
<p>

Principles are a way to define one's own identity: "I am a person with <it>these</it> principles." (Nozick developed the logic of such self-definition in the Closest-Continuer theory of personal identity in <work wordnetid="104599396" confidence="0.8">
<product wordnetid="104007894" confidence="0.8">
<creation wordnetid="103129123" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<book wordnetid="106410904" confidence="0.8">
<publication wordnetid="106589574" confidence="0.8">
<link xlink:type="simple" xlink:href="../633/6980633.xml">
Philosophical Explanations</link></publication>
</book>
</artifact>
</creation>
</product>
</work>
. Also following a principle through time makes for greater integration and coherence in one's life. Principles enable one's current self to count on one's future self's principled compliance. From an evolutionary perspective, principles act as an exclusionary or filtering device, saving decision effort and calculating time. 
</p>
</ss1>
<ss1>
<st>
 Overcoming Temptations </st>
<p>

Increasing sophistication about incorporating probability calculations into decision making creates a specter of <it>double discounting</it> of time. We learned from our ancestors to "discount" for the future, inheriting brute <link xlink:type="simple" xlink:href="../980/253980.xml">
time preference</link>. But then if we explicitly discount in our probabilistic calculations we are double discounting, "and surely that is too much." Principles help with this modern dilemma, because they link us (now) to moments of our lives that are more representative in purely aggregative terms. The period of temptation is shorter than the period that precedes it and the one that follows. The principled preference is the stable one, the temptation a preference of a nonrepresentative moment. So principles help maximize utility over a lifetime. They enable an action now to stand for or symbolize actions done at those other representative moments. In this way we can alter our utilities. And the law of effect can add its weight, as adhering to the principle this time makes future adherence more likely.</p>

</ss1>
<ss1>
<st>
 Sunk Costs </st>
<p>

A sunk cost of a concert ticket (say) is a cost that has been already been paid. If you now prefer to stay at home, you should stay at home, according to "the economists' doctrine" that sunk costs should be ignored. Though it may be a correct rule for maximizing monetary profits, Nozick rejects it because sunk costs that take the form of commitments to others or to ourselves are rationally clung to, as doing so contributes to our self-esteem and indeed our self-definition. Here he sides with the evolutionary psychologists rather than the economists. Our tendency to honor sunk costs is adaptive and was selected for.</p>

</ss1>
<ss1>
<st>
 Symbolic utility </st>
<p>

Symbolic utility is the (subjective) utility that an action or belief may have intrinsically or for its own sake. This may be because of its expressing or representing or meaning something. In any case it is utility that attaches to the action or belief itself, not to its further outcomes. He defends the rationality of living with symbolic meanings and imputing utilities in accordance with them. Perceiving other people and the world generally through a lens of values and their symbolic meanings "puts us on the side" of those values: "Being ethical is among our most effective ways of symbolizing (a connection to) what we value most highly." Even when what we value is causally or conceptually impossible, we may be able to achieve it symbolically. Nozick favors a "downward" conception of symbolic utility, from the patterns of social meanings that anthropologists delineate to their impact on individuals who make decisions that give some weight to symbolic utility.</p>
<p>

Influenced by the <link xlink:type="simple" xlink:href="../081/2289081.xml">
symbolic anthropology</link> of <scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../989/655989.xml">
Clifford Geertz</link></scientist>
, Nozick's mature philosophy in <it>The Nature of Rationality</it> conceives human beings as creatures of culture whose tracking of value draws upon their culture's store of symbols for making sense of their lives. This view arguably should be read back into the exploratory account of objective value in <it>Philosophical Explanations</it> (1981), favoring the fifth of five theories of objective value distinguished there, realizationism: "We choose or determine that there be values, that they exist, but their character is independent of us." The  'we' that chooses here can be understood by reference to Nozick's anthropological turn, as designating a cultural <it>we</it>, and the 'us' of which the chosen values are independent can be understood as referring to members of the culture individually. When a criminal fails to track value and "gets away with it", Nozick argues in <it>Philosophical Explanations</it> that he nevertheless suffers a <it>value sanction</it>. This can now be understood as the criminal's utility profile being dragged down by negative symbolic utility. It may <it>not</it> be dragged down, the criminal showing every ethnographic sign of unsanctioned flourishing. But detaching oneself from one's culture's values is typically not a trivial exercise. Furthermore, when the criminal is caught and jailed, the punishment sends a message of reduced value. A legal system's nuanced judgments in legislation and judicial decision are one way in which a society studies the independent nature of the values that it created (on the realizationist account).</p>

</ss1>
<ss1>
<st>
 Teleological Devices </st>
<p>

Principles are transmission devices for probability (as in scientific laws) and for utility (as in principles that help overcome temptation). The teleological device of principles may not be suited to every purpose. For instance, they may be less helpful in legislative contexts where compromise is essential than in judicial contexts in which principles about precedent (etc.) are vital. Moreover what principles express about us may be as important as their function: "Principles thus might have high utility for us, not because of what their use leads to, but because of what that use symbolizes and expresses."</p>

</ss1>
</sec>
<sec>
<st>
 Decision Value </st>

<p>

Nozick sees symbolic utility as having implications for decision theory's idea of <link xlink:type="simple" xlink:href="../803/736803.xml">
expected utility</link>, which is oriented exclusively towards outcomes. He replaces expected utility with <it>decision value</it>, which is the weighted sum of expected and symbolic utility. </p>

<ss1>
<st>
 Newcomb's Problem </st>
<p>

More precisely, decision value is the weighted sum of symbolic utility and two replacements for expected utility. 
Expected utility is factored into the weighted sum of (1) purely probabilistic expected utility, or what Nozick calls "evidential expected utility"; and (2) causal expected utility, which calculates the probabilities of outcomes conditional exclusively upon what the agent can make happen in the choice situation. 
This further factoring informs his approach to <link xlink:type="simple" xlink:href="../012/66012.xml">
Newcomb's Problem</link>, calling upon the rational agent to switch between purely probabilistic and causal/probabilistic reasoning depending on whether there is much to gain by reasoning in causal/probabilistic terms ("taking both boxes") or reasoning in purely probabilistic terms (taking only the opaque box that may have a million dollars inside). If there is almost a million dollars in the transparent box, take both boxes; if there is only a  penny in the transparent box, take only the opaque box. Both of these situations have the formal structure of Newcomb's Problem, but they differ in their "cash value" from a decision-value perspective.   </p>

</ss1>
<ss1>
<st>
 Prisoner's Dilemma </st>

<p>

His approach to the <link xlink:type="simple" xlink:href="../717/43717.xml">
Prisoner's Dilemma</link> turns on the  factoring that gives independent weight to symbolic utility, as it implies the rationality of taking into account utilities other than the expected utilities in the payoff matrix for the PD, notably the symbolic utility of expressing oneself as a cooperative person (by choosing the "optimal" action of doing what's best for both prisoners collectively, instead of the "dominant" action of doing what's best for me whatever the other prisoner decides.) The utility profile of someone whose construction of personal identity includes a considerably weighted <it>we</it>, in the sense of <work wordnetid="104599396" confidence="0.8">
<product wordnetid="104007894" confidence="0.8">
<creation wordnetid="103129123" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<book wordnetid="106410904" confidence="0.8">
<publication wordnetid="106589574" confidence="0.8">
<link>
The Examined Life</link></publication>
</book>
</artifact>
</creation>
</product>
</work>
, will reflect the weight of symbolic utility, as when childless democrats vote for a school-tax law that harms their purchasing power because doing so expresses their society's (<it>our</it>) commitment to education. Childless minimal-state citizens by contrast would have no such place in their utility profiles, so they would be irrational to bind themselves to such a law, barring the absurd <it>demoktesis</it> arrangement described in <link xlink:type="simple" xlink:href="../930/852930.xml">
Anarchy.State, and Utopia</link>. Nozick admits that it would be nice to reach a sharper result than that the cooperative action will be performed if the causal, evidential, and symbolic utilities are just so. He suggests a weak assumption that each should expect the other player to behave as he himself does, this assumption to be fed into the EEU component.</p>

</ss1>
<ss1>
<st>
 Finer Distinctions: Consequences and Goals </st>
<p>

Nozick suggests that decision theory's undifferentiated notion of "causal influence" should be replaced by finer distinctions between bringing about and letting happen, intending and foreseeing (the principle of double effect), and so forth. Furthermore these distinctions might be seen not as dichotomies but as arrayed on two dimensions, importance (causing more important that not preventing) and robustness (intending something more robust than foreseeing it as a possible outcome).</p>

</ss1>
</sec>
<sec>
<st>
 Rational Belief </st>
<p>

Nozick explores the theme, "Reasons without reliability seem empty, reliability without reasons seems blind." In these terms he accuses decision theory of being blind, because an action might maximize expected utility without having been   arrived at rationally. He infers that an expected-utility or DV formula marks an action as best, but not necessarily as rational. A rational action must in addition be generated by a process that tends to produce the best actions, the ones with maximal DV. A rational belief should be understood in similar terms. If believing the truth is the goal (comparable to maximizing utility), a rational belief would be arrived at by a process that reliably yields true beliefs. </p>

<ss1>
<st>
 Cognitive Goals </st>
<p>

Nozick speculates that our original interest in truth was instrumentally based. Truths serve us better than falsehoods. This doesn't quite mean that William James was right in saying that truth is what works. Serviceability presents the value of truth, not its nature. Truth is whatever underlies and explains serviceability. He reinforces this idea with a distinction between (1) the proposition that <it>p</it> is the rational thing to believe, and (2) believing <it>p</it> is the rational thing to do. He considers a mother with courtroom evidence that her son has committed a grave crime, evidence convincing to everyone else but such that her life would be miserable if she believed it. A Bayesian analysis might show that she should arrive at a different conclusion than the others, knowing more about her son than they do and so starting with a different prior probability. But this difference might be based simply upon her love for the son and unwillingness to believe that he could be guilty. For Nozick she would be rational in the sense of (2), but not of (1). Rational belief, as opposed to doing belief rationally, might be fostered by adopting a principle to believe only what the evidence shows to be true. "Believing a particular truth comes to have a symbolic utility not tied to <it>its</it> actual consequences.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref></p>

</ss1>
<ss1>
<st>
 Responsiveness to Reasons </st>
<p>

Rationality is not simply any kind of instrumentality, but rather it requires a certain type of instrument, namely, reasons and reasoning. If a procedure is reliable for arriving at truth, reasons and reasoning must contribute to the procedure's reliability. They will do so not only by supporting a hypothesis but also by undercutting it; there are reasons for, and reasons against. Nozick proposes a neural network model of reasons for and against, in which a structure of "nodes" is affected by aggravators and undercutters to reinforce or weaken the connections between nodes.
</p>
</ss1>
<ss1>
<st>
 Rules of Rationality </st>
<p>

The rules for rational belief may not comprise a small set that might be consciously used. Rather, the theory of the rule-governed process might be given by a computer program that simulates that process, or more radically by a process in which no rules are symbolically represented, the "rule" emerging as a regularity of behavior of a parallel distributed processing system whose matrix of weights determines activation of output or intermediate vectors modified repeatedly by some error-correction rule. (Nozick remarks that philosophers will become "technologically obsolescent"   if these computer models provide the theory of the reliable processes for arriving at belief.) One component of such a system would be Bayes' Theorem, derived from the axioms of probability theory, stating what the probability of a hypothesis <it>h</it> on evidence <it>e</it> should depend upon. Nozick argues for a "causalized" version of Bayes' Theorem that replaces the original version's purely conditional probabilities by probabilized subjunctives: not "h, given e", but "if h were true, then e would be true". Eventually arrived at is a network that incorporates a weighting of many factors --- including Bayesian probabilities, explanatory value (as represented by the causalized Bayesian formula), Popperian methodological maxims, and an assessment of undercuttings. These feed forward into a <it>credibility value</it> for a statement <it>h</it>, which figures in rules for rational belief such as "Do not believe <it>h</it> if some alternative statement incompatible with <it>h</it> has a higher credibility value than <it>h</it> does." This rule reflects the intellectual component of rational belief. Other rules would draw out the practical component by bringing decision value to bear: "Believe (an admissible) <it>h</it> only if the decision-value of believing <it>h</it> is at least as great as the decision-value of having no belief about <it>h</it>. 
</p>
</ss1>
<ss1>
<st>
 Belief </st>
<p>

Nozick thinks it's necessary to believe statements or propositions. He parts ways with radical Bayesians who, following Carnap, would simply assign probabilities (degrees of belief) to each and every statement without definitely believing any one, acting upon these probabilities "by (perhaps) maximizing expected utility". He doubts that radical Bayesianism can be formulated coherently, Consider the prime agument of the Bayesian, the "Dutch book argument" that belief should satisfy the axioms of the probability calculus. If degrees of belief represent willingness to bet at certain odds, and the degrees of belief do not satisfy the probability axioms, then the person will be willing to enter into a series of bets leading to no gain or even loss. Nozick replies: "But for this argument to work, the person must believe that she is facing such and such a betting situation; if she does not, she will not bet or behave appropriately." Nozick also rejects the other extreme presented by Isaac Levi, a critic of radical Bayesianism, who maintains that beliefs function as a standard of serious possibility. Nozick wends his way between these extremes with what he calls "radical contextualism": A belief excludes possibilities in a type of context.</p>

</ss1>
<ss1>
<st>
 Bias </st>
<p>

Because there is a tendency to overestimate the likelihood of a hypothesis in the absence of procedures designed to call up and consider countervailing evidence, assessment of a possible belief should always invoke such procedures. There are two kinds of bias. First-level bias is uneven application of existing standards. Second-level bias is bias in the selection of standards. Nozick discusses the latter in connection with admission of women candidates to graduate school, and membership conditions for inclusion within the literary canon.</p>

</ss1>
</sec>
<sec>
<st>
Evolutionary Reasons</st>
<p>

Believing <it>h</it> for reason <it>r</it> will be conducive to reaching our cognitive goal of true belief only when there is some connection between the truth of<it> r</it> and the truth of<it> h</it>. Nozick inquires here into the nature of this connection.
</p>
<ss1>
<st>
 Reasons and Facts </st>
<p>

The a priori view about this connection is that the faculty of reason can apprehend it. The factual view is that there is a contingent factual relation between <it>h</it> and the reason <it>r</it> that is evidence for it. Nozick combines the two views. In addition to the factual connection, the contents of <it>r</it> and <it>h</it> stand in a certain "structural connection that appears to us strikingly to make <it>h</it> (more) believable given <it>r</it>." There is a factual connection, and there was selection among our ancestors for that kind of connection seeming valid. (This is different from saying that acting on the factual connection is hard-wired, or instilled by operant conditioning.) The evolutionary account is supplemented by the neural-net model described above. Noticed factual connections are reflected in changing linkages and weights within the network, so "we are not limited to just the reasons that evolution has installed."
</p>
</ss1>
<ss1>
<st>
 Fitness and Function </st>
<p>

Nozick views an attribution of greater fitness as an existential quantification: there exists some heritable phenotypic feature F such that F explains (by causing) the greater reproductive success of organism A over organism B in environment E. The trait F always works through intermediate general functions G such as evading predators, etc.
Nozick combines theories of function from Nagel and Wright: Z is a function of X when Z is a consequence of X, and X's producing Z is itself the goal-state of some homeostatic mechanism (satisfying the Nagel analysis), and X was produced or maintained by this homeostatic mechanism M. He recommends this account as explaining why junk DNA doesn't have the function of doing nothing: junk DNA wasn't shaped by a homeostatic process to do nothing.
</p>
</ss1>
<ss1>
<st>
 Rationality's Function </st>
<p>

The function of "believing or acting for reasons" will be some effect this has that some underlying homeostatic mechanism "aims at" its having. The function of rationality will depend on what homeostatic mechanisms shaped us to act and believe on the basis of reasons. The fundamental homeostatic mechanism is the evolutionary process operating through natural selection. The second homeostatic mechanism comprises the processes by which societies mold their members. Organisms may be devices shaped to reproduce genes, as in Dawkins' selfish-gene view, but rationality is shaped to serve a level above the organism, the level of institutions.</p>

</ss1>
</sec>
<sec>
<st>
Instrumental Rationality and Its Limits</st>

<ss1>
<st>
 Is instrumental rationality enough? </st>
<p>

The instrumental notion of rationalty can be formulated in decision-theoretic terms within the framework of causal decision theory, whose notion of probabilistic causal connection captures the means-end connection. Instrumental rationality is within the intersection of all theories of rationality, "and perhaps nothing else is". But there are other legitimate modes of rationality. Indeed instrumental rationality can come to have intrinsic value --- "See John Dewey on means becoming ends." Moreover instruments can become extensions of ourselves, parts of our identity and being --- "a theme emphasized by Heidegger." </p>
<p>

Nozick's case for decision value takes rationality beyond the simply instrumental. Noninstrumental factors are included in his two-stage theory of rational belief --- not in the first stage, which pertains to credibility value, but in the second stage, which assesses the decision value of believing a candidate statement.</p>

</ss1>
<ss1>
<st>
 Rational Preferences </st>
<p>

One step towards a theory of the substantive rationality of desires and goals ("one tiny step beyond Hume") is taken by adopting the standard Von Neumann-Morgenstern conditions, such as that preferences be transitive, etc. Decision theory takes this step. "It does not say that any individual preference is irrational, but does say that a group of them together can be." A second step is that a person should prefer a valid structural condition C of rationality, such as the one laid down by Von-Neumann and Morgenstern. This leads to a third step: A person should desire the means  and preconditions to satisfy C. A fourth step demands that a person should want rational integration, which excludes conditions in which he prefers x to y, yet prefers that he did not have this preference. A fifth step is that a person should have a preference for the preconditions of making any choices, <it>ceteris paribus</it> (e.g., preferring being alive). And so on through fourteen steps that "take us some considerable distance past Hume toward substantive constraints upon preferences." He takes a fifteenth step by way of imposing conditions I-XIV as a goal of any reliable process that might give rise to desire: A particular desire is rational only if the process arriving at it reliably yields desires that satisfy the normative structural conditions I through XIV. And Nozick fint-tunes the structural conditions further, in XVI through XXIII. These lead him to conclude that a function of desire is to be rationally coherent; a function of  belief is to meet the cognitive goals.  Moreover, as people become self-conscious about desire and belief formation, the person's consciously aiming at the goals of desire and belief becomes part of the homeostatic process that forms those desires and beliefs. Ultimately rationality comes to shape and control its own function.</p>

</ss1>
<ss1>
<st>
 Testing, Interpretation, and Conditionalization </st>
<p>

Principles of charity in interpretation should not strive to make someone's sayings or writings as true as possible, because we may know that that person wasn't in a position to know the truth.More plausible is to interpret that person as being as rational as possible. But there is strong evidence that some people do not reason with what we take to be correct standards. He moves on to Dworkin's proposal that interpretation should seek to make what a person does and says "as good as possible, as justified, principled, and correct as possible." Nozick calls this the Panglossian Principle and finds it unfit to interpret institutions that we know to be compromises among competing interests. And he considers some other proposals, finding this one most satisfactory: Translate "p" so as to make as intelligible as possible the fact that in that context that person said "p". </p>
<p>

Substantive rationality must be considered over and above instrumental rationality, but "it is the step to decision-value that decisively transcends this broadly instrumental structure". </p>

</ss1>
<ss1>
<st>
 Philosophical Heuristics </st>
<p>

Among the heuristics that Nozick discusses in this section are:
<list>
<entry level="1" type="number">

 When a conflict between intellectual positions has gone on for a long time without any resolution or large movement, look for an assumption or presupposition that is common to <it>all</it> the contenting positions.  </entry>
<entry level="1" type="number">

 Use a radically new possibility, once it is thought of, to ask what is the deepest assumption that it violates, what new framework best accommodates it, etc.</entry>
<entry level="1" type="number">

 Apply an operation that has been fruitful elsewhere to a new case that is similar in appropriate respects.</entry>
<entry level="1" type="number">

 Try models or analogies from other areas to help solve a problem in the target area.</entry>
<entry level="1" type="number">

 Work backward from the goal and forward from the initial state to see if you can get a "transcontinental railway" to meet.</entry>
<entry level="1" type="number">

 Reduce one hard problem to a set of easier problems.</entry>
<entry level="1" type="number">

 Examine extreme cases and reconsider your intermediate case in the light of "this extremal behavior".</entry>
<entry level="1" type="number">

 Investigate and list the general features that a correct answer to the problem must have.</entry>
<entry level="1" type="number">

 Formulate a little formal structure or model to embed a new idea, and then explore its properties and implications.</entry>
<entry level="1" type="number">

 Find a more abstract description of a process, notion, or phenomenon and investigate its properties.</entry>
<entry level="1" type="number">

 In investigating a relation R, consider also the structure of the whole domain that is induced by R.</entry>
<entry level="1" type="number">

 Transform known phenomena to discover new ones.</entry>
</list>

And so on. (Nozick lists sixteen.)
</p>
</ss1>
<ss1>
<st>
 Rationality's Imagination </st>
<p>

The foregoing heuristics are a start at studying imagination: the ability to think up new and fruitful possibilities. Rationality will be myopic without the new possibilies for action and belief disclosed by imagination.</p>
<p>

The theory of rationality should not be expected to subsume ethics. "Instrumental rationality leaves us the room to pursue our <it>own</it> goals autonomously."</p>

</ss1>
</sec>
<sec>
<st>
 Notes </st>
<p>

<reflist>
<entry id="1">
Nozick, p. 68</entry>
</reflist>
</p>

</sec>
<sec>
<st>
 References </st>
<p>

<list>
<entry level="1" type="bullet">

Nozick, Robert. <it>The Nature of Rationality</it>. 1993: Princeton University Press.</entry>
</list>
</p>

</sec>
<sec>
<st>
 External links </st>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.findarticles.com/p/articles/mi_m1568/is_n2_v26/ai_15473477">
Loren Lomasky's review in <it>Reason</it></weblink>''</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://findarticles.com/p/articles/mi_m2346/is_n412_v103/ai_15908923">
John Heil's review in <it>Mind</it></weblink>''</entry>
</list>
</p>

</sec>
</bdy>
</publication>
</book>
</artifact>
</creation>
</product>
</work>
</article>
