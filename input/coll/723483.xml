<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 17:34:29[mciao0825] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Memoization</title>
<id>723483</id>
<revision>
<id>241516368</id>
<timestamp>2008-09-28T11:50:15Z</timestamp>
<contributor>
<username>ZeroOne</username>
<id>88248</id>
</contributor>
</revision>
<categories>
<category>Software performance optimization</category>
</categories>
</header>
<bdy>

In <link xlink:type="simple" xlink:href="../213/5213.xml">
computing</link>, <b>memoization</b> is an <link xlink:type="simple" xlink:href="../779/225779.xml">
optimization</link> technique used primarily to speed up <link xlink:type="simple" xlink:href="../783/5783.xml">
computer programs</link> by having <link xlink:type="simple" xlink:href="../988/40988.xml">
function calls</link> avoid repeating the calculation of results for previously-processed inputs.  Memoization has also been used in other contexts (and for other purposes other than speed gains), such as in simple mutually-recursive descent parsing by Norvig,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref> in a general <link xlink:type="simple" xlink:href="../102/339102.xml">
top-down</link> <link xlink:type="simple" xlink:href="../015/310015.xml">
parsing</link> algorithm by Frost, Hafiz and Callaghan<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%223%22])">3</ref> that accommodates ambiguity and left-recursion in polynomial time and space. Although related to <link xlink:type="simple" xlink:href="../829/6829.xml">
caching</link>, memoization refers to a specific case of this optimization, distinguishing it from forms of caching such as <link xlink:type="simple" xlink:href="../183/2406183.xml">
buffering</link> or <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../476/727476.xml">
page replacement</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
.
<sec>
<st>
Overview</st>

<p>

The term "memoization" was coined by <scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../921/5842921.xml">
Donald Michie</link></scientist>
 in 1968<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%224%22])">4</ref> and is derived from the <language wordnetid="106282651" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../730/17730.xml">
Latin</link></language>
 word <it><link xlink:type="simple" xlink:href="../798/1050798.xml">
memorandum</link></it> (<it>to be remembered</it>), and thus carries the meaning of <it>turning [the results of] a function into something to be remembered.</it> While <it>memoization</it> might be confused with <it>memorization</it> (because of the shared <link xlink:type="simple" xlink:href="../328/6328.xml">
cognate</link>), memoization has a specialized meaning in computing.</p>
<p>

A memoized function "remembers" the results corresponding to some set of specific inputs. Subsequent calls with remembered inputs return the remembered result rather than recalculating it, thus moving the primary cost of a call with given parameters to the first call made to the function with those parameters. The set of remembered associations may be a fixed-size set controlled by a replacement algorithm or a fixed set, depending on the nature of the function and its use.  A function can only be memoized if it is <link xlink:type="simple" xlink:href="../526/26526.xml">
referentially transparent</link>; that is, only if calling the function has the exact same effect as replacing that function call with its return value. (Special case exceptions to this restriction exist, however.) While related to <link xlink:type="simple" xlink:href="../457/356457.xml">
lookup table</link>s, since memoization often uses such tables in its implementation, memoization differs from pure table lookup in that the tables memoization might use are populated transparently on an <link xlink:type="simple" xlink:href="../147/348147.xml">
<it>as-needed''</it></link> basis. </p>
<p>

Memoization is a means of lowering a function's <it>time</it> cost in exchange for <it>space</it> cost; that is, memoized functions become optimized for <it>speed</it> in exchange for a higher use of <link xlink:type="simple" xlink:href="../847/25847.xml">
computer memory</link> <it>space</it>. The time/space "cost" of <link xlink:type="simple" xlink:href="../775/775.xml">
algorithm</link>s has a specific name in computing: <it><link xlink:type="simple" xlink:href="../543/7543.xml">
computational complexity</link></it>. All functions have a computational complexity in <it>time</it> (i.e. they take time to execute) and in <it>space</it>.</p>
<p>

Although a <link xlink:type="simple" xlink:href="../213/406213.xml">
trade-off</link> occurs (i.e., space used is speed gained), this differs from some other optimizations that involve time-space trade-off, such as <link xlink:type="simple" xlink:href="../907/475907.xml">
strength reduction</link>, in that memoization is a <link xlink:type="simple" xlink:href="../263/192263.xml">
runtime</link> rather than <link xlink:type="simple" xlink:href="../766/191766.xml">
compile time</link> optimization. Moreover, strength reduction potentially replaces an expensive operation such as multiplication with a less expensive operation such as addition, and the results in savings can be highly <link xlink:type="simple" xlink:href="../835/4472835.xml">
non-portable across machines</link>, whereas memoization is a <link xlink:type="simple" xlink:href="../193/81193.xml">
machine-independent</link> strategy.</p>
<p>

Consider the following <link xlink:type="simple" xlink:href="../185/24185.xml">
pseudocode</link> function to calculate the <link xlink:type="simple" xlink:href="../606/10606.xml">
factorial</link> of <it>n</it>:</p>
<p>

function factorial (<it>n</it> is a non-negative integer)
if <it>n</it> is 0 then
return 1 [''by the convention that'' '''0! = 1''']
else   
return factorial(n - 1) times <it>n</it> [''recursively invoke factorial with the parameter 1 less than n'']
end if
end function</p>
<p>

For every <link xlink:type="simple" xlink:href="../563/14563.xml">
integer</link> <it>n</it> such that <math>n \ge 0</math>, the final result of the function factorial is <know-how wordnetid="105616786" confidence="0.8">
<method wordnetid="105660268" confidence="0.8">
<link xlink:type="simple" xlink:href="../643/1126643.xml">
invariant</link></method>
</know-how>
; if invoked as x = factorial(3), the result is such that <it>x</it> will <it>always</it> be assigned the value 6. A non-memoized version of the above, given the nature of the <link xlink:type="simple" xlink:href="../407/25407.xml">
recursive</link> <link xlink:type="simple" xlink:href="../775/775.xml">
algorithm</link> involved, would require <it>n + 1</it> invocations of factorial to arrive at a result, and each of these invocations, in turn, has an associated cost in the time it takes the function to return the value computed. Depending on the machine, this cost might be the sum of:</p>
<p>

<list>
<entry level="1" type="number">

 The cost to set up the functional call stack frame.</entry>
<entry level="1" type="number">

 The cost to compare <it>n</it> to 0.</entry>
<entry level="1" type="number">

 The cost to subtract 1 from n.</entry>
<entry level="1" type="number">

 The cost to set up the recursive call stack frame. (As above.)</entry>
<entry level="1" type="number">

 The cost to multiply the result of the recursive call to factorial by <it>n</it>.</entry>
<entry level="1" type="number">

 The cost to store the return result so that it may be used by the calling context.</entry>
</list>
</p>
<p>

In a non-memoized implementation, <it>every</it> top-level call to factorial includes the cumulative cost of steps 2 through 6 proportional to the initial value of <it>n</it>. </p>
<p>

A memoized version of the factorial function follows:</p>
<p>

function factorial (<it>n</it> is a non-negative integer)
allocate temporary integer variable <it>x</it></p>
<p>

if <it>n</it> is in <it>lookup-table</it> then
return <it>lookup-table-value-for-n</it>;
else if <it>n</it> is 0 then
return 1 [''by the convention that'' '''0! = 1''']
else   
x = factorial(n - 1) times <it>n</it> [''recursively invoke factorial with the parameter 1 less than n'']
end if</p>
<p>

store <it>x</it> in <it>lookup-table</it> in the <it>n</it>th slot [''remember the result of n! for later'']</p>
<p>

return x
end function</p>
<p>

In the memoized version above, the lookup-table is assumed to be a persistent storage space, such as an <link xlink:type="simple" xlink:href="../154/95154.xml">
associative array</link> that uses <it>n</it> as its key. Since this <link xlink:type="simple" xlink:href="../457/356457.xml">
lookup table</link> will use <it>space</it> (that is, computer memory), the time required to call factorial repeatedly on a second call to the function with the same parameter has been traded for the memory required to store the lookup table.</p>
<p>

In this particular example, if factorial is first invoked with 5, and then invoked later with any value less than or equal to five, those return values will also have been memoized, since factorial will have been called recursively with the values 5, 4, 3, 2, 1, and 0, and the return values for <it>each</it> of those will have been stored. If it is then called with a number greater than 5, such as 7, only 2 recursive calls will be made (7 and 6), and the value for 5! will have been stored from the previous call. In this way, memoization allows a function to become more time-efficient the more often it is called, thus resulting in eventual overall <b>speed up</b>.</p>

</sec>
<sec>
<st>
Some other considerations</st>


<ss1>
<st>
Automatic memoization</st>

<p>

While memoization may be added to functions <it>internally</it> and <it>explicitly</it> by a <link xlink:type="simple" xlink:href="../716/23716.xml">
computer programmer</link> in much the same way the above memoized version of factorial is implemented, <link xlink:type="simple" xlink:href="../526/26526.xml">
referentially transparent</link> functions may also be automatically memoized <it>externally</it>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref> The techniques employed by Norvig have application not only in <programming_language wordnetid="106898352" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../068/6068.xml">
Common Lisp</link></programming_language>
 (the language in which his paper demonstrated automatic memoization), but in various other <link xlink:type="simple" xlink:href="../015/23015.xml">
programming language</link>s. Applications of automatic memoization have also been formally explored in the study of <link xlink:type="simple" xlink:href="../847/415847.xml">
term rewriting</link><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%225%22])">5</ref> and <link xlink:type="simple" xlink:href="../164/1164.xml">
artificial intelligence</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref></p>
<p>

In those programming languages where functions are <link xlink:type="simple" xlink:href="../844/662844.xml">
first or second-class objects</link> (such as <system wordnetid="104377057" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<device wordnetid="103183080" confidence="0.8">
<machine wordnetid="103699975" confidence="0.8">
<link xlink:type="simple" xlink:href="../150/46150.xml">
Lua</link></machine>
</device>
</instrumentality>
</artifact>
</system>
, with its first-class functions, or <programming_language wordnetid="106898352" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../939/23939.xml">
Perl</link></programming_language>
 <weblink xlink:type="simple" xlink:href="http://perl.plover.com/MiniMemoize/memoize.html">
http://perl.plover.com/MiniMemoize/memoize.html</weblink>), automatic memoization can be implemented by replacing (at <link xlink:type="simple" xlink:href="../263/192263.xml">
runtime</link>) a function with its calculated value once a value has been calculated for a given set of parameters. The function that does this value-for-function-object replacement can generically wrap any referentially transparent function. Consider the following <link xlink:type="simple" xlink:href="../185/24185.xml">
pseudocode</link> (where it is assumed that functions are first-class values):</p>
<p>

function memoized-call (<it>F</it> is a function object parameter)
if <it>F</it> has no attached array <it>values</it> then
allocate an <link xlink:type="simple" xlink:href="../154/95154.xml">
associative array</link> called <it>values</it>;
attach <it>values</it> to <it>F</it>;
end if;</p>
<p>

if F.<it>values[arguments]</it> is empty then
F.<it>values[arguments]</it> = <it>F</it>(arguments);
end if;</p>
<p>

return F.<it>values[arguments]</it>;     
end function</p>
<p>

In order to call an automatically memoized version of factorial using the above strategy, rather than calling factorial directly, code invokes memoized-call(factorial(<it>n</it>)). Each such call first checks to see if a holder array has been allocated to store results, and if not, attaches that array. If no entry exists at the position values[arguments] (where arguments are used as the key of the associative array), a <it>real</it> call is made to factorial with the supplied arguments. Finally, the entry in the array at the key position is returned to the caller.</p>
<p>

The above strategy requires <it>explicit</it> wrapping at each call to a function that is to be memoized. In those languages that allow <link xlink:type="simple" xlink:href="../319/62319.xml">
closures</link>, memoization can be effected <it>implicitly</it> by a <idea wordnetid="105833840" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<link xlink:type="simple" xlink:href="../999/509999.xml">
functor</link></concept>
</idea>
 factory that returns a wrapped memoized function object. In pseudocode, this can be expressed as follows:</p>
<p>

function construct-memoized-functor (<it>F</it> is a function object parameter)
allocate a function object called <it>memoized-version</it>;</p>
<p>

let memoized-version(arguments) be
if <it>self</it> has no attached array values then [''self is a reference to [[this (computer science)|this]] object'']
allocate an associative array called <it>values</it>;
attach <it>values</it> to <it>self</it>;
end if;</p>
<p>

if self.<it>values[arguments]</it> is empty then
self.<it>values[arguments]</it> = <it>F</it>(arguments);
end if;</p>
<p>

return self.<it>values[arguments]</it>;     
end let;</p>
<p>

return <it>memoized-version</it>;
end function</p>
<p>

Rather than call factorial, a new function object memfact is created as follows:</p>
<p>

memfact = construct-memoized-functor(factorial)</p>
<p>

The above example assumes that the function factorial has already been defined <it>before</it> the call to construct-memoized-functor is made. From this point forward, memfact(<it>n</it>) is called whenever the factorial of <it>n</it> is desired. In languages such as <system wordnetid="104377057" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<device wordnetid="103183080" confidence="0.8">
<machine wordnetid="103699975" confidence="0.8">
<link xlink:type="simple" xlink:href="../150/46150.xml">
Lua</link></machine>
</device>
</instrumentality>
</artifact>
</system>
, more sophisticated techniques exist which allow a function to be replaced by a new function with the same name, which would permit:</p>
<p>

factorial = construct-memoized-functor(factorial)</p>
<p>

Essentially, such techniques involve attaching the <it>original function object</it> to the created functor and forwarding calls to the original function being memoized via an alias when a call to the actual function is required (to avoid endless <link xlink:type="simple" xlink:href="../407/25407.xml">
recursion</link>), as illustrated below:</p>
<p>

function construct-memoized-functor (<it>F</it> is a function object parameter)
allocate a function object called <it>memoized-version</it>;</p>
<p>

let <it>memoized-version</it>(arguments) be
if <it>self</it> has no attached array values then [''self is a reference to [[this (computer science)|this]] object'']
allocate an associative array called <it>values</it>;
attach <it>values</it> to <it>self</it>;
allocate a new function object called <it>alias</it>;
attach <it>alias</it> to <it>self</it>; [''for later ability to invoke F indirectly'']
self.<it>alias</it> = <it>F</it>;
end if;</p>
<p>

if self.<it>values[arguments]</it> is empty then
self.<it>values[arguments]</it> = self.<it>alias</it>(arguments); [''not a direct call to F'']
end if;</p>
<p>

return self.<it>values[arguments]</it>;     
end let;</p>
<p>

return <it>memoized-version</it>;
end function</p>
<p>

(Note: Some of the steps shown above may be implicitly managed by the implementation language and are provided for illustration.)</p>

</ss1>
<ss1>
<st>
Parsers</st>
<p>

When a <link xlink:type="simple" xlink:href="../102/339102.xml">
top-down parser</link> tries to parse an <link xlink:type="simple" xlink:href="../677/677.xml">
ambiguous</link> input with respect to an ambiguous <message wordnetid="106598915" confidence="0.8">
<subject wordnetid="106599788" confidence="0.8">
<language wordnetid="106282651" confidence="0.8">
<link xlink:type="simple" xlink:href="../759/6759.xml">
CFG</link></language>
</subject>
</message>
, it may need exponential number of steps (with respect to the length of the input) to try all alternatives of the CFG in order to produce all possible parse trees, which eventually would require exponential memory space. Memoization was explored as a <link xlink:type="simple" xlink:href="../015/310015.xml">
parsing</link> strategy in 1991 by <physical_entity wordnetid="100001930" confidence="0.8">
<peer wordnetid="109626238" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<colleague wordnetid="109935990" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<employee wordnetid="110053808" confidence="0.8">
<research_worker wordnetid="110523076" confidence="0.8">
<associate wordnetid="109816771" confidence="0.8">
<link xlink:type="simple" xlink:href="../666/566666.xml">
Norvig</link></associate>
</research_worker>
</employee>
</scientist>
</causal_agent>
</colleague>
</worker>
</person>
</peer>
</physical_entity>
, who demonstrated that an algorithm similar to the use of dynamic programming and state-sets in <link>
 Earley's algorithm</link> (1970), and tables in the <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../929/53929.xml">
CYK algorithm</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
 of Cocke, Younger and Kasami, could be generated by introducing automatic memoization to a simple <link xlink:type="simple" xlink:href="../867/238867.xml">
backtracking</link> <link xlink:type="simple" xlink:href="../089/70089.xml">
recursive descent parser</link> to solve the problem of exponential time complexity.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref> The basic idea in Norvig’s approach is that when a parser is applied to the input, the result is stored in a memotable for subsequent reuse if the same parser is ever reapplied to the same input. Richard Frost also used memoization to reduce the exponential time complexity of <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<language wordnetid="106282651" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../666/16728666.xml">
parser combinators</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</language>
</rule>
</event>
, which can be viewed as “Purely Functional Top-Down Backtracking” parsing technique.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%227%22])">7</ref> He showed that basic memoized parser combinators can be used as building blocks to construct complex parsers as executable specifications of CFGs.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%228%22])">8</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%229%22])">9</ref> It was again explored in the context of parsing in 1995 by Johnson and Dörre.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2210%22])">10</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2211%22])">11</ref> In 2002, it was examined in considerable depth by Ford in the form called <link xlink:type="simple" xlink:href="../899/892899.xml">
packrat parsing</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2212%22])">12</ref> </p>
<p>

In 2007, Frost, Hafiz and Callaghan<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref> described a top-down parsing algorithm that uses <link xlink:type="simple" xlink:href="../483/723483.xml">
memoization</link> for refraining redundant computations to accommodate any form of ambiguous <link xlink:type="simple" xlink:href="../650/43650.xml">
CFG</link> in <link xlink:type="simple" xlink:href="../000/23000.xml">
polynomial</link> time (<link xlink:type="simple" xlink:href="../578/44578.xml">
Θ</link>(n4) for <link>
 left-recursive</link> grammars and <link xlink:type="simple" xlink:href="../578/44578.xml">
Θ</link>(n3) for non left-recursive grammars). Their top-down parsing algorithm also requires polynomial space for potentially exponential ambiguous parse trees by 'compact representation' and 'local ambiguities grouping'. Their compact representation is comparable with Tomita’s compact representation of <link xlink:type="simple" xlink:href="../521/679521.xml">
bottom-up parsing</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2213%22])">13</ref> Their use of memoization is not only limited to retrieving the previously-computed results when a parser is applied to a same input position repeatedly (which is essential for polynomial time requirment); it is specialized to perform the following additional tasks:
<list>
<entry level="1" type="bullet">

 The memoization process (which could be viewed as a ‘wrapper’ around any parser execution) accommodates an ever-growing <b>direct left-recursive</b> parse by imposing depth restrictions w.r.t. input length and current input position. </entry>
<entry level="1" type="bullet">

 The algorithm’s memo-table ‘lookup’ procedure also determines the reusability of saved result by comparing saved result’s computational context with the parser’s current context. This contextual comparison is the key to accommodate <b>indirect (or hidden) left-recursion</b>.</entry>
<entry level="1" type="bullet">

 When performing a successful lookup in memotable, instead of returning the complete result-set, the process only returns the references of the actual result and eventually speeds up the overall computation.</entry>
<entry level="1" type="bullet">

 During updating the memotable, the meoization process groups the (potentially exponential) ambiguous results and ensures the polynomial space requirement.</entry>
</list>
</p>
<p>

Frost, Hafiz and Callaghan also described the implementation of the algorithm in PADL’08<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%223%22])">3</ref> as a set of <link xlink:type="simple" xlink:href="../689/244689.xml">
higher-order function</link>s (called <link xlink:type="simple" xlink:href="../666/16728666.xml">
parser combinators</link>) in <programming_language wordnetid="106898352" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../630/13630.xml">
Haskell</link></programming_language>
, which enables the construction of directly executable specifications of <link xlink:type="simple" xlink:href="../650/43650.xml">
CFG</link>s as language processors. The importance of their polynomial algorithm’s power to accommodate ‘any form of ambiguous CFG’ with top-down parsing is vital with respect to the syntax and semantics analysis during <link xlink:type="simple" xlink:href="../652/21652.xml">
Natural Language Processing</link>. The <weblink xlink:type="simple" xlink:href="http://www.cs.uwindsor.ca/~hafiz/proHome.html">
X-SAIGA</weblink> site has more about the algorithm and implementation details.</p>
<p>

While Norvig increased the <it>power</it> of the parser through memoization, the augmented parser was still as time complex as Earley's algorithm, which demonstrates a case of the use of memoization for something other than speed optimization. Johnson and Dörre<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2211%22])">11</ref> demonstrate another such non-speed related application of memoization: the use of memoization to delay linguistic constraint resolution to a point in a parse where sufficient information has been accumulated to resolve those constraints. By contrast, in the speed optimization application of memoization, Ford demonstrated that memoization could guarantee that <link xlink:type="simple" xlink:href="../899/892899.xml">
parsing expression grammar</link>s could parse in <link xlink:type="simple" xlink:href="../578/44578.xml">
linear</link> time even those <link xlink:type="simple" xlink:href="../939/10939.xml">
languages</link> that resulted in worst-case backtracking behavior.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2212%22])">12</ref></p>
<p>

Consider the following <language wordnetid="106282651" confidence="0.8">
<link xlink:type="simple" xlink:href="../716/18020716.xml">
grammar</link></language>
:</p>
<p>

S → (A <b>c</b>) | (B <b>d</b>)
A → X (<b>a</b>|<b>b</b>)
B → X <b>b</b>
X → <b>x</b> [X]</p>
<p>

(Notation note: In the above example, the production S → (A <b>c</b>) | (B <b>d</b>) reads: "An <it>S</it> is either an <it>A</it> followed by a <b>c</b> or a <it>B</it> followed by a <b>d</b>." The production X → <b>x</b> [X] reads "An <it>X</it> is an <b>x</b> followed by an optional <it>X</it>.")</p>
<p>

This grammar generates one of the following three variations of <idea wordnetid="105833840" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<category wordnetid="105838765" confidence="0.8">
<language wordnetid="106282651" confidence="0.8">
<type wordnetid="105840188" confidence="0.8">
<kind wordnetid="105839024" confidence="0.8">
<link xlink:type="simple" xlink:href="../701/27701.xml">
string</link></kind>
</type>
</language>
</category>
</concept>
</idea>
: <it>xac</it>, <it>xbc</it>, or <it>xbd</it> (where <it>x</it> here is understood to mean <it>one or more </it>x<it>'s</it>.) Next, consider how this grammar, used as a parse specification, might effect a top-down, left-right parse of the string <it>xxxxxbd</it>:</p>
<p>

<indent level="1">

The rule <it>A</it> will recognize <it>xxxxxb</it> (by first descending into <it>X</it> to recognize one <it>x</it>, and again descending into <it>X</it> until all the <it>x</it>'s are consumed, and then recognizing the <it>b</it>), and then return to <it>S</it>, and fail to recognize a <it>c</it>. The next clause of <it>S</it> will then descend into B, which in turn <b>again descends into <it>X</it></b> and recognizes the <it>x</it>'s by means of many recursive calls to <it>X</it>, and then a <it>b</it>, and returns to <it>S</it> and finally recognizes a <it>d</it>.
</indent>

The key concept here is inherent in the phrase <b>again descends into <it>X</it></b>. The process of looking forward, failing, backing up, and then retrying the next alternative is known in parsing as <link xlink:type="simple" xlink:href="../867/238867.xml">
backtracking</link>, and it is primarily backtracking that presents opportunities for memoization in parsing. Consider a function RuleAcceptsSomeInput(Rule, Position, Input), where the parameters are as follows:</p>
<p>

<list>
<entry level="1" type="bullet">

 Rule is the name of the rule under consideration.</entry>
<entry level="1" type="bullet">

 Position is the offset currently under consideration in the input.</entry>
<entry level="1" type="bullet">

 Input is the input under consideration.</entry>
</list>
</p>
<p>

Let the return value of the function RuleAcceptsSomeInput be the length of the input accepted by Rule, or 0 if that rule does not accept any input at that offset in the string. In a backtracking scenario with such memoization, the parsing process is as follows:</p>
<p>

<indent level="1">

 When the rule <it>A</it> descends into <it>X</it> at offset 0, it memoizes the length 5 against that position and the rule <it>X</it>. After having failed at <it>d</it>, <it>B</it> then, rather than descending again into <it>X</it>, queries the position 0 against rule <it>X</it> in the memoization engine, and is returned a length of 5, thus saving having to actually descend again into <it>X</it>, and carries on <it>as if</it> it had descended into <it>X</it> as many times as before.
</indent>

In the above example, one or <it>many</it> descents into <it>X</it> may occur, allowing for strings such as <it>xxxxxxxxxxxxxxxxbd</it>. In fact, there may be <it>any number</it> of <it>x</it>'s before the <it>b</it>. While the call to S must recursively descend into X as many times as there are <it>x</it>'s, <it>B</it> will never have to descend into X at all, since the return value of RuleAcceptsSomeInput(<it>X</it>, 0, <it>xxxxxxxxxxxxxxxxbd</it>) will be 16 (in this particular case).</p>
<p>

Those parsers that make use of <link xlink:type="simple" xlink:href="../895/7400895.xml">
syntactic predicate</link>s are also able to memoize the results of predicate parses, as well, thereby reducing such constructions as:</p>
<p>

S → (A)? A
A → /* some rule */</p>
<p>

to one descent into <it>A</it>.</p>
<p>

If a parser builds a <link xlink:type="simple" xlink:href="../404/118404.xml">
parse tree</link> during a parse, it must memoize not only the <it>length</it> of the input that matches at some offset against a given rule, but also must store the sub-tree that is generated by that rule at that offset in the input, since subsequent calls to the rule by the parser will not actually descend and rebuild that tree. For the same reason, memoized parser algorithms that generate calls to external code (sometimes called a <link xlink:type="simple" xlink:href="../097/70097.xml">
semantic action routine</link>) when a rule matches must use some scheme to insure that such rules are invoked in a predictable order. </p>
<p>

Since, for any given backtracking or syntactic predicate capable parser not every grammar will <it>need</it> backtracking or predicate checks, the overhead of storing each rule's parse results against every offset in the input (and storing the parse tree if the parsing process does that implicitly) may actually <it>slow down</it> a parser. This effect can be mitigated by explicit selection of those rules the parser will memoize.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2214%22])">14</ref></p>

</ss1>
</sec>
<sec>
<st>
See also</st>

<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../543/7543.xml">
Computational complexity theory</link> - More information on algorithm complexity.</entry>
<entry level="1" type="bullet">

 <change_of_state wordnetid="100199130" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<change wordnetid="100191142" confidence="0.8">
<improvement wordnetid="100248977" confidence="0.8">
<action wordnetid="100037396" confidence="0.8">
<optimization wordnetid="100260051" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<link xlink:type="simple" xlink:href="../907/475907.xml">
Strength reduction</link></psychological_feature>
</act>
</optimization>
</action>
</improvement>
</change>
</event>
</change_of_state>
 - A <link xlink:type="simple" xlink:href="../739/5739.xml">
compiler</link> optimization that replaces an expensive operation with an equivalent, less expensive one.</entry>
<entry level="1" type="bullet">

 <change_of_state wordnetid="100199130" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<change wordnetid="100191142" confidence="0.8">
<improvement wordnetid="100248977" confidence="0.8">
<action wordnetid="100037396" confidence="0.8">
<optimization wordnetid="100260051" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<link xlink:type="simple" xlink:href="../155/18155.xml">
Lazy evaluation</link></psychological_feature>
</act>
</optimization>
</action>
</improvement>
</change>
</event>
</change_of_state>
 - Shares some concepts with memoization.</entry>
<entry level="1" type="bullet">

 <arrangement wordnetid="107938773" confidence="0.8">
<group wordnetid="100031264" confidence="0.8">
<array wordnetid="107939382" confidence="0.8">
<link xlink:type="simple" xlink:href="../457/356457.xml">
Lookup table</link></array>
</group>
</arrangement>
 - A key <link xlink:type="simple" xlink:href="../519/8519.xml">
data structure</link> used in memoization.</entry>
<entry level="1" type="bullet">

 <structure wordnetid="105726345" confidence="0.8">
<form wordnetid="105930736" confidence="0.8">
<link xlink:type="simple" xlink:href="../538/140538.xml">
Flyweight pattern</link></form>
</structure>
 - an object programming <link xlink:type="simple" xlink:href="../952/164952.xml">
design pattern</link>, that also uses kind of memoization</entry>
</list>
</p>

</sec>
<sec>
<st>
Notes and references</st>

<p>

<reflist>
<entry id="1">
Norvig, Peter, "Techniques for Automatic Memoization with Applications to Context-Free Parsing," <it>Computational Linguistics</it>, Vol. 17 No. 1, pp. 91-98, March 1991.</entry>
<entry id="2">
 Frost, Richard, Hafiz, Rahmatullah, and Callaghan, Paul. " Modular and Efficient Top-Down Parsing for Ambiguous Left-Recursive Grammars ." <it>10th International Workshop on Parsing Technologies (IWPT), ACL-SIGPARSE </it>, Pages: 109 - 120, June 2007, Prague.</entry>
<entry id="3">
Frost, Richard, Hafiz, Rahmatullah, and Callaghan, Paul. " Parser Combinators for Ambiguous Left-Recursive Grammars." <it> 10th International Symposium on Practical Aspects of Declarative Languages (PADL), ACM-SIGPLAN </it>, Volume 4902/2008, Pages: 167-181, January 2008, San Francisco.</entry>
<entry id="4">
Michie, Donald, "Memo Functions and Machine Learning," <it>Nature</it>, No. 218, pp. 19-22, 1968.</entry>
<entry id="5">
Hoffman, Berthold, "Term Rewriting with Sharing and Memoïzation," <it>Algebraic and Logic Programming: Third International Conference, Proceedings</it>, H. Kirchner and G. Levi (eds.), pp. 128-142, Volterra, Italy, 2-4 September 1992.</entry>
<entry id="6">
Mayfield, James, <it>et al</it>, <it>Using Automatic Memoization as a Software Engineering Tool in Real-World AI Systems</it>, TBD, 1995.</entry>
<entry id="7">
Frost, Richard. and Szydlowski, Barbara. "Memoizing Purely Functional Top-Down Backtracking Language Processors. "  "Sci. Comput. Program. " 1996 - 27(3): 263-288. </entry>
<entry id="8">
Frost, Richard. "Using Memoization to Achieve Polynomial Complexity of Purely Functional Executable Specifications of Non-Deterministic Top-Down Parsers. " "SIGPLAN Notices" 29(4): 23-30. </entry>
<entry id="9">
Frost, Richard. "Monadic Memoization towards Correctness-Preserving Reduction of Search. " "Canadian Conference on AI 2003." p 66-80.</entry>
<entry id="10">
Johnson, Mark, "Memoization of Top-Down Parsing,” <it>Computational Linguistics</it>, Vol. 21 No. 3, pp. 405-417, September 1995.</entry>
<entry id="11">
Johnson, Mark &amp; Dörre, Jochen, "Memoization of Coroutined Constraints," <it>Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics</it>, Cambridge, Massachusetts, 1995.</entry>
<entry id="12">
Ford, Bryan, <it>Packrat Parsing: a Practical Linear-Time Algorithm with Backtracking</it>, Master’s thesis, Massachusetts Institute of Technology, September, 2002.</entry>
<entry id="13">
Tomita, Masaru. “Efficient Parsing for Natural Language.” <it>Kluwer, Boston, MA</it>, 1985. </entry>
<entry id="14">
Acar, Umut A. A. <it>et al.</it>, "Selective Memoization," <it>Proceedings of the 30th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages</it>, New Orleans, Louisiana, pp. 14-25, 15-17 January 2003.</entry>
</reflist>
</p>

</sec>
<sec>
<st>
External links</st>

<p>

<list>
<entry level="1" type="definition">

 Examples of memoization in various programming languages</entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.cliki.net/memoize">
Memoize</weblink> - Memoize is a small library, written by Tim Bradshaw, for performing memoization in <programming_language wordnetid="106898352" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../068/6068.xml">
Common Lisp</link></programming_language>
.</entry>
<entry level="1" type="bullet">

Marty Hall's <weblink xlink:type="simple" xlink:href="http://apl.jhu.edu/~hall/lisp/Memoization/">
Automatic Memoization toolkit</weblink> in <programming_language wordnetid="106898352" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../068/6068.xml">
Common Lisp</link></programming_language>
</entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://search.cpan.org/dist/Memoize/Memoize.pm">
Memoize.pm</weblink> - a <programming_language wordnetid="106898352" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../939/23939.xml">
Perl</link></programming_language>
 <link xlink:type="simple" xlink:href="../136/528136.xml">
module</link> that implements memoized functions.</entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.onjava.com/pub/a/onjava/2003/08/20/memoization.html">
Java memoization</weblink> - an example in Java using dynamic proxy classes to create a generic memoization pattern.</entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://apl.jhu.edu/~paulmac/c++-memoization.html">
Memoization in C++</weblink> - although <programming_language wordnetid="106898352" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../038/72038.xml">
C++</link></programming_language>
 doesn't support first-class functions, here is a toolkit that supports automated memoization (via pre-processing).</entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.tek271.com/free/memoizer/tek271.memoizer.intro.html">
Tek271 Memoizer</weblink> - Open source Java memoizer using annotations and pluggable cache implementations.</entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://raa.ruby-lang.org/project/memoize/">
memoize</weblink> - A <link xlink:type="simple" xlink:href="../768/25768.xml">
Ruby</link> module that implements memoized methods.</entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://aspn.activestate.com/ASPN/Cookbook/Python/Recipe/52201">
Python memoization</weblink> - A <programming_language wordnetid="106898352" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../862/23862.xml">
Python</link></programming_language>
 example of memoization.</entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://martin.jambon.free.fr/pa_memo.ml.html">
OCaml memoization</weblink> - Implemented as a <family wordnetid="108078020" confidence="0.8">
<language wordnetid="106282651" confidence="0.8">
<link xlink:type="simple" xlink:href="../682/2148682.xml">
Camlp4</link></language>
</family>
 syntax extension.</entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://lua-users.org/wiki/FuncTables">
Memoization in Lua</weblink> - Two example implementations of a general memoize function in <system wordnetid="104377057" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<device wordnetid="103183080" confidence="0.8">
<machine wordnetid="103699975" confidence="0.8">
<link xlink:type="simple" xlink:href="../150/46150.xml">
Lua</link></machine>
</device>
</instrumentality>
</artifact>
</system>
.</entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://talideon.com/weblog/2005/07/javascript-memoization.cfm">
Memoization in Javascript</weblink> - Extending the Function prototype in <programming_language wordnetid="106898352" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../845/9845.xml">
JavaScript</link></programming_language>
.</entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.cs.uwindsor.ca/~hafiz/proHome.html">
X-SAIGA</weblink> - eXecutable SpecificAtIons of GrAmmars. Contains publications related to top-down parsing algorithm that supports left-recursion and ambiguity in polynomial time and space.</entry>
</list>
</p>



</sec>
</bdy>
</article>
