<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 17:34:32[mciao0827] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<event  confidence="0.8" wordnetid="100029378">
<rule  confidence="0.8" wordnetid="105846932">
<act  confidence="0.8" wordnetid="100030358">
<psychological_feature  confidence="0.8" wordnetid="100023100">
<procedure  confidence="0.8" wordnetid="101023820">
<activity  confidence="0.8" wordnetid="100407535">
<algorithm  confidence="0.8" wordnetid="105847438">
<header>
<title>Page replacement algorithm</title>
<id>727476</id>
<revision>
<id>243166370</id>
<timestamp>2008-10-05T12:36:14Z</timestamp>
<contributor>
<username>Lightbot</username>
<id>7178666</id>
</contributor>
</revision>
<categories>
<category>Memory management algorithms</category>
<category>Virtual memory</category>
<category>Online algorithms</category>
</categories>
</header>
<bdy>

This article is about algorithms specific to paging.&#32;&#32;For outline of general cache algorithms (e.g. processor, disk, database, web), see <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../281/954281.xml">
Cache algorithms</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
.&#32;&#32;
In a <link xlink:type="simple" xlink:href="../457/7878457.xml">
computer</link> <link xlink:type="simple" xlink:href="../194/22194.xml">
operating system</link> that utilizes <link xlink:type="simple" xlink:href="../193/311193.xml">
paging</link> for <link xlink:type="simple" xlink:href="../354/32354.xml">
virtual memory</link> <link xlink:type="simple" xlink:href="../924/66924.xml">
memory management</link>, <b>page replacement algorithms</b> decide which memory pages to page out (swap out, write to disk) when a page of memory needs to be allocated. Paging happens when a <link xlink:type="simple" xlink:href="../143/1157143.xml">
page fault</link> occurs and a free page cannot be used to satisfy the allocation, either because there are none, or because the number of free pages is lower than some threshold.<p>

When the page that was selected for replacement and paged out is referenced again it has to be paged in (read in from disk), and this involves waiting for I/O completion. This determines the <it>quality</it> of the page replacement algorithm: the less time waiting for page-ins, the better the algorithm. A page replacement algorithm looks at the limited information about accesses to the pages provided by hardware, and tries to guess which pages should be replaced to minimize the total number of page misses, while balancing this with the costs (primary storage and processor time) of the algorithm itself.</p>

<sec>
<st>
 History </st>
<p>

Page replacement algorithms were a hot topic of research and debate in the 1960s and 1970s.
That mostly ended with the development of sophisticated LRU approximations and working set algorithms. Since then, some basic assumptions made by the traditional page replacement algorithms were invalidated, resulting in a revival of research. In particular, the following trends in the behavior of underlying hardware and user-level software has affected the performance of page replacement algorithms:</p>
<p>

<list>
<entry level="1" type="bullet">

 Size of primary storage has increased by multiple orders of magnitude. With several gigabytes of primary memory, algorithms that require a periodic check of each and every memory frame are becoming less and less practical.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 Memory hierarchies have grown taller. The cost of a CPU cache miss is far more expensive. This exacerbates the previous problem.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <link>
Locality of reference</link> of user software has weakened. This is mostly attributed to the spread of <link xlink:type="simple" xlink:href="../757/22757.xml">
object-oriented programming</link> techniques that favor large numbers of small functions, use of sophisticated data structures like <link xlink:type="simple" xlink:href="../806/30806.xml">
tree</link>s and <link xlink:type="simple" xlink:href="../833/13833.xml">
hash table</link>s that tend to result in chaotic memory reference patterns, and the advent of <link xlink:type="simple" xlink:href="../734/6734.xml">
garbage collection</link> that drastically changed memory access behavior of applications.</entry>
</list>
</p>
<p>

Requirements for page replacement algorithms have changed due to differences in operating system <link xlink:type="simple" xlink:href="../394/50394.xml">
kernel</link> architectures. In particular, most modern OS kernels have unified virtual memory and file system caches, requiring the page replacement algorithm to select a page from among the pages of both user program virtual address spaces and cached files. The latter pages have specific properties. For example, they can be locked, or can have write ordering requirements imposed by <link xlink:type="simple" xlink:href="../073/48073.xml">
journaling</link>. Moreover, as the goal of page replacement is to minimize total time waiting for memory, it has to take into account memory requirements imposed by other kernel sub-systems that allocate memory. As a result, page replacement in modern kernels (<O wordnetid="106832680" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../297/6097297.xml">
Linux</link></O>
, <platform wordnetid="103961939" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<surface wordnetid="104362025" confidence="0.8">
<horizontal_surface wordnetid="103536348" confidence="0.8">
<link xlink:type="simple" xlink:href="../554/7580554.xml">
FreeBSD</link></horizontal_surface>
</surface>
</artifact>
</platform>
, and <message wordnetid="106598915" confidence="0.8">
<information wordnetid="106634376" confidence="0.8">
<electronic_database wordnetid="106588511" confidence="0.8">
<lexical_database wordnetid="106638868" confidence="0.8">
<wordnet wordnetid="106639428" confidence="0.8">
<database wordnetid="106637824" confidence="0.8">
<link xlink:type="simple" xlink:href="../145/46145.xml">
Solaris</link></database>
</wordnet>
</lexical_database>
</electronic_database>
</information>
</message>
) tends to work at the level of a general purpose kernel memory allocator, rather than at the higher level of a virtual memory subsystem.</p>

</sec>
<sec>
<st>
 Local vs. global replacement </st>
<p>

Replacement algorithms can be <it>local</it> or <it>global</it>.</p>
<p>

When a process incurs a page fault, a local page replacement algorithm selects for replacement some page that belongs to that same process (or a group of processes sharing a memory partition).
A global replacement algorithm is free to select any page in memory.</p>
<p>

Local page replacement assumes some form of memory partitioning that determines how many pages are to be assigned to a given process or a group of processes. Most popular forms of partitioning are <it>fixed partitioning</it> and <it>balanced set</it> algorithms based on the <link xlink:type="simple" xlink:href="../794/3007794.xml">
working set</link> model. The advantage of local page replacement is its scalability: each process can handle its page faults independently without contending for some shared global data structure.</p>

</sec>
<sec>
<st>
 Precleaning </st>
<p>

Most replacement algorithms simply return the target page as their result. This means that if target page is <it>dirty</it> (that is, contains data that have to be written to the stable storage before page can be reclaimed), I/O has to be initiated to send that page to the stable storage (to <it>clean</it> the page). In the early days of virtual memory, time spent on cleaning was not of much concern, because virtual memory was first implemented on systems with <link xlink:type="simple" xlink:href="../491/2112491.xml">
full duplex</link> channels to the stable storage, and cleaning was customarily overlapped with paging. Contemporary commodity hardware, on the other hand, does not support full duplex transfers, and cleaning of target pages becomes an issue. </p>
<p>

To deal with this situation, various <it>precleaning</it> policies are implemented. Precleaning is the mechanism that starts I/O on dirty pages that are (likely) to be replaced soon. The idea is that by the time the precleaned page is actually selected for the replacement, the I/O will complete and the page will be clean. Precleaning assumes that it is possible to identify pages that will be replaced <it>next</it>. Precleaning that is too eager can waste I/O bandwidth by writing pages that manage to get re-dirtied before being selected for replacement.</p>

</sec>
<sec>
<st>
Anticipatory paging</st>

<p>

Some systems use <link xlink:type="simple" xlink:href="../997/1310997.xml">
demand paging</link> -- waiting until a page is actually requested before loading it into RAM.</p>
<p>

Other systems attempt to reduce latency by guessing which pages not in RAM are likely to be needed soon, and pre-loading such pages into RAM, before that page is requested. (This is often in combination with pre-cleaning, which guesses which pages currently in RAM are not likely to be needed soon, and pre-writing them out to storage).</p>
<p>

When a page fault occurs, "anticipatory paging" systems will not only bring in the referenced page, but also the next few consecutive pages (analogous to a <link xlink:type="simple" xlink:href="../822/439822.xml">
prefetch input queue</link> in a CPU).</p>
<p>

The <link xlink:type="simple" xlink:href="../193/311193.xml#xpointer(//*[./st=%22Swapping_in_Linux+%22])">
 swap prefetch</link> mechanism goes even further in loading pages (even if they are not consecutive) that are likely to be needed soon.</p>

</sec>
<sec>
<st>
Page replacement algorithms</st>
<p>

There are a variety of page replacement algorithms
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref>:</p>

<ss1>
<st>
The theoretically optimal page replacement algorithm</st>
<p>

The theoretically optimal page replacement algorithm (also known as OPT or <link xlink:type="simple" xlink:href="../737/7737.xml">
clairvoyant</link> replacement algorithm, or <physical_entity wordnetid="100001930" confidence="0.8">
<executive wordnetid="110069645" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<leader wordnetid="109623038" confidence="0.8">
<administrator wordnetid="109770949" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<head wordnetid="110162991" confidence="0.8">
<employee wordnetid="110053808" confidence="0.8">
<research_worker wordnetid="110523076" confidence="0.8">
<link xlink:type="simple" xlink:href="../489/2120489.xml">
Belady's</link></research_worker>
</employee>
</head>
</scientist>
</causal_agent>
</worker>
</administrator>
</leader>
</person>
</executive>
</physical_entity>
 optimal page replacement policy)<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%223%22])">3</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%224%22])">4</ref> is an algorithm that works as follows: when a page needs to be swapped in, the <link xlink:type="simple" xlink:href="../194/22194.xml">
operating system</link> swaps out the page whose next use will occur farthest in the future. For example, a page that is not going to be used for the next 6 seconds will be swapped out over a page that is going to be used within the next 0.4 seconds.</p>
<p>

This algorithm cannot be implemented in the general purpose operating system because it is impossible to compute reliably how long it will be before a page is going to be used, except when all software that will run on a system is either known beforehand and is amenable to the static analysis of its memory reference patterns, or only a class of applications allowing run-time analysis is allowed. Despite this limitation, algorithms exist that can offer near-optimal performance &mdash; the operating system keeps track of all pages referenced by the program, and it uses those data to decide which pages to swap in and out on subsequent runs. This algorithm can offer near-optimal performance, but not on the first run of a program, and only if the program's memory reference pattern is relatively consistent each time it runs.</p>
<p>

Analysis of the paging problem has also been done in the field of <link xlink:type="simple" xlink:href="../716/22716.xml">
 online algorithms</link>. Efficiency of randomized online algorithms for the paging problem is measured using <link xlink:type="simple" xlink:href="../683/236683.xml">
 amortized analysis</link>.</p>

</ss1>
<ss1>
<st>
Not recently used</st>
<p>

The not recently used (NRU) page replacement algorithm is an algorithm that favours keeping pages in memory that have been recently used. This algorithm works on the following principle: when a page is referenced, a referenced bit is set for that page, marking it as referenced. Similarly, when a page is modified (written to), a modified bit is set. The setting of the bits is usually done by the hardware, although it is possible to do so on the software level as well. </p>
<p>

At a certain fixed time interval, the clock interrupt triggers and clears the referenced bit of all the pages, so only pages referenced within the current clock interval are marked with a referenced bit. When a page needs to be replaced, the <link xlink:type="simple" xlink:href="../194/22194.xml">
operating system</link> divides the pages into four classes:</p>
<p>

<list>
<entry level="1" type="bullet">

Class 0: not referenced, not modified</entry>
<entry level="1" type="bullet">

Class 1: not referenced, modified</entry>
<entry level="1" type="bullet">

Class 2: referenced, not modified</entry>
<entry level="1" type="bullet">

Class 3: referenced, modified</entry>
</list>
</p>
<p>

Although it does not seem possible for a page to be not referenced yet modified, this happens when a category 3 page has its referenced bit cleared by the clock interrupt. The NRU algorithm picks a random page from the lowest category for removal. Note that this algorithm implies that a referenced page is more important than a modified page.</p>

</ss1>
<ss1>
<st>
First-in, first-out</st>
<p>

The first-in, first-out (FIFO) page replacement algorithm is a low-overhead algorithm that requires little book-keeping on the part of the <link xlink:type="simple" xlink:href="../194/22194.xml">
operating system</link>. The idea is obvious from the name - the operating system keeps track of all the pages in memory in a queue, with the most recent arrival at the back, and the earliest arrival in front. When a page needs to be replaced, the page at the front of the queue (the oldest page) is selected. While FIFO is cheap and intuitive, it performs poorly in practical application. Thus, it is rarely used in its unmodified form. This algorithm experiences <link xlink:type="simple" xlink:href="../677/3185677.xml">
Belady's anomaly</link>.</p>
<p>

FIFO page replacement algorithm is used by the <link>
VAX/VMS</link> operating system, with some modifications.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%225%22])">5</ref>
Partial second chance is provided by skipping a limited number of entries with valid translation table references <weblink xlink:type="simple" xlink:href="http://mx.isti.cnr.it/cgi-bin/conan?key=Sys_Parameters~TBSKIPWSL&amp;title=VMS%20Help&amp;referer=">
http://mx.isti.cnr.it/cgi-bin/conan?key=Sys_Parameters~TBSKIPWSL&amp;title=VMS%20Help&amp;referer=</weblink>, and additionally, pages are displaced from process working set to a systemwide pool from which they can be recovered if not already re-used.</p>

</ss1>
<ss1>
<st>
Second-chance</st>
<p>

A modified form of the FIFO page replacement algorithm, known as the Second-chance page replacement algorithm, fares relatively better than FIFO at little cost for the improvement.  It works by looking at the front of the queue as FIFO does, but instead of immediately paging out that page, it checks to see if its referenced bit is set. If it is not set, the page is swapped out. Otherwise, the referenced bit is cleared, the page is inserted at the back of the queue (as if it were a new page) and this process is repeated. This can also be thought of as a circular queue.  If all the pages have their referenced bit set, on the second encounter of the first page in the list, that page will be swapped out, as it now has its referenced bit cleared.</p>
<p>

As its name suggests, Second-chance gives every page a "second-chance" - an old page that has been referenced is probably in use, and should not be swapped out over a new page that has not been referenced.</p>

</ss1>
<ss1>
<st>
Clock</st>
<p>

Clock is a more efficient version of FIFO than Second-chance because pages don't have to be constantly pushed to the back of the list, but it performs the same general function as Second-Chance. The clock algorithm keeps a circular list of pages in memory, with the "hand" (iterator) pointing to the oldest page in the list. When a page fault occurs and no empty frames exist, then the R (referenced) bit is inspected at the hand's location. If R is 0, the new page is put in place of the page the "hand" points to, otherwise the R bit is cleared. Then, the clock hand is incremented and the process is repeated until a page is replaced. <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref></p>

</ss1>
<ss1>
<st>
Least recently used</st>
<p>

The least recently used page (LRU) replacement algorithm, though similar in name to NRU, differs in the fact that LRU keeps track of page usage over a short period of time, while NRU just looks at the usage in the last clock interval. LRU works on the idea that pages that have been most heavily used in the past few instructions are most likely to be used heavily in the next few instructions too. While LRU can provide near-optimal performance in theory (almost as good as <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../427/8910427.xml">
Adaptive Replacement Cache</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
), it is rather expensive to implement in practice. There are a few implementation methods for this algorithm that try to reduce the cost yet keep as much of the performance as possible.</p>
<p>

The most expensive method is the linked list method, which uses a linked list containing all the pages in memory. At the back of this list is the least recently used page, and at the front is the most recently used page. The cost of this implementation lies in the fact that items in the list will have to be moved about every memory reference, which is a very time-consuming process.</p>
<p>

Another method that requires hardware support is as follows: suppose the hardware has a 64-bit counter that is incremented at every instruction. Whenever a page is accessed, it gains a value equal to the counter at the time of page access. Whenever a page needs to be replaced, the <link xlink:type="simple" xlink:href="../194/22194.xml">
operating system</link> selects the page with the lowest counter and swaps it out. With present hardware, this is not feasible because the required hardware counters do not exist.</p>
<p>

Because of implementation costs, one may consider algorithms (like those that follow) that are similar to LRU, but which offer cheaper implementations.</p>
<p>

One important advantage of LRU algorithm is that it is amenable to full statistical analysis. It has been proved, for example, that LRU can never result in more than N-times more page faults than OPT algorithm, where N is proportional to the number of pages in the managed pool.</p>
<p>

On the other hand, LRU's weakness is that its performance tends to degenerate under many quite common reference patterns. For example, if there are N pages in the LRU pool, an application executing a  loop over array of N + 1 pages will cause a page fault on each and every access. As loops over large arrays are common, much effort has been put into modifying LRU to work better in such situations. Many of the proposed LRU modifications try to detect looping reference patterns and to switch into suitable replacement algorithm, like Most Recently Used (MRU).</p>

<ss2>
<st>
Variants on LRU</st>
<p>

<list>
<entry level="1" type="number">

<weblink xlink:type="simple" xlink:href="http://www.ics.forth.gr/dcs/Activities/papers/2000.WCW.caching_search.pdf">
LRU-K</weblink> improves greatly on LRU with regard to locality in time. It's also known as LRU-2, for the case that K=2. LRU-1 (i.e. K=1) is the same as normal LRU.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="number">

The <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../427/8910427.xml">
ARC</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%227%22])">7</ref> algorithm extends LRU by maintaining a history of recently evicted pages and uses this to change preference to recent or frequent access. It is particularly resistant to sequential scans.</entry>
</list>
</p>
<p>

A comparison of ARC with other algorithms (LRU,MQ,2Q,LRU-2,LRFU,LIRS) can be found in Megiddo &amp; Modha<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%228%22])">8</ref></p>

</ss2>
</ss1>
<ss1>
<st>
Random</st>
<p>

Random replacement algorithm replaces a random page in memory. This eliminates the overhead cost of tracking page references. Usually it fares better than FIFO, and for looping memory references it is better than LRU, although generally LRU performs better in practice. <link xlink:type="simple" xlink:href="../129/39129.xml">
OS/390</link> uses global LRU approximation and falls back to random replacement when LRU performance degenerates, and the <chip wordnetid="103020034" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<microprocessor wordnetid="103760310" confidence="0.8">
<conductor wordnetid="103088707" confidence="0.8">
<device wordnetid="103183080" confidence="0.8">
<semiconductor_device wordnetid="104171831" confidence="0.8">
<link xlink:type="simple" xlink:href="../208/129208.xml">
Intel i860</link></semiconductor_device>
</device>
</conductor>
</microprocessor>
</instrumentality>
</artifact>
</chip>
 processor used a random replacement policy (Rhodehamel 1989).</p>

</ss1>
<ss1>
<st>
Not frequently used</st>

<p>

The not frequently used (NFU) page replacement algorithm requires a counter, and every page has one counter of its own which is initially set to 0. At each clock interval, all pages that have been referenced within that interval will have their counter incremented by 1. In effect, the counters keep track of how frequently a page has been used. Thus, the page with the lowest counter can be swapped out when necessary.</p>
<p>

The main problem with NFU is that it keeps track of the frequency of use without regard to the time span of use. Thus, in a multi-pass compiler, pages which were heavily used during the first pass, but are not needed in the second pass will be favoured over pages which are comparably lightly used in the second pass, as they have higher frequency counters. This results in poor performance. Other common scenarios exist where NFU will perform similarly, such as an OS boot-up. Thankfully, a similar and better algorithm exists, and its description follows.</p>
<p>

The not frequently used page-replacement algorithm generates fewer page faults than the least recently used page replacement algorithm when the page table contains null pointer values.</p>

</ss1>
<ss1>
<st>
Ageing</st>
<p>

The ageing algorithm is a descendant of the NFU algorithm, with modifications to make it aware of the time span of use. Instead of just incrementing the counters of pages referenced, putting equal emphasis on page references regardless of the time, the reference counter on a page is first shifted right (divided by 2), before adding the referenced bit to the left of that binary number. For instance, if a page has referenced bits 1,0,0,1,1,0 in the past 6 clock ticks, its referenced counter will look like this: 10000000, 01000000, 00100000, 10010000, 11001000, 01100100. Page references closer to the present time have more impact than page references long ago. This ensures that pages referenced more recently, though less frequently referenced, will have higher priority over pages more frequently referenced in the past. Thus, when a page needs to be swapped out, the page with the lowest counter will be chosen.</p>
<p>

Note that aging differs from LRU in the sense that aging can only keep track of the references in the latest 16/32 (depending on the bit size of the processor's integers) time intervals. Consequently, two pages may have referenced counters of 00000000, even though one page was referenced 9 intervals ago and the other 1000 intervals ago. Generally speaking, knowing the usage within the past 16 intervals is sufficient for making a good decision as to which page to swap out. Thus, aging can offer near-optimal performance for a moderate price.</p>

</ss1>
</sec>
<sec>
<st>
 Working Set </st>
<p>

The <link xlink:type="simple" xlink:href="../794/3007794.xml">
working set</link> isn't a page replacement algorithm in the strict sense, but a page-replacement algorithm that can remove a page if it's not in the working set for a process. For example, the Clock algorithm can be modified to ignore pages currently in the working set, or if the R bit set. (<weblink xlink:type="simple" xlink:href="http://portal.acm.org/citation.cfm?id=806596">
Carr and Hennessey, 1981</weblink>)</p>

</sec>
<sec>
<st>
 References </st>

<p>

<reflist>
<entry id="1">
<weblink xlink:type="simple" xlink:href="http://www.cs.uiowa.edu/~jones/opsys/fall95/notes/0908.html">
"Lecture Notes"</weblink> by Douglas W. Jones 1995
</entry>
<entry id="2">
<weblink xlink:type="simple" xlink:href="http://www.read.cs.ucla.edu/111/2006fall/notes/lec11">
2006fall:notes:lec11 [CS111&#93;</weblink></entry>
<entry id="3">
<weblink xlink:type="simple" xlink:href="http://cat.inist.fr/?aModele=afficheN&amp;cpsidt=15530156">
Characterization of Web reference behavior revisited: Evidence for Dichotomized Cache management</weblink></entry>
<entry id="4">
<weblink xlink:type="simple" xlink:href="http://www.cs.uiowa.edu/~jones/opsys/fall95/notes/0908.html">
22C:116, Notes, Sept. 8, 1995</weblink></entry>
<entry id="5">
Abraham Silberschatz, Peter Baer Galvin, Greg Gagne. <it>Operating Systems Concepts (Seventh Edition).</it>: Wiley 2005. p. 339.</entry>
<entry id="6">
Andrew S. Tanenbaum. <it>Modern Operating Systems (Second Edition)</it>. pp. 218 (4.4.5). 2001.</entry>
<entry id="7">
Megiddo &amp; Modha, <it><weblink xlink:type="simple" xlink:href="http://www.almaden.ibm.com/cs/people/dmodha/arcfast.pdf">
ARC: A Self-tuning, low overhead replacement cache</weblink>''</it></entry>
<entry id="8">
Nimrod Megiddo &amp; Dharmendra S. Modha, <it><weblink xlink:type="simple" xlink:href="http://www.almaden.ibm.com/cs/people/dmodha/ARC.pdf">
Outperforming LRU with an Adaptive Replacement Cache Algorithm</weblink><message wordnetid="106598915" confidence="0.8">
<information wordnetid="106634376" confidence="0.8">
<language wordnetid="106282651" confidence="0.8">
<format wordnetid="106636806" confidence="0.8">
<link xlink:type="simple" xlink:href="../077/24077.xml">
PDF</link></format>
</language>
</information>
</message>
&nbsp;(123&nbsp;<link xlink:type="simple" xlink:href="../755/149755.xml">
KiB</link>)</it>, IEEE Computer Magazine, pp. 58-65, April 2004.</entry>
</reflist>
</p>

<ss1>
<st>
See also</st>
<p>

<list>
<entry level="1" type="bullet">

 Aho, Denning and Ullman, <it><weblink xlink:type="simple" xlink:href="http://portal.acm.org/citation.cfm?id=321632&amp;coll=portal&amp;dl=ACM">
Principles of Optimal Page Replacement</weblink></it>, Journal of the ACM, Vol. 18, Issue 1,January 1971, pp 80-93   </entry>
<entry level="1" type="bullet">

 Rhodehamel, Michael W. "<weblink xlink:type="simple" xlink:href="http://ieeexplore.ieee.org/xpl/abs_free.jsp?arNumber=63392">
The Bus Interface and Paging Units of the i860(tm) Microprocessor</weblink>". In Proc. IEEE International Conference on Computer Design, p. 380-384, 1989.</entry>
<entry level="1" type="bullet">

 Tanenbaum, Andrew S. <it>Operating Systems: Design and Implementation (Second Edition)</it>. New Jersey: Prentice-Hall 1997.</entry>
<entry level="1" type="bullet">

 Tanenbaum, Andrew S. <it>Modern Operating Systems (Second Edition)</it>. New Jersey: Prentice-Hall 2001. Online excerpt on page replacement algorithms: <weblink xlink:type="simple" xlink:href="http://www.informit.com/articles/article.aspx?p=25260">
Page Replacement Algorithms</weblink>.</entry>
<entry level="1" type="bullet">

 Johnson and Shasha, <it><weblink xlink:type="simple" xlink:href="http://www.vldb.org/conf/1994/P439.PDF">
2Q: A Low Overhead High Performance Buffer Management Replacement Algorithm</weblink><message wordnetid="106598915" confidence="0.8">
<information wordnetid="106634376" confidence="0.8">
<language wordnetid="106282651" confidence="0.8">
<format wordnetid="106636806" confidence="0.8">
<link xlink:type="simple" xlink:href="../077/24077.xml">
PDF</link></format>
</language>
</information>
</message>
&nbsp;(1.01&nbsp;<link xlink:type="simple" xlink:href="../727/60727.xml">
MiB</link>)</it> <weblink xlink:type="simple" xlink:href="http://www.vldb.org/dblp/db/conf/vldb/vldb94-439.html">
abstract</weblink></entry>
<entry level="1" type="bullet">

 Gideon Glass and Pei Cao <weblink xlink:type="simple" xlink:href="http://portal.acm.org/citation.cfm?id=258681&amp;jmp=abstract&amp;coll=portal&amp;dl=ACM&amp;CFID=12125227&amp;CFTOKEN=21656990#abstract">
 Adaptive-Page-Replacement-Based-on-Memory-Reference-Behavior</weblink>.  Also available in extended form as <weblink xlink:type="simple" xlink:href="http://www.cs.wisc.edu/techreports/viewreport.php?report=1338">
Technical Report 1338</weblink> at www.cs.wisc.edu</entry>
<entry level="1" type="bullet">

 Jongmin Kim and others, <it><weblink xlink:type="simple" xlink:href="http://ssrnet.snu.ac.kr/~choijm/paper/IC-2000-OSDI-UBM.pdf">
A Low-Overhead High-Performance Unified Buffer Management Scheme that Exploits Sequential and Looping References</weblink><message wordnetid="106598915" confidence="0.8">
<information wordnetid="106634376" confidence="0.8">
<language wordnetid="106282651" confidence="0.8">
<format wordnetid="106636806" confidence="0.8">
<link xlink:type="simple" xlink:href="../077/24077.xml">
PDF</link></format>
</language>
</information>
</message>
&nbsp;(4.14&nbsp;<link xlink:type="simple" xlink:href="../727/60727.xml">
MiB</link>)</it>, <weblink xlink:type="simple" xlink:href="http://www.usenix.org/events/osdi2000/">
Usenix Symposium on Operating System Design and Implementation (OSDI'2000)</weblink>, San Diego, CA, October 17-21, 2000</entry>
<entry level="1" type="bullet">

 Sorav Bansal and Dharmendra S. Modha, <it><weblink xlink:type="simple" xlink:href="http://www.almaden.ibm.com/cs/people/dmodha/clockfast.pdf">
CAR: Clock with Adaptive Replacement</weblink><message wordnetid="106598915" confidence="0.8">
<information wordnetid="106634376" confidence="0.8">
<language wordnetid="106282651" confidence="0.8">
<format wordnetid="106636806" confidence="0.8">
<link xlink:type="simple" xlink:href="../077/24077.xml">
PDF</link></format>
</language>
</information>
</message>
&nbsp;(212&nbsp;<link xlink:type="simple" xlink:href="../755/149755.xml">
KiB</link>)''</it></entry>
<entry level="1" type="bullet">

 Smaragdakis and others, <it><weblink xlink:type="simple" xlink:href="http://www.cs.amherst.edu/~sfkaplan/courses/spring-2004/cs40/papers/SKW:EELRUSEAPR.pdf">
EELRU: Simple and Effective Adaptive Page Replacement</weblink><message wordnetid="106598915" confidence="0.8">
<information wordnetid="106634376" confidence="0.8">
<language wordnetid="106282651" confidence="0.8">
<format wordnetid="106636806" confidence="0.8">
<link xlink:type="simple" xlink:href="../077/24077.xml">
PDF</link></format>
</language>
</information>
</message>
&nbsp;(1.55&nbsp;<link xlink:type="simple" xlink:href="../727/60727.xml">
MiB</link>)''</it></entry>
<entry level="1" type="bullet">

 Song Jiang and Xiaodong Zhang, <it><weblink xlink:type="simple" xlink:href="http://www.cse.ohio-state.edu/hpcs/WWW/HTML/publications/papers/TR-02-6.pdf">
LIRS: a Low Inter Reference recency Set replacement</weblink><message wordnetid="106598915" confidence="0.8">
<information wordnetid="106634376" confidence="0.8">
<language wordnetid="106282651" confidence="0.8">
<format wordnetid="106636806" confidence="0.8">
<link xlink:type="simple" xlink:href="../077/24077.xml">
PDF</link></format>
</language>
</information>
</message>
&nbsp;(309&nbsp;<link xlink:type="simple" xlink:href="../755/149755.xml">
KiB</link>)</it>, SIGMETRICS 2002</entry>
<entry level="1" type="bullet">

 D. Lee and others, <it><weblink xlink:type="simple" xlink:href="http://csdl2.computer.org/persagen/DLAbsToc.jsp?resourcePath=/dl/proceedings/&amp;toc=comp/proceedings/euromicro/1997/8215/00/8215toc.xml&amp;DOI=10.1109/EMSCNT.1997.658446">
  Implementation and Performance Evaluation of the LRFU Replacement Policy</weblink></it>, p. 0106,  23rd <weblink xlink:type="simple" xlink:href="http://csdl2.computer.org/persagen/DLAbsToc.jsp?resourcePath=/dl/proceedings/euromicro/&amp;toc=comp/proceedings/euromicro/1997/8215/00/8215toc.xml">
Euromicro Conference: New Frontiers of Information Technology-Short Contributions</weblink>, 1997</entry>
<entry level="1" type="bullet">

 Elizabeth J. O'Neil and others, <it><weblink xlink:type="simple" xlink:href="http://www.cs.cmu.edu/~christos/courses/721-resources/p297-o_neil.pdf">
The LRU-K page replacement algorithm for database disk buffering</weblink><message wordnetid="106598915" confidence="0.8">
<information wordnetid="106634376" confidence="0.8">
<language wordnetid="106282651" confidence="0.8">
<format wordnetid="106636806" confidence="0.8">
<link xlink:type="simple" xlink:href="../077/24077.xml">
PDF</link></format>
</language>
</information>
</message>
&nbsp;(1.17&nbsp;<link xlink:type="simple" xlink:href="../727/60727.xml">
MiB</link>)</it>,  <weblink xlink:type="simple" xlink:href="http://portal.acm.org/citation.cfm?id=170036.170081">
ACM SIGMOD Conf.</weblink>, pp. 297â€“306, 1993.</entry>
<entry level="1" type="bullet">

 Y. Zhou and J.F. Philbin, <it><weblink xlink:type="simple" xlink:href="http://www.usenix.org/events/usenix01/full_papers/zhou/">
The Multi-Queue Replacement Algorithm for Second-Level Buffer Caches</weblink></it>, Proc. Usenix Ann. Tech. Conf. (Usenix 2001), pp. 91-104.</entry>
</list>
</p>


</ss1>
</sec>
</bdy>
</algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</article>
