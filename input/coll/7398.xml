<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 15:23:45[mciao0825] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Computer security</title>
<id>7398</id>
<revision>
<id>244634742</id>
<timestamp>2008-10-11T20:19:54Z</timestamp>
<contributor>
<username>Closedmouth</username>
<id>372693</id>
</contributor>
</revision>
<categories>
<category>Computer security</category>
<category>Security</category>
<category>All articles needing copy edit</category>
<category>Computer network security</category>
<category>Articles with invalid date parameter in template</category>
<category>Wikipedia articles needing copy edit from July 2007</category>
<category>Secure communication</category>
<category>Crime prevention</category>
<category>Electronic commerce</category>
<category>National security</category>
</categories>
</header>
<bdy>

<table class="metadata plainlinks ambox ">
<row>
<col>

ambox-style" style=""</col>
</row>
<row>
<col class="mbox-image"><p>

<image width="30px" src="Acap.svg">
</image>
</p>
</col>
<col style="" class="mbox-text">
 <b>This article or section needs  for  grammar, style, cohesion, tone or spelling.</b>
You can assist by <weblink xlink:type="simple" xlink:href="http://localhost:18088/wiki/index.php?title=Computer_security&amp;action=edit">
editing it</weblink> now. A how-to is available.<it>&nbsp;(July 2007)''</it></col>
</row>
</table>


<indent level="1">

 <it>This article describes how security can be achieved through design and engineering. See the <link xlink:type="simple" xlink:href="../885/55885.xml">
computer insecurity</link> article for an alternative approach that describes computer security exploits and defenses.</it>
</indent>
<b>Computer security </b> is a branch of technology known as <link xlink:type="simple" xlink:href="../036/15036.xml">
information security</link> as applied to <link xlink:type="simple" xlink:href="../457/7878457.xml">
computer</link>s. The objective of computer security varies and can include protection of information from theft or corruption, or the preservation of availability, as defined in the security policy. <p>

Computer security imposes requirements on computers that are different from most system requirements because they often take the form of constraints on what computers are not supposed to do. This makes computer security particularly challenging because it is hard enough just to make computer programs do everything they are designed to do correctly. Furthermore, negative requirements are deceptively complicated to satisfy and require exhaustive testing to verify, which is impractical for most computer programs. Computer security provides a technical strategy to convert negative requirements to positive enforceable rules. For this reason, computer security is often more technical and mathematical than some <link xlink:type="simple" xlink:href="../323/5323.xml">
computer science</link> fields. </p>
<p>

Typical approaches to improving computer security (in approximate order of strength) can include the following: </p>
<p>

<list>
<entry level="1" type="bullet">

Physically limit access to computers to only those who will not compromise security. </entry>
<entry level="1" type="bullet">

Hardware mechanisms that impose rules on computer programs, thus avoiding depending on computer programs for computer security. </entry>
<entry level="1" type="bullet">

Operating system mechanisms that impose rules on programs to avoid trusting computer programs.</entry>
<entry level="1" type="bullet">

Programming strategies to make computer programs dependable and resist subversion. </entry>
</list>
</p>

<sec>
<st>
 Secure operating systems </st>
<p>

One use of the term computer security refers to technology to implement a secure <link xlink:type="simple" xlink:href="../194/22194.xml">
operating system</link>. Much of this technology is based on science developed in the 1980s and used to produce what may be some of the most impenetrable operating systems ever. Though still valid, the technology is in limited use today, primarily because it imposes some changes to system management and also because it is not widely understood. Such ultra-strong secure operating systems are based on <link xlink:type="simple" xlink:href="../394/50394.xml">
operating system kernel</link> technology that can guarantee that certain security policies are absolutely enforced in an operating environment. An example of such a <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<link xlink:type="simple" xlink:href="../175/1000175.xml">
Computer security policy</link></activity>
</procedure>
</psychological_feature>
</act>
</causal_agent>
</worker>
</event>
</assistant>
</model>
</person>
</physical_entity>
 is the <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../866/423866.xml">
Bell-LaPadula model</link></causal_agent>
</worker>
</assistant>
</model>
</person>
</physical_entity>
. The strategy is based on a coupling of special <link xlink:type="simple" xlink:href="../553/19553.xml">
microprocessor</link> hardware features, often involving the <link xlink:type="simple" xlink:href="../112/177112.xml">
memory management unit</link>, to a special correctly implemented operating system kernel. This forms the foundation for a secure operating system which, if certain critical parts are designed and implemented correctly, can ensure the absolute impossibility of penetration by hostile elements. This capability is enabled because the configuration not only imposes a security policy, but in theory completely protects itself from corruption. Ordinary operating systems, on the other hand, lack the features that assure this maximal level of security. The design methodology to produce such secure systems is precise, deterministic and logical. </p>
<p>

Systems designed with such methodology represent the state of the art of computer security although products using such security are not widely known. In sharp contrast to most kinds of software, they meet specifications with verifiable certainty comparable to specifications for size, weight and power. Secure operating systems designed this way are used primarily to protect national security information, military secrets, and the data of international financial institutions. These are very powerful security tools and very few secure operating systems have been certified at the highest level (<event wordnetid="100029378" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<link xlink:type="simple" xlink:href="../300/6687300.xml">
Orange Book</link></activity>
</procedure>
</psychological_feature>
</act>
</event>
 A-1) to operate over the range of "Top Secret" to "unclassified" (including Honeywell SCOMP, USAF SACDIN, NSA Blacker and Boeing MLS LAN.) The assurance of security depends not only on the soundness of the design strategy, but also on the assurance of correctness of the implementation, and therefore there are degrees of security strength defined for COMPUSEC. The <standard wordnetid="107260623" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<system_of_measurement wordnetid="113577171" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<link xlink:type="simple" xlink:href="../625/57625.xml">
Common Criteria</link></activity>
</procedure>
</system_of_measurement>
</psychological_feature>
</act>
</event>
</standard>
 quantifies security strength of products in terms of two components, security functionality and assurance level (such as EAL levels), and these are specified in a <event wordnetid="100029378" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<link xlink:type="simple" xlink:href="../859/6440859.xml">
Protection Profile</link></activity>
</procedure>
</psychological_feature>
</act>
</event>
 for requirements and a <event wordnetid="100029378" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<link xlink:type="simple" xlink:href="../784/15353784.xml">
Security Target</link></activity>
</procedure>
</psychological_feature>
</act>
</event>
 for product descriptions. None of these ultra-high assurance secure general purpose operating systems have been produced for decades or certified under the Common Criteria.</p>
<p>

In USA parlance, the term High Assurance usually suggests the system has the right security functions that are implemented robustly enough to protect DoD and DoE classified information.  Medium assurance suggests it can protect less valuable information, such as income tax information.  Secure operating systems designed to meet medium robustness levels of security functionality and assurance have seen wider use within both government and commercial markets. Medium robust systems may provide the same the security functions as high assurance secure operating systems but do so at a lower assurance level (such as Common Criteria levels EAL4 or EAL5). Lower levels mean we can be less certain that the security functions are implemented flawlessly, and therefore less dependable.  These systems are found in use on web servers, guards, database servers, and management hosts and are used not only to protect the data stored on these systems but also to provide a high level of protection for network connections and routing services.</p>

</sec>
<sec>
<st>
 Security architecture </st>
<p>

Security Architecture can be defined as the design artifacts that describe how the security controls (security countermeasures) are positioned, and how they relate to the overall information technology architecture. These controls serve the purpose to maintain the system's quality attributes, among them <link xlink:type="simple" xlink:href="../859/353859.xml">
confidentiality</link>, <link xlink:type="simple" xlink:href="../859/127859.xml">
integrity</link>, <link xlink:type="simple" xlink:href="../760/40760.xml">
availability</link>, <link xlink:type="simple" xlink:href="../973/161973.xml">
accountability</link> and <link xlink:type="simple" xlink:href="../276/176276.xml">
assurance</link>."<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref>. In simpler words, a security architecture is the plan that shows where security measures need to be placed. If the plan describes a specific solution then, prior to building such a plan, one would make a risk analysis. If the plan describes a generic high level design (reference architecture) then the plan should be based on a threat analysis.</p>

</sec>
<sec>
<st>
 Security by design </st>
<p>

The technologies of computer security are based on <link xlink:type="simple" xlink:href="../225/3729225.xml">
logic</link>. There is no universal standard notion of what secure behavior is. "Security" is a concept that is unique to each situation. Security is extraneous to the function of a computer application, rather than ancillary to it, thus security necessarily imposes restrictions on the application's behavior.</p>
<p>

There are several approaches to <link xlink:type="simple" xlink:href="../684/41684.xml">
security</link> in <link xlink:type="simple" xlink:href="../213/5213.xml">
computing</link>, sometimes a combination of approaches is valid:
<list>
<entry level="1" type="number">

Trust all the software to abide by a security policy but the software is not trustworthy (this is <link xlink:type="simple" xlink:href="../885/55885.xml">
computer insecurity</link>).</entry>
<entry level="1" type="number">

Trust all the software to abide by a security policy and the software is validated as trustworthy (by tedious branch and path analysis for example).</entry>
<entry level="1" type="number">

Trust no software but enforce a security policy with <link xlink:type="simple" xlink:href="../838/12323838.xml">
mechanisms</link> that are not trustworthy (again this is <link xlink:type="simple" xlink:href="../885/55885.xml">
computer insecurity</link>).</entry>
<entry level="1" type="number">

Trust no software but enforce a security policy with trustworthy mechanisms. </entry>
</list>
</p>
<p>

Many systems have unintentionally resulted in the first possibility. Since approach two is expensive and non-deterministic, its use is very limited. Approaches one and three lead to failure. Because approach number four is often based on hardware mechanisms and avoids abstractions and a multiplicity of degrees of freedom, it is more practical. Combinations of approaches two and four are often used in a layered architecture with thin layers of two and thick layers of four. </p>
<p>

There are myriad strategies and techniques used to design security systems. There are few, if any, effective strategies to enhance security after design. </p>
<p>

One technique enforces the <link xlink:type="simple" xlink:href="../226/1695226.xml">
principle of least privilege</link> to great extent, where an entity has only the privileges that are needed for its function. That way even if an <link xlink:type="simple" xlink:href="../940/487940.xml">
attacker</link> gains access to one part of the system, fine-grained security ensures that it is just as difficult for them to access the rest.</p>
<p>

Furthermore, by breaking the system up into smaller components, the complexity of individual components is reduced, opening up the possibility of using techniques such as <link xlink:type="simple" xlink:href="../546/2546.xml">
automated theorem proving</link> to prove the correctness of crucial software subsystems. This enables a <link xlink:type="simple" xlink:href="../143/585143.xml">
closed form solution</link> to security that works well when only a single well-characterized property can be isolated as critical, and that property is also assessable to math. Not surprisingly, it is impractical for generalized correctness, which probably cannot even be defined, much less proven. Where formal correctness proofs are not possible, rigorous use of <link xlink:type="simple" xlink:href="../249/528249.xml">
code review</link> and <link xlink:type="simple" xlink:href="../828/222828.xml">
unit testing</link> represent a best-effort approach to make modules secure.</p>
<p>

The design should use "<link xlink:type="simple" xlink:href="../195/7991195.xml">
defense in depth</link>", where more than one subsystem needs to be violated to compromise the integrity of the system and the information it holds. Defense in depth works when the breaching of one security measure does not provide a platform to facilitate subverting another. Also, the cascading principle acknowledges that several low hurdles does not make a high hurdle. So cascading several weak mechanisms does not provide the safety of a single stronger mechanism. </p>
<p>

Subsystems should default to secure settings, and wherever possible should be designed to "fail secure" rather than "fail insecure" (see <link xlink:type="simple" xlink:href="../136/41136.xml">
fail safe</link> for the equivalent in safety engineering). Ideally, a secure system should require a deliberate, conscious, knowledgeable and free decision on the part of legitimate authorities in order to make it insecure. </p>
<p>

In addition, security should not be an all or nothing issue. The designers and operators of systems should assume that security breaches are inevitable.
Full <link xlink:type="simple" xlink:href="../742/40742.xml">
audit trail</link>s should be kept of system activity, so that when a security breach occurs, the mechanism and extent of the breach can be determined. Storing audit trails remotely, where they can only be appended to, can keep intruders from covering their tracks. Finally, <link xlink:type="simple" xlink:href="../586/11586.xml">
full disclosure</link> helps to ensure that when bugs are found the "<link xlink:type="simple" xlink:href="../704/1904704.xml">
window of vulnerability</link>" is kept as short as possible.</p>

<ss1>
<st>
 Early history of security by design </st>
<p>

The early <O wordnetid="106832680" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../847/18847.xml">
Multics</link></O>
 operating system was notable for its early emphasis on computer security by design, and Multics was possibly the very first operating system to be designed as a secure system from the ground up. In spite of this, Multics' security was broken, not once, but repeatedly. The strategy was known as 'penetrate and test' and has become widely known as a non-terminating process that fails to produce computer security. This led to further work on computer security that prefigured modern <link xlink:type="simple" xlink:href="../730/28730.xml">
security engineering</link> techniques producing <link xlink:type="simple" xlink:href="../327/358327.xml">
closed form</link> processes that terminate.</p>

</ss1>
</sec>
<sec>
<st>
 Secure coding </st>
<p>

If the operating environment is not based on a secure operating system capable of maintaining a domain for its own execution, and capable of protecting application code from malicious subversion, and capable of protecting the system from subverted code, then high degrees of security are understandably not possible. While such secure operating systems are possible and have been implemented, most commercial systems fall in a 'low security' category because they rely on features not supported by secure operating systems (like portability, et al.). In low security operating environments, applications must be relied on to participate in their own protection. There are 'best effort' secure coding practices that can be followed to make an application more resistant to malicious subversion. </p>
<p>

In commercial environments, the majority of software subversion <link xlink:type="simple" xlink:href="../827/1129827.xml">
vulnerabilities</link> result from a few known kinds of coding defects. Common software defects include <link xlink:type="simple" xlink:href="../373/4373.xml">
buffer overflows</link>, <link xlink:type="simple" xlink:href="../607/532607.xml">
format string vulnerabilities</link>, <link xlink:type="simple" xlink:href="../421/2151421.xml">
integer overflow</link>, and <accomplishment wordnetid="100035189" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<action wordnetid="100037396" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<feat wordnetid="100036762" confidence="0.8">
<link xlink:type="simple" xlink:href="../470/1065470.xml">
code/command injection</link></feat>
</psychological_feature>
</act>
</action>
</event>
</accomplishment>
.</p>
<p>

Some common languages such as C and C++ are vulnerable to all of these defects (see <weblink xlink:type="simple" xlink:href="http://www.cert.org/books/secure-coding">
Seacord, <it>"Secure Coding in C and C++"''</it></weblink>). Other languages, such as Java, are more resistant to some of these defects, but are still prone to code/command injection and other software defects which facilitate subversion.</p>
<p>

Recently another bad coding practice has come under scrutiny; <link xlink:type="simple" xlink:href="../856/1119856.xml">
dangling pointer</link>s. The first known exploit for this particular problem was presented in July 2007. Before this publication the problem was known but considered to be academic and not practically exploitable. <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref> </p>
<p>

In summary, 'secure coding' can provide significant payback in low security operating environments, and therefore worth the effort. Still there is no known way to provide a reliable degree of subversion resistance with any degree or combination of 'secure coding.'</p>

</sec>
<sec>
<st>
 Capabilities vs. ACLs </st>
<p>

Within computer systems, the two fundamental means of enforcing privilege separation are <link xlink:type="simple" xlink:href="../589/61589.xml">
access control list</link>s (ACLs) and <link xlink:type="simple" xlink:href="../717/539717.xml">
capabilities</link>. The semantics of ACLs have been proven to be insecure in many situations (e.g., <link xlink:type="simple" xlink:href="../076/207076.xml">
Confused deputy problem</link>). It has also been shown that ACL's promise of giving access to an object to only one person can never be guaranteed in practice. Both of these problems are resolved by capabilities. This does not mean practical flaws exist in all ACL-based systems, but only that the designers of certain utilities must take responsibility to ensure that they do not introduce flaws.</p>
<p>

Unfortunately, for various historical reasons, capabilities have been mostly restricted to research <link xlink:type="simple" xlink:href="../194/22194.xml">
operating system</link>s and commercial OSs still use ACLs. Capabilities can, however, also be implemented at the language level, leading to a style of programming that is essentially a refinement of standard object-oriented design. An open source project in the area is the <link xlink:type="simple" xlink:href="../046/1377046.xml">
E language</link>.</p>
<p>

First the Plessey <link xlink:type="simple" xlink:href="../744/401744.xml">
System 250</link> and then Cambridge <link xlink:type="simple" xlink:href="../448/1626448.xml">
CAP computer</link> demonstrated the use of capabilities, both in hardware and software, in the 1970s, so this technology is hardly new. A reason for the lack of adoption of capabilities may be that ACLs appeared to offer a 'quick fix' for security without pervasive redesign of the operating system and hardware.</p>
<p>

The most secure computers are those not connected to the Internet and shielded from any interference. In the real world, the most security comes from <link xlink:type="simple" xlink:href="../194/22194.xml">
operating system</link>s where <link xlink:type="simple" xlink:href="../684/41684.xml">
security</link> is not an add-on, such as <link xlink:type="simple" xlink:href="../005/248005.xml">
OS/400</link> from <company wordnetid="108058098" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../259/18622259.xml">
IBM</link></company>
. This almost never shows up in lists of vulnerabilities for good reason. Years may elapse between one problem needing remediation and the next.</p>
<p>

A good example of a secure system is <link xlink:type="simple" xlink:href="../077/353077.xml">
EROS</link>. But see also the article on <link>
secure operating systems</link>. <platform wordnetid="103961939" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<surface wordnetid="104362025" confidence="0.8">
<horizontal_surface wordnetid="103536348" confidence="0.8">
<link xlink:type="simple" xlink:href="../554/7580554.xml#xpointer(//*[./st=%22TrustedBSD%22])">
TrustedBSD</link></horizontal_surface>
</surface>
</artifact>
</platform>
 is an example of an <link xlink:type="simple" xlink:href="../758/18938758.xml">
open source</link> project with a goal, among other things, of building capability functionality into the <platform wordnetid="103961939" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<surface wordnetid="104362025" confidence="0.8">
<horizontal_surface wordnetid="103536348" confidence="0.8">
<link xlink:type="simple" xlink:href="../554/7580554.xml">
FreeBSD</link></horizontal_surface>
</surface>
</artifact>
</platform>
 operating system. Much of the work is already done.</p>

</sec>
<sec>
<st>
 Applications </st>
<p>

Computer security is critical in almost any technology-driven industry which operates on computer systems. The issues of computer based systems and addressing their countless vulnerabilities are an integral part of maintaining an operational industry. <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%223%22])">3</ref></p>

<ss1>
<st>
 In aviation </st>
<p>

The aviation industry is especially important when analyzing computer security because the involved risks include expensive equipment and cargo, transportation infrastructure, and human life. Security can be compromised by hardware and software malpractice, human error, and faulty operating environments. Threats that exploit computer vulnerabilities can stem from sabotage, espionage, industrial competition, terrorist attack, mechanical malfunction, and human error. <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%224%22])">4</ref></p>
<p>

The consequences of a successful deliberate or inadvertent misuse of a computer system in the aviation industry range from loss of confidentiality to loss of system integrity, which may lead to more serious concerns such as data theft or loss, network and <link xlink:type="simple" xlink:href="../563/48563.xml">
air traffic control</link> outages, which in turn can lead to airport closures, loss of aircraft, loss of passenger life. <link xlink:type="simple" xlink:href="../357/92357.xml">
Military</link> systems that control munitions can pose an even greater risk.</p>
<p>

A proper attack does not need to be very high tech or well funded for a power outage at an airport alone can cause repercussions worldwide. <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%225%22])">5</ref>. One of the easiest and, arguably, the most difficult to trace security vulnerabilities is achievable by transmitting unauthorized communications over specific radio frequencies. These transmissions may spoof air traffic controllers or simply disrupt communications altogether. These incidents are very common, having altered flight courses of commercial aircraft and caused panic and confusion in the past. Controlling aircraft over oceans is especially dangerous because radar surveillance only extends 175 to 225 miles offshore. Beyond the radar's sight controllers must rely on periodic radio communications with a third party.</p>
<p>

Lightning, power fluctuations, surges, <link xlink:type="simple" xlink:href="../299/5631299.xml">
brown-out</link>s, blown fuses, and various other power outages instantly disable all computer systems, since they are dependent on electrical source. Other accidental and intentional faults have caused significant disruption of safety critical systems throughout the last few decades and dependence on reliable communication and electrical power only
jeopardizes computer safety.</p>

<ss2>
<st>
Notable system accidents</st>
<p>

In 1983, Korean Airlines <link xlink:type="simple" xlink:href="../257/108257.xml">
Flight 007</link>, a <aircraft wordnetid="102686568" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../614/4614.xml">
Boeing 747</link></aircraft>
 was shot down by Soviet <link xlink:type="simple" xlink:href="../641/809641.xml">
Su-15</link> jets after a navigation computer malfunction caused the aircraft to steer 185 miles off course into Soviet Union airspace. All 269 passengers were killed. <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref></p>
<p>

In 1994, over a hundred intrusions were made by unidentified hackers into the Rome Laboratory, the US Air Force's main command and research facility. Using <link>
trojan horse</link> viruses, hackers were able to obtain unrestricted access to Rome's networking systems and remove traces of their activities. The intruders were able to obtain classified files, such as air tasking order systems data and furthermore able to penetrate connected networks of <link xlink:type="simple" xlink:href="../568/18426568.xml">
National Aeronautics and Space Administration</link>'s Goddard Space Flight Center, Wright-Patterson Air Force Base, some Defense contractors, and other private sector organizations, by posing as
a trusted Rome center user. <ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%227%22])">7</ref></p>
<p>

<link xlink:type="simple" xlink:href="../324/1072324.xml">
Electromagnetic interference</link> is another threat to computer safety and in 1989, a United States Air Force <link xlink:type="simple" xlink:href="../813/11813.xml">
F-16</link> jet accidentally dropped a 230 kg bomb in West <symbol wordnetid="106806469" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../830/48830.xml">
Georgia</link></symbol>
 after unspecified interference caused the jet's computers to release it.
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%228%22])">8</ref></p>
<p>

A similar telecommunications accident also happened in 1994, when two <link xlink:type="simple" xlink:href="../941/37941.xml">
UH-60 Blackhawk</link> helicopters were destroyed by <link xlink:type="simple" xlink:href="../715/11715.xml">
F-15</link> aircraft in Iraq because the <link xlink:type="simple" xlink:href="../595/1069595.xml">
IFF</link> system's encryption system malfunctioned.</p>

</ss2>
</ss1>
</sec>
<sec>
<st>
 Terminology </st>
<p>

The following terms used in engineering secure systems are explained below. 
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../296/1362296.xml">
Firewall</link>s can either be hardware devices or software programs. They provide some protection from online intrusion, but since they allow some applications (e.g. web browsers) to connect to the Internet, they don't protect against some unpatched vulnerabilities in these applications (e.g. lists of known unpatched holes from <company wordnetid="108058098" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../310/1569310.xml">
Secunia</link></company>
 and <link xlink:type="simple" xlink:href="../213/3988213.xml">
SecurityFocus</link>).</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <know-how wordnetid="105616786" confidence="0.8">
<method wordnetid="105660268" confidence="0.8">
<link xlink:type="simple" xlink:href="../546/2546.xml">
Automated theorem proving</link></method>
</know-how>
 and other verification tools can enable critical algorithms and code used in secure systems to be mathematically proven to meet their specifications.</entry>
<entry level="1" type="bullet">

 Thus simple <link xlink:type="simple" xlink:href="../023/20023.xml#xpointer(//*[./st=%22Microkernels%22])">
microkernels</link> can be written so that we can be sure they don't contain any bugs: eg <link xlink:type="simple" xlink:href="../077/353077.xml">
EROS</link> and <message wordnetid="106598915" confidence="0.8">
<information wordnetid="106634376" confidence="0.8">
<electronic_database wordnetid="106588511" confidence="0.8">
<lexical_database wordnetid="106638868" confidence="0.8">
<wordnet wordnetid="106639428" confidence="0.8">
<database wordnetid="106637824" confidence="0.8">
<link xlink:type="simple" xlink:href="../689/3654689.xml">
Coyotos</link></database>
</wordnet>
</lexical_database>
</electronic_database>
</information>
</message>
.</entry>
</list>
</p>
<p>

A bigger OS, capable of providing a standard <link xlink:type="simple" xlink:href="../ury/24th_century.xml">
API</link> like <standard wordnetid="107260623" confidence="0.8">
<system_of_measurement wordnetid="113577171" confidence="0.8">
<link xlink:type="simple" xlink:href="../305/23305.xml">
POSIX</link></system_of_measurement>
</standard>
, can be built on a secure microkernel using small API servers running as normal programs. If one of these API servers has a bug, the kernel and the other servers are not affected: e.g. <software wordnetid="106566077" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../236/13236.xml">
Hurd</link></software>
 or <link xlink:type="simple" xlink:href="../880/5574880.xml">
Minix 3</link>.</p>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../432/18934432.xml">
Cryptographic</link> techniques can be used to defend data in transit between systems, reducing the probability that data exchanged between systems can be intercepted or modified.</entry>
<entry level="1" type="bullet">

 Strong <link xlink:type="simple" xlink:href="../967/47967.xml">
authentication</link> techniques can be used to ensure that communication end-points are who they say they are.</entry>
</list>
</p>
<p>

<link xlink:type="simple" xlink:href="../865/59865.xml">
Secure cryptoprocessor</link>s can be used to leverage <link xlink:type="simple" xlink:href="../725/58725.xml">
physical security</link> techniques into protecting the security of the computer system.</p>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../374/5044374.xml">
Chain of trust</link> techniques can be used to attempt to ensure that all software loaded has been certified as authentic by the system's designers.</entry>
<entry level="1" type="bullet">

 <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../900/879900.xml">
Mandatory access control</link></causal_agent>
</worker>
</assistant>
</model>
</person>
</physical_entity>
 can be used to ensure that privileged access is withdrawn when privileges are revoked. For example, deleting a user account should also stop any processes that are running with that user's privileges.</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../717/539717.xml">
Capability</link> and <link xlink:type="simple" xlink:href="../589/61589.xml">
access control list</link> techniques can be used to ensure privilege separation and mandatory access control. The next sections discuss their use.</entry>
</list>
</p>
<p>

<it>Some of the following items may belong to the <link xlink:type="simple" xlink:href="../885/55885.xml">
computer insecurity</link> article:</it></p>

<p>

<list>
<entry level="1" type="bullet">

 <artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<furnishing wordnetid="103405265" confidence="0.8">
<table wordnetid="104379243" confidence="0.8">
<furniture wordnetid="103405725" confidence="0.8">
<console_table wordnetid="103092883" confidence="0.8">
<link xlink:type="simple" xlink:href="../746/454746.xml">
application</link></console_table>
</furniture>
</table>
</furnishing>
</instrumentality>
</artifact>
 with known security flaws should not be run. Either leave it turned off until it can be patched or otherwise fixed, or delete it and replace it with some other application. Publicly known flaws are the main entry used by <link xlink:type="simple" xlink:href="../010/6010.xml">
worms</link> to automatically break into a system and then spread to other systems connected to it. The security website <company wordnetid="108058098" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../310/1569310.xml">
Secunia</link></company>
 provides a search tool for unpatched known flaws in popular products.</entry>
</list>
</p>
<p>

<image width="300px" src="Encryption_-_decryption.svg" type="thumb">
</image>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../867/533867.xml">
Backup</link>s are a way of securing information; they are another copy of all the important computer files kept in another location. These files are kept on hard disks, <link xlink:type="simple" xlink:href="../780/6780.xml">
CD-R</link>s, <link xlink:type="simple" xlink:href="../495/4487495.xml">
CD-RW</link>s, and <link xlink:type="simple" xlink:href="../357/16267357.xml">
tape</link>s. Suggested locations for backups are a fireproof, waterproof, and heat proof safe, or in a separate, offsite location than that in which the original files are contained. Some individuals and companies also keep their backups in <link xlink:type="simple" xlink:href="../274/921274.xml">
safe deposit box</link>es inside <link xlink:type="simple" xlink:href="../143/744143.xml">
bank vault</link>s. There is also a fourth option, which involves using one of the <link xlink:type="simple" xlink:href="../035/1693035.xml">
file hosting service</link>s that backs up files over the <link xlink:type="simple" xlink:href="../539/14539.xml">
Internet</link> for both business and individuals.</entry>
<entry level="2" type="bullet">

 Backups are also important for reasons other than security. Natural disasters, such as earthquakes, hurricanes, or tornadoes, may strike the building where the computer is located. The building can be on fire, or an explosion may occur. There needs to be a recent backup at an alternate secure location, in case of such kind of disaster. Further, it is recommended that the alternate location be placed where the same disaster would not affect both locations. Examples of alternate disaster recovery sites being compromised by the same disaster that affected the primary site include having had a primary site in <skyscraper wordnetid="104233124" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../198/11395198.xml">
World Trade Center</link></skyscraper>
 I and the recovery site in <skyscraper wordnetid="104233124" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../990/312990.xml">
7 World Trade Center</link></skyscraper>
, both of which were destroyed in the <link xlink:type="simple" xlink:href="../704/177704.xml">
9/11</link> attack, and having one's primary site and recovery site in the same coastal region, which leads to both being vulnerable to hurricane damage (e.g. primary site in New Orleans and recovery site in <link xlink:type="simple" xlink:href="../694/97694.xml">
Jefferson Parish</link>, both of which were hit by <hurricane wordnetid="111467018" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../378/2569378.xml">
Hurricane Katrina</link></hurricane>
 in 2005). The backup media should be moved between the geographic sites in a secure manner, in order to prevent them from being stolen.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../622/268622.xml">
Anti-virus software</link> consists of computer programs that attempt to identify, thwart and eliminate <link xlink:type="simple" xlink:href="../196/18994196.xml">
computer viruses</link> and other malicious software (<link xlink:type="simple" xlink:href="../901/20901.xml">
malware</link>).</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../296/1362296.xml">
Firewalls</link> are systems which help protect computers and computer networks from attack and subsequent intrusion by restricting the network traffic which can pass through them, based on a set of system administrator defined rules.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 Access <link xlink:type="simple" xlink:href="../617/151617.xml">
authorization</link> restricts access to a computer to group of users through the use of <link xlink:type="simple" xlink:href="../967/47967.xml">
authentication</link> systems. These systems can protect either the whole computer - such as through an interactive <link xlink:type="simple" xlink:href="../760/722760.xml">
logon</link> screen - or individual services, such as an <link xlink:type="simple" xlink:href="../289/53289.xml">
FTP</link> server. There are many methods for identifying and authenticating users, such as <link xlink:type="simple" xlink:href="../304/24304.xml">
password</link>s, <link xlink:type="simple" xlink:href="../578/364578.xml">
identification card</link>s, and, more recently, <link xlink:type="simple" xlink:href="../957/59957.xml">
smart card</link>s and <link xlink:type="simple" xlink:href="../622/290622.xml">
biometric</link> systems.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../294/10294.xml">
Encryption</link> is used to protect the message from the eyes of others. It can be done in several ways by switching the characters around, replacing characters with others, and even removing characters from the message. These have to be used in combination to make the encryption secure enough, that is to say, sufficiently difficult to <link xlink:type="simple" xlink:href="../715/5715.xml">
crack</link>. <link xlink:type="simple" xlink:href="../222/24222.xml">
Public key encryption</link> is a refined and practical way of doing encryption. It allows for example anyone to write a message for a list of recipients, and only those recipients will be able to read that message.</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../021/113021.xml">
Intrusion-detection system</link>s can scan a network for people that are on the network but who should not be there or are doing things that they should not be doing, for example trying a lot of passwords to gain access to the network.</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../265/24265.xml">
Ping</link>ing The ping application can be used by potential crackers to find if an IP address is reachable. If a cracker finds a computer they can try a port scan to detect and attack services on that computer.</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../243/730243.xml">
Social engineering</link> awareness keeps employees aware of the dangers of social engineering and/or having a policy in place to prevent social engineering can reduce successful breaches of the network and servers.</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../952/287952.xml">
Honey pots</link> are computers that are either intentionally or unintentionally left vulnerable to attack by crackers. They can be used to catch crackers or fix vulnerabilities.</entry>
</list>
</p>

</sec>
<sec>
<st>
Notes</st>

<p>

<reflist>
<entry id="1">
<weblink xlink:type="simple" xlink:href="http://opensecurityarchitecture.com">
Definitions: IT Security Architecture</weblink>. SecurityArchitecture.org, Jan, 2008</entry>
<entry id="2">
<weblink xlink:type="simple" xlink:href="http://searchsecurity.techtarget.com/originalContent/0,289142,sid14_gci1265116,00.html">
New hacking technique exploits common programming error</weblink>. SearchSecurity.com, July 2007</entry>
<entry id="3">
J. C. Willemssen, "FAA Computer Security". GAO/T-AIMD-00-330. Presented at Committee on Science, House of Representatives, 2000.</entry>
<entry id="4">
P. G. Neumann, "Computer Security in Aviation," presented at International Conference on Aviation Safety and Security in the 21st Century, White House Commission on Safety and Security, 1997.</entry>
<entry id="5">
J. Zellan, Aviation Security. Hauppauge, NY: Nova Science, 2003, pp. 65-70.</entry>
<entry id="6">
<weblink xlink:type="simple" xlink:href="http://www.check-six.com/lib/Famous_Missing/KAL_Flight_007.htm">
KAL Flight 007</weblink>. Check-six.com, Mar 2008</entry>
<entry id="7">
<weblink xlink:type="simple" xlink:href="http://www.fas.org/irp/gao/aim96084.htm">
Information Security</weblink>. United States Department of Defense, 1986</entry>
<entry id="8">
<weblink xlink:type="simple" xlink:href="http://catless.ncl.ac.uk/Risks/8.72.html">
Air Force Bombs Georgia</weblink>. The Risks Digest, vol. 8, no. 72, May 1989</entry>
</reflist>
</p>


</sec>
<sec>
<st>
References</st>

<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../571/61571.xml">
Ross J. Anderson</link>:  <cite ><weblink xlink:type="simple" xlink:href="http://www.cl.cam.ac.uk/~rja14/book.html">
Security Engineering: A Guide to Building Dependable Distributed Systems</weblink></cite>, ISBN 0-471-38922-6</entry>
<entry level="1" type="bullet">

 <person wordnetid="100007846" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../732/36732.xml">
Bruce Schneier</link></person>
:  <cite >Secrets &amp; Lies: Digital Security in a Networked World</cite>, ISBN 0-471-25311-1</entry>
<entry level="1" type="bullet">

 <physical_entity wordnetid="100001930" confidence="0.8">
<expert wordnetid="109617867" confidence="0.8">
<communicator wordnetid="109610660" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<specialist wordnetid="110631941" confidence="0.8">
<intellectual wordnetid="109621545" confidence="0.8">
<alumnus wordnetid="109786338" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<writer wordnetid="110794014" confidence="0.8">
<scholar wordnetid="110557854" confidence="0.8">
<link xlink:type="simple" xlink:href="../094/6788094.xml">
Robert C. Seacord</link></scholar>
</writer>
</causal_agent>
</alumnus>
</intellectual>
</specialist>
</person>
</communicator>
</expert>
</physical_entity>
:  <cite >Secure Coding in C and C++</cite>. Addison Wesley, September, 2005. ISBN 0-321-33572-4</entry>
<entry level="1" type="bullet">

 <link>
Paul A. Karger</link>, <physical_entity wordnetid="100001930" confidence="0.8">
<expert wordnetid="109617867" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<specialist wordnetid="110631941" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../758/7339758.xml">
Roger R. Schell</link></causal_agent>
</specialist>
</person>
</expert>
</physical_entity>
: <weblink xlink:type="simple" xlink:href="http://www.acsac.org/2002/papers/classic-multics.pdf">
<cite >Thirty Years Later: Lessons from the Multics Security Evaluation</cite></weblink>, IBM white paper.</entry>
<entry level="1" type="bullet">

 <physical_entity wordnetid="100001930" confidence="0.8">
<communicator wordnetid="109610660" confidence="0.8">
<physicist wordnetid="110428004" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<astronomer wordnetid="109818343" confidence="0.8">
<writer wordnetid="110794014" confidence="0.8">
<link xlink:type="simple" xlink:href="../223/712223.xml">
Clifford Stoll</link></writer>
</astronomer>
</scientist>
</causal_agent>
</person>
</physicist>
</communicator>
</physical_entity>
:  <cite >Cuckoo's Egg: Tracking a Spy Through the Maze of Computer Espionage</cite>, Pocket Books, ISBN 0-7434-1146-3</entry>
<entry level="1" type="bullet">

 <link>
Stephen Haag</link>, <link>
Maeve Cummings</link>, <link>
Donald McCubbrey</link>, <link>
Alain Pinsonneault</link>, <link xlink:type="simple" xlink:href="../004/15447004.xml">
Richard Donovan</link>:  <cite >Management Information Systems for the information age</cite>, ISBN 0-07-091120-7</entry>
<entry level="1" type="bullet">

 <physical_entity wordnetid="100001930" confidence="0.8">
<peer wordnetid="109626238" confidence="0.8">
<expert wordnetid="109617867" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<specialist wordnetid="110631941" confidence="0.8">
<colleague wordnetid="109935990" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<associate wordnetid="109816771" confidence="0.8">
<link xlink:type="simple" xlink:href="../127/383127.xml">
Peter G. Neumann</link></associate>
</scientist>
</causal_agent>
</colleague>
</specialist>
</person>
</expert>
</peer>
</physical_entity>
: <weblink xlink:type="simple" xlink:href="http://www.csl.sri.com/neumann/chats4.pdf">
 <cite >Principled Assuredly Trustworthy Composable Architectures</cite></weblink> 2004</entry>
<entry level="1" type="bullet">

 <link>
Morrie Gasser</link>: <weblink xlink:type="simple" xlink:href="http://cs.unomaha.edu/~stanw/gasserbook.pdf">
 <cite >Building a secure computer system</cite></weblink> ISBN 0-442-23022-2 1988</entry>
<entry level="1" type="bullet">

 <link>
E. Stewart Lee</link>: <weblink xlink:type="simple" xlink:href="http://www.cl.cam.ac.uk/~mgk25/lee-essays.pdf">
 <cite >Essays about Computer Security</cite></weblink> Cambridge, 1999</entry>
</list>
</p>


</sec>
<sec>
<st>
 Further reading </st>

<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.wikibooks.org/wiki/The_Information_Age">
The Information Age</weblink> - an e-primer providing a comprehensive review of the digital and information and communications technology revolutions and how they are changing the economy and society. The primer also addresses the challenges arising from the widening digital divide.</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.theregister.co.uk/2008/03/19/pwn2own_contest_returns/">
pwn2own</weblink> - a $25,000 computer security competition in which competitors are challenged to create a previously unknown <link xlink:type="simple" xlink:href="../875/9875.xml">
security exploit</link> and fully penetrate security on a correctly <link xlink:type="simple" xlink:href="../765/23765.xml">
patch</link>ed Windows, Mac or Linux computer. The 2007 winner took 12 hours to <link xlink:type="simple" xlink:href="../982/5982.xml">
crack</link> <link xlink:type="simple" xlink:href="../640/20640.xml">
Mac OS X</link> security via a vulnerability later classified as "highly critical" by <company wordnetid="108058098" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../310/1569310.xml">
Secunia</link></company>
 <weblink xlink:type="simple" xlink:href="http://www.theregister.co.uk/2007/04/25/quicktime_vuln_fells_mac/">
http://www.theregister.co.uk/2007/04/25/quicktime_vuln_fells_mac/</weblink>.</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.aviationtoday.com/av/categories/commercial/932.html/">
Boeing 787 Integration</weblink> - Avionics Magazine provides an overview of computer systems and their security and integration upon <company wordnetid="108058098" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../266/18933266.xml">
Boeing</link></company>
's latest and largest long-range airliner, including <link xlink:type="simple" xlink:href="../934/36934.xml">
networking</link> and fly-by-wire concerns.</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.securitypresentations.com">
Internet Security presentations</weblink> - How to secure yourself and stay safe online.</entry>
</list>
</p>

<p>

<table style="background:#f9f9f9; font-size:85%; line-height:110%; ">
<row>
<col>
 <image width="32x28px" src="Portal.svg">
</image>
</col>
<col style="padding:0 0.2em;">
 <b><it>
Computer security&#32;portal</it></b></col>
</row>
</table>
</p>


</sec>
<sec>
<st>
 See also </st>

<p>

<table style="background:transparent; width:100%;" cellpadding="0" class=" multicol" cellspacing="0">
<row>
<col align="left" width="50%" valign="top">
<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../301/4339301.xml">
Attack tree</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../967/47967.xml">
Authentication</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../617/151617.xml">
Authorization</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../854/5328854.xml">
CERT</link></entry>
<entry level="1" type="bullet">

 <underground wordnetid="108360672" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../829/7829.xml">
Chaos Computer Club</link></underground>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../922/3024922.xml">
Computer security model</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../432/18934432.xml">
Cryptography</link></entry>
<entry level="1" type="bullet">

 <event wordnetid="100029378" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<link xlink:type="simple" xlink:href="../742/3392742.xml">
Cyber security standards</link></activity>
</procedure>
</psychological_feature>
</act>
</event>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../125/1412125.xml">
Dancing pigs</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../832/1157832.xml">
Data security</link></entry>
<entry level="1" type="bullet">

 <event wordnetid="100029378" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<link xlink:type="simple" xlink:href="../336/8030336.xml">
Differentiated security</link></activity>
</procedure>
</psychological_feature>
</act>
</event>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../720/2573720.xml">
Fault tolerance</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../296/1362296.xml">
Firewalls</link></entry>
<entry level="1" type="bullet">

 <belief wordnetid="105941423" confidence="0.8">
<doctrine wordnetid="105943300" confidence="0.8">
<link xlink:type="simple" xlink:href="../883/161883.xml">
Formal methods</link></doctrine>
</belief>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../593/15696593.xml">
Human-computer interaction (security)</link></entry>
<entry level="1" type="bullet">

 <event wordnetid="100029378" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<link xlink:type="simple" xlink:href="../507/927507.xml">
Identity management</link></activity>
</procedure>
</psychological_feature>
</act>
</event>
</entry>
</list>
</col>
<col align="left" width="50%" valign="top">
<list>
<entry level="1" type="bullet">

 <standard wordnetid="107260623" confidence="0.8">
<system_of_measurement wordnetid="113577171" confidence="0.8">
<link xlink:type="simple" xlink:href="../024/15040024.xml">
ISO/IEC 15408</link></system_of_measurement>
</standard>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../060/1228060.xml">
Internet privacy</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../356/9105356.xml">
Information Leak Prevention</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../687/592687.xml">
Network security</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../396/19103396.xml">
Network Security Toolkit</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../967/2056967.xml">
Packetstorm</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../534/18248534.xml">
Proactive Cyber Defence</link></entry>
<entry level="1" type="bullet">

 <event wordnetid="100029378" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<link xlink:type="simple" xlink:href="../793/1199793.xml">
Penetration test</link></activity>
</procedure>
</psychological_feature>
</act>
</event>
</entry>
<entry level="1" type="bullet">

 <accomplishment wordnetid="100035189" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<action wordnetid="100037396" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<feat wordnetid="100036762" confidence="0.8">
<link xlink:type="simple" xlink:href="../085/7089085.xml">
Physical information security</link></feat>
</psychological_feature>
</act>
</action>
</event>
</accomplishment>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../725/58725.xml">
Physical security</link></entry>
<entry level="1" type="bullet">

 <accomplishment wordnetid="100035189" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<action wordnetid="100037396" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<feat wordnetid="100036762" confidence="0.8">
<link xlink:type="simple" xlink:href="../049/2123049.xml">
OWASP</link></feat>
</psychological_feature>
</act>
</action>
</event>
</accomplishment>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../928/3024928.xml">
Security Architecture</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../990/12310990.xml">
Separation of protection and security</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../422/421422.xml">
Timeline of hacker history</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../823/4563823.xml">
Wireless LAN Security</link></entry>
</list>
</col>
</row>
</table>
</p>



</sec>
</bdy>
</article>
