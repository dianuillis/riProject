<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 17:38:49[mciao0827] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Strassen algorithm</title>
<id>771965</id>
<revision>
<id>243870582</id>
<timestamp>2008-10-08T12:03:46Z</timestamp>
<contributor>
<username>H1523702</username>
<id>56128</id>
</contributor>
</revision>
<categories>
<category>All pages needing cleanup</category>
<category>Numerical linear algebra</category>
<category>Articles with disputed statements </category>
</categories>
</header>
<bdy>

Not to be confused with the <link>
Schönhage-Strassen algorithm</link> for multiplication of polynomials.
In the <link xlink:type="simple" xlink:href="../831/18831.xml">
mathematical</link> discipline of <link xlink:type="simple" xlink:href="../422/18422.xml">
linear algebra</link>, <b>the Strassen algorithm</b>, named after <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<mathematician wordnetid="110301261" confidence="0.8">
<link xlink:type="simple" xlink:href="../960/771960.xml">
Volker Strassen</link></mathematician>
</scientist>
</causal_agent>
</person>
</physical_entity>
, is an <link xlink:type="simple" xlink:href="../775/775.xml">
algorithm</link> used for <link xlink:type="simple" xlink:href="../280/125280.xml">
matrix multiplication</link>. It is asymptotically faster than the standard matrix multiplication algorithm, but slower than <link>
the fastest known algorithm</link>, and is useful in practice for large matrices.
<sec>
<st>
 History </st>

<p>

Volker Strassen published the Strassen algorithm in 1969. Although his algorithm is only slightly faster than the standard algorithm for matrix multiplication, he was the first to point out that <link xlink:type="simple" xlink:href="../035/13035.xml">
Gaussian elimination</link> is not optimal. His paper started the search for even faster algorithms such as the <link>
Coppersmith–Winograd algorithm</link> of <physical_entity wordnetid="100001930" confidence="0.8">
<peer wordnetid="109626238" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<colleague wordnetid="109935990" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<employee wordnetid="110053808" confidence="0.8">
<associate wordnetid="109816771" confidence="0.8">
<link xlink:type="simple" xlink:href="../155/1744155.xml">
Shmuel Winograd</link></associate>
</employee>
</causal_agent>
</colleague>
</worker>
</person>
</peer>
</physical_entity>
 in 1980&#91;&#32; &ndash; &#93; (which uses 7 binary multiplications, but 15 binary additions instead of 18 with the Strassen algorithm), and the more complex <link>
Coppersmith–Winograd algorithm</link> published in 1987.</p>

</sec>
<sec>
<st>
 Algorithm </st>

<p>

<image location="right" width="150px" src="Strassen_algorithm.svg" type="thumb">
<caption>

The left column represents 2x2 <link xlink:type="simple" xlink:href="../280/125280.xml">
matrix multiplication</link>. Naïve matrix multiplication requires one multiplication for each "1" of the left column. Each of the other columns represents a single one of the 7 multiplications in the algorithm, and the sum of the columns gives the full matrix multiplication on the left. 
</caption>
</image>
</p>
<p>

Let <it>A</it>, <it>B</it> be two <link>
square matrices</link> over a <link xlink:type="simple" xlink:href="../404/48404.xml">
ring</link> <it>R</it>. We want to calculate the matrix product <it>C</it> as</p>
<p>

<indent level="1">

<math>\mathbf{C} = \mathbf{A} \mathbf{B} \qquad \mathbf{A},\mathbf{B},\mathbf{C} \in R^{2^n \times 2^n}</math>
</indent>

If the matrices <it>A</it>, <it>B</it> are not of type 2n x 2n we fill the missing rows and columns with zeros.</p>
<p>

We partition <it>A</it>, <it>B</it> and <it>C</it> into equally sized <link xlink:type="simple" xlink:href="../464/457464.xml">
block matrices</link>
<indent level="1">

<math> 
\mathbf{A} =
\begin{bmatrix}
\mathbf{A}_{1,1} &amp; \mathbf{A}_{1,2} \\
\mathbf{A}_{2,1} &amp; \mathbf{A}_{2,2}
\end{bmatrix}
\mbox { , }
\mathbf{B} =
\begin{bmatrix}
\mathbf{B}_{1,1} &amp; \mathbf{B}_{1,2} \\
\mathbf{B}_{2,1} &amp; \mathbf{B}_{2,2}
\end{bmatrix}
\mbox { , }
\mathbf{C} =
\begin{bmatrix}
\mathbf{C}_{1,1} &amp; \mathbf{C}_{1,2} \\
\mathbf{C}_{2,1} &amp; \mathbf{C}_{2,2}
\end{bmatrix}
</math>
</indent>

with</p>
<p>

<indent level="1">

<math>\mathbf{A}_{i,j}, \mathbf{B}_{i,j}, \mathbf{C}_{i,j} \in R^{2^{n-1} \times 2^{n-1}}</math>
</indent>

then </p>
<p>

<indent level="1">

<math>\mathbf{C}_{1,1} = \mathbf{A}_{1,1} \mathbf{B}_{1,1} + \mathbf{A}_{1,2} \mathbf{B}_{2,1} </math>
</indent>
:<math>\mathbf{C}_{1,2} = \mathbf{A}_{1,1} \mathbf{B}_{1,2} + \mathbf{A}_{1,2} \mathbf{B}_{2,2} </math>
<indent level="1">

<math>\mathbf{C}_{2,1} = \mathbf{A}_{2,1} \mathbf{B}_{1,1} + \mathbf{A}_{2,2} \mathbf{B}_{2,1} </math>
</indent>
:<math>\mathbf{C}_{2,2} = \mathbf{A}_{2,1} \mathbf{B}_{1,2} + \mathbf{A}_{2,2} \mathbf{B}_{2,2} </math></p>
<p>

With this construction we have not reduced the number of multiplications. We still need 8 multiplications to calculate the <it>Ci,j</it> matrices, the same number of multiplications we need when using standard matrix multiplication.</p>
<p>

Now comes the important part. We define new matrices</p>
<p>

<indent level="1">

<math>\mathbf{M}_{1} := (\mathbf{A}_{1,1} + \mathbf{A}_{2,2}) (\mathbf{B}_{1,1} + \mathbf{B}_{2,2})</math>
</indent>
:<math>\mathbf{M}_{2} := (\mathbf{A}_{2,1} + \mathbf{A}_{2,2}) \mathbf{B}_{1,1}</math>
<indent level="1">

<math>\mathbf{M}_{3} := \mathbf{A}_{1,1} (\mathbf{B}_{1,2} - \mathbf{B}_{2,2})</math>
</indent>
:<math>\mathbf{M}_{4} := \mathbf{A}_{2,2} (\mathbf{B}_{2,1} - \mathbf{B}_{1,1})</math>
<indent level="1">

<math>\mathbf{M}_{5} := (\mathbf{A}_{1,1} + \mathbf{A}_{1,2}) \mathbf{B}_{2,2}</math>
</indent>
:<math>\mathbf{M}_{6} := (\mathbf{A}_{2,1} - \mathbf{A}_{1,1}) (\mathbf{B}_{1,1} + \mathbf{B}_{1,2})</math>
<indent level="1">

<math>\mathbf{M}_{7} := (\mathbf{A}_{1,2} - \mathbf{A}_{2,2}) (\mathbf{B}_{2,1} + \mathbf{B}_{2,2})</math>
</indent>

which are then used to express the <it>C</it>i,j in terms of <it>M</it>k. Because of our definition of the <it>M</it>k we can eliminate one matrix multiplication and reduce the number of multiplications to 7 (one multiplication for each <it>M</it>k) and express the <it>C</it>i,j as</p>
<p>

<indent level="1">

<math>\mathbf{C}_{1,1} = \mathbf{M}_{1} + \mathbf{M}_{4} - \mathbf{M}_{5} + \mathbf{M}_{7}</math>
</indent>
:<math>\mathbf{C}_{1,2} = \mathbf{M}_{3} + \mathbf{M}_{5}</math>
<indent level="1">

<math>\mathbf{C}_{2,1} = \mathbf{M}_{2} + \mathbf{M}_{4}</math>
</indent>
:<math>\mathbf{C}_{2,2} = \mathbf{M}_{1} - \mathbf{M}_{2} + \mathbf{M}_{3} + \mathbf{M}_{6}</math></p>
<p>

We iterate this division process <it>n</it>-times until the <link xlink:type="simple" xlink:href="../519/207519.xml">
submatrices</link> degenerate into numbers (group elements).</p>
<p>

Practical implementations of Strassen's algorithm switch to standard methods of matrix multiplication for small enough submatrices, for which they are more efficient. The particular crossover point for which Strassen's algorithm is more efficient depends on the specific implementation and hardware. It has been estimated that Strassen's algorithm is faster for matrices with widths from 32 to 128 for optimized implementations,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref> and 60,000 or more for basic implementations.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref></p>

</sec>
<sec>
<st>
 Numerical analysis </st>

<p>

The standard matrix multiplications takes 
<indent level="1">

<math>n^3 = n^{\log_{2}8}</math>
</indent>
multiplications of the elements in the ring <it>R</it>. We ignore the additions needed because, depending on <it>R</it>, they can be much faster than the multiplications in computer implementations, especially if the sizes of the matrix entries exceed the <link xlink:type="simple" xlink:href="../344/1613344.xml">
word size</link> of the machine.</p>
<p>

With the Strassen algorithm we can reduce the number of multiplications to
<indent level="1">

<math>n^{\log_{2}7}\approx n^{2.807}</math>.
</indent>

The reduction in the number of multiplications however comes at the price of a somewhat reduced <link xlink:type="simple" xlink:href="../807/233807.xml">
numerical stability</link>.</p>

</sec>
<sec>
<st>
 See also </st>
<p>

<list>
<entry level="1" type="bullet">

 <curve wordnetid="113867641" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<line wordnetid="113863771" confidence="0.8">
<shape wordnetid="100027807" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../416/1699416.xml">
Z-order matrix representation</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</shape>
</line>
</rule>
</event>
</curve>
</entry>
</list>
</p>

</sec>
<sec>
<st>
 References </st>
<p>

<reflist>
<entry id="1">
<weblink xlink:type="simple" xlink:href="http://www2.toki.or.id/book/AlgDesignManual/BOOK/BOOK3/NODE138.HTM">
Matrix Multiplication notes</weblink></entry>
<entry id="2">
<weblink xlink:type="simple" xlink:href="http://www.stanford.edu/~boyko/pubs/MatrixMult_SURJ_2004.pdf">
Ultra-Fast Matrix Multiplication</weblink></entry>
</reflist>

<list>
<entry level="1" type="bullet">

 Strassen, Volker, <it>Gaussian Elimination is not Optimal</it>, Numer. Math. 13, p. 354-356, 1969</entry>
<entry level="1" type="bullet">

 <scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../475/4108475.xml">
Thomas H. Cormen</link></scientist>
, <scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../884/1400884.xml">
Charles E. Leiserson</link></scientist>
, <link xlink:type="simple" xlink:href="../057/68057.xml">
Ronald L. Rivest</link>, and <scientist wordnetid="110560637" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../993/3489993.xml">
Clifford Stein</link></scientist>
. <it><work wordnetid="104599396" confidence="0.8">
<product wordnetid="104007894" confidence="0.8">
<creation wordnetid="103129123" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<book wordnetid="106410904" confidence="0.8">
<publication wordnetid="106589574" confidence="0.8">
<link xlink:type="simple" xlink:href="../226/3499226.xml">
Introduction to Algorithms</link></publication>
</book>
</artifact>
</creation>
</product>
</work>
</it>, Second Edition. MIT Press and McGraw-Hill, 2001. ISBN 0-262-03293-7. Chapter 28: Section 28.2: Strassen's algorithm for matrix multiplication, pp.735&ndash;741.</entry>
</list>
</p>

</sec>
<sec>
<st>
External links</st>
<p>

<list>
<entry level="1" type="bullet">

 <cite id="Reference-Mathworld-Strassen's Formulas"><physical_entity wordnetid="100001930" confidence="0.8">
<communicator wordnetid="109610660" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<intellectual wordnetid="109621545" confidence="0.8">
<encyclopedist wordnetid="110055566" confidence="0.8">
<compiler wordnetid="109946957" confidence="0.8">
<alumnus wordnetid="109786338" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<writer wordnetid="110794014" confidence="0.8">
<mathematician wordnetid="110301261" confidence="0.8">
<scholar wordnetid="110557854" confidence="0.8">
<link xlink:type="simple" xlink:href="../189/836189.xml">
Eric W. Weisstein</link></scholar>
</mathematician>
</writer>
</scientist>
</causal_agent>
</alumnus>
</compiler>
</encyclopedist>
</intellectual>
</person>
</communicator>
</physical_entity>
, <it><weblink xlink:type="simple" xlink:href="http://mathworld.wolfram.com/StrassenFormulas.html">
Strassen's Formulas</weblink></it> at <computer wordnetid="103082979" confidence="0.8">
<work wordnetid="104599396" confidence="0.8">
<creation wordnetid="103129123" confidence="0.8">
<machine wordnetid="103699975" confidence="0.8">
<reference_book wordnetid="106417598" confidence="0.8">
<publication wordnetid="106589574" confidence="0.8">
<encyclopedia wordnetid="106427387" confidence="0.8">
<product wordnetid="104007894" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<instrumentality wordnetid="103575240" confidence="0.8">
<book wordnetid="106410904" confidence="0.8">
<device wordnetid="103183080" confidence="0.8">
<web_site wordnetid="106359193" confidence="0.8">
<link xlink:type="simple" xlink:href="../235/374235.xml">
MathWorld</link></web_site>
</device>
</book>
</instrumentality>
</artifact>
</product>
</encyclopedia>
</publication>
</reference_book>
</machine>
</creation>
</work>
</computer>
.</cite> (also includes formulas for fast <link xlink:type="simple" xlink:href="../122/217122.xml">
matrix inversion</link>)</entry>
</list>
</p>


</sec>
</bdy>
</article>
