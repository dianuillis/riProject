<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 22:55:08[mciao0828] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<physical_entity  confidence="0.8" wordnetid="100001930">
<person  confidence="0.8" wordnetid="100007846">
<model  confidence="0.8" wordnetid="110324560">
<assistant  confidence="0.8" wordnetid="109815790">
<worker  confidence="0.8" wordnetid="109632518">
<causal_agent  confidence="0.8" wordnetid="100007347">
<header>
<title>Bulk synchronous parallel</title>
<id>7776927</id>
<revision>
<id>244224994</id>
<timestamp>2008-10-09T21:21:55Z</timestamp>
<contributor>
<username>Electionworld</username>
<id>201260</id>
</contributor>
</revision>
<categories>
<category>Parallel computing</category>
<category>Computational models</category>
</categories>
</header>
<bdy>

The <b>Bulk Synchronous Parallel</b> computer is a model for designing parallel
algorithms.  It serves a similar purpose to the 
<physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../675/956675.xml">
PRAM</link></causal_agent>
</worker>
</assistant>
</model>
</person>
</physical_entity>
 model.  BSP differs from PRAM 
by not taking communication and synchronization for granted.  An important
part of analysing a BSP algorithm rests on quantifying the synchronisation 
and communication needed.
<sec>
<st>
The model</st>

<p>

A BSP computer consists of processors connected by a communication
network.  Each processor has a fast local memory, and may follow
different threads of computation.  </p>
<p>

A BSP computation proceeds in a series of global <it>supersteps</it>.  A
superstep consists of three ordered stages:</p>
<p>

<list>
<entry level="1" type="number">

 <it>Concurrent computation</it> : Several computations take place on every participating processor. Each process only uses values stored in the local memory of the processor.  The computations are independent in the sense that they occur asynchronously of all the others.</entry>
<entry level="1" type="number">

 <it>Communication</it> : At this stage, the processes exchange data between themselves.  </entry>
<entry level="1" type="number">

 <it>Barrier synchronisation</it> : When a process reaches this point (the <it>barrier</it>), it waits until all other processes have finished their communication actions.</entry>
</list>
</p>
<p>

The figure below shows this in a diagrammatic form.  The processes are not
regarded as having a particular linear order (from left to right or
otherwise), and may be mapped to processors in any way.  </p>
<p>

<image width="400px" src="bsp.wiki.fig1.svg" type="thumb">
</image>
</p>

</sec>
<sec>
<st>
Communication</st>

<p>

In many parallel programming systems, communications are considered at
the level of individual actions: sending and receiving a message, memory
to memory transfer, etc.  This is difficult to work with, since there
are many simultaneous communication actions in a parallel program, and
their interactions are typically complex.  In particular, it is
difficult to say much about the time any single communication action
will take to complete.</p>
<p>

The BSP model considers communication actions <it>en masse</it>.  This has
the effect that an upper bound on the time taken to communicate a set of
data can be given.  BSP considers all communication actions of a
superstep as one unit, and assumes all messages have a fixed size.</p>
<p>

The maximum number of incoming or outgoing messages for a superstep is
denoted by <math>h</math>.  The ability of a communication network to
deliver data is captured by a parameter <math>g</math>, defined such
that it takes time <math>hg</math> for a processor to deliver
<math>h</math> messages of size 1.</p>
<p>

A message of length <math>m</math> obviously takes longer to send than a
message of size 1.  However, the BSP model does not make a distinction
between a message length of <math>m</math> or <math>m</math> messages of
length 1.  In either case the cost is said to be <math>mhg</math>.</p>
<p>

The parameter <math>g</math> is dependent on the following factors:</p>
<p>

<list>
<entry level="1" type="bullet">

 The protocols used to interact within the communication network.</entry>
<entry level="1" type="bullet">

 Buffer management by both the processors and the communication network.</entry>
<entry level="1" type="bullet">

 The routing strategy used in the network.</entry>
<entry level="1" type="bullet">

 The BSP runtime system.</entry>
</list>
</p>
<p>

A value for <math>g</math> is, in practice, determined empirically for
each parallel computer.  Note that <math>g</math> is not the normalised
single-word delivery time, but the single-word delivery time under
continuous traffic conditions.</p>

</sec>
<sec>
<st>
Barriers</st>

<p>

On most of today's architectures, barrier synchronisation is often
expensive, so should be used sparingly.  However, future architecture
developments may make them much cheaper.  The cost of barrier
synchronisation is influenced by a couple of issues:</p>
<p>

<list>
<entry level="1" type="number">

 The cost imposed by the variation in the completion time of the participating concurrent computations.  Take the example where all but one of the processes have completed their work for this superstep, and are waiting for the last process, which still has a lot of work to complete.  The best that an implementation can do is ensure that each process works on roughly the same problem size.</entry>
<entry level="1" type="number">

 The cost of reaching a globally-consistent state in all of the processors.  This depends on the communication network, but also on whether there is special-purpose hardware available for synchronising, and on the way in which interrupts are handled by processors.</entry>
</list>
</p>
<p>

The cost of a barrier synchronisation is denoted by <math>l</math>.  In
practice, a value of <math>l</math> is determined empirically.</p>

<p>

Barriers are potentially costly, but have a number of attractions.  They
do not introduce the possibility of deadlock or livelock, since barriers
do not create circular data dependencies.    Therefore tools to detect and deal with them are
unnecessary.  Barriers also permit novel forms of fault tolerance.</p>

</sec>
<sec>
<st>
The Cost of a BSP algorithm</st>

<p>

The cost of a superstep is determined as the sum of three terms;  the
cost of the longest running local computation, the cost of global
communication between the processors, and the cost of the barrier
synchronisation at the end of the superstep.  The cost of one superstep
for <math>p</math> processors:</p>
<p>

<math>
max_{i = 1}^{p}(w_i) + max_{i=1}^{p}(h_i g) + l 
</math></p>
<p>

where <math>w_i</math> is the cost for the local computation in process
<math>i</math>, and <math>h_i</math> is the number of messages sent or
received by process <math>i</math>.  Note that homogeneous processors
are assumed here.  It is more common for the expression to be written as
<math>w + hg + l</math> where <math>w</math> and <math>h</math> are
maxima.  The cost of the algorithm then, is the sum of the costs of each
superstep.</p>
<p>

<math>
W + Hg + Sl = \sum_{s=1}^{S}w_s + g \sum_{s=1}^{S}h_s + Sl
</math></p>
<p>

where <math>S</math> is the number of supersteps.</p>
<p>

<math>W</math>, <math>H</math>, and <math>S</math> are usually modelled
as functions, that vary with problem size.  These three characteristics
of a BSP algorithm are usually described in terms of asymptotic
notation, e.g. <math>H \in O(n/p)</math>.</p>

</sec>
<sec>
<st>
References</st>



<p>

<list>
<entry level="1" type="bullet">

 D.B. Skillicorn, Jonathan Hill, W. F. McColl, <weblink xlink:type="simple" xlink:href="ftp://ftp.comlab.ox.ac.uk/pub/Documents/techpapers/Jonathan.Hill/SkillHillMcColl_QA.ps.gz">
Questions and answers about BSP</weblink> (1996)</entry>
</list>
</p>

</sec>
<sec>
<st>
See also</st>

<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../896/18949896.xml">
Computer cluster</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../605/2581605.xml">
Concurrent computing</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../467/928467.xml">
Concurrency</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../373/49373.xml">
Grid computing</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../162/145162.xml">
Parallel computing</link></entry>
<entry level="1" type="bullet">

 <structure wordnetid="104341686" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<area wordnetid="102735688" confidence="0.8">
<library wordnetid="103660909" confidence="0.8">
<room wordnetid="104105893" confidence="0.8">
<link xlink:type="simple" xlink:href="../299/1205299.xml">
ScientificPython</link></room>
</library>
</area>
</artifact>
</structure>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../404/19664404.xml">
LogP machine</link></entry>
</list>
</p>

</sec>
<sec>
<st>
External links</st>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.bsp-worldwide.org/">
BSP Worldwide</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.bsp-worldwide.org/implmnts/oxtool/papers.html">
BSP related papers</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://web.comlab.ox.ac.uk/oucl/work/bill.mccoll/oparl.html">
WWW Resources on BSP Computing</weblink></entry>
</list>
</p>

</sec>
</bdy>
</causal_agent>
</worker>
</assistant>
</model>
</person>
</physical_entity>
</article>
