<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 23:07:46[mciao0827] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<event  confidence="0.8" wordnetid="100029378">
<rule  confidence="0.8" wordnetid="105846932">
<act  confidence="0.8" wordnetid="100030358">
<psychological_feature  confidence="0.8" wordnetid="100023100">
<procedure  confidence="0.8" wordnetid="101023820">
<activity  confidence="0.8" wordnetid="100407535">
<algorithm  confidence="0.8" wordnetid="105847438">
<header>
<title>Package-merge algorithm</title>
<id>7816625</id>
<revision>
<id>140017868</id>
<timestamp>2007-06-23T00:22:59Z</timestamp>
<contributor>
<username>ClueBot</username>
<id>4928500</id>
</contributor>
</revision>
<categories>
<category>Coding theory</category>
<category>Lossless compression algorithms</category>
</categories>
</header>
<bdy>

The <b>Package-Merge Algorithm</b> is an <it><link xlink:type="simple" xlink:href="../578/44578.xml">
O</link>(nL)</it>-time algorithm for finding an
optimal <plant wordnetid="100017222" confidence="0.8">
<tree wordnetid="113104059" confidence="0.8">
<vascular_plant wordnetid="113083586" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<woody_plant wordnetid="113103136" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../883/13883.xml#xpointer(//*[./st=%22Length-limited+Huffman+coding%22])">
length-limited Huffman code</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</woody_plant>
</rule>
</event>
</vascular_plant>
</tree>
</plant>
 for a given distribution on a given alphabet of size <it>n</it>, where no <link xlink:type="simple" xlink:href="../891/40891.xml">
code word</link> is longer than <it>L</it>.  It is a <link xlink:type="simple" xlink:href="../247/89247.xml">
greedy algorithm</link>, and a generalization of <plant wordnetid="100017222" confidence="0.8">
<tree wordnetid="113104059" confidence="0.8">
<vascular_plant wordnetid="113083586" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<woody_plant wordnetid="113103136" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../883/13883.xml">
Huffman's original algorithm</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</woody_plant>
</rule>
</event>
</vascular_plant>
</tree>
</plant>
.  Package-merge works by reducing the code construction problem to the binary <b>Coin Collector's problem</b>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref>
<sec>
<st>
The Coin Collector's Problem</st>

<p>

Suppose a coin collector has a number of coins of various denominations, each of which has a  <link xlink:type="simple" xlink:href="../212/38212.xml">
numismatic value</link>.  The coin collector has run out
of money and needs to use some of his coin collection to buy something of cost <it>N</it>.  He wishes to select a subset of coins from his collection of minimum numismatic value whose denominations total <it>N</it>.</p>
<p>

The binary version of this problem is that all denominations are powers of 2, that is, 1, 1/2, 1/4, etc. dollars.</p>

</sec>
<sec>
<st>
Description of the Package-Merge Algorithm</st>

<p>

Assume that the largest denomination is 1 dollar, and that N is an integer.  (The  algorithm works even if these assumptions do not hold, by trivial modifications.) The coin collector first separates his coins into lists, one for each denomination, sorted by numismatic value.  He then <b>packages</b> the smallest denomination coins in pairs, starting from the pair of smallest total numismatic value.  If there is one coin left over, it will be the coin of highest numismatic value of that denomination, and it is set aside and ignored henceforth.  These packages are then <b>merged</b> into the list of coins of the next smallest denomination, again in order of numismatic value.  The items in that list are then <b>packaged</b> in pairs, and merged into the next smallest list, and so forth.</p>
<p>

Finally, there is a list of items, each of which is a 1 dollar coin or a package consisting of two or more smaller coins whose denominations total 1 dollar.  They are also sorted in order of numismatic value.  The coin collector then selects the least value N of them.</p>
<p>

Note that the time of the algorithm is linear in the number of coins.</p>

</sec>
<sec>
<st>
Reduction of Length-Limited Huffman Coding to the Coin Collector's Problem</st>

<p>

Let <it>L</it> be the maximum length any code word is permitted to have.
Let <it>p</it>1,&nbsp;&amp;hellip;,&nbsp;<it>pn</it> be the frequencies of the
symbols of the alphabet to be encoded.  We first sort the symbols so that <it>pi</it>&nbsp;&amp;le;&nbsp;<it>pi</it>+1.  Create <it>L</it> coins for each symbol, of denominations 2&amp;minus;1,&nbsp;&amp;hellip;,&nbsp;2&amp;minus;<it>L</it>, each of numismatic value <it>pi</it>.  Use the package-merge algorithm to select the set of coins of minimum numismatic value whose denominations total <it>n</it>&nbsp;&amp;minus;&nbsp;1.  Let <it>hi</it> be the number of coins of numismatic value <it>pi</it> selected.</p>
<p>

The optimal length-limited Huffman code will encode symbol <it>i</it> with a bit string of length <it>hi</it>.  The <link xlink:type="simple" xlink:href="../171/6946171.xml">
canonical Huffman code</link> can easily be constructed by a simple bottom-up greedy method, given that the <it>hi</it> are known, and this can be the basis for fast <link xlink:type="simple" xlink:href="../013/8013.xml">
data compression</link><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref>.</p>

</sec>
<sec>
<st>
 Performance Improvements and Generalizations </st>

<p>

With this reduction, the algorithm is <it>O(nL)</it>-time and <it>O(nL)</it>-space.  However, the original paper, "A fast algorithm for optimal length-limited Huffman codes," shows how this can be improved to <it>O(nL)</it>-time and <it>O(n)</it>-space.  The idea is to run the algorithm a first time, only keeping enough data to be able to determine two equivalent subproblems that sum to half the size of the original problem.  This is done recursively, resulting in an algorithm that takes about twice as long but requires only linear space.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref></p>
<p>

Many other improvements have been made to the Package-Merge Algorithm to reduce the <link xlink:type="simple" xlink:href="../578/44578.xml">
multiplicative constant</link> and to make it faster in special cases, such as those problems having repeated <it>pi</it>s<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%223%22])">3</ref>.  The Package-Merge approach has also been adapted to related problems such as <plant wordnetid="100017222" confidence="0.8">
<tree wordnetid="113104059" confidence="0.8">
<vascular_plant wordnetid="113083586" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<woody_plant wordnetid="113103136" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../883/13883.xml#xpointer(//*[./st=%22Optimal+alphabetic+binary+trees+.28Hu-Tucker+coding+and+the+canonical+Huffman+code.29%22])">
alphabetic coding</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</woody_plant>
</rule>
</event>
</vascular_plant>
</tree>
</plant>
<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%224%22])">4</ref>.</p>
<p>

Methods involving <link xlink:type="simple" xlink:href="../401/12401.xml">
graph theory</link> have been shown to have better asymptotic space complexity than the Package-Merge Algorithm, but these have not seen as much practical application.</p>

</sec>
<sec>
<st>
External links</st>
<p>

<list>
<entry level="1" type="bullet">

 Michael B. Baer "<weblink xlink:type="simple" xlink:href="http://132.236.180.11/pdf/cs.IT/0602085">
Twenty (or so) Questions: $D$-ary Length-Bounded Prefix Coding.</weblink>" (PDF) </entry>
<entry level="1" type="bullet">

 Alistair Moffat and Andrew Turpin "<weblink xlink:type="simple" xlink:href="http://www.cs.mu.oz.au/~alistair/abstracts/dcc95.pm.html">
Space-Efficient Construction of Optimal Prefix Codes.</weblink>"</entry>
<entry level="1" type="bullet">

 An implementation of the package-merge algorithm "<weblink xlink:type="simple" xlink:href="http://www.koders.com/delphi/fid65738C1383AB6F1E0D556659A91CB5F85B09C941.aspx?s=algorithm">
http://www.koders.com/delphi/fid65738C1383AB6F1E0D556659A91CB5F85B09C941.aspx?s=algorithm</weblink>"</entry>
</list>
</p>

</sec>
<sec>
<st>
References</st>
<p>

<reflist>
<entry id="1">
<physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<intellectual wordnetid="109621545" confidence="0.8">
<alumnus wordnetid="109786338" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<academician wordnetid="109759069" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<adult wordnetid="109605289" confidence="0.8">
<professional wordnetid="110480253" confidence="0.8">
<mathematician wordnetid="110301261" confidence="0.8">
<scholar wordnetid="110557854" confidence="0.8">
<educator wordnetid="110045713" confidence="0.8">
<link xlink:type="simple" xlink:href="../588/6849588.xml">
L. L. Larmore</link></educator>
</scholar>
</mathematician>
</professional>
</adult>
</scientist>
</academician>
</causal_agent>
</alumnus>
</intellectual>
</person>
</physical_entity>
 and <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<link xlink:type="simple" xlink:href="../958/7816958.xml">
D. S. Hirschberg</link></scientist>
</causal_agent>
</person>
</physical_entity>
. A fast algorithm for optimal length-limited Huffman codes. Journal of the Association for Computing Machinery, V 37 No. 3:464--473, 1990.</entry>
<entry id="2">
A. Moffat and A. Turpin. On the implementation of minimum redundancy prefix codes. <work wordnetid="104599396" confidence="0.8">
<product wordnetid="104007894" confidence="0.8">
<creation wordnetid="103129123" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<periodical wordnetid="106593296" confidence="0.8">
<publication wordnetid="106589574" confidence="0.8">
<link xlink:type="simple" xlink:href="../417/12953417.xml">
IEEE Transactions on Communications</link></publication>
</periodical>
</artifact>
</creation>
</product>
</work>
. V 45 No. 10:1200--1207, Oct 1997. (<weblink xlink:type="simple" xlink:href="http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=634683|link">
http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=634683|link</weblink>)</entry>
<entry id="3">
I. H. Witten and A. Moffat and T. Bell. <it>Managing Gigabytes</it>.  Second Edition.  Morgan Kaufmann Publishers, 1999.  ISBN 978-1-55860-570-1.</entry>
<entry id="4">
L. L. Larmore and T. M. Przytycka. A Fast Algorithm for Optimal Height-Limited Alphabetic Binary-Trees. <work wordnetid="104599396" confidence="0.8">
<product wordnetid="104007894" confidence="0.8">
<creation wordnetid="103129123" confidence="0.8">
<artifact wordnetid="100021939" confidence="0.8">
<periodical wordnetid="106593296" confidence="0.8">
<publication wordnetid="106589574" confidence="0.8">
<link xlink:type="simple" xlink:href="../724/1230724.xml">
SIAM Journal on Computing</link></publication>
</periodical>
</artifact>
</creation>
</product>
</work>
, V 23 No. 6:1283--1312, 1994.</entry>
</reflist>
</p>

</sec>
</bdy>
</algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</article>
