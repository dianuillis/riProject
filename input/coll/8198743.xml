<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 23:07:51[mciao0828] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<event  confidence="0.8" wordnetid="100029378">
<rule  confidence="0.8" wordnetid="105846932">
<act  confidence="0.8" wordnetid="100030358">
<psychological_feature  confidence="0.8" wordnetid="100023100">
<procedure  confidence="0.8" wordnetid="101023820">
<activity  confidence="0.8" wordnetid="100407535">
<algorithm  confidence="0.8" wordnetid="105847438">
<header>
<title>Competitive analysis (online algorithm)</title>
<id>8198743</id>
<revision>
<id>201860557</id>
<timestamp>2008-03-29T18:30:58Z</timestamp>
<contributor>
<username>David Eppstein</username>
<id>2051880</id>
</contributor>
</revision>
<categories>
<category>Online algorithms</category>
<category>Analysis of algorithms</category>
</categories>
</header>
<bdy>

<b>Competitive analysis</b> is a method invented for analyzing <link xlink:type="simple" xlink:href="../716/22716.xml">
online algorithms</link>, in which the performance of an online algorithm (which must satisfy an unpredictable sequence of requests, completing each request without being able to see the future) is compared to the performance of an optimal <it>offline algorithm</it> that can view the sequence of requests in advance.  An algorithm is <it>competitive</it> if its <it>competitive ratio</it>—the ratio between its performance and the offline algorithm's performance—is bounded.  Unlike traditional <link xlink:type="simple" xlink:href="../956/37956.xml">
worst-case analysis</link>, where the performance of an algorithm is measured only for "hard" inputs, competitive analysis requires that an algorithm perform well both on hard and easy inputs, where "hard" and "easy" are defined by the performance of the optimal offline algorithm.<p>

For many algorithms, performance is dependent on not only the size of the inputs, but also their values.  One such example is the <link xlink:type="simple" xlink:href="../249/3268249.xml">
quicksort</link> algorithm, which sorts an <link xlink:type="simple" xlink:href="../052/2052.xml">
array</link> of elements.  Such data dependent algorithms are analysed for average case and worst case data.  Competitive analysis is a way of doing worst case analysis for on-line and <link xlink:type="simple" xlink:href="../383/495383.xml">
randomized algorithm</link>s, which are typically data dependent.</p>
<p>

In competitive analysis, one imagines an "adversary" that deliberately chooses difficult data, to maximize the ratio of the cost of the algorithm being studied and some optimal algorithm.  Adversaries range in power from the <it>oblivious adversary</it>, which has no knowledge of the random choices made by the algorithm pitted against it, to the <it>adaptive adversary</it> that has full knowledge of how an algorithm works and its internal state at any point during its execution.  Note that this distinction is only meaningful for randomized algorithms.  For a deterministic algorithm, either adversary can simply compute what state that algorithm must have at any time in the future, and choose difficult data accordingly.</p>
<p>

For example, the quicksort algorithm chooses one element, called the "pivot" that is, on average, not too far from the center value of the data being sorted, and then separates the data into two piles, one of which contains all elements with value less than the value of the pivot, and the other containing the rest of the elements.  If quicksort chooses the pivot in some deterministic fashion (for instance, always choosing the first element in the list), then it is easy for an adversary to arrange the data beforehand so that quicksort will perform in worst case time.  If, however, quicksort chooses some random element to be the pivot, then an adversary without knowledge of what random numbers are coming up cannot arrange the data to guarantee worst case execution time for quicksort.</p>
<p>

The classic on-line problem first analysed with competitive analysis is the <it>List Update problem</it>: Given a list of items and a sequence of requests for the various items, minimize the cost of accessing the list where the elements closer to the front of the list cost less to access.  (Typically, the cost of accessing an item is equal to its position in the list.)  After an access, the list may be rearranged.  Most rearrangements have a cost.  The <it>Move-To-Front algorithm</it> simply moves the requested item to the front after the access, at no cost.  The <it>Transpose algorithm</it> swaps the accessed item with the item immediately before it, also at no cost.  Classical methods of analysis showed that Transpose is optimal in certain contexts.  In practice, Move-To-Front performed much better.  Competitive analysis was used to show that an adversary can make Transpose perform arbitrarily badly compared to an optimal algorithm, whereas Move-To-Front can never be made to incur more than twice the cost of an optimal algorithm.</p>

<sec>
<st>
See also</st>
<p>

<list>
<entry level="1" type="bullet">

 <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../634/8198634.xml">
Adversary (online algorithm)</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../683/236683.xml">
Amortized analysis</link></entry>
<entry level="1" type="bullet">

 <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../038/7767038.xml">
K-server problem</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../716/22716.xml">
Online algorithm</link></entry>
</list>
</p>


</sec>
<sec>
<st>
References</st>
<p>

<list>
<entry level="1" type="bullet">

 "Amortized Efficiency of List Update and Paging Rules", Sleator and Tarjan, Communications of the ACM, Feb. 1985.</entry>
<entry level="1" type="bullet">

 "Competitive Analysis of Distributed Algorithms", James Aspnes (1998)</entry>
<entry level="1" type="bullet">

 Borodin, A.; El-Yaniv, R. (1998). Online Computation and Competitive Analysis. Cambridge University Press. ISBN 0-521-56392-5. </entry>
</list>
</p>



</sec>
</bdy>
</algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</article>
