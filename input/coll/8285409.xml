<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 23:17:41[mciao0826] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<measure  confidence="0.9511911446218017" wordnetid="100174412">
<header>
<title>Semantic relatedness</title>
<id>8285409</id>
<revision>
<id>241720144</id>
<timestamp>2008-09-29T07:22:45Z</timestamp>
<contributor>
<username>Lizorkin</username>
<id>6735338</id>
</contributor>
</revision>
<categories>
<category>Statistical distance measures</category>
<category>Computational linguistics</category>
</categories>
</header>
<bdy>

<indent level="1">

<it>Main article: <link xlink:type="simple" xlink:href="../135/1473135.xml">
Semantic similarity</link></it>
</indent>

Computational Measures of <b>Semantic Relatedness</b> are <weblink xlink:type="simple" xlink:href="http://cwl-projects.cogsci.rpi.edu/msr/">
publically available</weblink> means for approximating the relative meaning of words/documents. These have been used for essay-grading by the <company wordnetid="108058098" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../550/347550.xml">
Educational Testing Service</link></company>
, search engine technology, predicting which links people are likely to click on, etc.<p>

<list>
<entry level="1" type="bullet">

 LSA (<link xlink:type="simple" xlink:href="../427/689427.xml">
Latent semantic analysis</link>) (+) vector-based, adds vectors to measure multi-word terms; (-) non-incremental vocabulary, long pre-processing times</entry>
<entry level="1" type="bullet">

 PMI (<link xlink:type="simple" xlink:href="../679/6793679.xml">
Pointwise Mutual Information</link>) (+) large vocab, because it uses any search engine (like Google); (-) cannot measure relatedness between whole sentences or documents</entry>
<entry level="1" type="bullet">

 GLSA (Generalized Latent Semantic Analysis)  (+) vector-based, adds vectors to measure multi-word terms; (-) non-incremental vocabulary, long pre-processing times</entry>
<entry level="1" type="bullet">

 ICAN (Incremental Construction of an Associative Network) (+) incremental, network-based measure, good for spreading activation, accounts for second-order relatedness; (-) cannot measure relatedness between multi-word terms, long pre-processing times</entry>
<entry level="1" type="bullet">

 NGD (Normalized Google Distance; see below) (+) large vocab, because it uses any search engine (like Google); (-) cannot measure relatedness between whole sentences or documents</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../955/33955.xml">
WordNet</link>: (+) humanly constructed; (-) humanly constructed (not automatically learned), cannot measure relatedness between multi-word term, non-incremental vocabulary</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.cs.technion.ac.il/~gabr/papers/ijcai-2007-sim.pdf">
ESA (Explicit Semantic Analysis)</weblink> based on <web_site wordnetid="106359193" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../734/5043734.xml">
Wikipedia</link></web_site>
 and the <work wordnetid="100575741" confidence="0.8">
<possession wordnetid="100032613" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<company wordnetid="108058098" confidence="0.8">
<undertaking wordnetid="100795720" confidence="0.8">
<property wordnetid="113244109" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<subsidiary_company wordnetid="108003935" confidence="0.8">
<institution wordnetid="108053576" confidence="0.8">
<link xlink:type="simple" xlink:href="../501/18949501.xml">
ODP</link></institution>
</subsidiary_company>
</activity>
</psychological_feature>
</act>
</property>
</undertaking>
</company>
</event>
</possession>
</work>
</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://cwl-projects.cogsci.rpi.edu/papers/VGG08.pdf">
VGEM</weblink> (Vector Generation of an Explicitly-defined Multidimensional Semantic Space) (+) incremental vocab, can compare multi-word terms (-) performance depends on choosing specific dimensions</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.cogsci.rpi.edu/cogworks/publications/270_BLOSSOM_final.pdf">
BLOSSOM</weblink> (Best path Length On a Semantic Self-Organizing Map) (+) uses a <link>
Self Organizing Map</link> to reduce high dimensional spaces, can use different vector representations (VGEM or word-document matrix), provides 'concept path linking' from one word to another (-) highly experimental, requires nontrivial SOM calculation</entry>
</list>
</p>

<sec>
<st>
 Semantic similarity measures </st>


<ss1>
<st>
 SimRank </st>

<p>

<indent level="1">

<it>Main article: <link xlink:type="simple" xlink:href="../308/19518308.xml">
SimRank</link></it>
</indent>

</p>
</ss1>
<ss1>
<st>
 Google distance </st>
<p>

<b>Google distance</b> is a measure of semantic interrelatedness derived from the number of hits returned by the <web_site wordnetid="106359193" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../431/12431.xml">
Google search engine</link></web_site>
 for a given <link xlink:type="simple" xlink:href="../127/201127.xml">
set</link> of <link xlink:type="simple" xlink:href="../940/6118940.xml">
keyword</link>s. Keywords with the same or similar meanings in a natural language sense tend to be "close" in units of Google distance, while words with dissimilar meanings tend to be farther apart.</p>
<p>

Specifically, the <it>normalized Google distance</it> between two search terms <it>x</it> and <it>y</it> is</p>
<p>

<indent level="1">

<math>
\operatorname{NGD}(x,y) = \frac{\max\{\log f(x), \log f(y)\} - \log f(x,y)}
{\log M - \min\{\log f(x), \log f(y)\}}
</math>
</indent>

where <it>M</it> is the total number of web pages searched by Google; <it>f</it>(<it>x</it>) and <it>f</it>(<it>y</it>) are the number of hits for search terms <it>x</it> and <it>y</it>, respectively; and <it>f</it>(<it>x</it>,&nbsp;<it>y</it>) is the number of web pages on which both <it>x</it> and <it>y</it> occur.</p>
<p>

If the two search terms <it>x</it> and <it>y</it> never occur together on the same web page, but do occur separately, the normalized Google distance between them is infinite. If both terms always occur together, their NGD is zero.</p>

</ss1>
</sec>
<sec>
<st>
 See also </st>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../004/2208004.xml">
Semantic differential</link></entry>
</list>
</p>

</sec>
<sec>
<st>
 References </st>
<p>

<list>
<entry level="1" type="bullet">

 Cilibrasi, R. &amp; Vitanyi, P.M.B. (2006). Similarity of objects and the meaning of words. Proc. 3rd Conf. Theory and Applications of Models of Computation (TAMC), J.-Y. Cai, S. B. Cooper, and A. Li (Eds.), Lecture Notes in Computer Science, Vol. 3959, Springer-Verlag, Berlin.</entry>
<entry level="1" type="bullet">

 Dumais, S. (2003). Data-driven approaches to information access. Cognitive Science, 27(3), 491-524.</entry>
<entry level="1" type="bullet">

 Gabrilovich, E. and Markovitch, S. (2007). "Computing Semantic Relatedness using Wikipedia-based Explicit Semantic Analysis", Proceedings of The 20th International Joint Conference on Artificial Intelligence (IJCAI), Hyderabad, India, January 2007. <weblink xlink:type="simple" xlink:href="http://www.cs.technion.ac.il/~gabr/papers/ijcai-2007-sim.pdf">
http://www.cs.technion.ac.il/~gabr/papers/ijcai-2007-sim.pdf</weblink></entry>
<entry level="1" type="bullet">

 Juvina, I., van Oostendorp, H., Karbor, P., &amp; Pauw, B. (2005). Towards modeling contextual information in web navigation. In B. G. Bara &amp; L. Barsalou &amp; M. Bucciarelli (Eds.), 27th Annual Meeting of the Cognitive Science Society, CogSci2005 (pp. 1078-1083). Austin, Tx: The Cognitive Science Society, Inc.</entry>
<entry level="1" type="bullet">

 Kaur, I. &amp; Hornof, A.J. (2005). A Comparison of LSA, WordNet and PMI for Predicting User Click Behavior. Proceedings of the Conference on Human Factors in Computing, CHI 2005 (pp. 51-60).</entry>
<entry level="1" type="bullet">

 Landauer, T. K., &amp; Dumais, S. T. (1997). A solution to Plato's problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge. Psychological Review, 104(2), 211-240.</entry>
<entry level="1" type="bullet">

 Landauer, T. K., Foltz, P. W., &amp; Laham, D. (1998). Introduction to Latent Semantic Analysis. Discourse Processes, 25, 259-284.</entry>
<entry level="1" type="bullet">

 Lee, M. D., Pincombe, B., &amp; Welsh, M. (2005). An empirical evaluation of models of text document similarity. In B. G. Bara &amp; L. Barsalou &amp; M. Bucciarelli (Eds.), 27th Annual Meeting of the Cognitive Science Society, CogSci2005 (pp. 1254-1259). Austin, Tx: The Cognitive Science Society, Inc.</entry>
<entry level="1" type="bullet">

 Lemaire, B., &amp; Denhi√©re, G. (2004). Incremental construction of an associative network from a corpus. In K. D. Forbus &amp; D. Gentner &amp; T. Regier (Eds.), 26th Annual Meeting of the Cognitive Science Society, CogSci2004. Hillsdale, NJ: Lawrence Erlbaum Publisher.</entry>
<entry level="1" type="bullet">

 Lindsey, R., Veksler, V.D., Grintsvayg, A., Gray, W.D. (2007). The Effects of Corpus Selection on Measuring Semantic Relatedness. Proceedings of the 8th International Conference on Cognitive Modeling, Ann Arbor, MI.</entry>
<entry level="1" type="bullet">

 Pirolli, P. (2005). Rational analyses of information foraging on the Web. Cognitive Science, 29(3), 343-373.</entry>
<entry level="1" type="bullet">

 Pirolli, P., &amp; Fu, W.-T. (2003). SNIF-ACT: A model of information foraging on the World Wide Web. Lecture Notes in Computer Science, 2702, 45-54.</entry>
<entry level="1" type="bullet">

 Turney, P. (2001). Mining the Web for Synonyms: PMI versus LSA on TOEFL. In L. De Raedt &amp; P. Flach (Eds.), Proceedings of the Twelfth European Conference on Machine Learning (ECML-2001) (pp. 491-502). Freiburg, Germany.</entry>
<entry level="1" type="bullet">

 Veksler, V.D. &amp; Gray, W.D. (2006). Test Case Selection for Evaluating Measures of Semantic Distance. Proceedings of the 28th Annual Meeting of the Cognitive Science Society, CogSci2006.</entry>
</list>
</p>

<ss1>
<st>
Google distance references</st>
<p>

<list>
<entry level="1" type="bullet">

Rudi Cilibrasi and Paul Vitanyi (2004). <weblink xlink:type="simple" xlink:href="http://arxiv.org/abs/cs.CL/0412098">
, The Google Similarity Distance, ArXiv.org</weblink> or <weblink xlink:type="simple" xlink:href="http://csdl2.computer.org/persagen/DLAbsToc.jsp?resourcePath=/dl/trans/tk/&amp;toc=comp/trans/tk/2007/03/k3toc.xml&amp;DOI=10.1109/TKDE.2007.48">
 The Google Similarity Distance, IEEE Trans. Knowledge and Data Engineering, 19:3(2007), 370-383.</weblink>.</entry>
<entry level="1" type="bullet">

<weblink xlink:type="simple" xlink:href="http://www.newscientist.com/article.ns?id=dn6924">
Google's search for meaning</weblink> at Newscientist.com.</entry>
<entry level="1" type="bullet">

Jan Poland and Thomas Zeugmann (2006), <weblink xlink:type="simple" xlink:href="http://www-alg.ist.hokudai.ac.jp/~thomas/publications/dag_c2c_pz.pdf">
Clustering the Google Distance with Eigenvectors and Semidefinite Programming</weblink></entry>
<entry level="1" type="bullet">

Aarti Gupta and Tim Oates (2007), <weblink xlink:type="simple" xlink:href="http://www.ijcai.org/papers07/Papers/IJCAI07-261.pdf">
Using Ontologies and the Web to Learn Lexical Semantics</weblink> (Includes comparison of NGD to other algorithms.)</entry>
<entry level="1" type="bullet">

 Wilson Wong, Wei Liu and Mohammed Bennamoun (2007), <weblink xlink:type="simple" xlink:href="http://www.springerlink.com/content/u331u5122822046m/">
Tree-Traversing Ant Algorithm for term clustering based on featureless similarities</weblink>, Journal of Data Mining and Knowledge Discovery (the use of NGD for term clustering)</entry>
</list>
</p>

</ss1>
</sec>
<sec>
<st>
External links</st>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://cwl-projects.cogsci.rpi.edu/msr/">
Measures of Semantic Relatedness</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://wn-similarity.sourceforge.net">
WordNet-Similarity</weblink>, an open source package for computing the similarity and relatedness of concepts found in WordNet</entry>
</list>
</p>

</sec>
</bdy>
</measure>
</article>
