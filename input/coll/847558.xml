<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 17:45:30[mciao0828] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Confusion matrix</title>
<id>847558</id>
<revision>
<id>223324537</id>
<timestamp>2008-07-03T15:55:39Z</timestamp>
<contributor>
<username>Rror</username>
<id>6252166</id>
</contributor>
</revision>
<categories>
<category>Machine learning</category>
</categories>
</header>
<bdy>

In the field of <link xlink:type="simple" xlink:href="../164/1164.xml">
artificial intelligence</link>, a <b>confusion matrix</b> is a visualization tool typically used in <link xlink:type="simple" xlink:href="../926/20926.xml">
supervised learning</link> (in <link xlink:type="simple" xlink:href="../497/233497.xml">
unsupervised learning</link> it is typically called a <b>matching matrix</b>).  Each column of the matrix represents the instances in a predicted class, while each row represents the instances in an actual class.  One benefit of a confusion matrix is that it is easy to see if the system is confusing two classes (i.e. commonly mislabelling one as another). <p>

When a data set is unbalanced (when the number of samples in different classes vary greatly) the error rate of a classifier is not representative of the true performance of the classifier. This can easily be understood by an example: If there are for example 990 samples from class A and only 10 samples from class B, the classifier can easily be biased towards class A. If the classifier classifies all the samples as class A, the accuracy will be 99%. This is not a good indication of the classifier's true performance. The classifier has a 100% recognition rate for class A but a 0% recognition rate for class B.</p>
<p>

In the example confusion matrix below, of the 8 actual cats, the system predicted that three were dogs, and of the six dogs, it predicted that one was a rabbit and two were cats.  We can see from the matrix that the system in question has trouble distinguishing between cats and dogs, but can make the distinction between rabbits and other types of animals pretty well. </p>
<p>

<table cellpadding="2" border="1" cellspacing="0">
<caption>
Example confusion matrix</caption>
<row>

<header>
Cat</header>
<header>
Dog</header>
<header>
Rabbit</header>
</row>
<row>
<header>
Cat</header>
<col>
5</col>
<col>
3</col>
<col>
0</col>
</row>
<row>
<header>
Dog</header>
<col>
2</col>
<col>
3</col>
<col>
1</col>
</row>
<row>
<header>
Rabbit</header>
<col>
0</col>
<col>
2</col>
<col>
11</col>
</row>
</table>
</p>

<sec>
<st>
Table of Confusion</st>
<p>

In <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../563/4141563.xml">
Predictive Analytics</link></causal_agent>
</worker>
</assistant>
</model>
</person>
</physical_entity>
, a <b>Table of Confusion</b>, also known as a <b>confusion matrix</b>, is a table with two rows and two columns that reports the number of True Negatives, False Positives, False Negatives, and True Positives.</p>
<p>

<table align="center">
<row>
<header colspan="2">
&nbsp;</header>
<header colspan="2" align="center">
actual value</header>
</row>
<row>
<header colspan="2">
&nbsp;</header>
<header>
<it>p''</it></header>
<header>
<it>n''</it></header>
<header style="padding-left:1em;">
total</header>
</row>
<row>
<header rowspan="2" valign="middle">
predictionoutcome</header>
<header style="padding-right:1em;" valign="middle">
<it>p</it>'</header>
<col style="border:thin solid; padding:1em;">
TruePositive</col>
<col style="border:thin solid; padding:1em;">
FalsePositive</col>
<col style="padding-left:1em;">
P'</col>
</row>
<row>
<header style="padding-right:1em;" valign="middle">
<it>n</it>'</header>
<col style="border:thin solid; padding:1em;">
FalseNegative</col>
<col style="border:thin solid; padding:1em;">
TrueNegative</col>
<col style="padding-left:1em;">
N'</col>
</row>
<row>
<header colspan="2" style="padding-right:1em;" align="right">
total</header>
<col align="center">
P</col>
<col align="center">
N</col>
</row>
</table>

<it>Table 1: Table of Confusion.</it></p>
<p>

For example, consider a model which predicts for 10,000 <link xlink:type="simple" xlink:href="../176/15176.xml">
Insurance</link> <link xlink:type="simple" xlink:href="../490/51490.xml">
Claims</link> whether each case is <link xlink:type="simple" xlink:href="../790/58790.xml">
Fraudulent</link>.  This model correctly predicts 9,700 non-fraudulent cases, and 100 fraudulent cases.  The model also incorrectly predicts 150 cases which are not fraudulent to be fraudulent, and 50 cases which are fraudulent to be non-fraudulent.  The resulting Table of Confusion is shown below.</p>
<p>

<table align="center">
<row>
<header colspan="2">
&nbsp;</header>
<header colspan="2" align="center">
actual value</header>
</row>
<row>
<header colspan="2">
&nbsp;</header>
<header>
<it>p''</it></header>
<header>
<it>n''</it></header>
<header style="padding-left:1em;">
total</header>
</row>
<row>
<header rowspan="2" valign="middle">
predictionoutcome</header>
<header style="padding-right:1em;" valign="middle">
<it>p</it>'</header>
<col style="border:thin solid; padding:1em;">
100</col>
<col style="border:thin solid; padding:1em;">
150</col>
<col style="padding-left:1em;">
P'</col>
</row>
<row>
<header style="padding-right:1em;" valign="middle">
<it>n</it>'</header>
<col style="border:thin solid; padding:1em;">
50</col>
<col style="border:thin solid; padding:1em;">
9700</col>
<col style="padding-left:1em;">
N'</col>
</row>
<row>
<header colspan="2" style="padding-right:1em;" align="right">
total</header>
<col align="center">
P</col>
<col align="center">
N</col>
</row>
</table>
</p>
<p>

<it>Table 2: Example Table of Confusion.</it></p>

</sec>
<sec>
<st>
 See also </st>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../393/205393.xml">
Binary classification</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../330/5599330.xml">
Sensitivity (tests)</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../330/5599330.xml">
Specificity (tests)</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../877/5657877.xml">
Type I and type II errors</link></entry>
</list>
</p>

</sec>
<sec>
<st>
 External links </st>

<p>

http://www2.cs.uregina.ca/~dbd/cs831/notes/confusion_matrix/confusion_matrix.html</p>


</sec>
</bdy>
</article>
