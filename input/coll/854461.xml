<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 17:46:31[mciao0828] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<event  confidence="0.8" wordnetid="100029378">
<rule  confidence="0.8" wordnetid="105846932">
<act  confidence="0.8" wordnetid="100030358">
<psychological_feature  confidence="0.8" wordnetid="100023100">
<procedure  confidence="0.8" wordnetid="101023820">
<activity  confidence="0.8" wordnetid="100407535">
<algorithm  confidence="0.8" wordnetid="105847438">
<header>
<title>Learning classifier system</title>
<id>854461</id>
<revision>
<id>220891063</id>
<timestamp>2008-06-22T02:41:22Z</timestamp>
<contributor>
<username>SmackBot</username>
<id>433328</id>
</contributor>
</revision>
<categories>
<category>Evolutionary algorithms</category>
<category>Machine learning</category>
</categories>
</header>
<bdy>
<p>

A <b>learning classifier system</b>, or LCS,  is a <link xlink:type="simple" xlink:href="../488/233488.xml">
machine learning</link> system with close links to  <link xlink:type="simple" xlink:href="../294/66294.xml">
reinforcement learning</link> and <link xlink:type="simple" xlink:href="../254/40254.xml">
genetic algorithms</link>. First described by <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<scientist wordnetid="110560637" confidence="0.8">
<psychologist wordnetid="110488865" confidence="0.8">
<link>
John Holland</link></psychologist>
</scientist>
</causal_agent>
</person>
</physical_entity>
, his LCS consisted of a population of binary rules on which a genetic algorithm altered and selected the best rules.
Rule fitness was based on a reinforcement learning technique.</p>
<p>

Learning classifier systems can be split into two types depending upon where the genetic algorithm acts. A Pittsburgh-type LCS has a population of separate rule sets, where the genetic algorithm recombines and reproduces the best of these rule sets. In a Michigan-style LCS there is only a single population and the algorithm's action focuses on selecting the best classifiers within that ruleset. Michigan-style LCSs have two main types of fitness definitions, strength-based (e.g. <b>ZCS</b>) and accuracy-based (e.g. <b>XCS</b>). The term "learning classifier system" most often refers
to Michigan-style LCSs.</p>
<p>

Initially the classifiers or rules were , but recent research has expanded this representation to include real-valued,
<link xlink:type="simple" xlink:href="../542/1729542.xml">
neural network</link>, and functional (<message wordnetid="106598915" confidence="0.8">
<information wordnetid="106634376" confidence="0.8">
<format wordnetid="106636806" confidence="0.8">
<link xlink:type="simple" xlink:href="../458/54458.xml">
S-expression</link></format>
</information>
</message>
) conditions.</p>
<p>

Learning classifier systems are not fully understood <link xlink:type="simple" xlink:href="../831/18831.xml">
mathematically</link> and doing so remains an area of active research. Despite this, they have been successfully applied in many problem domains.</p>


<p>

A Brief Tutorial on Accuracy-Based "Michigan" LCSs</p>
<p>

<b>A learning classifier system</b> (LCS) is an adaptive system that learns to
perform the best action given its input.  By "best" is generally meant
the action that will receive the most reward or reinforcement from the
system's environment.  By "input" is meant the environment as sensed by
the system, usually a vector of numerical values.  The set of available
actions depends on the system context: if the system is a mobile robot,
the available actions may be physical: "turn left", "turn right", etc.
In a classification context, the available actions may be "yes", "no",
or "benign", "malignant", etc.  In a decision context, for instance a
financial one, the actions might be "buy", "sell", etc.  In general, an LCS
is a simple model of an intelligent agent interacting with an environment.</p>
<p>

<b>An LCS is "adaptive"</b> in the sense that its ability to choose the best
action improves with experience.  The source of the improvement is
reinforcement--technically, payoff--provided by the environment.
In many cases, the payoff is arranged by the experimenter or trainer of
the LCS.  For instance, in a classification context, the payoff may be
1.0 for "correct" and 0.0 for "incorrect".  In a robotic context, the
payoff could be a number representing the change in distance to a
recharging source, with more desirable changes (getting closer) represented
by larger positive numbers, etc.  Often, systems can be set up so that
effective reinforcement is provided automatically, for instance via a distance
sensor.  Payoff received for a given action is used by the LCS to alter the
likelihood of taking that action, in those circumstances, in the future.
To understand how this works, it is necessary to describe some
of the LCS mechanics.</p>
<p>

<b>Inside the LCS</b> is a set--technically, a population--of
"condition-action
rules" called classifiers.  There may be hundreds of classifiers in the
population.  When a particular input occurs, the LCS forms a
so-called match set of classifiers whose conditions are satisfied by
that input.
Technically, a condition is a truth function t(x) which is
satisfied for certain input vectors x.  For instance, in a certain
classifier, it may be that t(x)=1 (true)
for 43  x3  54, where x3 is a component
of x, and represents, say, the age of a medical patient.  In general,
a classifier's condition will refer to more than one of the input components,
usually
all of them.  If a classifier's condition is satisfied, i.e. its t(x)=1,
then that classifier joins the match set and influences the system's action
decision.  In a sense, the match set consists of classifiers in the
population that recognize the current input.</p>
<p>

Among the classifiers--the condition-action rules--of the match set will
be some that advocate one of the possible actions, some that advocate another
of the actions, and so forth.  Besides advocating an action, a classifier
will also contain a prediction of the amount of payoff which, speaking
loosely, "it thinks" will be received if the system takes that action.
How can the LCS decide which action to take?  Clearly, it should pick
the action that is likely to receive the highest payoff, but with all
the classifiers making (in general) different predictions, how can it decide?
The technique adopted is to compute, for each action, an average of
the predictions of the classifiers advocating that action--and then
choose the action with the largest average.  The prediction average is
in fact weighted by another classifier quantity, its fitness, which
will be described later but is intended to reflect the reliability of
the classifier's prediction.</p>
<p>

<b>The LCS takes the action</b> with the largest average prediction, and
in response the environment returns some amount of payoff.  If it is
in a learning mode, the LCS will use this payoff, P, to alter the
predictions of the responsible classifiers, namely those advocating
the chosen action; they form what is called the action set.
In this adjustment, each action set classifier's prediction p is
changed mathematically to bring it slightly closer to P, with the aim of
increasing its accuracy.  Besides its prediction, each classifier
maintains an estimate ε of the error of its predictions.  Like
p, ε is adjusted on each learning encounter with the
environment
by moving ε slightly closer to the current absolute error
|p - P|.
Finally, a quantity called the classifier's fitness is adjusted
by moving it closer to an inverse function of ε, which can be
regarded as measuring the accuracy of the classifier.  The result
of these adjustments will hopefully be to improve
the classifier's prediction and to derive a measure--the
fitness--that indicates its accuracy.</p>
<p>

<b>The adaptivity of the LCS</b> is not, however, limited to adjusting
classifier predictions.  At a deeper level, the system treats the classifiers
as an evolving population in which accurate--i.e. high
fitness--classifiers are reproduced over less accurate ones and the
"offspring" are
modified by genetic operators such as mutation and crossover.  In this
way, the population of classifiers gradually changes over time, that is,
it adapts structurally.  Evolution of the population is the key to
high performance since the accuracy of predictions depends closely
on the classifier conditions, which are changed by evolution.</p>
<p>

<b>Evolution takes place</b> in the background as the system is interacting
with its environment.  Each time an action set is formed, there is
finite chance that a genetic algorithm will occur in the set.  Specifically,
two classifiers are selected from the set with probabilities proportional
to their fitnesses.  The two are copied and the copies (offspring)
may, with certain probabilities, be mutated and recombined ("crossed").
Mutation means changing, slightly, some quantity or aspect of the
classifier condition; the action may also be changed to one of the
other actions.  Crossover means exchanging parts of the two classifiers.
Then the offspring are inserted into the population and two classifiers
are deleted to keep the population at a constant size.  The new
classifiers, in effect, compete with their parents, which are still
(with high probability) in the population.</p>
<p>

<b>The effect of classifier evolution</b> is to modify their conditions so
as to increase the overall prediction accuracy of the population.
This occurs because fitness is based on accuracy.  In addition, however,
the evolution leads to an increase in what can be called the
"accurate generality" of the population.  That is, classifier conditions
evolve to be as general as possible without sacrificing accuracy.
Here, general means maximizing the number of input vectors that the
condition matches.  The increase in generality results in the population
needing fewer distinct classifiers to cover all inputs, which means
(if identical classifiers are merged) that populations are smaller,
and also that the knowledge contained in the population is more
visible to humans--which is important in many applications.
The specific mechanism by which generality increases is a major,
if subtle, side-effect of the overall evolution.</p>
<p>

<b>Summarizing</b>, a learning classifier system is a broadly-applicable
adaptive system that learns from external reinforcement and through
an internal structural evolution derived from that reinforcement.
In addition to adaptively increasing its performance, the LCS
develops knowledge in the form of rules that respond
to different aspects of the environment and capture environmental
regularities through the generality of their conditions.</p>
<p>

<b>Many important aspects</b> of LCS were omitted in the above presentation,
including among others: use in sequential (multi-step) tasks, modifications
for non-Markov (locally ambiguous) environments, learning in the presence
of noise, incorporation of continuous-valued actions, learning of relational
concepts, learning of hyper-heuristics, and use for on-line function
approximation and clustering.  An LCS appears to be a widely applicable
cognitive/agent model that can act as a framework for a diversity
of learning investigations and practical applications.</p>

<sec>
<st>
External links</st>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://lcsweb.cs.bath.ac.uk/">
Learning Classifier System Web</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.illigal.uiuc.edu/web/lcs-n-gbml/">
IlliGAL LCS Blog</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.cems.uwe.ac.uk/lcsg/">
UWE Learning Classifier Research Group</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://prediction-dynamics.com/">
Prediction Dynamics</weblink></entry>
</list>
</p>

</sec>
</bdy>
</algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
</article>
