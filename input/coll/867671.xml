<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 17:46:25[mciao0825] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<know-how  confidence="0.8" wordnetid="105616786">
<method  confidence="0.8" wordnetid="105660268">
<header>
<title>Importance sampling</title>
<id>867671</id>
<revision>
<id>237031063</id>
<timestamp>2008-09-08T09:05:32Z</timestamp>
<contributor>
<username>Rodrigo braz</username>
<id>2383274</id>
</contributor>
</revision>
<categories>
<category>Monte Carlo methods</category>
</categories>
</header>
<bdy>

In <link xlink:type="simple" xlink:href="../685/26685.xml">
statistics</link>, <b>importance sampling</b> is a general technique for estimating the properties of a particular <link xlink:type="simple" xlink:href="../543/23543.xml">
distribution</link>, while only having samples generated from a different distribution rather than the distribution of interest.  Depending on the application, the term may refer to the process of sampling from this alternative distribution, the process of inference, or both.
<sec>
<st>
 Basic theory </st>
<p>

More formally, let <math>X</math> be a <link xlink:type="simple" xlink:href="../685/25685.xml">
random variable</link> in <math>S</math>.  Let <math>p</math> be a
<link>
probability measure</link> on <math>S</math>, and <math>f</math> some function on <math>S</math>. Then the expectation of <math>f</math> under <math>p</math> can be written as</p>
<p>

<indent level="1">

 <math>
  \mathbf{E}[f(X)|p] \equiv \int f(x) p(x) \,dx.
</math>
</indent>

If we have random samples <math>x_1, \ldots, x_n</math>, generated according to
<math>p</math>, then an empirical estimate of <math>p</math> is</p>
<p>

<indent level="1">

<math>
  P_n(x) = \frac{1}{n}\sum_{i=1}^n \delta_{x_i}(x).
</math>
</indent>

where <math>\delta_{x_i}(x) = 1</math> for <math>x_i=x</math> and 0 otherwise.</p>
<p>

In that case, we can easily obtain the Monte-Carlo empirical estimate of 
<math>\mathbf{E}[f(X)|p]</math></p>
<p>

<indent level="1">

 <math>
  \hat{\mathbf{E}}_n[f] = \int f(x) d P_n(x)  = \frac{1}{n} \sum_{i=1}^n f(x_i).
</math>
</indent>

The basic idea of importance sampling is to draw from a distribution other than <math>p</math>, say <math>q</math> and modify the above formula to still get a consistent estimate of <math>\mathbf{E}[f(X)]</math>. A main reason for such a procedure is the potential to reduce the variance of <math>\hat{\mathbf{E}}[f(X)]</math> by an appropriate choice of <math>q</math>, hence the name importance sampling, as samples from <math>q</math> can be more "important" for the estimation of the integral. Other reasons include difficulties to draw samples from distribution <math>p</math> or efficiency considerations.</p>
<p>

More formally, consider
another probability measure, <math>q</math>, with the same <link xlink:type="simple" xlink:href="../013/381013.xml">
support</link> as
<math>p</math>.  From the definition of the expectation given above, we have</p>
<p>

<indent level="1">

 <math>
  \mathbf{E}[f(X)|p] = \frac{\int f(x) w(x) q(x) \,dx}{\int w(x) q(x)
dx}, </math>
</indent>

where <math>w(x) = \frac{p(x)}{q(x)}</math>, is known as
the <it>importance weight</it> and the distribution <math>q</math> is frequently referred to as the <it>sampling</it> or <it>proposal</it> distribution.  Then, if we have random samples <math>x_1, \ldots, x_n</math>, generated
according to <math>q</math>, a Monte Carlo estimate of <math>\mathbf{E}[f(X)|p]</math> follows from
the above equation by viewing the problem as that of
estimating the expectations <math>\mathbf{E}[f(X)w(X)|q]</math> and <math>\mathbf{E}[w(X)|q]</math>.</p>
<p>

<indent level="1">

 <math>
  \hat{\mathbf{E}}_{n,q}[f] = \frac{1/n \sum_{i=1}^n f(x_i) w(x_i)}{1/n \sum_{j=1}^n w(x_j)}
  = \sum_{i=1}^n f(x_i) v_i,
</math>
</indent>

where <math>v_i=\frac{w(x_i)}{\sum_{j=1}^n w(x_j)}</math> are the <it>normalised importance weights</it>.</p>
<p>

The technique is completely general and the above analysis can be repeated essentially exactly also for other choices of <math>p</math>, for example when it represents a conditional distribution.  Note that when <math>p</math> is the uniform distribution, we are just estimating the (scaled) integral of <math>f</math> over <math>S</math>, so the method can also be used for estimating simple integrals.</p>
<p>

There are two main applications of importance sampling methods which, naturally, are interrelated.  While the aim of both applications is to estimate statistics of random variables, the field of probabilistic inference focuses more on the estimation of <math>p</math> or related statistics, while the field of simulation focuses more on the choice of the distribution <math>q</math>.  Nevertheless, the basic theory and tools are identical.</p>

</sec>
<sec>
<st>
 Application to probabilistic inference </st>

<p>

Such methods are frequently used to estimate posterior densities or expectations in state and/or parameter estimation problems in probabilistic models that are too hard to treat analytically, for example in <physical_entity wordnetid="100001930" confidence="0.8">
<person wordnetid="100007846" confidence="0.8">
<model wordnetid="110324560" confidence="0.8">
<assistant wordnetid="109815790" confidence="0.8">
<worker wordnetid="109632518" confidence="0.8">
<causal_agent wordnetid="100007347" confidence="0.8">
<link xlink:type="simple" xlink:href="../996/203996.xml">
Bayesian networks</link></causal_agent>
</worker>
</assistant>
</model>
</person>
</physical_entity>
.</p>

</sec>
<sec>
<st>
 Application to simulation </st>
<p>

<b>Importance sampling</b> (IS) is a <link xlink:type="simple" xlink:href="../715/5187715.xml">
variance reduction</link> technique that can be used in the <technique wordnetid="105665146" confidence="0.8">
<know-how wordnetid="105616786" confidence="0.8">
<method wordnetid="105660268" confidence="0.8">
<link xlink:type="simple" xlink:href="../098/56098.xml">
Monte Carlo method</link></method>
</know-how>
</technique>
. The idea behind IS is that certain values of the input <link xlink:type="simple" xlink:href="../685/25685.xml">
random variables</link> in a <link xlink:type="simple" xlink:href="../444/43444.xml">
simulation</link> have more impact on the parameter being estimated than others. If these "important" values are emphasized by sampling more frequently, then the <link xlink:type="simple" xlink:href="../043/10043.xml">
estimator</link> variance can be reduced. Hence, the basic methodology in IS is to choose a distribution which "encourages" the important values. This use of "biased" distributions will result in a biased estimator if it is applied directly in the simulation. However, the simulation outputs are weighted to correct for the use of the biased distribution, and this ensures that the new IS estimator is unbiased. The weight is given by the <link xlink:type="simple" xlink:href="../035/45035.xml">
likelihood ratio</link>, that is, the <link xlink:type="simple" xlink:href="../746/338746.xml">
Radon-Nikodym derivative</link> of the true underlying distribution with respect to the biased simulation distribution. </p>
<p>

The fundamental issue in implementing IS simulation is the choice of the biased distribution which encourages the important regions of the input variables. Choosing or designing a good biased distribution is the "art" of IS. The rewards for a good distribution can be huge run-time savings; the penalty for a bad distribution can be longer run times than for a general Monte Carlo simulation without importance sampling.</p>

<ss1>
<st>
 Mathematical approach </st>

<p>

Consider estimating by simulation the probability <math>p_t\,</math> of an event <math>{ X \ge t\ }</math>, where <math>X</math> is a random variable with <link xlink:type="simple" xlink:href="../543/23543.xml">
distribution</link> <math>F</math> and <link xlink:type="simple" xlink:href="../487/43487.xml">
probability density function</link> <math>f(x)= F'(x)\,</math>, where prime denotes <link xlink:type="simple" xlink:href="../921/7921.xml">
derivative</link>. A <math>K</math>-length <link xlink:type="simple" xlink:href="../067/453067.xml">
independent and identically distributed</link> (i.i.d.) sequence <math>X_i\,</math> is generated from the distribution <math>F</math>, and the number <math>k_t</math> of random variables that lie above the threshold <math>t</math> are counted. The random variable <math>k_t</math> is characterized by the <link xlink:type="simple" xlink:href="../876/3876.xml">
Binomial distribution</link></p>
<p>

<indent level="1">

<math>P(k_t = k)={K\choose k}p_t^k(1-p_t)^{K-k},\,\quad \quad k=0,1,\dots,K.</math>
</indent>

Importance sampling is concerned with the determination and use of an alternate density function <math>f_*\,</math>(for X), usually referred to as a biasing density, for the simulation experiment. This density allows the event <math>{ X \ge t\ }</math> to occur more frequently, so the sequence lengths <math>K</math> gets smaller for a given <link xlink:type="simple" xlink:href="../043/10043.xml">
estimator</link> variance. Alternatively, for a given <math>K</math>, use of the biasing density results in a variance smaller than that of the conventional Monte Carlo estimate. From the definition of <math>p_t\,</math>, we can introduce <math>f_*\,</math> as below.</p>
<p>

<indent level="1">

<math>
\begin{align}
p_t &amp; {} = {E} [1(X \ge t)] \\
&amp; {} = \int 1(x \ge t) \frac{f(x)}{f_*(x)} f_*(x) \,dx \\
&amp; {} = {E_*} [1(X \ge t) W(X)]
\end{align}
</math>
</indent>

where</p>
<p>

<indent level="1">

<math>W(\cdot) \equiv \frac{f(\cdot)}{f_*(\cdot)} </math>
</indent>

is a likelihood ratio and is referred to as the weighting function. The last equality in the above equation motivates the estimator</p>
<p>

<indent level="1">

<math> \hat p_t = \frac{1}{K}\,\sum_{i=1}^K 1(X_i \ge t) W(X_i),\,\quad \quad X_i \sim  f_*</math>
</indent>

This is the IS estimator of <math>p_t\,</math> and is unbiased. That is, the estimation procedure is to generate i.i.d. samples from <math>f_*\,</math> and for each sample which exceeds <math>t\,</math>, the estimate is incremented by the weight <math>W\,</math> evaluated at the sample value. The results are averaged over <math>K\,</math> trials. The variance of the IS estimator is easily shown to be</p>
<p>

<indent level="1">

<math>
\begin{align}
\operatorname{var}_*\hat p_t &amp; {} =   \operatorname{var}_* [1(X \ge t)W(X)] \\
&amp; {} = {E_*}[1(X \ge t)^2 W^2(X)] - p_t^2 \\
&amp; {} =  {E}[1(X \ge t)^2 W(X)] - p_t^2 
\end{align}
</math>
</indent>

Now, the IS problem then focuses on finding a biasing density <math>f_*\,</math> such that the variance of the IS estimator is less than the variance of the general Monte Carlo estimate. For some biasing density function, which minimizes the variance, and under certain conditions reduces it to zero, it is called an optimal biasing density function.</p>

</ss1>
<ss1>
<st>
 Conventional biasing methods </st>

<p>

Although there are many kinds of biasing methods, the following two methods are most widely used in the applications of IS. </p>

<ss2>
<st>
 Scaling </st>

<p>

Shifting probability mass into the event region <math>{ X \ge t\ }</math> by positive scaling of the random variable <math>X\,</math> with a number greater than unity has the effect of increasing the variance (mean also) of the density function. This results in a heavier tail of the density, leading to an increase in the event probability. Scaling is probably one of the earliest biasing methods known and has been extensively used in practice. It is simple to implement and usually provides conservative simulation gains as compared to other methods.</p>
<p>

In IS by scaling, the simulation density is chosen as the density function of the scaled random variable <math>aX\,</math>, where usually <math>a&amp;gt;1</math> for tail probability estimation. By transformation,</p>
<p>

<indent level="1">

<math> f_*(x)=\frac{1}{a} f \bigg( \frac{x}{a} \bigg)\,</math>
</indent>

and the weighting function is</p>
<p>

<indent level="1">

<math> W(x)= a \frac{f(x)}{f(x/a)} \,</math>
</indent>

While scaling shifts probability mass into the desired event region, it also pushes mass into the complementary region <math>X&amp;lt;t\,</math> which is undesirable. If <math>X\,</math> is a sum of <math>n\,</math> random variables, the spreading of mass takes place in an <math>n\,</math> dimensional space. The consequence of this is a decreasing IS gain for increasing <math>n\,</math>, and is called the dimensionality effect.</p>

</ss2>
<ss2>
<st>
 Translation </st>

<p>

Another simple and effective biasing technique employs translation of the density function (and hence random variable) to place much of its probability mass in the rare event region. Translation does not suffer from a dimensionality effect and has been successfully used in several applications relating to simulation of <link xlink:type="simple" xlink:href="../301/1616301.xml">
digital communication</link> systems. It often provides better simulation gains than scaling. In biasing by translation, the simulation density is given by</p>
<p>

<indent level="1">

<math> f_*(x)= f(x-c), \quad c&amp;gt;0 \,</math>
</indent>

where <math>c\,</math> is the amount of shift and is to be chosen to minimize the variance of the IS estimator.</p>

</ss2>
</ss1>
<ss1>
<st>
 Effects of system complexity  </st>

<p>

The fundamental problem with IS is that designing good biased distributions becomes more complicated as the system complexity increases. Complex systems are the systems with long memory since complex processing of a few inputs is much easier to handle. This dimensionality or memory can cause problems in three ways:</p>
<p>

<list>
<entry level="1" type="bullet">

 long memory (severe <link xlink:type="simple" xlink:href="../287/41287.xml">
intersymbol interference</link> (ISI))</entry>
<entry level="1" type="bullet">

 unknown memory (<link xlink:type="simple" xlink:href="../015/1653015.xml">
Viterbi decoder</link>s)</entry>
<entry level="1" type="bullet">

 possibly infinite memory (adaptive equalizers)</entry>
</list>
</p>
<p>

In principle, the IS ideas remain the same in these situations, but the design becomes much harder. A successful approach to combat this problem is essentially breaking down a simulation into several smaller, more sharply defined subproblems. Then IS strategies are used to target each of the simpler subproblems. Examples of techniques to break the simulation down are conditioning and error-event simulation (EES) and regenerative simulation.</p>

</ss1>
<ss1>
<st>
 Evaluation of IS </st>

<p>

In order to identify successful IS techniques, it is useful to be able to quantify the run-time savings due to the use of the IS approach. The performance measure commonly used is <math>\sigma^2_{MC} / \sigma^2_{IS} \,</math>, and this can be interpreted as the speed-up factor by which the IS estimator achieves the same precision as the MC estimator. This has to be computed empirically since the estimator variances are not likely to be analytically possible when their mean is intractable. Other useful concepts in quantifying an IS estimator are the variance bounds and the notion of asymptotic efficiency. </p>

</ss1>
<ss1>
<st>
 Variance cost function </st>

<p>

Variance is not the only possible <link xlink:type="simple" xlink:href="../033/52033.xml">
cost function</link> for a simulation, and other cost functions, such as the mean absolute deviation, are used in various statistical applications. Nevertheless, the variance is the primary cost function addressed in the literature, probably due to the use of variances in <link xlink:type="simple" xlink:href="../911/280911.xml">
confidence interval</link>s and in the performance measure <math>\sigma^2_{MC} / \sigma^2_{IS} \,</math>.</p>
<p>

An associated issue is the fact that the ratio <math>\sigma^2_{MC} / \sigma^2_{IS} \,</math> overestimates the run-time savings due to IS since it does not include the extra computing time required to compute the weight function. Hence, some people evaluate the net run-time improvement by various means. Perhaps a more serious overhead to IS is the time taken to devise and program the technique and analytically derive the desired weight function.</p>

</ss1>
</sec>
<sec>
<st>
 References </st>
<p>

<list>
<entry level="1" type="bullet">

 R. Srinivasan, <it>Importance sampling - Applications in communications and detection</it>, Springer-Verlag, Berlin, 2002.</entry>
<entry level="1" type="bullet">

 B. D. Ripley, <it>Stochastic Simulation</it>, 1987, Wiley &amp; Sons</entry>
<entry level="1" type="bullet">

 <it>Sequential Monte Carlo Methods in Practice</it>, by A Doucet, N de Freitas and N Gordon.  Springer, 2001. ISBN 978-0387951461</entry>
<entry level="1" type="bullet">

 <it>Introduction to rare event simulation</it>, James Antonio Bucklew, Springer-Verlag, New York, 2004.</entry>
<entry level="1" type="bullet">

 P. J.Smith, M.Shafi, and H. Gao, "Quick simulation: A review of importance sampling techniques in communication systems," IEEE J.Select.Areas Commun., vol. 15, pp. 597-613, May 1997.</entry>
<entry level="1" type="bullet">

 M. Ferrari, S. Bellini, "Importance Sampling simulation of turbo product codes," ICC2001, The IEEE International Conference on Communications, vol. 9, pp. 2773-2777, June 2001.</entry>
<entry level="1" type="bullet">

 Tommy Oberg, Modulation, Detection, and Coding, John Wiley &amp; Sons, Inc., New York, 2001.</entry>
<entry level="1" type="bullet">

 Arouna. Adaptative Monte Carlo Method, A Variance Reduction Technique. Monte Carlo Methods and Their Applications. 2004</entry>
</list>
</p>

</sec>
<sec>
<st>
 See also </st>
<p>

<list>
<entry level="1" type="bullet">

 <technique wordnetid="105665146" confidence="0.8">
<know-how wordnetid="105616786" confidence="0.8">
<method wordnetid="105660268" confidence="0.8">
<link xlink:type="simple" xlink:href="../098/56098.xml">
Monte Carlo method</link></method>
</know-how>
</technique>
</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../596/27596.xml">
Stratified sampling</link></entry>
<entry level="1" type="bullet">

 <link>
Recursive stratified sampling</link></entry>
<entry level="1" type="bullet">

 <know-how wordnetid="105616786" confidence="0.8">
<method wordnetid="105660268" confidence="0.8">
<link xlink:type="simple" xlink:href="../948/1396948.xml">
Particle filter</link></method>
</know-how>
 &mdash; a sequential Monte Carlo method, which uses importance sampling</entry>
<entry level="1" type="bullet">

 <know-how wordnetid="105616786" confidence="0.8">
<method wordnetid="105660268" confidence="0.8">
<link xlink:type="simple" xlink:href="../018/5474018.xml">
Auxiliary field Monte Carlo</link></method>
</know-how>
</entry>
</list>
</p>

</sec>
<sec>
<st>
External links</st>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.creem.st-and.ac.uk/ken/Classes/S540/Handouts/rvgen6.pdf">
Monte Carlo Methods and Importance Sampling</weblink>, Eric C. Anderson, Lecture notes for Stat 587C</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www-sigproc.eng.cam.ac.uk/smc/">
Sequential Monte Carlo Methods (Particle Filtering)</weblink> homepage on University of Cambridge</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.iop.org/EJ/abstract/0143-0807/22/4/315">
Introduction to importance sampling in rare-event simulations</weblink> European journal of Physics. PDF document.</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://portal.acm.org/citation.cfm?id=1030470">
Adaptive monte carlo methods for rare event simulation: adaptive monte carlo methods for rare event simulations</weblink> Winter Simulation Conference</entry>
</list>
</p>


</sec>
</bdy>
</method>
</know-how>
</article>
