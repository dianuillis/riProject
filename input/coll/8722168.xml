<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 23:32:19[mciao0825] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Terminology extraction</title>
<id>8722168</id>
<revision>
<id>228926110</id>
<timestamp>2008-07-31T01:19:47Z</timestamp>
<contributor>
<username>Jeanenawhitney</username>
<id>5473836</id>
</contributor>
</revision>
<categories>
<category>Natural language processing</category>
</categories>
</header>
<bdy>

<b>Terminology extraction</b>, <b>term extraction</b>, or <b>glossary extraction</b>, is a subtask of <link xlink:type="simple" xlink:href="../162/383162.xml">
information extraction</link>. The goal of terminology extraction is to automatically extract relevant terms from a given <link xlink:type="simple" xlink:href="../887/53887.xml">
corpus</link>.<p>

In the <link xlink:type="simple" xlink:href="../123/29123.xml">
semantic web</link> era, a growing number of communities and networked enterprises started to access and interoperate through the <link xlink:type="simple" xlink:href="../539/14539.xml">
internet</link>. Modeling these communities and their information needs is important for several <link xlink:type="simple" xlink:href="../311/288311.xml">
web application</link>s, like topic-driven <link xlink:type="simple" xlink:href="../120/33120.xml">
web crawler</link>s,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref> <link xlink:type="simple" xlink:href="../483/93483.xml">
web services</link>,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref> <link xlink:type="simple" xlink:href="../646/596646.xml">
recommender systems</link>,<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%223%22])">3</ref> etc.</p>
<p>

One of the first steps to model the <link xlink:type="simple" xlink:href="../101/750101.xml">
knowledge domain</link> of a <link xlink:type="simple" xlink:href="../320/176320.xml">
virtual community</link> is to collect a vocabulary of domain-relevant terms, constituting the linguistic surface manifestation of domain <link>
concepts</link>. Several methods to automatically extract technical terms from domain-specific document <link xlink:type="simple" xlink:href="../146/549146.xml">
warehouse</link>s have been described in the literature.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%224%22])">4</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%225%22])">5</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%227%22])">7</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%228%22])">8</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%229%22])">9</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2210%22])">10</ref></p>
<p>

Typically, approaches to automatic term extraction make use of linguistic processors (<link>
part of speech tagging</link>, <link xlink:type="simple" xlink:href="../303/8925303.xml">
phrase chunking</link>) to extract terminological candidates, i.e. syntactically plausible terminological <link xlink:type="simple" xlink:href="../958/64958.xml">
noun phrase</link>s, NPs (e.g. compounds "credit card", adjective-NPs "local tourist information office", and prepositional-NPs "board of directors" - in English, the first two constructs are the most frequent). Terminological entries are then filtered from the candidate list using statistical and <link>
machine learning</link> methods. Once filtered, because of their low ambiguity and high specificity, these terms are particularly useful for conceptualizing a <link xlink:type="simple" xlink:href="../101/750101.xml">
knowledge domain</link> or for supporting the creation of a <link>
domain ontology</link>. Furthermore, terminology extraction is a very useful starting point for <link xlink:type="simple" xlink:href="../135/1473135.xml">
semantic similarity</link>, <link xlink:type="simple" xlink:href="../896/72896.xml">
knowledge management</link>, <link xlink:type="simple" xlink:href="../637/18630637.xml">
human translation</link> and <link xlink:type="simple" xlink:href="../980/19980.xml">
machine translation</link>, etc.</p>

<sec>
<st>
See also</st>
<p>

<list>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../162/383162.xml">
Information extraction</link></entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../561/5561.xml">
Computational linguistics</link></entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../652/21652.xml">
Natural language processing</link></entry>
<entry level="1" type="bullet">

<link>
Domain Ontology</link></entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../463/30463.xml">
Taxonomy</link></entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../629/151629.xml">
Glossary</link></entry>
<entry level="1" type="bullet">

<link xlink:type="simple" xlink:href="../588/7794588.xml">
Text simplification</link></entry>
<entry level="1" type="bullet">

<software wordnetid="106566077" confidence="0.8">
<application wordnetid="106570110" confidence="0.8">
<program wordnetid="106568978" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106359877" confidence="0.8">
<code wordnetid="106355894" confidence="0.8">
<coding_system wordnetid="106353757" confidence="0.8">
<link xlink:type="simple" xlink:href="../439/318439.xml">
Text mining</link></coding_system>
</code>
</writing>
</written_communication>
</program>
</application>
</software>
</entry>
</list>
</p>

</sec>
<sec>
<st>
References</st>

<p>

<reflist>
<entry id="1">
Menczer F., Pant G. and Srinivasan P. : Topic-Driven Crawlers: machine learning issues <weblink xlink:type="simple" xlink:href="http://citeseer.ist.psu.edu/menczer02topicdriven.html">
http://citeseer.ist.psu.edu/menczer02topicdriven.html</weblink></entry>
<entry id="2">
Fan J. and Kambhampati S. : A Snapshot of Public Web Services, in ACM SIGMOD Record  archive Volume 34 ,  Issue 1  (March 2005). <weblink xlink:type="simple" xlink:href="http://portal.acm.org/citation.cfm?id=1058150.1058156">
http://portal.acm.org/citation.cfm?id=1058150.1058156</weblink></entry>
<entry id="3">
Yan Zheng Wei, Luc Moreau, Nicholas R. Jennings: A market-based approach to recommender systems, in ACM Transactions on Information Systems (TOIS),  Volume 23 Issue 3, July 2005 <weblink xlink:type="simple" xlink:href="http://portal.acm.org/citation.cfm?id=1080344&amp;dl=ACM&amp;coll=&amp;CFID=15151515&amp;CFTOKEN=6184618">
http://portal.acm.org/citation.cfm?id=1080344&amp;dl=ACM&amp;coll=&amp;CFID=15151515&amp;CFTOKEN=6184618</weblink></entry>
<entry id="4">
<weblink xlink:type="simple" xlink:href="http://lcl2.di.uniroma1.it/~sclano">
Sclano, F.</weblink> and <weblink xlink:type="simple" xlink:href="http://www.dsi.uniroma1.it/~velardi/welcome.htm">
Velardi, P.</weblink>. <weblink xlink:type="simple" xlink:href="http://lcl2.di.uniroma1.it/termextractor">
TermExtractor</weblink>: a Web Application to Learn the Shared Terminology of Emergent Web Communities. To appear in Proc. of the 3rd International Conference on Interoperability for Enterprise Software and Applications (I-ESA 2007). Funchal (Madeira Island), Portugal, March 28â€“30th, 2007.</entry>
<entry id="5">
Navigli R.<weblink xlink:type="simple" xlink:href="http://www.dsi.uniroma1.it/~navigli/">
http://www.dsi.uniroma1.it/~navigli/</weblink> and Velardi, P. (2004). "Learning Domain Ontologies from Document Warehouses and Dedicated Web Sites". Computational Linguistics. vol. 50 (2) <weblink xlink:type="simple" xlink:href="http://www.dsi.uniroma1.it/~navigli/pubs/CL_2004_Navigli_Velardi.pdf">
http://www.dsi.uniroma1.it/~navigli/pubs/CL_2004_Navigli_Velardi.pdf</weblink></entry>
<entry id="6">
Wermter J. and Hahn U.: Finding New terminology in Very large Corpora, in Proc. of K-CAP'05, October 2-5, 2005, Banff, Alberta, Canada <weblink xlink:type="simple" xlink:href="http://portal.acm.org/citation.cfm?id=1088648">
http://portal.acm.org/citation.cfm?id=1088648</weblink></entry>
<entry id="7">
Bourigault D. and Jacquemin C.: Term Extraction+Term Clustering: an integrated platform for computer-aided terminology, in Proc. of EACL , 1999 <weblink xlink:type="simple" xlink:href="http://acl.ldc.upenn.edu/E/E99/E99-1003.pdf">
http://acl.ldc.upenn.edu/E/E99/E99-1003.pdf</weblink></entry>
<entry id="8">
Collier N., Nobata C. and Tsujii J. : Automatic acquisition and classification of terminology using a tagged corpus in the molecular biology domain, Terminology, 7(2). 239-257, 2002 <weblink xlink:type="simple" xlink:href="http://research.nii.ac.jp/~collier/papers/Terminology.pdf">
http://research.nii.ac.jp/~collier/papers/Terminology.pdf</weblink></entry>
<entry id="9">
L. Kozakov, Y. Park, T. Fin, Y. Drissi, Y. Doganata, and T. Cofino "Glossary extraction and utilization in the information search and delivery system for IBM Technical Support", IBM System Journal, Volume 43, Number 3, 2004 <weblink xlink:type="simple" xlink:href="http://www.research.ibm.com/journal/sj/433/kozakov.pdf">
http://www.research.ibm.com/journal/sj/433/kozakov.pdf</weblink></entry>
<entry id="10">
Y. Park, R. J. Byrd, B. Boguraev "Automatic glossary extraction: beyond terminology identification" International Conference On Computational Linguistics, Proceedings of the 19th international conference on Computational linguistics - Taipei, Taiwan, 2002 <weblink xlink:type="simple" xlink:href="http://portal.acm.org/citation.cfm?id=1072370&amp;dl=ACM&amp;coll=&amp;CFID=15151515&amp;CFTOKEN=6184618">
http://portal.acm.org/citation.cfm?id=1072370&amp;dl=ACM&amp;coll=&amp;CFID=15151515&amp;CFTOKEN=6184618</weblink></entry>
</reflist>
</p>

</sec>
<sec>
<st>
External links</st>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www-306.ibm.com/software/globalization/topics/terminology/introduction.jsp">
Introduction to terminology management</weblink>, by <company wordnetid="108058098" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../259/18622259.xml">
IBM</link></company>
</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://lcl2.di.uniroma1.it/termextractor">
TermExtractor</weblink>, a free terminology extraction <link xlink:type="simple" xlink:href="../311/288311.xml">
web application</link></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://labs.translated.net/terminology-extraction/">
TermFinder</weblink>, free online terminology extractor <link xlink:type="simple" xlink:href="../311/288311.xml">
web application</link></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.termserver.eu/cms/content/view/14/28/">
Statistical Bilingual Terminology Extractor</weblink>, online terminology extractor <link xlink:type="simple" xlink:href="../311/288311.xml">
web application</link></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://ngram.sourceforge.net">
Ngram Statistics Package</weblink>, open source package for identifying collocations</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.termextractor.com">
Bilingual Terminology Extraction from Translation Memory files</weblink>, by Masterin, online and free, supports English, Swedish and Finnish (all language pairs and translation directions) <link xlink:type="simple" xlink:href="../311/288311.xml">
web application</link></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.blogscope.net//tools/phrase.jsp">
English Phrases Extractor</weblink>, by the Blogscope team at the <weblink xlink:type="simple" xlink:href="http://www.cs.toronto.edu">
University of Toronto</weblink>, extracted terms are used to search for conceptually related blogs over the web rather than for linguistic analysis purpose <link xlink:type="simple" xlink:href="../311/288311.xml">
web application</link></entry>
</list>
</p>


</sec>
</bdy>
</article>
