<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 23:40:18[mciao0826] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Category utility</title>
<id>8964665</id>
<revision>
<id>175689721</id>
<timestamp>2007-12-04T11:14:20Z</timestamp>
<contributor>
<username>CharlesGillingham</username>
<id>4604963</id>
</contributor>
</revision>
<categories>
<category>Cognitive science</category>
<category>Machine learning</category>
</categories>
</header>
<bdy>

<b>Category utility</b> is a measure of "category goodness" defined in <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFGluckCorter1985%22])">
Gluck &amp; Corter (1985)</link> and <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCorterGluck1992%22])">
Corter &amp; Gluck (1992)</link>.  It was intended to supersede more limited measures of category goodness such as "<link xlink:type="simple" xlink:href="../656/3002656.xml">
cue validity</link>" (<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFReed1972%22])">
Reed 1972</link>;<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRoschMervis1975%22])">
Rosch &amp; Mervis 1975</link>) and "collocation index"  <cite class="inline">(<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFJones1983%22])">
Jones 1983</link>)</cite>. It provides a normative <link xlink:type="simple" xlink:href="../773/14773.xml">
information-theoretic</link> measure of the <it>predictive advantage</it> gained by the observer who possesses knowledge of the given category structure (i.e., the class labels of instances) over the observer who does <it>not</it> possess knowledge of the category structure.  In this sense the motivation for the <it>category utility</it> measure is similar to the <plant wordnetid="100017222" confidence="0.8">
<tree wordnetid="113104059" confidence="0.8">
<vascular_plant wordnetid="113083586" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<woody_plant wordnetid="113103136" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../412/2507412.xml">
information gain</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</woody_plant>
</rule>
</event>
</vascular_plant>
</tree>
</plant>
 metric used in <link xlink:type="simple" xlink:href="../602/232602.xml">
decision tree</link> learning. In certain presentations, it is also formally equivalent to the <link xlink:type="simple" xlink:href="../282/427282.xml">
mutual information</link>, as discussed below.  An excellent review of <it>category utility</it> in its probabilistic incarnation, with applications to <link xlink:type="simple" xlink:href="../488/233488.xml">
machine learning</link>, is provided in <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFWittenFrank2005%22])">
Witten &amp; Frank (2005</link>, pp.&nbsp;260â€“262).

<sec>
<st>
Probability-theoretic definition of the Category Utility</st>
<p>

The <link xlink:type="simple" xlink:href="../542/23542.xml">
probability-theoretic</link> definition of <it>category utility</it> given in <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFFisher1987%22])">
Fisher (1987)</link> and <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFWittenFrank2005%22])">
Witten &amp; Frank (2005)</link> is as follows:</p>

<p>

<indent level="1">

<math>
CU(C,F) = \tfrac{1}{p} \sum_{c_j \in C} p(c_j) \left [\sum_{f_i \in F} \sum_{k=1}^m p(f_{ik}|c_j)^2 - \sum_{f_i \in F} \sum_{k=1}^m p(f_{ik})^2\right ]
</math>
</indent>
</p>
<p>

where <math>F = \{f_i\}, \ i=1 \ldots n</math> is a size-<math>n\ </math> set of <math>m\ </math>-ary  features, and <math>C = \{c_j\} \ j=1 \ldots p</math> is a set of <math>p\ </math> categories.  The term  <math>p(f_{ik})\ </math> designates the <link xlink:type="simple" xlink:href="../791/5791.xml">
marginal probability</link> that feature <math>f_i\ </math> takes on value <math>k\ </math>, and the term  <math>p(f_{ik}|c_j)\ </math> designates the category-<link xlink:type="simple" xlink:href="../791/5791.xml">
conditional probability</link> that feature <math>f_i\ </math> takes on value <math>k\ </math> <it>given</it> that the object in question belongs to category <math>c_j\ </math>. </p>
<p>

The motivation and development of this expression for <it>category utility</it>, and the role of the multiplicand <math>\textstyle \tfrac{1}{p}</math> as a crude overfitting control, is given in the above sources.  Loosely  <cite class="inline">(<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFFisher1987%22])">
Fisher 1987</link>)</cite>, the term <math>\textstyle  p(c_j) \sum_{f_i \in F} \sum_{k=1}^m p(f_{ik}|c_j)^2</math> is  the expected number of attribute values that can be correctly guessed by an observer using a <link xlink:type="simple" xlink:href="../945/9731945.xml">
probability-matching</link> strategy together with knowledge of the category labels, while <math>\textstyle p(c_j) \sum_{f_i \in F} \sum_{k=1}^m p(f_{ik})^2</math> is the expected number of attribute values that can be correctly guessed by an observer the same strategy but without any knowledge of the category labels.  Their difference therefore reflects the relative advantage accruing to the observer by having knowledge of the category structure.</p>

</sec>
<sec>
<st>
 Information-theoretic definition of the Category Utility </st>
<p>

The <link xlink:type="simple" xlink:href="../773/14773.xml">
information-theoretic</link> definition of <it>category utility</it>  for a set of entities with size-<math>n\ </math> binary feature set  <math>F = \{f_i\}, \ i=1 \ldots n</math>,  and a binary category  <math>C = \{c,\bar{c}\}</math> is given in <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFGluckCorter1985%22])">
Gluck &amp; Corter (1985)</link> as follows: </p>

<p>

<indent level="1">

<math>
CU(C,F) = \left [p(c) \sum_{i=1}^n p(f_i|c)\log p(f_i|c) + p(\bar{c}) \sum_{i=1}^n p(f_i|\bar{c})\log p(f_i|\bar{c}) \right ] - \sum_{i=1}^n p(f_i)\log p(f_i)
</math>
</indent>
</p>
<p>

where <math>p(c)\ </math> is the <link xlink:type="simple" xlink:href="../877/472877.xml">
prior probability</link> of an entity belonging to the positive category <math>c\ </math> (in the absence of any feature information), <math>p(f_i|c)\ </math> is the <link xlink:type="simple" xlink:href="../791/5791.xml">
conditional probability</link> of an entity having feature <math>f_i\ </math> given that the entity belongs to category <math>c\ </math>, <math>p(f_i|\bar{c})</math> is likewise the conditional probability of an entity having feature <math>f_i\ </math> given that the entity belongs to category <math>\bar{c}</math>, and <math>p(f_i)\ </math> is the prior probability of an entity possessing feature <math>f_i\ </math> (in the absence of any category information).</p>
<p>

The intuition behind the above expression is as follows: The term  <math>p(c)\textstyle  \sum_{i=1}^n p(f_i|c)\log p(f_i|c)</math> represents the cost (in bits) of optimally encoding (or transmitting) feature information when it known that the objects to be described belong to category <math>c\ </math>.  Similarly, the term  <math>p(\bar{c})\textstyle  \sum_{i=1}^n p(f_i|\bar{c})\log p(f_i|\bar{c})</math> represents the cost (in bits) of optimally encoding (or transmitting) feature information when it known that the objects to be described belong to  category <math>\bar{c}</math>.  The sum of these two terms in the brackets is therefore the <link xlink:type="simple" xlink:href="../274/33274.xml">
weighted average</link> of these two costs.  The  final term, <math>\textstyle  \sum_{i=1}^n p(f_i)\log p(f_i)</math>, represents the cost (in bits) of optimally encoding (or transmitting) feature information when no category information is available.  The value of the <it>category utility</it> will, in the above formulation, be negative (???).</p>

<ss1>
<st>
 Category Utility and Mutual Information </st>
<p>

It is mentioned in <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFGluckCorter1985%22])">
Gluck &amp; Corter (1985)</link> and <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCorterGluck1992%22])">
Corter &amp; Gluck (1992)</link> that the category utility is equivalent to the <link xlink:type="simple" xlink:href="../282/427282.xml">
mutual information</link>.  Here we provide a simple demonstration of the nature of this equivalence.  Let us assume a set of entities each having the same <math>n</math>  features, i.e.,  feature set <math>F = \{f_i\}, \ i=1 \ldots n</math>, with each feature variable having cardinality  <math>m</math>. That is, each feature has the capacity to adopt any of <math>m</math> distinct values (which need <it>not</it> be ordered; all variables can be nominal); for the special case <math>m=2</math> these features would be considered <it>binary</it>, but more generally, for any <math>m</math>, the features are simply <it>m-ary</it>.  For our purposes, without loss of generality, we can replace feature set <math>F</math> with a single aggregate variable <math>F_a</math> that has cardinality <math>m^n</math>, and adopts a unique value <math>v_i, \ i=1 \ldots m^n</math> corresponding to each feature combination in the <idea wordnetid="105833840" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<link xlink:type="simple" xlink:href="../795/5795.xml">
Cartesian product</link></concept>
</idea>
 <math>\otimes F</math>.  (Ordinality does <it>not</it> matter, because the mutual information is not sensitive to ordinality.)  In what follows, a term such as <math>p(F_a=v_i)</math> or simply <math>p(v_i)</math> refers to the <link xlink:type="simple" xlink:href="../934/22934.xml">
probability</link> with which <math>F_a</math> adopts the particular value <math>v_i</math>.  (Using the aggregate feature variable <math>F_a</math> replaces multiple summations, and simplifies the presentation to follow.) </p>
<p>

We assume also a single category  variable <math>C</math> which has cardinality <math>p</math>. This is equivalent to a classification system in which there are <math>p</math> non-intersecting categories.  In the special case of <math>p=2</math> we have the two-category case discussed above.  From the definition of <link xlink:type="simple" xlink:href="../282/427282.xml">
mutual information</link> for discrete variables, the mutual information <math>I(F_a;C)</math> between the aggregate feature variable <math>F_a</math> and the category variable <math>C</math> is given by:</p>

<p>

<indent level="1">

<math> 
I(F_a;C) = \sum_{v_i \in F_a} \sum_{c_j \in C} p(v_i,c_j) \log \frac{p(v_i,c_j)}{p(v_i)\,p(c_j)}
</math>
</indent>
</p>
<p>

where <math>p(v_i)</math> is the <link xlink:type="simple" xlink:href="../877/472877.xml">
prior probability</link> of feature variable <math>F_a</math> adopting value <math>v_i</math>, <math>p(c_j)</math> is the <link xlink:type="simple" xlink:href="../791/5791.xml">
marginal probability</link> of category variable <math>C</math> adopting value <math>c_j</math>, and <math>p(v_i,c_j)</math> is the <link xlink:type="simple" xlink:href="../637/879637.xml">
joint probability</link> of variables <math>F_a</math> and <math>C</math> simultaneously adopting those respective values.  In terms of the conditional probabilities this can be re-written (or defined) as </p>

<p>

<indent level="1">

<math> 
\begin{align}
I(F_a;C) &amp; = \sum_{v_i \in F_a} \sum_{c_j \in C} p(v_i,c_j) \log \frac{p(v_i|c_j)}{p(v_i)} \\
   &amp; = \sum_{v_i \in F_a} \sum_{c_j \in C} p(v_i|c_j)p(c_j) \left [\log p(v_i|c_j)- \log p(v_i) \right ] \\
   &amp; = \sum_{v_i \in F_a} \sum_{c_j \in C} p(v_i|c_j)p(c_j) \log p(v_i|c_j)- \sum_{v_i \in F_a} \sum_{c_j \in C} p(v_i|c_j)p(c_j) \log p(v_i) \\
   &amp; = \sum_{v_i \in F_a} \sum_{c_j \in C} p(v_i|c_j)p(c_j) \log p(v_i|c_j)- \sum_{v_i \in F_a} \sum_{c_j \in C} p(v_i,c_j) \log p(v_i) \\
   &amp; = \sum_{v_i \in F_a} \sum_{c_j \in C} p(v_i|c_j)p(c_j) \log p(v_i|c_j)- \sum_{v_i \in F_a} \log p(v_i) \sum_{c_j \in C} p(v_i,c_j)  \\
   &amp; = {\color{Blue}\sum_{v_i \in F_a} \sum_{c_j \in C} p(v_i|c_j)p(c_j) \log p(v_i|c_j)- \sum_{v_i \in F_a} p(v_i) \log p(v_i)}   \\
\end{align}
</math>
</indent>
</p>
<p>

If we will rewrite the original <link xlink:type="simple" xlink:href="../665/8964665.xml#xpointer(//*[./st=%22Definition+of+the+Category+Utility%22])">
definition of the category utility</link> from above, with <math>C = \{c,\bar{c}\}</math>, we have</p>

<p>

<indent level="1">

<math>
CU(C,F) = \sum_{f_i \in F} \sum_{c_j \in C}   p(f_i|c_j) p(c_j) \log p(f_i|c_j) - \sum_{f_i \in F} p(f_i) \log p(f_i)
</math>
</indent>
</p>
<p>

This equation clearly has the same <b>form</b> as the (blue) equation expressing the mutual information between the feature set and the category variable; the difference is that the sum <math>\textstyle \sum_{f_i \in F}</math> in the <it>category utility</it> equation  runs over independent binary variables <math>F = \{f_i\}, \ i=1 \ldots n</math>, whereas the sum <math>\textstyle \sum_{v_i \in F_a}</math> in the mutual information runs over <it>values</it> of the single <math>m^n</math>-ary variable <math>F_a</math>.  The two measures are actually equivalent then <it>only</it> when the features <math>\{f_i\}</math>, are <it>independent</it> (and assuming that terms in the sum corresponding to <math>p(\bar{f_i})</math> are also added).</p>

</ss1>
</sec>
<sec>
<st>
 Insensitivity of category utility to ordinality </st>
<p>

Like the <link xlink:type="simple" xlink:href="../282/427282.xml">
mutual information</link>, the <it>category utility</it> is not sensitive to any <it>ordering</it> in the feature or category variable values.  That is, as far as the <it>category utility</it> is concerned, the category set {small,medium,large,jumbo} is not qualitatively different than the category set {desk,fish,tree,mop} since the formulation of the <it>category utility</it> does not account for any ordering of the class variable.  Similarly, a feature variable adopting values {1,2,3,4,5} is not qualitatively different from a feature variable adopting values {fred,joe,bob,sue,elaine}.  As far as the <it>category utility</it> or  <it>mutual information</it> are concerned, <it>all</it> category and feature variables are <it>nominal variables.</it>  For this reason, <it>category utility</it> does not reflect any <it><technique wordnetid="105665146" confidence="0.8">
<school wordnetid="108276720" confidence="0.8">
<know-how wordnetid="105616786" confidence="0.8">
<method wordnetid="105660268" confidence="0.8">
<educational_institution wordnetid="108276342" confidence="0.8">
<institution wordnetid="108053576" confidence="0.8">
<link xlink:type="simple" xlink:href="../402/70402.xml">
gestalt</link></institution>
</educational_institution>
</method>
</know-how>
</school>
</technique>
</it> aspects of "category goodness" that might be based on such ordering effects.  One possible adjustment for this insensitivity to ordinality is given by the weighting scheme described in the article for <link xlink:type="simple" xlink:href="../282/427282.xml">
mutual information</link>.</p>

</sec>
<sec>
<st>
 Category "goodness": Models and Philosophy</st>
<p>

This section provides some background on the origins of, and need for, formal measures of "category goodness" such as the <it>category utility</it>, and some of the history that lead to the development of this particular metric.
</p>
<ss1>
<st>
What makes a good category?</st>
<p>

At least since the time of <person wordnetid="100007846" confidence="0.9508927676800064">
<philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../308/308.xml">
Aristotle</link></philosopher>
</person>
 there has been a tremendous fascination in philosophy with the nature of <link xlink:type="simple" xlink:href="../978/6978.xml">
concepts</link> and <link xlink:type="simple" xlink:href="../120/32120.xml">
universals</link>.  What kind of <it>entity</it> is a concept such as "horse"?  Such abstractions do not designate any particular individual in the world, and yet we can scarcely imagine being able to comprehend the world without their use.  Does the concept "horse" therefore have an independent existence outside of the mind?  If it does, then what is the locus of this independent existence?  The question of locus was an important  issue on which the classical schools of <person wordnetid="100007846" confidence="0.9508927676800064">
<philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../954/22954.xml">
Plato</link></philosopher>
</person>
 and <person wordnetid="100007846" confidence="0.9508927676800064">
<philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../308/308.xml">
Aristotle</link></philosopher>
</person>
 famously differed.  However, they remained  in agreement that universals  <it>did</it> indeed have a mind-independent existence. There was, therefore, always a <it>fact to the matter</it> about which concepts and universals exist in the world.</p>
<p>

In the late <link xlink:type="simple" xlink:href="../836/18836.xml">
Middle Ages</link> (perhaps beginning with <philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../617/33617.xml">
Occam</link></philosopher>
, although <link xlink:type="simple" xlink:href="../868/37868.xml">
Porphyry</link> also makes a much earlier remark indicating a certain discomfort with the status quo), however, the certainty that existed on this issue  began to erode, and it became acceptable among the so-called <link xlink:type="simple" xlink:href="../176/21176.xml">
nominalists</link> and <link xlink:type="simple" xlink:href="../174/10174.xml">
empiricists</link> to consider concepts and universals as strictly mental entities or conventions of language.  On this view of conceptsâ€”that they are purely representational constructsâ€”a new question then comes to the fore: <it>Why do we possess one set of concepts rather than another?</it>  What makes one set of concepts "good" and another set of concepts "bad"?  This is a question that modern philosophers, and subsequently <link xlink:type="simple" xlink:href="../488/233488.xml">
machine learning</link> theorists and cognitive scientists, have struggled with for many decades.</p>

</ss1>
<ss1>
<st>
What purpose do concepts serve?</st>
<p>

One approach to answering such questions is to investigate the "role" or "purpose" of concepts in cognition.  Thus, we ask: <it>What are concepts good for in the first place?</it>  The answer provided by <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMill1843/1936%22])">
Mill (1843/1936</link>, p.&nbsp;425) and many others is that classification (conception) is a precursor to <it><link xlink:type="simple" xlink:href="../736/393736.xml">
induction</link></it>:   By imposing a particular categorization on the universe, an organism gains the ability to deal with physically non-identical objects or situations in an identical fashion, thereby gaining substantial predictive leverage  (<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFSmithMedin1981%22])">
Smith &amp; Medin 1981</link>;<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFHarnad2005%22])">
Harnad 2005</link>). As <link xlink:type="simple" xlink:href="../626/15626.xml">
J.S. Mill</link> puts it  <cite class="inline">(<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMill1843/1936%22])">
Mill 1843/1936</link>, pp.&nbsp;466â€“468)</cite>,</p>
<p>

The general problem of classification... [is] to provide that things shall be thought of in such groups, and those groups in such an order, as will best conduce to the remembrance and to the ascertainment of their laws... [and] one of the uses of such a classification that by drawing attention to the properties on which it is founded, and which, if the classification be good, are marks of many others, it facilitates the discovery of those others.</p>


<p>

From this base, <link xlink:type="simple" xlink:href="../626/15626.xml">
Mill</link> reaches the following conclusion, which foreshadows much subsequent thinking about category goodness, including the notion of <it>category utility</it>:</p>
<p>

The ends of scientific classification are best answered when the objects are formed into groups respecting which a greater number of general propositions can be made, and those propositions more important, than could be made respecting any other groups into which the same things could be distributed. The properties, therefore, according to which objects are classified should, if possible, be those which are causes of many other properties; or, at any rate, which are sure marks of them.</p>


<p>

One may compare this to the "category utility hypothesis" proposed by <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCorterGluck1992%22])">
Corter &amp; Gluck (1992)</link>: "A category is useful to the extent that it can be expected to improve the ability of a person to accurately predict the features of instances of that category."   Mill here seems to be suggesting that the best category structure is one in which object features (properties) are maximally informative about the object's class, and, simultaneously, the object class is maximally informative about the object's features.  In other words, a useful classification scheme is one in which we can use category knowledge to accurately infer object properties, and we can use property knowledge to accurately infer object classes.  One may also compare this idea to <person wordnetid="100007846" confidence="0.9508927676800064">
<philosopher wordnetid="110423589" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../308/308.xml">
Aristotle</link></philosopher>
</person>
's criterion of <it>counter-predication</it> for definitional predicates, as well as to the notion of concepts described in <link xlink:type="simple" xlink:href="../845/313845.xml">
formal concept analysis</link>.</p>

</ss1>
<ss1>
<st>
Attempts at formalization</st>
<p>

A variety of different measures have been suggested with an aim of formally capturing this notion of "category goodness,"  the best known of which is probably the "<link xlink:type="simple" xlink:href="../656/3002656.xml">
cue validity</link>". Cue validity of a feature <math>f_i\ </math> with respect to category <math>c_j\ </math> is defined as the conditional probability of the category given the feature (<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFReed1972%22])">
Reed 1972</link>;<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRoschMervis1975%22])">
Rosch &amp; Mervis 1975</link>;<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFRosch1978%22])">
Rosch 1978</link>), <math>p(c_j|f_i)\ </math>, or as the deviation of the conditional probability from the category base rate (<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFEdgell1993%22])">
Edgell 1993</link>;<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFKruschkeJohansen1999%22])">
Kruschke &amp; Johansen 1999</link>), <math>p(c_j|f_i)-p(c_j)\ </math>. Clearly, these measures quantify only inference from feature to category (i.e., <it>cue validity</it>), but not from category to feature, i.e., the <it>category validity</it> <math>p(f_i|c_j)\ </math>.  Also, while the cue validity was originally intended to account for the demonstrable appearance of <it><link xlink:type="simple" xlink:href="../290/12913290.xml">
basic categories</link></it> in human cognitionâ€”categories of a particular level of generality that are evidently preferred by human learnersâ€”a number of major flaws in the cue validity quickly emerged in this regard (<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFJones1983%22])">
Jones 1983</link>;<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFMurphy1982%22])">
Murphy 1982</link>;<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCorterGluck1992%22])">
Corter &amp; Gluck 1992</link>, and others).  </p>
<p>

One attempt to address both problems by simultaneously maximizing both feature validity and category validity was made by <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFJones1983%22])">
Jones (1983)</link> in defining the "collocation index" as the product <math>p(c_j|f_i) p(f_i|c_j)\ </math>, but this construction was  fairly <it>ad hoc</it> (see <link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCorterGluck1992%22])">
Corter &amp; Gluck 1992</link>).  The <it>category utility</it> was introduced as a more sophisticated  refinement of the cue validity which attempts to more rigorously quantify the full inferential power of a class structure.  As shown above, on a certain view the category utility  is equivalent  to the <link xlink:type="simple" xlink:href="../282/427282.xml">
mutual information</link> between the feature variable and the category variable. It has been suggested that categories having the greatest overall  <it>category utility</it> are those which are not only those which are "best" in a normative sense, but are also those which human learners prefer to use, e.g., "basic" categories  <cite class="inline">(<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFCorterGluck1992%22])">
Corter &amp; Gluck 1992</link>)</cite>.  Other related measures of category goodness are "cohesion" (<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFHansonBauer1989%22])">
Hanson &amp; Bauer 1989</link>;<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFGennariLangleyFisher1989%22])">
Gennari, Langley &amp; Fisher 1989</link>) and "salience"  <cite class="inline">(<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFGennari1989%22])">
Gennari 1989</link>)</cite>.</p>

</ss1>
</sec>
<sec>
<st>
 Applications </st>
<p>

<list>
<entry level="1" type="bullet">

 Category utilility is used as the category evaluation measure in the popular <link xlink:type="simple" xlink:href="../740/6979740.xml">
conceptual clustering</link> algorithm called COBWEB  <cite class="inline">(<link xlink:type="simple" xlink:href="#xpointer(//cite[@id=%22CITEREFFisher1987%22])">
Fisher 1987</link>)</cite>.</entry>
</list>
</p>

</sec>
<sec>
<st>
 References </st>

<p>

<list>
<entry level="1" type="bullet">

 <cite id="CITEREFCorterGluck1992">Corter, James E.&#32;&amp;&#32;Mark A. Gluck&#32;(1992),&#32;"Explaining basic categories: Feature predictability and information",&#32;<it>Psychological Bulletin</it>&#32;<b>111</b>&amp;#x00a0;(2):  291â€“303</cite></entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <cite id="CITEREFEdgell1993">Edgell, Stephen E.&#32;(1993),&#32;"Using configural and dimensional information", written at <village wordnetid="108672738" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../984/124984.xml">
Hillsdale, New Jersey</link></village>
, in&#32;N. John Castellan,&#32;<it>Individual and Group Decision Making: Current Issues</it>, Lawrence Erlbaum,  43â€“64</cite></entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

  <cite id="CITEREFFisher1987">Fisher, Douglas H.&#32;(1987),&#32;"<weblink xlink:type="simple" xlink:href="http://www.springerlink.com/content/qj16212n7537n6p3/">
Knowledge acquisition via incremental conceptual clustering</weblink>",&#32;<it>Machine Learning</it>&#32;<b>2</b>&amp;#x00a0;(2):  139â€“172, </cite></entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <cite id="CITEREFGennari1989">Gennari, John H.&#32;(1989),&#32;"Focused concept formation", written at <link xlink:type="simple" xlink:href="../973/14973.xml">
Ithaca, NY</link>, in&#32;Alberto Maria Segre,&#32;<it>Proceedings of the Sixth International Workshop on Machine Learning</it>, Morgan Kaufmann,  379â€“382</cite></entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <cite id="CITEREFGennariLangleyFisher1989">Gennari, John H.; Pat Langley&#32;&amp; Doug Fisher&#32;(1989),&#32;"Models of incremental concept formation",&#32;<it>Artificial Intelligence</it>&#32;<b>40</b>&amp;#x00a0;(1-3):  11â€“61</cite></entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

  <cite id="CITEREFGluckCorter1985">Gluck, Mark A.&#32;&amp;&#32;James E. Corter&#32;(1985),&#32;"Information, uncertainty, and the utility of categories",&#32;<it>Program of the Seventh Annual Conference of the Cognitive Science Society</it>,  283â€“287</cite></entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

  <cite id="CITEREFHansonBauer1989">Hanson, Stephen JosÃ©&#32;&amp;&#32;Malcolm Bauer&#32;(1989),&#32;"<weblink xlink:type="simple" xlink:href="http://www.springerlink.com/content/j383105014543328/">
Conceptual clustering, categorization, and polymorphy</weblink>",&#32;<it>Machine Learning</it>&#32;<b>3</b>&amp;#x00a0;(4):  343â€“372, </cite></entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <cite id="CITEREFHarnad2005">Harnad, Stevan&#32;(2005),&#32;<weblink xlink:type="simple" xlink:href="http://eprints.ecs.soton.ac.uk/11725/">
"To cognize is to categorize: Cognition is categorization"</weblink>, written at Amsterdam, in&#32;Henri Cohen &amp; Claire Lefebvre,&#32;<it>Handbook of Categorization in Cognitive Science</it>, Elsevier,  19â€“43, </cite></entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <cite id="CITEREFJones1983">Jones, Gregory V.&#32;(1983),&#32;"Identifying basic categories",&#32;<it>Psychological Bulletin</it>&#32;<b>94</b>&amp;#x00a0;(3):  423â€“428</cite></entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <cite id="CITEREFKruschkeJohansen1999">Kruschke, John K.&#32;&amp;&#32;Mark K. Johansen&#32;(1999),&#32;"A model of probabilistic category learning",&#32;<it>Journal of Experimental Psychology: Learning, Memory, and Cognition</it>&#32;<b>25</b>&amp;#x00a0;(5):  1083â€“1119</cite></entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <cite id="CITEREFMill1843/1936"><link>
Mill, John Stuart</link>&#32;(1843/1936), written at <village wordnetid="108672738" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../867/17867.xml">
London</link></village>
,&#32;<it>A System of Logic, Ratiocinative and Inductive: Being a Connected View of the Principles of Evidence and the Methods of Scientific Investigation</it>, Longmans, Green and Co.</cite>.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <cite id="CITEREFMurphy1982">Murphy, Gregory L.&#32;(1982),&#32;"Cue validity and levels of categorization",&#32;<it>Psychological Bulletin</it>&#32;<b>91</b>&amp;#x00a0;(1):  174â€“177</cite></entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <cite id="CITEREFReed1972">Reed, Stephen K.&#32;(1972),&#32;"Pattern recognition and categorization",&#32;<it>Cognitive Psychology</it>&#32;<b>3</b>&amp;#x00a0;(3):  382â€“407</cite></entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <cite id="CITEREFRosch1978">Rosch, Eleanor&#32;(1978),&#32;"Principles of categorization", written at <village wordnetid="108672738" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../984/124984.xml">
Hillsdale, New Jersey</link></village>
, in&#32;Eleanor Rosch &amp; Barbara B. Lloyd,&#32;<it>Cognition and Categorization</it>, Lawrence Erlbaum,  27â€“48</cite></entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <cite id="CITEREFRoschMervis1975">Rosch, Eleanor&#32;&amp;&#32;Carolyn B. Mervis&#32;(1975),&#32;"Family Resemblances: Studies in the Internal Structure of Categories",&#32;<it>Cognitive Psychology</it>&#32;<b>7</b>&amp;#x00a0;(4):  573â€“605</cite></entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <cite id="CITEREFSmithMedin1981">Smith, Edward E.&#32;&amp;&#32;Douglas L. Medin&#32;(1981), written at <link xlink:type="simple" xlink:href="../685/5685.xml">
Cambridge, MA</link>,&#32;<it>Categories and Concepts</it>, Harvard University Press</cite></entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 <cite id="CITEREFWittenFrank2005">Witten, Ian H.&#32;&amp;&#32;Eibe Frank&#32;(2005), written at <village wordnetid="108672738" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../844/844.xml">
Amsterdam</link></village>
,&#32;<it><weblink xlink:type="simple" xlink:href="http://www.cs.waikato.ac.nz/~ml/weka/book.html">
Data Mining: Practical Machine Learning Tools and Techniques</weblink></it>, Morgan Kaufmann, </cite></entry>
</list>
</p>


</sec>
<sec>
<st>
 See also </st>
<p>

<link xlink:type="simple" xlink:href="../978/6978.xml">
Concepts</link>, <link xlink:type="simple" xlink:href="../451/6968451.xml">
Concept learning</link>, <link xlink:type="simple" xlink:href="../ury/30th_century.xml">
Abstraction</link>, <link xlink:type="simple" xlink:href="../120/32120.xml">
Universals</link>, <link xlink:type="simple" xlink:href="../740/6979740.xml">
Conceptual Clustering</link>, <link xlink:type="simple" xlink:href="../497/233497.xml">
Unsupervised learning</link></p>



</sec>
</bdy>
</article>
