<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 17:51:40[mciao0826] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<entity  confidence="0.9511911446218017" wordnetid="100001740">
<header>
<title>Receiver operating characteristic</title>
<id>922505</id>
<revision>
<id>242515534</id>
<timestamp>2008-10-02T15:39:43Z</timestamp>
<contributor>
<username>Calimo</username>
<id>5527108</id>
</contributor>
</revision>
<categories>
<category>Statistical classification</category>
<category>Data mining</category>
<category>Socioeconomics</category>
<category>Detection theory</category>
<category>Biostatistics</category>
</categories>
</header>
<bdy>

<image location="right" width="150px" src="roc.png" type="thumb">
<caption>

ROC curve of three epitope predictors.
</caption>
</image>

In <link xlink:type="simple" xlink:href="../527/1156527.xml">
signal detection theory</link>, a <b>receiver operating characteristic</b> (<b>ROC</b>), or simply <b>ROC curve</b>, is a <link xlink:type="simple" xlink:href="../352/87352.xml">
graph</link>ical plot of the <link xlink:type="simple" xlink:href="../330/5599330.xml">
sensitivity</link> vs. (1 - <link xlink:type="simple" xlink:href="../330/5599330.xml">
 specificity</link>) for a <link xlink:type="simple" xlink:href="../393/205393.xml">
binary classifier</link> system as its discrimination threshold is varied.  The ROC can also be represented equivalently by plotting the fraction of <link xlink:type="simple" xlink:href="../877/5657877.xml">
true positive</link>s (TPR = true positive rate) vs. the fraction of <link>
false positive</link>s (FPR = false positive rate). Also known as a Relative Operating Characteristic curve, because it is a comparison of two operating characteristics (TPR &amp; FPR) as the criterion changes.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%221%22])">1</ref> <p>

ROC analysis provides tools to select possibly optimal models and to discard suboptimal ones independently from (and prior to specifying) the cost context or the class distribution. ROC analysis is related in a direct and natural way to cost/benefit analysis of diagnostic <link xlink:type="simple" xlink:href="../752/265752.xml">
decision making</link>. Widely used in <link xlink:type="simple" xlink:href="../957/18957.xml">
medicine</link>, <link xlink:type="simple" xlink:href="../623/152623.xml">
radiology</link>, <link xlink:type="simple" xlink:href="../921/22921.xml">
psychology</link> and other areas for many decades, it has been introduced relatively recently in other areas like <link xlink:type="simple" xlink:href="../488/233488.xml">
machine learning</link> and <link xlink:type="simple" xlink:href="../253/42253.xml">
data mining</link>.</p>

<sec>
<st>
Basic concept</st>
<p>

<table style="font-size:98%; margin-left:0.5em; padding:0.25em; background:#f1f5fc;" width="30%" align="right" class="wikitable">
<caption>
Terminology and derivationsfrom a confusion matrix</caption>
<row valign="top">
<col>
<list>
<entry level="1" type="definition">

 true positive (TP)</entry>
<entry level="1" type="indent">

eqv. with hit</entry>
<entry level="1" type="definition">

 true negative (TN)</entry>
<entry level="1" type="indent">

eqv. with correct rejection</entry>
<entry level="1" type="definition">

 false positive (FP)</entry>
<entry level="1" type="indent">

eqv. with <link xlink:type="simple" xlink:href="../895/1860895.xml">
false alarm</link>, <link>
Type I error</link></entry>
<entry level="1" type="definition">

 false negative (FN)</entry>
<entry level="1" type="indent">

eqv. with miss, <link>
Type II error</link></entry>
<entry level="1" type="definition">

 true positive rate (TPR)</entry>
<entry level="1" type="indent">

eqv. with <link xlink:type="simple" xlink:href="../464/2667464.xml">
hit rate</link>, <link>
recall</link>, <link xlink:type="simple" xlink:href="../330/5599330.xml">
sensitivity</link></entry>
<entry level="1" type="indent">

<math>TPR = TP / P = TP / (TP+FN)</math></entry>
<entry level="1" type="definition">

 false positive rate (FPR)</entry>
<entry level="1" type="indent">

eqv. with false alarm rate, <link>
fall-out</link></entry>
<entry level="1" type="indent">

<math>FPR = FP / N = FP / (FP + TN)</math></entry>
<entry level="1" type="definition">

 <link xlink:type="simple" xlink:href="../932/41932.xml">
accuracy</link> (ACC)</entry>
<entry level="1" type="indent">

<math>ACC = (TP + TN) / (P + N)</math></entry>
<entry level="1" type="definition">

 <link xlink:type="simple" xlink:href="../330/5599330.xml">
specificity</link> (SPC)</entry>
<entry level="1" type="indent">

<math>SPC = TN / (FP + TN) = 1 - FPR </math></entry>
<entry level="1" type="definition">

 <link xlink:type="simple" xlink:href="../952/1556952.xml">
positive predictive value</link> (PPV)</entry>
<entry level="1" type="indent">

eqv. with <link>
precision</link></entry>
<entry level="1" type="indent">

<math>PPV = TP / (TP + FP)</math></entry>
<entry level="1" type="definition">

 <link xlink:type="simple" xlink:href="../957/1556957.xml">
negative predictive value</link> (NPV)</entry>
<entry level="1" type="indent">

<math>NPV = TN / (TN + FN)</math></entry>
<entry level="1" type="definition">

 <link xlink:type="simple" xlink:href="../271/4574271.xml">
false discovery rate</link> (FDR)</entry>
<entry level="1" type="indent">

<math>FDR = FP / (FP + TP)</math></entry>
<entry level="1" type="definition">

 <link xlink:type="simple" xlink:href="../500/12306500.xml">
Matthews Correlation Coefficient</link>(MCC)</entry>
<entry level="1" type="definition">

<math>\mbox{MCC} = (\mbox{TP}\; \mbox{TN} - \mbox{FP}\; \mbox{FN})/ \sqrt{P N P' N'}</math></entry>
</list>

<it>Source: Fawcett (2004).''</it></col>
</row>
</table>
</p>
<p>

<indent level="1">

<it>See also: <link xlink:type="simple" xlink:href="../877/5657877.xml">
Type I and type II errors</link></it>
</indent>
A classification model (<link xlink:type="simple" xlink:href="../224/1579224.xml">
classifier</link> or <link xlink:type="simple" xlink:href="../525/18507525.xml">
diagnosis</link>) is a <link xlink:type="simple" xlink:href="../931/516931.xml">
mapping</link> of instances into a certain class/group. The classifier or diagnosis result can be in a <link xlink:type="simple" xlink:href="../491/19725491.xml">
real value</link> (continuous output) in which the classifier boundary between classes must be determined by a threshold value, for instance to determine whether a person has <link xlink:type="simple" xlink:href="../432/77432.xml">
hypertension</link> based on <link xlink:type="simple" xlink:href="../558/56558.xml">
blood pressure</link> measure, or it can be in a <idea wordnetid="105833840" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<link xlink:type="simple" xlink:href="../026/6026.xml">
discrete</link></concept>
</idea>
 class label indicating one of the classes. </p>
<p>

Let us consider a two-class prediction problem (<link xlink:type="simple" xlink:href="../393/205393.xml">
binary classification</link>), in which the outcomes are labeled either as positive (<it>p</it>) or negative (<it>n</it>) class. There are four possible outcomes from a binary classifier. If the outcome from a prediction is <it>p</it> and the actual value is also <it>p</it>, then it is called a <it>true positive</it> (TP); however if the actual value is <it>n</it> then it is said a <it>false positive</it> (FP). Conversely, a <it>true negative</it> has occurred when both the prediction outcome and the actual value are <it>n</it>, and <it>false negative</it> is when the prediction outcome is <it>n</it> while the actual value is <it>p</it>. </p>
<p>

To get an appropriate example in a real-world problem, consider a diagnostic test that seeks to determine whether a person has a certain disease. A false positive in this case occurs when the person tests positive, but actually does not have the disease. A false negative, on the other hand, occurs when the person tests negative, suggesting they are healthy, when they actually do have the disease.</p>
<p>

Let us define an experiment from P positive instances and N negative instances. The four outcomes can be formulated in a 2&amp;times;2 <it><link xlink:type="simple" xlink:href="../515/935515.xml">
contingency table</link></it>  or <it><link xlink:type="simple" xlink:href="../558/847558.xml">
confusion matrix</link></it>,  as follows:
<table align="center">
<row>
<header colspan="2">
&nbsp;</header>
<header colspan="2" align="center">
actual value</header>
</row>
<row>
<header colspan="2">
&nbsp;</header>
<header>
<it>p''</it></header>
<header>
<it>n''</it></header>
<header style="padding-left:1em;">
total</header>
</row>
<row>
<header rowspan="2" valign="middle">
predictionoutcome</header>
<header style="padding-right:1em;" valign="middle">
<it>p</it>'</header>
<col style="border:thin solid; padding:1em;">
TruePositive</col>
<col style="border:thin solid; padding:1em;">
FalsePositive</col>
<col style="padding-left:1em;">
P'</col>
</row>
<row>
<header style="padding-right:1em;" valign="middle">
<it>n</it>'</header>
<col style="border:thin solid; padding:1em;">
FalseNegative</col>
<col style="border:thin solid; padding:1em;">
TrueNegative</col>
<col style="padding-left:1em;">
N'</col>
</row>
<row>
<header colspan="2" style="padding-right:1em;" align="right">
total</header>
<col align="center">
P</col>
<col align="center">
N</col>
</row>
</table>
</p>

</sec>
<sec>
<st>
 ROC space </st>
<p>

<image location="right" width="250px" src="ROC_space.png" type="thumb">
<caption>

The ROC space and plots of the four prediction examples.
</caption>
</image>

The contingency table can derive several evaluation <link xlink:type="simple" xlink:href="../467/1561467.xml">
metric</link>s (see infobox). To draw a ROC curve, only the true positive rate (TPR) and false positive rate (FPR) are needed. TPR determines a classifier or a diagnostic test performance on classifying positive instances correctly among all positive samples available during the test. FPR, on the other hand, defines how many incorrect positive results occur among all negative samples available during the test.</p>
<p>

A ROC space is defined by FPR and TPR as <it>x</it> and <it>y</it> axes respectively, which depicts relative trade-offs between true positive (benefits) and false positive (costs). Since TPR is equivalent with <link xlink:type="simple" xlink:href="../330/5599330.xml">
sensitivity</link> and FPR is equal to 1 - <link xlink:type="simple" xlink:href="../330/5599330.xml">
specificity</link>, the ROC graph is sometimes called the sensitivity vs (1 - specificity) plot. Each prediction result or one instance of a confusion matrix represents one point in the ROC space.</p>
<p>

The best possible prediction method would yield a point in the upper left corner or coordinate (0,1) of the ROC space, representing 100% <link xlink:type="simple" xlink:href="../330/5599330.xml">
sensitivity</link> (all true positives are found) and 100% <link xlink:type="simple" xlink:href="../330/5599330.xml">
 specificity</link> (no false positives are found). The (0,1) point is also called a <it>perfect classification</it>. A completely <link xlink:type="simple" xlink:href="../523/19196523.xml">
random guess</link> would give a point along a diagonal line (the so-called <it>line of no-discrimination</it>) from the left bottom to the top right corners. An intuitive example of random guessing is a decision by <link xlink:type="simple" xlink:href="../410/494410.xml">
flipping coins (head or tail)</link>. </p>
<p>

The diagonal line divides the ROC space in areas of good or bad classification/diagnostic. Points above the diagonal line indicate good classification results, while points below the line indicate wrong results (although the prediction method can be simply inverted to get points above the line).
Let us look into four prediction results from 100 positive and 100 negative instances:
<table style="font-size:95%; margin-left:1em;">
<header>
A</header>
<header>
B</header>
<header>
C</header>
<header>
C'</header>
<row>
<col>
<table style="text-align:center;">
<row>
<col style=" border:thin solid; padding:1em;">
TP=63</col>
<col style=" border:thin solid; padding:1em;">
FP=28</col>
<col>
91</col>
</row>
<row>
<col style=" border:thin solid; padding:1em;">
FN=37</col>
<col style=" border:thin solid; padding:1em;">
TN=72</col>
<col>
109</col>
</row>
<row>
<col>
100</col>
<col>
100</col>
<col>
200</col>
</row>
</table>
</col>
<col style="padding-left:1em;">
<table style="text-align:center;">
<row>
<col style=" border:thin solid; padding:1em;">
TP=77</col>
<col style=" border:thin solid; padding:1em;">
FP=77</col>
<col>
154</col>
</row>
<row>
<col style=" border:thin solid; padding:1em;">
FN=23</col>
<col style=" border:thin solid; padding:1em;">
TN=23</col>
<col>
46</col>
</row>
<row>
<col>
100</col>
<col>
100</col>
<col>
200</col>
</row>
</table>
</col>
<col style="padding-left:1em;">
<table style="text-align:center;">
<row>
<col style=" border:thin solid; padding:1em;">
TP=24</col>
<col style=" border:thin solid; padding:1em;">
FP=88</col>
<col>
112</col>
</row>
<row>
<col style=" border:thin solid; padding:1em;">
FN=76</col>
<col style=" border:thin solid; padding:1em;">
TN=12</col>
<col>
88</col>
</row>
<row>
<col>
100</col>
<col>
100</col>
<col>
200</col>
</row>
</table>
</col>
<col style="padding-left:1em;">
<table style="text-align:center;">
<row>
<col style=" border:thin solid; padding:1em;">
TP=88</col>
<col style=" border:thin solid; padding:1em;">
FP=24</col>
<col>
112</col>
</row>
<row>
<col style=" border:thin solid; padding:1em;">
FN=12</col>
<col style=" border:thin solid; padding:1em;">
TN=76</col>
<col>
88</col>
</row>
<row>
<col>
100</col>
<col>
100</col>
<col>
200</col>
</row>
</table>
</col>
</row>
<row>
<col style="padding-left:1em;">
TPR = 0.63</col>
<col style="padding-left:2em;">
TPR = 0.77</col>
<col style="padding-left:2em;">
TPR = 0.24</col>
<col style="padding-left:2em;">
TPR = 0.88</col>
</row>
<row>
<col style="padding-left:1em;">
FPR = 0.28</col>
<col style="padding-left:2em;">
FPR = 0.77</col>
<col style="padding-left:2em;">
FPR = 0.88</col>
<col style="padding-left:2em;">
FPR = 0.24</col>
</row>
<row>
<col style="padding-left:1em;">
ACC = 0.68</col>
<col style="padding-left:2em;">
ACC = 0.50</col>
<col style="padding-left:2em;">
ACC = 0.18</col>
<col style="padding-left:2em;">
ACC = 0.82</col>
</row>
</table>
</p>
<p>

Plots of the four results above in the ROC space are given in the figure. The result <b>A</b> clearly shows the best among <b>B</b> and <b>C</b>. The result <b>B</b> lies on the random guess line (the diagonal line), and it can be seen in the table that the accuracy of <b>B</b> is 50%. However, when <b>C</b> is mirrored onto the diagonal line, as seen in <b>C</b>', the result is even better than <b>A</b>.  </p>
<p>

Since this mirrored <b>C</b> method or test simply reverses the predictions of whatever method or test produced the <b>C</b> contingency table, the <b>C</b> method has positive predictive power simply by reversing all of its decisions.  When the <b>C</b> method predicts <b>p</b> or <b>n</b>, the <b>C</b>' method would predict <b>n</b> or <b>p</b>, respectively.  In this manner, the C' test would perform the best.  While the closer a result from a contingency table is to the upper left corner the better it predicts, the distance from the random guess line in either direction is the best indicator of how much predictive power a method has, albeit, if it is below the line, all of its predictions including its more often wrong predictions must be reversed in order to utilize the method's power.</p>

</sec>
<sec>
<st>
 Curves in ROC space </st>
<p>

Discrete classifiers, such as <link xlink:type="simple" xlink:href="../602/232602.xml">
decision tree</link> or rule set, yield numerical values or binary label. When a set is given to such classifiers, the result is a single point in the ROC space. For other classifiers, such as <link xlink:type="simple" xlink:href="../339/87339.xml">
naive Bayesian</link> and <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../523/21523.xml">
neural network</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
, they produce <link xlink:type="simple" xlink:href="../934/22934.xml">
probability value</link>s representing the degree to which class the instance belongs to. For these methods, setting a threshold value will determine a point in the ROC space. For instance, if probability values below or equal to a threshold value of 0.8 are sent to the positive class, and other values are assigned to the negative class, then a confusion matrix can be calculated. Plotting the ROC point for each possible threshold value results in a curve.</p>

</sec>
<sec>
<st>
 Further interpretations </st>
<p>

<image location="left" width="300px" src="roc-general.png" type="thumb">
<caption>

How a ROC curve can be interpreted
</caption>
</image>

Sometimes, the ROC is used to generate a summary statistic. Three common versions are:
<list>
<entry level="1" type="bullet">

 the intercept of the ROC curve with the line at 90 degrees to the no-discrimination line</entry>
<entry level="1" type="bullet">

 the area between the ROC curve and the no-discrimination line</entry>
<entry level="1" type="bullet">

 the area under the ROC curve, or "AUC".</entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../822/5895822.xml">
d'</link> (pronounced "d-prime"), the distance between the mean of the distribution of activity in the system under noise-alone conditions and its distribution under signal plus noise conditions, divided by their <link xlink:type="simple" xlink:href="../590/27590.xml">
standard deviation</link>, under the assumption that both these distributions are <link xlink:type="simple" xlink:href="../462/21462.xml">
normal</link> with the same standard deviation. Under these assumptions, it can be proved that the shape of the ROC depends only on <link xlink:type="simple" xlink:href="../822/5895822.xml">
d'</link>.</entry>
</list>
</p>
<p>

The AUC is equal to the probability that a classifier will rank a randomly chosen positive instance higher than a randomly chosen negative one.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%222%22])">2</ref>It can be shown that the area under the ROC curve is equivalent to the <process wordnetid="105701363" confidence="0.8">
<inquiry wordnetid="105797597" confidence="0.8">
<thinking wordnetid="105770926" confidence="0.8">
<problem_solving wordnetid="105796750" confidence="0.8">
<experiment wordnetid="105798043" confidence="0.8">
<trial wordnetid="105799212" confidence="0.8">
<higher_cognitive_process wordnetid="105770664" confidence="0.8">
<link xlink:type="simple" xlink:href="../164/433164.xml">
Mann-Whitney U</link></higher_cognitive_process>
</trial>
</experiment>
</problem_solving>
</thinking>
</inquiry>
</process>
, which tests for the median difference between scores obtained in the two groups considered if the groups are of continuous data. It is also equivalent to the <process wordnetid="105701363" confidence="0.8">
<inquiry wordnetid="105797597" confidence="0.8">
<thinking wordnetid="105770926" confidence="0.8">
<problem_solving wordnetid="105796750" confidence="0.8">
<experiment wordnetid="105798043" confidence="0.8">
<trial wordnetid="105799212" confidence="0.8">
<higher_cognitive_process wordnetid="105770664" confidence="0.8">
<link xlink:type="simple" xlink:href="../987/1954987.xml">
Wilcoxon test of ranks</link></higher_cognitive_process>
</trial>
</experiment>
</problem_solving>
</thinking>
</inquiry>
</process>
. The AUC has been found to be related to the <link xlink:type="simple" xlink:href="../883/12883.xml">
Gini coefficient</link>(G) by the following formula<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%223%22])">3</ref> <math>G_1 + 1 = 2 x AUC</math>, where:</p>
<p>

<indent level="1">

<math>G_1 = 1 - \sum_{k=1}^{n} (X_{k} - X_{k-1}) (Y_{k} + Y_{k-1})</math> 
</indent>

In this way, it is possible to calculate the AUC by using an average of a number of trapezoidal approximations.</p>
<p>

However, any attempt to summarize the ROC curve into a single number loses information about the pattern of tradeoffs of the particular discriminator algorithm.</p>
<p>

The machine learning community most often uses the ROC AUC statistic. This measure can be interpreted as the probability that when we randomly pick one positive and one negative example, the classifier will assign a higher score to the positive example than to the negative.
In engineering, the area between the ROC curve and the no-discrimination line is often preferred, because of its useful mathematical properties as a <link>
non-parametric statistic</link>. This area is often simply known as the <b>discrimination</b>.  
In <link xlink:type="simple" xlink:href="../004/438004.xml">
psychophysics</link>, <link xlink:type="simple" xlink:href="../822/5895822.xml">
d'</link> is the most commonly used measure.</p>
<p>

The illustration at the top right of the page shows the use of ROC graphs for the discrimination between the quality of different <link xlink:type="simple" xlink:href="../045/495045.xml">
epitope</link> predicting algorithms. If you wish to discover at least 60% of the epitopes in a <link xlink:type="simple" xlink:href="../679/19167679.xml">
virus</link> protein, you can read out of the graph that about 1/3 of the output would be falsely marked as an epitope. The information that is not visible in this graph is that the person that uses the algorithms knows what threshold settings give a certain point in the ROC graph.</p>
<p>

Sometimes it can be more useful to look at a specific region of the ROC Curve rather than at the whole curve. It is possible to compute partial AUC.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%224%22])">4</ref> For example, one could focus on the region of the curve with low false positive rate, which is often of prime interest for population screening tests.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%225%22])">5</ref></p>

</sec>
<sec>
<st>
 History </st>
<p>

The ROC curve was first used during the <military_action wordnetid="100952963" confidence="0.8">
<group_action wordnetid="101080366" confidence="0.8">
<event wordnetid="100029378" confidence="0.8">
<conflict wordnetid="100958896" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<war wordnetid="100973077" confidence="0.8">
<link xlink:type="simple" xlink:href="../927/32927.xml">
World War II</link></war>
</psychological_feature>
</act>
</conflict>
</event>
</group_action>
</military_action>
 for the analysis of <link xlink:type="simple" xlink:href="../676/25676.xml">
radar signal</link>s before it was employed in <link xlink:type="simple" xlink:href="../527/1156527.xml">
signal detection theory</link>.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref> Following the <link xlink:type="simple" xlink:href="../098/60098.xml">
attack on Pearl Harbor</link> in 1941, the United States army began new research to increase the prediction of correctly detected Japanese aircraft from their radar signals.</p>
<p>

In the 1950s, ROC curves were employed in <link xlink:type="simple" xlink:href="../004/438004.xml">
psychophysics</link> to assess human (and occasionally non-human animal) detection of weak signals.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%226%22])">6</ref> In <link xlink:type="simple" xlink:href="../957/18957.xml">
medicine</link>, ROC analysis has been extensively used in the evaluation of <link xlink:type="simple" xlink:href="../086/337086.xml">
diagnostic test</link>s.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%227%22])">7</ref><ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%228%22])">8</ref> ROC curves are also used extensively in <link xlink:type="simple" xlink:href="../997/66997.xml">
epidemiology</link> and <link xlink:type="simple" xlink:href="../783/2245783.xml">
medical research</link> and are frequently mentioned in conjunction with <link xlink:type="simple" xlink:href="../013/10013.xml">
evidence-based medicine</link>. In <link xlink:type="simple" xlink:href="../623/152623.xml">
radiology</link>, ROC analysis is a common technique to evaluate new radiology techniques.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%229%22])">9</ref>. In the social sciences, ROC analysis is often called the ROC Accuracy Ratio, a common technique for judging the accuracy of default probability models.</p>
<p>

ROC curves also proved useful for the evaluation of <link xlink:type="simple" xlink:href="../488/233488.xml">
machine learning</link> techniques. The first application of ROC in machine learning was by Spackman who demonstrated the value of ROC curves in comparing and evaluating different classification <link xlink:type="simple" xlink:href="../775/775.xml">
algorithm</link>s.<ref xlink:type="simple" xlink:href="#xpointer(//reflist/entry[@id=%2210%22])">10</ref></p>

</sec>
<sec>
<st>
References</st>

<p>

<reflist>
<entry id="1">
Signal detection theory and ROC analysis in psychology and diagnostics : collected papers; Swets, 1996</entry>
<entry id="2">
Fawcett, T. (2006). An introduction to ROC analysis. Pattern Recognition Letters, 27, 861-874.</entry>
<entry id="3">
Hand, D.J., &amp; Till, R.J. (2001). A simple generalization of the area under the ROC curve to multiple class classification problems. Machine Learning, 45, 171-186.</entry>
<entry id="4">
 <cite style="font-style:normal">McClish, Donna Katzman&#32;(1989-08-01).&#32;"<weblink xlink:type="simple" xlink:href="http://mdm.sagepub.com/cgi/content/abstract/9/3/190">
Analyzing a Portion of the ROC Curve</weblink>". <it>Med Decis Making</it>&#32;<b>9</b>&#32;(3): 190-195. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1177%2F0272989X8900900307">
10.1177/0272989X8900900307</weblink>. Retrieved on <link>
2008-09-29</link>.</cite>&nbsp;</entry>
<entry id="5">
 <cite style="font-style:normal">Dodd, Lori E.; Margaret S. Pepe&#32;(2003).&#32;"<weblink xlink:type="simple" xlink:href="http://www.blackwell-synergy.com/doi/abs/10.1111/1541-0420.00071">
Partial AUC Estimation and Regression</weblink>". <it>Biometrics</it>&#32;<b>59</b>&#32;(3): 614-623. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1111%2F1541-0420.00071">
10.1111/1541-0420.00071</weblink>. Retrieved on <link>
2007-12-18</link>.</cite>&nbsp;</entry>
<entry id="6">
 <cite style="font-style:normal" class="book">D.M. Green and J.M. Swets&#32;(<link xlink:type="simple" xlink:href="../691/34691.xml">
1966</link>). Signal detection theory and psychophysics.&#32;New York:&#32;John Wiley and Sons Inc.. ISBN 0-471-32420-5.</cite>&nbsp;</entry>
<entry id="7">
 <cite style="font-style:normal">M.H. Zweig and G. Campbell&#32;(1993).&#32;"Receiver-operating characteristic (ROC) plots: a fundamental evaluation tool in clinical medicine". <it>Clinical chemistry</it>&#32;<b>39</b>&#32;(8): 561&ndash;577. PMID 8472349.</cite>&nbsp;</entry>
<entry id="8">
 <cite style="font-style:normal" class="book">M.S. Pepe&#32;(2003). The statistical evaluation of medical tests for classification and prediction.&#32;New York:&#32;Oxford.</cite>&nbsp;</entry>
<entry id="9">
 <cite style="font-style:normal">N.A. Obuchowski&#32;(2003).&#32;"Receiver operating characteristic curves and their use in radiology". <it>Radiology</it>&#32;<b>229</b>&#32;(1): 3&ndash;8. <document wordnetid="106470073" confidence="0.8">
<written_communication wordnetid="106349220" confidence="0.8">
<writing wordnetid="106362953" confidence="0.8">
<link xlink:type="simple" xlink:href="../994/422994.xml">
doi</link></writing>
</written_communication>
</document>
:<weblink xlink:type="simple" xlink:href="http://dx.doi.org/10.1148%2Fradiol.2291010898">
10.1148/radiol.2291010898</weblink>. PMID 14519861.</cite>&nbsp;</entry>
<entry id="10">
 <cite style="font-style:normal">Spackman, K. A.&#32;(1989). "Signal detection theory: Valuable tools for evaluating inductive learning".&#32;<it>Proceedings of the Sixth International Workshop on Machine Learning</it>: 160&ndash;163, San Mateo, CA:&#32;Morgan Kaufman.</cite>&nbsp;</entry>
</reflist>
</p>

</sec>
<sec>
<st>
See also</st>
<p>

<list>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../232/7252232.xml">
Constant false alarm rate</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../527/1156527.xml">
Detection theory</link></entry>
<entry level="1" type="bullet">

 <link xlink:type="simple" xlink:href="../895/1860895.xml">
False alarm</link></entry>
</list>
</p>

<ss1>
<st>
General references</st>
<p>

<list>
<entry level="1" type="bullet">

  <cite style="font-style:normal">T. Fawcett&#32;(2004). "<weblink xlink:type="simple" xlink:href="http://home.comcast.net/~tom.fawcett/public_html/papers/ROC101.pdf">
ROC Graphs: Notes and Practical Considerations for Researchers</weblink>".&#32;<it>Technical report</it>, Palo Alto, USA:&#32;HP Laboratories.</cite>&nbsp;</entry>
</list>
</p>

</ss1>
</sec>
<sec>
<st>
Further reading</st>
<p>

<list>
<entry level="1" type="bullet">

 Balakrishnan, N., <it>Handbook of the Logistic Distribution</it>, Marcel Dekker, Inc., 1991, ISBN-13: 978-0824785871.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 Gonen M., <it>Analyzing Receiver Operating Characteristic Curves Using SAS</it>, SAS Press, 2007, ISBN: 978-1-59994-298-1.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 Green, William H., <it>Econometric Analysis</it>, fifth edition, Prentice Hall, 2003, ISBN 0-13-066189-9.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 Hosmer, David W. and Stanley Lemeshow, <it>Applied Logistic Regression</it>, 2nd ed., New York; Chichester, Wiley, 2000, ISBN 0-471-35632-8.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 Lasko, T. A., J.G. Bhagwat, K.H. Zou and L. Ohno-Machado (Oct. 2005). The use of receiver operating characteristic curves in biomedical informatics. <it>Journal of Biomedical Informatics</it> 38(5):404-415. PMID 16198999</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 Mason, S. J. and N.E. Graham, Areas beneath the relative operating characteristics (ROC) and relative operating levels (ROL) curves: Statistical significance and interpretation. <it>Q.J.R. Meteorol. Soc.</it> (2002), 128, pp. 2145–2166.</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 Pepe, M. S. (2003). <it>The statistical evaluation of medical tests for classification and prediction</it>. Oxford. ISBN  0198565828</entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 Stephan, Carsten, Sebastian Wesseling, Tania Schink, and Klaus Jung. Comparison of Eight Computer Programs for Receiver-Operating Characteristic Analysis. Clin. Chem., Mar 2003; 49: 433 - 439. <weblink xlink:type="simple" xlink:href="http://www.clinchem.org/cgi/reprint/49/3/433">
http://www.clinchem.org/cgi/reprint/49/3/433</weblink></entry>
</list>
</p>
<p>

<list>
<entry level="1" type="bullet">

 Swets, J.A. (1995).  <it>Signal detection theory and ROC analysis in psychology and diagnostics: Collected papers.</it> Lawrence Erlbaum Associates.</entry>
</list>
</p>

</sec>
<sec>
<st>
 External links </st>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://gim.unmc.edu/dxtests/roc2.htm">
A simple example of a ROC curve</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.csee.usf.edu/~candamo/site/papers/ROCintro.pdf">
An introduction to ROC analysis</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www-psych.stanford.edu/~lera/psych115s/notes/signal/">
A more thorough treatment of ROC curves and signal detection theory</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.medcalc.be/calc/diagnostic_test.php">
Diagnostic test evaluation - online calculator</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.spl.harvard.edu/archive/spl-pre2007/pages/ppl/zou/roc.html">
Kelly H. Zou's Bibliography of ROC Literature and Articles</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://home.comcast.net/~tom.fawcett/public_html/ROCCH/index.html">
Tom Fawcett's ROC Convex Hull: tutorial, program and papers</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.cs.bris.ac.uk/~flach/ICML04tutorial/index.html">
Peter Flach's tutorial on ROC analysis in machine learning</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.anaesthetist.com/mnm/stats/roc/">
The magnificent ROC</weblink> — An explanation and interactive demonstration of the connection of ROCs to archetypal bi-normal test result plots </entry>
</list>
</p>

<ss1>
<st>
Software</st>
<p>

<list>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.mskcc.org/mskcc/html/84563.cfm">
SAS and R code for ROC curves</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.clinchem.org/cgi/content/full/49/3/433">
Comparison of Eight Computer Programs for Receiver-Operating Characteristic Analysis, Clinical Chemistry. 2003;49:433-439</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://protein.bio.puc.cl/star.html">
StAR, a software for the statistical comparison of ROC curves</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://rocr.bioinf.mpi-sb.mpg.de">
ROCR, a comprehensive R package for evaluating scoring classifiers</weblink> (<weblink xlink:type="simple" xlink:href="http://bioinformatics.oxfordjournals.org/cgi/content/full/21/20/3940">
Introductory article</weblink>)</entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://epiweb.massey.ac.nz/ROC_analysis_software.htm">
List of ROC analysis software</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://bioconductor.org/packages/1.9/bioc/html/ROC.html">
ROC package for R (part of the BioConductor suite)</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.acm.org/sigs/sigkdd/kddcup/index.php?section=2004&amp;method=soft">
Standalone PERF program used by the KDD Cup competition</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.rad.jhmi.edu/jeng/javarad/roc/JROCFITi.html">
Web-based calculator of ROC curves from user-supplied data</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.cs.bris.ac.uk/Research/MachineLearning/rocon/index.html">
ROC curve visualiser</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.analyse-it.com/method_evaluation/roc.aspx">
Analyse-it ROC software</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.gepsoft.com/LogisticRegression/Section03.htm">
GeneXproTools ROC Analysis</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.pinel.qc.ca/GeneralList.aspx?nav_id=2984&amp;lang_id=E">
ROCTools ROC software</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://theoval.sys.uea.ac.uk/~gcc/matlab/#roc">
ROC Curve Tools, m-files for MATLAB, written by Dr. Gavin C. Cawley</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://www.medcalc.be/">
MedCalc software</weblink></entry>
<entry level="1" type="bullet">

 <weblink xlink:type="simple" xlink:href="http://pages.cs.wisc.edu/~richm/programs/AUC/">
AUCCalculator, a Java program for finding AUC-ROC by Jesse Davis and Mark Goadrich</weblink></entry>
</list>
</p>


</ss1>
</sec>
</bdy>
</entity>
</article>
