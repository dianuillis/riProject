<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 23:46:39[mciao0825] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<know-how  confidence="0.8" wordnetid="105616786">
<method  confidence="0.8" wordnetid="105660268">
<header>
<title>Gittins index</title>
<id>9267447</id>
<revision>
<id>239747023</id>
<timestamp>2008-09-20T07:40:07Z</timestamp>
<contributor>
<username>LachlanA</username>
<id>1559980</id>
</contributor>
</revision>
<categories>
<category>Sequential methods</category>
<category>Experimental design</category>
<category>Machine learning</category>
<category>Decision theory</category>
</categories>
</header>
<bdy>

In machine learning theory, the <b>Gittins index</b> is commonly related to the classic <link xlink:type="simple" xlink:href="../828/2854828.xml">
two armed bandit</link> problem. A two-armed bandit is a <link xlink:type="simple" xlink:href="../229/29229.xml">
slot machine</link> with two levers, each with a (possibly) different probability of payoff.  The objective is to play the arms, one at a time, in any order, so as to maximise the expected discounted earnings. The critical factors are that the player doesn't know the probabilities of either arms to begin with, and can only gain knowledge of the probabilities by actually playing the machine. <p>

In simple terms, the value of the probability that a player will be indifferent to playing only one of the arms forever (given a known probability for that arm), as opposed to at least trying the other arm, with the option of switching at some future time and continuing with that arm forever, is the value of the Gittins index. </p>
<p>

A good example might be attempting to pick which of two emerging technologies is likely to be successful in the long run. Each technology improves through learning, which can imply that the technology that has a head start may appear superior initially. The <link xlink:type="simple" xlink:href="../337/322337.xml">
learning curve</link> may reinforce the perception of superiority despite the fact that a technology turns out to be inferior in the long run &mdash; compare <link xlink:type="simple" xlink:href="../578/188578.xml">
beta</link> versus <message wordnetid="106598915" confidence="0.8">
<information wordnetid="106634376" confidence="0.8">
<hallmark wordnetid="104732543" confidence="0.8">
<format wordnetid="106636806" confidence="0.8">
<characteristic wordnetid="104731497" confidence="0.8">
<link xlink:type="simple" xlink:href="../124/52124.xml">
VHS</link></characteristic>
</format>
</hallmark>
</information>
</message>
 video formats. Only through implementing both technologies can the true answer be known. </p>

<sec>
<st>
 References </st>
<p>

<list>
<entry level="1" type="bullet">

J. C. Gittins, <it><weblink xlink:type="simple" xlink:href="http://links.jstor.org/sici?sici=0035-9246%281979%2941%3A2%3C148%3ABPADAI%3E2.0.CO%3B2-0">
Bandit Processes and Dynamic Allocation Indices</weblink></it>, <periodical wordnetid="106593296" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../143/13327143.xml">
Journal of the Royal Statistical Society</link></periodical>
. Series B (Methodological), Vol. 41, No. 2. (1979), pp. 148-177. </entry>
<entry level="1" type="bullet">

J. C. Gittins, D. M. Jones, <it><weblink xlink:type="simple" xlink:href="http://links.jstor.org/sici?sici=0006-3444(197912)66%3A3%3C561%3AADAIFT%3E2.0.CO%3B2-H">
A Dynamic Allocation Index for the Discounted Multiarmed Bandit Problem</weblink></it>, <periodical wordnetid="106593296" confidence="0.9508927676800064">
<link xlink:type="simple" xlink:href="../178/1734178.xml">
Biometrika</link></periodical>
, Vol 66, No. 3. (1979), pp. 561-565.</entry>
<entry level="1" type="bullet">

Cowan, R. <it><weblink xlink:type="simple" xlink:href="http://links.jstor.org/sici?sici=0013-0133(199107)101%3A407%3C801%3ATAHCAT%3E2.0.CO%3B2-S">
Tortoises and Hares: Choice among technologies of unknown merit</weblink>''</it></entry>
</list>
</p>

</sec>
</bdy>
</method>
</know-how>
</article>
