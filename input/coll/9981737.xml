<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 23:58:44[mciao0828] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Scoring algorithm</title>
<id>9981737</id>
<revision>
<id>215532981</id>
<timestamp>2008-05-28T16:55:12Z</timestamp>
<contributor>
<username>Melcombe</username>
<id>4682566</id>
</contributor>
</revision>
<categories>
<category>Estimation theory</category>
</categories>
</header>
<bdy>

In <link xlink:type="simple" xlink:href="../685/26685.xml">
statistics</link>, <person wordnetid="100007846" confidence="0.9508927676800064">
<scientist wordnetid="110560637" confidence="0.9508927676800064">
<link>
Fisher's</link></scientist>
</person>
 <b>Scoring algorithm</b> is a form of <event wordnetid="100029378" confidence="0.8">
<rule wordnetid="105846932" confidence="0.8">
<act wordnetid="100030358" confidence="0.8">
<psychological_feature wordnetid="100023100" confidence="0.8">
<procedure wordnetid="101023820" confidence="0.8">
<activity wordnetid="100407535" confidence="0.8">
<algorithm wordnetid="105847438" confidence="0.8">
<link xlink:type="simple" xlink:href="../145/22145.xml">
Newton's method</link></algorithm>
</activity>
</procedure>
</psychological_feature>
</act>
</rule>
</event>
 used to solve <link xlink:type="simple" xlink:href="../806/140806.xml">
maximum likelihood</link> equations <link xlink:type="simple" xlink:href="../506/21506.xml">
numerically</link>.

<sec>
<st>
Sketch of Derivation</st>
<p>

Let <math>Y_1,\ldots,Y_n</math> be <link xlink:type="simple" xlink:href="../685/25685.xml">
random variable</link>s, independent and identically distributed with twice differentiable <idea wordnetid="105833840" confidence="0.8">
<concept wordnetid="105835747" confidence="0.8">
<link xlink:type="simple" xlink:href="../487/43487.xml">
p.d.f.</link></concept>
</idea>
 <math>f(y; \theta)</math>, and we wish to calculate the <link xlink:type="simple" xlink:href="../806/140806.xml">
maximum likelihood estimator</link> (M.L.E.) <math>\theta^*</math> of <math>\theta</math>.  First, suppose we have a starting point for our algorithm <math>\theta_0</math>, and consider a <mathematical_relation wordnetid="113783581" confidence="0.8">
<function wordnetid="113783816" confidence="0.8">
<link>
Taylor expansion</link></function>
</mathematical_relation>
 of the <link>
score function</link>, <math>V(\theta)</math>, about <math>\theta_0</math>:</p>
<p>

<indent level="1">

 <math>V(\theta) \approx V(\theta_0) - \mathcal{J}(\theta_0)(\theta - \theta_0)</math>,
</indent>

where </p>
<p>

<indent level="1">

 <math>\mathcal{J}(\theta_0) = - \sum_{i=1}^n \left. \nabla \nabla^{\top} \right|_{\theta=\theta_0} \log f(Y_i ; \theta)</math>
</indent>

is the <link>
observed information matrix</link> at <math>\theta_0</math>.  Now, setting <math>\theta = \theta^*</math>, using that <math>V(\theta^*) = 0</math> and rearranging gives us:</p>
<p>

<indent level="1">

 <math>\theta^* = \theta_{0} + \mathcal{J}^{-1}(\theta_{0})V(\theta_{0})</math>.
</indent>

We therefore use the algorithm</p>
<p>

<indent level="1">

 <math>\theta_{m+1} = \theta_{m} + \mathcal{J}^{-1}(\theta_{m})V(\theta_{m})</math>,
</indent>

and under certain regularity conditions, it can be shown that <math>\theta_m \rightarrow \theta^*</math>.</p>

</sec>
<sec>
<st>
Fisher Scoring</st>

<p>

In practice, <math>\mathcal{J}(\theta)</math> is usually replaced by <math>\mathcal{I}(\theta)= \mathrm{E}[J(\theta)]</math>, the <link xlink:type="simple" xlink:href="../971/598971.xml">
Fisher information</link>, thus giving us the <b>Fisher Scoring Algorithm</b>:</p>
<p>

<indent level="1">

 <math>\theta_{m+1} = \theta_{m} + \mathcal{I}^{-1}(\theta_{m})V(\theta_{m})</math>.
</indent>
</p>

</sec>
<sec>
<st>
References</st>
<p>


</p>

</sec>
</bdy>
</article>
